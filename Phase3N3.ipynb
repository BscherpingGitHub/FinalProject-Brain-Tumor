{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  1.6  171.8 ...  8.9  0.9  0.0]\n",
      " [ 1.0  8.4  1043.9 ...  5.3  1.0  0.0]\n",
      " [ 0.0  11.7  602.2 ...  3.4  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  8.8  660.2 ...  3.9  1.0  0.0]\n",
      " [ 1.0  19.9  1237.7 ...  5.1  1.0  0.0]\n",
      " [ 0.0  15.7  809.8 ...  4.0  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 11ms/step - loss: 77.3976 - accuracy: 0.4400 - val_loss: 48.5605 - val_accuracy: 0.4326\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 24.1944 - accuracy: 0.4347 - val_loss: 7.9691 - val_accuracy: 0.4362\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 3.3220 - accuracy: 0.4484 - val_loss: 0.6828 - val_accuracy: 0.5275\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6730 - accuracy: 0.5687 - val_loss: 0.6907 - val_accuracy: 0.5115\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.5850 - val_loss: 0.6765 - val_accuracy: 0.5576\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.6002 - val_loss: 0.6838 - val_accuracy: 0.5319\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.5995 - val_loss: 0.6633 - val_accuracy: 0.6294\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6648 - accuracy: 0.6074 - val_loss: 0.6716 - val_accuracy: 0.6321\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6619 - accuracy: 0.6230 - val_loss: 0.6918 - val_accuracy: 0.5567\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.6245 - val_loss: 0.6700 - val_accuracy: 0.5638\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6249 - val_loss: 0.6795 - val_accuracy: 0.5585\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6552 - accuracy: 0.6264 - val_loss: 0.6633 - val_accuracy: 0.6020\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6344 - val_loss: 0.6474 - val_accuracy: 0.6285\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6390 - val_loss: 0.6430 - val_accuracy: 0.6498\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.6390 - val_loss: 0.6430 - val_accuracy: 0.6206\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.6503 - val_loss: 0.6393 - val_accuracy: 0.6303\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.6511 - val_loss: 0.6376 - val_accuracy: 0.6383\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.6663 - val_loss: 0.6262 - val_accuracy: 0.6782\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6120 - accuracy: 0.6807 - val_loss: 0.6139 - val_accuracy: 0.6915\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.7046 - val_loss: 0.5822 - val_accuracy: 0.7207\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5630 - accuracy: 0.7491 - val_loss: 0.5427 - val_accuracy: 0.7677\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.8007 - val_loss: 0.4907 - val_accuracy: 0.8209\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.8432 - val_loss: 0.4566 - val_accuracy: 0.8564\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8679 - val_loss: 0.4330 - val_accuracy: 0.8759\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8740 - val_loss: 0.4254 - val_accuracy: 0.8768\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8732 - val_loss: 0.4176 - val_accuracy: 0.8785\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8766 - val_loss: 0.4148 - val_accuracy: 0.8821\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8762 - val_loss: 0.4104 - val_accuracy: 0.8830\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8736 - val_loss: 0.4243 - val_accuracy: 0.8652\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8732 - val_loss: 0.4004 - val_accuracy: 0.8785\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8762 - val_loss: 0.4096 - val_accuracy: 0.8750\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4061 - accuracy: 0.8789 - val_loss: 0.4141 - val_accuracy: 0.8741\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8781 - val_loss: 0.3956 - val_accuracy: 0.8821\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8740 - val_loss: 0.3879 - val_accuracy: 0.8759\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8747 - val_loss: 0.3935 - val_accuracy: 0.8839\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8762 - val_loss: 0.3948 - val_accuracy: 0.8759\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8789 - val_loss: 0.3794 - val_accuracy: 0.8803\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8759 - val_loss: 0.3830 - val_accuracy: 0.8741\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8732 - val_loss: 0.3828 - val_accuracy: 0.8865\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8785 - val_loss: 0.3740 - val_accuracy: 0.8794\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8804 - val_loss: 0.3690 - val_accuracy: 0.8865\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8800 - val_loss: 0.3733 - val_accuracy: 0.8892\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8736 - val_loss: 0.3655 - val_accuracy: 0.8839\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8812 - val_loss: 0.3697 - val_accuracy: 0.8812\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8785 - val_loss: 0.3685 - val_accuracy: 0.8794\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8774 - val_loss: 0.3713 - val_accuracy: 0.8794\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8781 - val_loss: 0.3731 - val_accuracy: 0.8874\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.8804 - val_loss: 0.3729 - val_accuracy: 0.8910\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8797 - val_loss: 0.3573 - val_accuracy: 0.8901\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8823 - val_loss: 0.3571 - val_accuracy: 0.8839\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8808 - val_loss: 0.3525 - val_accuracy: 0.8936\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8812 - val_loss: 0.3499 - val_accuracy: 0.8918\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8827 - val_loss: 0.3568 - val_accuracy: 0.8945\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3661 - accuracy: 0.8785 - val_loss: 0.3529 - val_accuracy: 0.8848\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3627 - accuracy: 0.8838 - val_loss: 0.3491 - val_accuracy: 0.8945\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8853 - val_loss: 0.3444 - val_accuracy: 0.8910\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3612 - accuracy: 0.8797 - val_loss: 0.3446 - val_accuracy: 0.8927\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3591 - accuracy: 0.8797 - val_loss: 0.3593 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8827 - val_loss: 0.3403 - val_accuracy: 0.8945\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8869 - val_loss: 0.3387 - val_accuracy: 0.8945\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.8850 - val_loss: 0.3483 - val_accuracy: 0.8954\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3553 - accuracy: 0.8872 - val_loss: 0.3383 - val_accuracy: 0.8963\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3546 - accuracy: 0.8857 - val_loss: 0.3360 - val_accuracy: 0.8972\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3521 - accuracy: 0.8872 - val_loss: 0.3367 - val_accuracy: 0.8972\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3532 - accuracy: 0.8884 - val_loss: 0.3371 - val_accuracy: 0.8936\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3502 - accuracy: 0.8884 - val_loss: 0.3379 - val_accuracy: 0.8963\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3474 - accuracy: 0.8918 - val_loss: 0.3531 - val_accuracy: 0.8777\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3497 - accuracy: 0.8872 - val_loss: 0.3459 - val_accuracy: 0.8839\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3470 - accuracy: 0.8899 - val_loss: 0.3280 - val_accuracy: 0.8980\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3444 - accuracy: 0.8884 - val_loss: 0.3381 - val_accuracy: 0.8901\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3431 - accuracy: 0.8907 - val_loss: 0.3260 - val_accuracy: 0.8998\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3450 - accuracy: 0.8903 - val_loss: 0.3296 - val_accuracy: 0.9007\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3422 - accuracy: 0.8914 - val_loss: 0.3335 - val_accuracy: 0.9025\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3402 - accuracy: 0.8929 - val_loss: 0.3277 - val_accuracy: 0.9025\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8880 - val_loss: 0.3222 - val_accuracy: 0.9007\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8857 - val_loss: 0.3180 - val_accuracy: 0.9025\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8918 - val_loss: 0.3168 - val_accuracy: 0.9025\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8910 - val_loss: 0.3196 - val_accuracy: 0.9007\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8975 - val_loss: 0.3220 - val_accuracy: 0.8980\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8952 - val_loss: 0.3158 - val_accuracy: 0.9051\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8975 - val_loss: 0.3153 - val_accuracy: 0.9069\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8929 - val_loss: 0.3123 - val_accuracy: 0.9025\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3263 - accuracy: 0.8941 - val_loss: 0.3226 - val_accuracy: 0.8963\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8952 - val_loss: 0.3107 - val_accuracy: 0.9051\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3252 - accuracy: 0.8983 - val_loss: 0.3198 - val_accuracy: 0.8936\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3255 - accuracy: 0.8964 - val_loss: 0.3125 - val_accuracy: 0.9069\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3231 - accuracy: 0.8979 - val_loss: 0.3057 - val_accuracy: 0.9043\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.8967 - val_loss: 0.3091 - val_accuracy: 0.9034\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3199 - accuracy: 0.9009 - val_loss: 0.3006 - val_accuracy: 0.9087\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8983 - val_loss: 0.3026 - val_accuracy: 0.9122\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3150 - accuracy: 0.8990 - val_loss: 0.3427 - val_accuracy: 0.8989\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3160 - accuracy: 0.9009 - val_loss: 0.3079 - val_accuracy: 0.9016\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3159 - accuracy: 0.9028 - val_loss: 0.2963 - val_accuracy: 0.9113\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3142 - accuracy: 0.8998 - val_loss: 0.3038 - val_accuracy: 0.9069\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3120 - accuracy: 0.9024 - val_loss: 0.2921 - val_accuracy: 0.9122\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3095 - accuracy: 0.9017 - val_loss: 0.2931 - val_accuracy: 0.9113\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3086 - accuracy: 0.9005 - val_loss: 0.3007 - val_accuracy: 0.9025\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3074 - accuracy: 0.9043 - val_loss: 0.2926 - val_accuracy: 0.9122\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3070 - accuracy: 0.9047 - val_loss: 0.2877 - val_accuracy: 0.9131\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3055 - accuracy: 0.9028 - val_loss: 0.2950 - val_accuracy: 0.9096\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3034 - accuracy: 0.9051 - val_loss: 0.2889 - val_accuracy: 0.9060\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2991 - accuracy: 0.9062 - val_loss: 0.2839 - val_accuracy: 0.9105\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2995 - accuracy: 0.9093 - val_loss: 0.2924 - val_accuracy: 0.9105\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2990 - accuracy: 0.9058 - val_loss: 0.2835 - val_accuracy: 0.9167\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2997 - accuracy: 0.9047 - val_loss: 0.2802 - val_accuracy: 0.9131\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2938 - accuracy: 0.9089 - val_loss: 0.3081 - val_accuracy: 0.9096\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2947 - accuracy: 0.9085 - val_loss: 0.2860 - val_accuracy: 0.9087\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.9085 - val_loss: 0.2743 - val_accuracy: 0.9113\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.9115 - val_loss: 0.2776 - val_accuracy: 0.9176\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2902 - accuracy: 0.9096 - val_loss: 0.2863 - val_accuracy: 0.9096\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.9077 - val_loss: 0.2820 - val_accuracy: 0.9140\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.9100 - val_loss: 0.2683 - val_accuracy: 0.9131\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.9108 - val_loss: 0.2724 - val_accuracy: 0.9113\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2818 - accuracy: 0.9100 - val_loss: 0.3109 - val_accuracy: 0.8936\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2821 - accuracy: 0.9108 - val_loss: 0.2651 - val_accuracy: 0.9184\n",
      "Epoch 116/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2779 - accuracy: 0.9115 - val_loss: 0.2788 - val_accuracy: 0.9131\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.9119 - val_loss: 0.2864 - val_accuracy: 0.9096\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2746 - accuracy: 0.9115 - val_loss: 0.2682 - val_accuracy: 0.9193\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.9131 - val_loss: 0.2618 - val_accuracy: 0.9158\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.9176 - val_loss: 0.2957 - val_accuracy: 0.9016\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.9146 - val_loss: 0.2580 - val_accuracy: 0.9158\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2675 - accuracy: 0.9188 - val_loss: 0.2595 - val_accuracy: 0.9158\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2649 - accuracy: 0.9176 - val_loss: 0.2509 - val_accuracy: 0.9193\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.9150 - val_loss: 0.2575 - val_accuracy: 0.9238\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.9191 - val_loss: 0.2501 - val_accuracy: 0.9193\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9195 - val_loss: 0.2478 - val_accuracy: 0.9184\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.9165 - val_loss: 0.2733 - val_accuracy: 0.9149\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2596 - accuracy: 0.9195 - val_loss: 0.2443 - val_accuracy: 0.9193\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.9226 - val_loss: 0.2477 - val_accuracy: 0.9202\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2521 - accuracy: 0.9237 - val_loss: 0.2502 - val_accuracy: 0.9220\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2505 - accuracy: 0.9203 - val_loss: 0.2374 - val_accuracy: 0.9246\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.9195 - val_loss: 0.2443 - val_accuracy: 0.9220\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2487 - accuracy: 0.9214 - val_loss: 0.2394 - val_accuracy: 0.9238\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2437 - accuracy: 0.9237 - val_loss: 0.2331 - val_accuracy: 0.9229\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2435 - accuracy: 0.9222 - val_loss: 0.2442 - val_accuracy: 0.9246\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.9241 - val_loss: 0.2337 - val_accuracy: 0.9238\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9222 - val_loss: 0.2267 - val_accuracy: 0.9246\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2387 - accuracy: 0.9229 - val_loss: 0.2277 - val_accuracy: 0.9273\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9267 - val_loss: 0.2321 - val_accuracy: 0.9264\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9252 - val_loss: 0.2393 - val_accuracy: 0.9255\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2313 - accuracy: 0.9275 - val_loss: 0.2203 - val_accuracy: 0.9291\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.9241 - val_loss: 0.2211 - val_accuracy: 0.9264\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2276 - accuracy: 0.9252 - val_loss: 0.2166 - val_accuracy: 0.9309\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9290 - val_loss: 0.2219 - val_accuracy: 0.9300\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9263 - val_loss: 0.2166 - val_accuracy: 0.9282\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9298 - val_loss: 0.2112 - val_accuracy: 0.9335\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2183 - accuracy: 0.9317 - val_loss: 0.2117 - val_accuracy: 0.9309\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2176 - accuracy: 0.9305 - val_loss: 0.2108 - val_accuracy: 0.9326\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9286 - val_loss: 0.2199 - val_accuracy: 0.9344\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2131 - accuracy: 0.9313 - val_loss: 0.2227 - val_accuracy: 0.9309\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2121 - accuracy: 0.9298 - val_loss: 0.2036 - val_accuracy: 0.9353\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2107 - accuracy: 0.9309 - val_loss: 0.2027 - val_accuracy: 0.9362\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2072 - accuracy: 0.9336 - val_loss: 0.2222 - val_accuracy: 0.9309\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9313 - val_loss: 0.2018 - val_accuracy: 0.9397\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9320 - val_loss: 0.2042 - val_accuracy: 0.9317\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.9332 - val_loss: 0.2292 - val_accuracy: 0.9255\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2021 - accuracy: 0.9347 - val_loss: 0.1968 - val_accuracy: 0.9362\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9358 - val_loss: 0.1958 - val_accuracy: 0.9406\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9366 - val_loss: 0.1917 - val_accuracy: 0.9371\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1955 - accuracy: 0.9332 - val_loss: 0.2168 - val_accuracy: 0.9264\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1922 - accuracy: 0.9347 - val_loss: 0.1901 - val_accuracy: 0.9362\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1912 - accuracy: 0.9355 - val_loss: 0.1897 - val_accuracy: 0.9362\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1910 - accuracy: 0.9362 - val_loss: 0.1933 - val_accuracy: 0.9326\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9347 - val_loss: 0.2123 - val_accuracy: 0.9273\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9355 - val_loss: 0.2106 - val_accuracy: 0.9317\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1891 - accuracy: 0.9362 - val_loss: 0.1996 - val_accuracy: 0.9344\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1836 - accuracy: 0.9366 - val_loss: 0.1828 - val_accuracy: 0.9397\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1813 - accuracy: 0.9389 - val_loss: 0.1839 - val_accuracy: 0.9388\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1802 - accuracy: 0.9389 - val_loss: 0.2117 - val_accuracy: 0.9255\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1835 - accuracy: 0.9377 - val_loss: 0.1818 - val_accuracy: 0.9379\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9400 - val_loss: 0.2278 - val_accuracy: 0.9255\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9385 - val_loss: 0.2036 - val_accuracy: 0.9273\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.9366 - val_loss: 0.1839 - val_accuracy: 0.9406\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1742 - accuracy: 0.9404 - val_loss: 0.1802 - val_accuracy: 0.9362\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9381 - val_loss: 0.1856 - val_accuracy: 0.9362\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1723 - accuracy: 0.9408 - val_loss: 0.1820 - val_accuracy: 0.9371\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9412 - val_loss: 0.1861 - val_accuracy: 0.9406\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1691 - accuracy: 0.9404 - val_loss: 0.1812 - val_accuracy: 0.9371\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1662 - accuracy: 0.9457 - val_loss: 0.2061 - val_accuracy: 0.9273\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1705 - accuracy: 0.9423 - val_loss: 0.1693 - val_accuracy: 0.9397\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9419 - val_loss: 0.1978 - val_accuracy: 0.9317\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9400 - val_loss: 0.1717 - val_accuracy: 0.9424\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9423 - val_loss: 0.1680 - val_accuracy: 0.9433\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9465 - val_loss: 0.1733 - val_accuracy: 0.9388\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9434 - val_loss: 0.2491 - val_accuracy: 0.9113\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9408 - val_loss: 0.1976 - val_accuracy: 0.9309\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1625 - accuracy: 0.9461 - val_loss: 0.1696 - val_accuracy: 0.9406\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1654 - accuracy: 0.9431 - val_loss: 0.1977 - val_accuracy: 0.9264\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9480 - val_loss: 0.2027 - val_accuracy: 0.9326\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9487 - val_loss: 0.1629 - val_accuracy: 0.9441\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.9438 - val_loss: 0.1619 - val_accuracy: 0.9415\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9438 - val_loss: 0.1644 - val_accuracy: 0.9433\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1586 - accuracy: 0.9450 - val_loss: 0.1593 - val_accuracy: 0.9468\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.9431 - val_loss: 0.1695 - val_accuracy: 0.9433\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9457 - val_loss: 0.2747 - val_accuracy: 0.9051\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9465 - val_loss: 0.1590 - val_accuracy: 0.9468\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 0.9434 - val_loss: 0.1558 - val_accuracy: 0.9486\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.9438 - val_loss: 0.1539 - val_accuracy: 0.9512\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1528 - accuracy: 0.9419 - val_loss: 0.1567 - val_accuracy: 0.9459\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9476 - val_loss: 0.1604 - val_accuracy: 0.9433\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9472 - val_loss: 0.1556 - val_accuracy: 0.9441\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9453 - val_loss: 0.1611 - val_accuracy: 0.9450\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9457 - val_loss: 0.1577 - val_accuracy: 0.9450\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9472 - val_loss: 0.1516 - val_accuracy: 0.9477\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1467 - accuracy: 0.9461 - val_loss: 0.1611 - val_accuracy: 0.9459\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9499 - val_loss: 0.1494 - val_accuracy: 0.9424\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.9499 - val_loss: 0.1838 - val_accuracy: 0.9371\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1475 - accuracy: 0.9461 - val_loss: 0.1530 - val_accuracy: 0.9459\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9491 - val_loss: 0.1544 - val_accuracy: 0.9441\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9487 - val_loss: 0.2380 - val_accuracy: 0.9176\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1419 - accuracy: 0.9522 - val_loss: 0.1478 - val_accuracy: 0.9530\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1386 - accuracy: 0.9506 - val_loss: 0.1767 - val_accuracy: 0.9388\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1376 - accuracy: 0.9487 - val_loss: 0.1443 - val_accuracy: 0.9486\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9491 - val_loss: 0.1530 - val_accuracy: 0.9441\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1392 - accuracy: 0.9487 - val_loss: 0.1447 - val_accuracy: 0.9468\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.9499 - val_loss: 0.2199 - val_accuracy: 0.9229\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9506 - val_loss: 0.1769 - val_accuracy: 0.9326\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9484 - val_loss: 0.1442 - val_accuracy: 0.9566\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9487 - val_loss: 0.1420 - val_accuracy: 0.9486\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9506 - val_loss: 0.1697 - val_accuracy: 0.9415\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.9495 - val_loss: 0.1444 - val_accuracy: 0.9557\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9525 - val_loss: 0.1565 - val_accuracy: 0.9406\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1342 - accuracy: 0.9525 - val_loss: 0.1532 - val_accuracy: 0.9441\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9514 - val_loss: 0.1832 - val_accuracy: 0.9300\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9522 - val_loss: 0.1393 - val_accuracy: 0.9566\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 0.9548 - val_loss: 0.1461 - val_accuracy: 0.9477\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9491 - val_loss: 0.1387 - val_accuracy: 0.9521\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1307 - accuracy: 0.9586 - val_loss: 0.1955 - val_accuracy: 0.9335\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1317 - accuracy: 0.9510 - val_loss: 0.1444 - val_accuracy: 0.9468\n",
      "Epoch 230/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1365 - accuracy: 0.9533 - val_loss: 0.1547 - val_accuracy: 0.9424\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9518 - val_loss: 0.1450 - val_accuracy: 0.9477\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9544 - val_loss: 0.1368 - val_accuracy: 0.9512\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9548 - val_loss: 0.1772 - val_accuracy: 0.9371\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1296 - accuracy: 0.9537 - val_loss: 0.1487 - val_accuracy: 0.9459\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1300 - accuracy: 0.9537 - val_loss: 0.1367 - val_accuracy: 0.9557\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1315 - accuracy: 0.9480 - val_loss: 0.1628 - val_accuracy: 0.9397\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1271 - accuracy: 0.9556 - val_loss: 0.1350 - val_accuracy: 0.9512\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9556 - val_loss: 0.1402 - val_accuracy: 0.9486\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1282 - accuracy: 0.9563 - val_loss: 0.2244 - val_accuracy: 0.9229\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9529 - val_loss: 0.1483 - val_accuracy: 0.9450\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9544 - val_loss: 0.1848 - val_accuracy: 0.9388\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1285 - accuracy: 0.9541 - val_loss: 0.1351 - val_accuracy: 0.9539\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1278 - accuracy: 0.9525 - val_loss: 0.1388 - val_accuracy: 0.9548\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1279 - accuracy: 0.9544 - val_loss: 0.1476 - val_accuracy: 0.9459\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9548 - val_loss: 0.1324 - val_accuracy: 0.9530\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1216 - accuracy: 0.9537 - val_loss: 0.1749 - val_accuracy: 0.9371\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9567 - val_loss: 0.1296 - val_accuracy: 0.9583\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.9582 - val_loss: 0.1284 - val_accuracy: 0.9539\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.9560 - val_loss: 0.1284 - val_accuracy: 0.9548\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9563 - val_loss: 0.1586 - val_accuracy: 0.9450\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.9590 - val_loss: 0.1312 - val_accuracy: 0.9557\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9525 - val_loss: 0.1324 - val_accuracy: 0.9557\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9560 - val_loss: 0.1322 - val_accuracy: 0.9539\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1223 - accuracy: 0.9586 - val_loss: 0.1264 - val_accuracy: 0.9548\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1233 - accuracy: 0.9563 - val_loss: 0.1302 - val_accuracy: 0.9548\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9560 - val_loss: 0.1731 - val_accuracy: 0.9406\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9563 - val_loss: 0.1357 - val_accuracy: 0.9539\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9567 - val_loss: 0.1739 - val_accuracy: 0.9379\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9613 - val_loss: 0.1666 - val_accuracy: 0.9424\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.9590 - val_loss: 0.1930 - val_accuracy: 0.9344\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.9575 - val_loss: 0.1432 - val_accuracy: 0.9459\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.9586 - val_loss: 0.1810 - val_accuracy: 0.9379\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9582 - val_loss: 0.1547 - val_accuracy: 0.9459\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9609 - val_loss: 0.1276 - val_accuracy: 0.9601\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9613 - val_loss: 0.1493 - val_accuracy: 0.9459\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9594 - val_loss: 0.1758 - val_accuracy: 0.9406\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9567 - val_loss: 0.2386 - val_accuracy: 0.9193\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9620 - val_loss: 0.1625 - val_accuracy: 0.9424\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1131 - accuracy: 0.9601 - val_loss: 0.1222 - val_accuracy: 0.9566\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9598 - val_loss: 0.1351 - val_accuracy: 0.9548\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.9563 - val_loss: 0.1270 - val_accuracy: 0.9574\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.1434 - val_accuracy: 0.9548\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9609 - val_loss: 0.1590 - val_accuracy: 0.9450\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9598 - val_loss: 0.1221 - val_accuracy: 0.9583\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9594 - val_loss: 0.1273 - val_accuracy: 0.9583\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9598 - val_loss: 0.2250 - val_accuracy: 0.9220\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9613 - val_loss: 0.1182 - val_accuracy: 0.9601\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9594 - val_loss: 0.1208 - val_accuracy: 0.9592\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9632 - val_loss: 0.1317 - val_accuracy: 0.9566\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9613 - val_loss: 0.1893 - val_accuracy: 0.9353\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9620 - val_loss: 0.1179 - val_accuracy: 0.9601\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9632 - val_loss: 0.1768 - val_accuracy: 0.9415\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.9613 - val_loss: 0.1224 - val_accuracy: 0.9601\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1119 - accuracy: 0.9620 - val_loss: 0.1170 - val_accuracy: 0.9610\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9651 - val_loss: 0.1312 - val_accuracy: 0.9566\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1124 - accuracy: 0.9620 - val_loss: 0.1346 - val_accuracy: 0.9530\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9620 - val_loss: 0.1359 - val_accuracy: 0.9539\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1122 - accuracy: 0.9651 - val_loss: 0.1141 - val_accuracy: 0.9583\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9601 - val_loss: 0.1213 - val_accuracy: 0.9574\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1142 - accuracy: 0.9636 - val_loss: 0.1619 - val_accuracy: 0.9433\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1119 - accuracy: 0.9628 - val_loss: 0.1526 - val_accuracy: 0.9459\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1104 - accuracy: 0.9674 - val_loss: 0.1278 - val_accuracy: 0.9574\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1106 - accuracy: 0.9658 - val_loss: 0.1137 - val_accuracy: 0.9628\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9651 - val_loss: 0.1263 - val_accuracy: 0.9592\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9662 - val_loss: 0.1285 - val_accuracy: 0.9592\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9609 - val_loss: 0.1161 - val_accuracy: 0.9610\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1108 - accuracy: 0.9609 - val_loss: 0.1178 - val_accuracy: 0.9610\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 0.9628 - val_loss: 0.1464 - val_accuracy: 0.9486\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.9666 - val_loss: 0.1126 - val_accuracy: 0.9637\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1129 - accuracy: 0.9643 - val_loss: 0.1275 - val_accuracy: 0.9583\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9624 - val_loss: 0.1173 - val_accuracy: 0.9645\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9658 - val_loss: 0.1722 - val_accuracy: 0.9433\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9647 - val_loss: 0.1200 - val_accuracy: 0.9601\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.9632 - val_loss: 0.1261 - val_accuracy: 0.9592\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1146 - accuracy: 0.9598 - val_loss: 0.1130 - val_accuracy: 0.9628\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1070 - accuracy: 0.9666 - val_loss: 0.1130 - val_accuracy: 0.9628\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9620 - val_loss: 0.1493 - val_accuracy: 0.9504\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9651 - val_loss: 0.1260 - val_accuracy: 0.9574\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9643 - val_loss: 0.1776 - val_accuracy: 0.9397\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1089 - accuracy: 0.9670 - val_loss: 0.1589 - val_accuracy: 0.9450\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 0.1822 - val_accuracy: 0.9344\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9624 - val_loss: 0.1370 - val_accuracy: 0.9566\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1076 - accuracy: 0.9651 - val_loss: 0.1224 - val_accuracy: 0.9619\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.1138 - val_accuracy: 0.9610\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1060 - accuracy: 0.9651 - val_loss: 0.1119 - val_accuracy: 0.9628\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1068 - accuracy: 0.9670 - val_loss: 0.1307 - val_accuracy: 0.9566\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9639 - val_loss: 0.1641 - val_accuracy: 0.9433\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9639 - val_loss: 0.1069 - val_accuracy: 0.9663\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9643 - val_loss: 0.1818 - val_accuracy: 0.9353\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9677 - val_loss: 0.1161 - val_accuracy: 0.9601\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9692 - val_loss: 0.1299 - val_accuracy: 0.9583\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9643 - val_loss: 0.1752 - val_accuracy: 0.9362\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.9704 - val_loss: 0.1194 - val_accuracy: 0.9592\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1021 - accuracy: 0.9658 - val_loss: 0.1117 - val_accuracy: 0.9601\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1052 - accuracy: 0.9666 - val_loss: 0.1133 - val_accuracy: 0.9592\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.1026 - val_accuracy: 0.9690\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1049 - accuracy: 0.9681 - val_loss: 0.1435 - val_accuracy: 0.9539\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1033 - accuracy: 0.9647 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1006 - accuracy: 0.9628 - val_loss: 0.1058 - val_accuracy: 0.9645\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1054 - accuracy: 0.9674 - val_loss: 0.1668 - val_accuracy: 0.9459\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1038 - accuracy: 0.9685 - val_loss: 0.1054 - val_accuracy: 0.9637\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1049 - accuracy: 0.9677 - val_loss: 0.1087 - val_accuracy: 0.9610\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 0.1066 - val_accuracy: 0.9663\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0978 - accuracy: 0.9696 - val_loss: 0.1185 - val_accuracy: 0.9601\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1048 - accuracy: 0.9655 - val_loss: 0.1193 - val_accuracy: 0.9592\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0994 - accuracy: 0.9655 - val_loss: 0.1344 - val_accuracy: 0.9557\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9711 - val_loss: 0.1656 - val_accuracy: 0.9406\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9677 - val_loss: 0.1316 - val_accuracy: 0.9548\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9704 - val_loss: 0.1150 - val_accuracy: 0.9654\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1017 - accuracy: 0.9666 - val_loss: 0.1330 - val_accuracy: 0.9548\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0977 - accuracy: 0.9666 - val_loss: 0.1123 - val_accuracy: 0.9592\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9704 - val_loss: 0.1413 - val_accuracy: 0.9557\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9655 - val_loss: 0.1026 - val_accuracy: 0.9654\n",
      "Epoch 344/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9696 - val_loss: 0.1160 - val_accuracy: 0.9592\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9689 - val_loss: 0.1036 - val_accuracy: 0.9663\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9700 - val_loss: 0.1005 - val_accuracy: 0.9672\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9632 - val_loss: 0.0988 - val_accuracy: 0.9716\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9715 - val_loss: 0.1162 - val_accuracy: 0.9592\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9692 - val_loss: 0.1767 - val_accuracy: 0.9433\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9674 - val_loss: 0.0972 - val_accuracy: 0.9690\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9715 - val_loss: 0.4494 - val_accuracy: 0.8546\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9727 - val_loss: 0.0975 - val_accuracy: 0.9707\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9685 - val_loss: 0.0983 - val_accuracy: 0.9707\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.1022 - val_accuracy: 0.9699\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9689 - val_loss: 0.1937 - val_accuracy: 0.9397\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9692 - val_loss: 0.1072 - val_accuracy: 0.9672\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1012 - accuracy: 0.9704 - val_loss: 0.1032 - val_accuracy: 0.9699\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 0.0979 - val_accuracy: 0.9690\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0981 - accuracy: 0.9700 - val_loss: 0.1481 - val_accuracy: 0.9477\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9685 - val_loss: 0.1321 - val_accuracy: 0.9566\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9681 - val_loss: 0.0968 - val_accuracy: 0.9672\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.1195 - val_accuracy: 0.9592\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9689 - val_loss: 0.1162 - val_accuracy: 0.9583\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9677 - val_loss: 0.0992 - val_accuracy: 0.9716\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9692 - val_loss: 0.2678 - val_accuracy: 0.9060\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9719 - val_loss: 0.1173 - val_accuracy: 0.9592\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9674 - val_loss: 0.2039 - val_accuracy: 0.9309\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9685 - val_loss: 0.1548 - val_accuracy: 0.9424\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9719 - val_loss: 0.0904 - val_accuracy: 0.9707\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9708 - val_loss: 0.1000 - val_accuracy: 0.9645\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9704 - val_loss: 0.0983 - val_accuracy: 0.9654\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9727 - val_loss: 0.1175 - val_accuracy: 0.9601\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9708 - val_loss: 0.1341 - val_accuracy: 0.9548\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.0914 - val_accuracy: 0.9716\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9700 - val_loss: 0.0907 - val_accuracy: 0.9725\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.1212 - val_accuracy: 0.9557\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9704 - val_loss: 0.0984 - val_accuracy: 0.9716\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9704 - val_loss: 0.0999 - val_accuracy: 0.9654\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9738 - val_loss: 0.1502 - val_accuracy: 0.9468\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9696 - val_loss: 0.1295 - val_accuracy: 0.9566\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9700 - val_loss: 0.0936 - val_accuracy: 0.9707\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9746 - val_loss: 0.1142 - val_accuracy: 0.9601\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9689 - val_loss: 0.0951 - val_accuracy: 0.9699\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9746 - val_loss: 0.0933 - val_accuracy: 0.9716\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9727 - val_loss: 0.1375 - val_accuracy: 0.9566\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.9700 - val_loss: 0.1006 - val_accuracy: 0.9672\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9715 - val_loss: 0.1256 - val_accuracy: 0.9574\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9715 - val_loss: 0.1057 - val_accuracy: 0.9637\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9719 - val_loss: 0.1451 - val_accuracy: 0.9548\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.1518 - val_accuracy: 0.9459\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9708 - val_loss: 0.1088 - val_accuracy: 0.9663\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9727 - val_loss: 0.0936 - val_accuracy: 0.9663\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9711 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9742 - val_loss: 0.0867 - val_accuracy: 0.9725\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9692 - val_loss: 0.0905 - val_accuracy: 0.9725\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9711 - val_loss: 0.0880 - val_accuracy: 0.9716\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0897 - accuracy: 0.9715 - val_loss: 0.0892 - val_accuracy: 0.9707\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 0.0963 - val_accuracy: 0.9654\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9730 - val_loss: 0.1048 - val_accuracy: 0.9663\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9715 - val_loss: 0.1336 - val_accuracy: 0.9548\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9719 - val_loss: 0.0988 - val_accuracy: 0.9628\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9672\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9723 - val_loss: 0.1947 - val_accuracy: 0.9379\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9708 - val_loss: 0.0887 - val_accuracy: 0.9734\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9704 - val_loss: 0.1104 - val_accuracy: 0.9610\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0847 - accuracy: 0.9753 - val_loss: 0.1034 - val_accuracy: 0.9690\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9723 - val_loss: 0.1434 - val_accuracy: 0.9521\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9730 - val_loss: 0.1606 - val_accuracy: 0.9468\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9723 - val_loss: 0.0841 - val_accuracy: 0.9725\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9715 - val_loss: 0.0855 - val_accuracy: 0.9743\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.0828 - val_accuracy: 0.9725\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9734 - val_loss: 0.0895 - val_accuracy: 0.9707\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9704 - val_loss: 0.1794 - val_accuracy: 0.9424\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9753 - val_loss: 0.1154 - val_accuracy: 0.9583\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9746 - val_loss: 0.1028 - val_accuracy: 0.9672\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9730 - val_loss: 0.1504 - val_accuracy: 0.9486\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.1007 - val_accuracy: 0.9690\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9742 - val_loss: 0.1387 - val_accuracy: 0.9539\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9742 - val_loss: 0.1189 - val_accuracy: 0.9583\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9723 - val_loss: 0.0897 - val_accuracy: 0.9716\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9715 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9727 - val_loss: 0.1618 - val_accuracy: 0.9415\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9742 - val_loss: 0.0888 - val_accuracy: 0.9743\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9770\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0898 - accuracy: 0.9704 - val_loss: 0.1022 - val_accuracy: 0.9637\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0893 - accuracy: 0.9723 - val_loss: 0.1628 - val_accuracy: 0.9406\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0919 - accuracy: 0.9719 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0882 - accuracy: 0.9742 - val_loss: 0.0841 - val_accuracy: 0.9743\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0856 - accuracy: 0.9730 - val_loss: 0.1486 - val_accuracy: 0.9504\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 0.1162 - val_accuracy: 0.9566\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0851 - accuracy: 0.9692 - val_loss: 0.0878 - val_accuracy: 0.9681\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.0911 - val_accuracy: 0.9654\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0885 - accuracy: 0.9738 - val_loss: 0.1030 - val_accuracy: 0.9654\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0818 - accuracy: 0.9749 - val_loss: 0.0968 - val_accuracy: 0.9645\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9730 - val_loss: 0.1614 - val_accuracy: 0.9495\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0861 - accuracy: 0.9719 - val_loss: 0.0890 - val_accuracy: 0.9681\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9723 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.0849 - val_accuracy: 0.9761\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0819 - accuracy: 0.9734 - val_loss: 0.1064 - val_accuracy: 0.9610\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9730 - val_loss: 0.0807 - val_accuracy: 0.9743\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0849 - accuracy: 0.9727 - val_loss: 0.1246 - val_accuracy: 0.9539\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0814 - accuracy: 0.9742 - val_loss: 0.0885 - val_accuracy: 0.9743\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0845 - accuracy: 0.9734 - val_loss: 0.2561 - val_accuracy: 0.9140\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0853 - accuracy: 0.9727 - val_loss: 0.2290 - val_accuracy: 0.9255\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0841 - accuracy: 0.9727 - val_loss: 0.0794 - val_accuracy: 0.9725\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9742 - val_loss: 0.0879 - val_accuracy: 0.9681\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0808 - accuracy: 0.9730 - val_loss: 0.1301 - val_accuracy: 0.9521\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9742 - val_loss: 0.1270 - val_accuracy: 0.9521\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 0.1416 - val_accuracy: 0.9512\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.1128 - val_accuracy: 0.9574\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0848 - accuracy: 0.9719 - val_loss: 0.0892 - val_accuracy: 0.9672\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9753 - val_loss: 0.1395 - val_accuracy: 0.9504\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9749 - val_loss: 0.3296 - val_accuracy: 0.8874\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0910 - accuracy: 0.9734 - val_loss: 0.1621 - val_accuracy: 0.9433\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0832 - accuracy: 0.9749 - val_loss: 0.0899 - val_accuracy: 0.9672\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0843 - accuracy: 0.9715 - val_loss: 0.0848 - val_accuracy: 0.9699\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9711 - val_loss: 0.1809 - val_accuracy: 0.9353\n",
      "Epoch 458/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9768 - val_loss: 0.1630 - val_accuracy: 0.9415\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.9738 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 0.0884 - val_accuracy: 0.9707\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0799 - accuracy: 0.9727 - val_loss: 0.0750 - val_accuracy: 0.9743\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0850 - accuracy: 0.9753 - val_loss: 0.0817 - val_accuracy: 0.9752\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0857 - accuracy: 0.9723 - val_loss: 0.0948 - val_accuracy: 0.9672\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9730 - val_loss: 0.0804 - val_accuracy: 0.9725\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0841 - accuracy: 0.9727 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 0.0774 - val_accuracy: 0.9725\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0836 - accuracy: 0.9708 - val_loss: 0.1664 - val_accuracy: 0.9459\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9723 - val_loss: 0.0733 - val_accuracy: 0.9734\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9753 - val_loss: 0.0959 - val_accuracy: 0.9637\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0806 - accuracy: 0.9768 - val_loss: 0.1054 - val_accuracy: 0.9619\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.1598 - val_accuracy: 0.9415\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9746 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9734 - val_loss: 0.1185 - val_accuracy: 0.9583\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0807 - accuracy: 0.9715 - val_loss: 0.0827 - val_accuracy: 0.9681\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0821 - accuracy: 0.9757 - val_loss: 0.0754 - val_accuracy: 0.9734\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0743 - accuracy: 0.9749 - val_loss: 0.0749 - val_accuracy: 0.9805\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0946 - val_accuracy: 0.9645\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9742 - val_loss: 0.0831 - val_accuracy: 0.9699\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 0.0911 - val_accuracy: 0.9663\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0807 - accuracy: 0.9753 - val_loss: 0.2900 - val_accuracy: 0.8998\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 0.0922 - val_accuracy: 0.9663\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0764 - accuracy: 0.9749 - val_loss: 0.1878 - val_accuracy: 0.9335\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.0774 - val_accuracy: 0.9725\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9734 - val_loss: 0.0791 - val_accuracy: 0.9707\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9746 - val_loss: 0.1906 - val_accuracy: 0.9335\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9734 - val_loss: 0.0991 - val_accuracy: 0.9637\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: 0.1295 - val_accuracy: 0.9495\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.0734 - val_accuracy: 0.9752\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0743 - accuracy: 0.9776 - val_loss: 0.0724 - val_accuracy: 0.9787\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0839 - accuracy: 0.9715 - val_loss: 0.2024 - val_accuracy: 0.9326\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.9749 - val_loss: 0.0814 - val_accuracy: 0.9699\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0867 - accuracy: 0.9711 - val_loss: 0.0965 - val_accuracy: 0.9672\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9746 - val_loss: 0.1125 - val_accuracy: 0.9601\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9715 - val_loss: 0.1218 - val_accuracy: 0.9574\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 0.0778 - val_accuracy: 0.9743\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0787 - accuracy: 0.9746 - val_loss: 0.0969 - val_accuracy: 0.9681\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0867 - accuracy: 0.9734 - val_loss: 0.0800 - val_accuracy: 0.9752\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.3337 - val_accuracy: 0.8918\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0820 - accuracy: 0.9734 - val_loss: 0.1552 - val_accuracy: 0.9486\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0814 - accuracy: 0.9768 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N3check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569ac21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9879414298018949\n",
      "0.9703891708967851\n",
      "0.979086641058472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e90fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e79b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817813765182186\n",
      "0.9680638722554891\n",
      "0.9748743718592965\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facb05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
