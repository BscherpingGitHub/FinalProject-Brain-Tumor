{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  8.8  374.4 ...  2.8  1.0  0.0]\n",
      " [ 0.0  8.8  462.3 ...  4.3  1.0  0.0]\n",
      " [ 0.0  11.2  502.8 ...  3.5  0.9  0.0]\n",
      " ...\n",
      " [ 1.0  14.1  1095.0 ...  2.5  1.0  0.0]\n",
      " [ 0.0  1.5  84.4 ...  5.1  0.9  0.0]\n",
      " [ 0.0  17.3  1342.6 ...  4.4  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 8]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 8]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 13ms/step - loss: 0.6527 - accuracy: 0.5421 - val_loss: 0.6390 - val_accuracy: 0.5771\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6372 - accuracy: 0.5421 - val_loss: 0.6250 - val_accuracy: 0.5771\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6258 - accuracy: 0.5421 - val_loss: 0.6145 - val_accuracy: 0.5984\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6145 - accuracy: 0.6291 - val_loss: 0.6029 - val_accuracy: 0.7447\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6024 - accuracy: 0.7411 - val_loss: 0.5904 - val_accuracy: 0.7943\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5897 - accuracy: 0.7813 - val_loss: 0.5774 - val_accuracy: 0.8254\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5764 - accuracy: 0.8113 - val_loss: 0.5634 - val_accuracy: 0.8395\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5621 - accuracy: 0.8326 - val_loss: 0.5485 - val_accuracy: 0.8528\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5472 - accuracy: 0.8485 - val_loss: 0.5338 - val_accuracy: 0.8750\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.8652 - val_loss: 0.5181 - val_accuracy: 0.8803\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5169 - accuracy: 0.8747 - val_loss: 0.5031 - val_accuracy: 0.8972\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5010 - accuracy: 0.8861 - val_loss: 0.4875 - val_accuracy: 0.9105\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4847 - accuracy: 0.8979 - val_loss: 0.4713 - val_accuracy: 0.9113\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4685 - accuracy: 0.9077 - val_loss: 0.4552 - val_accuracy: 0.9184\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4524 - accuracy: 0.9138 - val_loss: 0.4401 - val_accuracy: 0.9264\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4363 - accuracy: 0.9214 - val_loss: 0.4236 - val_accuracy: 0.9246\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4204 - accuracy: 0.9218 - val_loss: 0.4086 - val_accuracy: 0.9326\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4045 - accuracy: 0.9263 - val_loss: 0.3934 - val_accuracy: 0.9388\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3887 - accuracy: 0.9282 - val_loss: 0.3786 - val_accuracy: 0.9415\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3737 - accuracy: 0.9328 - val_loss: 0.3641 - val_accuracy: 0.9424\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3591 - accuracy: 0.9355 - val_loss: 0.3508 - val_accuracy: 0.9459\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3454 - accuracy: 0.9385 - val_loss: 0.3381 - val_accuracy: 0.9477\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3319 - accuracy: 0.9442 - val_loss: 0.3254 - val_accuracy: 0.9495\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3191 - accuracy: 0.9453 - val_loss: 0.3133 - val_accuracy: 0.9495\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.9453 - val_loss: 0.3018 - val_accuracy: 0.9495\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2949 - accuracy: 0.9495 - val_loss: 0.2918 - val_accuracy: 0.9495\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2841 - accuracy: 0.9514 - val_loss: 0.2815 - val_accuracy: 0.9495\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2738 - accuracy: 0.9518 - val_loss: 0.2719 - val_accuracy: 0.9504\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2632 - accuracy: 0.9529 - val_loss: 0.2623 - val_accuracy: 0.9530\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2536 - accuracy: 0.9541 - val_loss: 0.2538 - val_accuracy: 0.9530\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2447 - accuracy: 0.9571 - val_loss: 0.2451 - val_accuracy: 0.9530\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2363 - accuracy: 0.9548 - val_loss: 0.2380 - val_accuracy: 0.9548\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2282 - accuracy: 0.9579 - val_loss: 0.2311 - val_accuracy: 0.9574\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2206 - accuracy: 0.9613 - val_loss: 0.2243 - val_accuracy: 0.9583\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2136 - accuracy: 0.9613 - val_loss: 0.2178 - val_accuracy: 0.9601\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2068 - accuracy: 0.9620 - val_loss: 0.2117 - val_accuracy: 0.9610\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2005 - accuracy: 0.9628 - val_loss: 0.2061 - val_accuracy: 0.9610\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1944 - accuracy: 0.9643 - val_loss: 0.2007 - val_accuracy: 0.9610\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1890 - accuracy: 0.9632 - val_loss: 0.1962 - val_accuracy: 0.9619\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1837 - accuracy: 0.9643 - val_loss: 0.1918 - val_accuracy: 0.9628\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1789 - accuracy: 0.9651 - val_loss: 0.1877 - val_accuracy: 0.9628\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1745 - accuracy: 0.9655 - val_loss: 0.1838 - val_accuracy: 0.9628\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1700 - accuracy: 0.9662 - val_loss: 0.1796 - val_accuracy: 0.9628\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.9655 - val_loss: 0.1763 - val_accuracy: 0.9654\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1622 - accuracy: 0.9651 - val_loss: 0.1734 - val_accuracy: 0.9654\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1588 - accuracy: 0.9674 - val_loss: 0.1703 - val_accuracy: 0.9654\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1557 - accuracy: 0.9666 - val_loss: 0.1677 - val_accuracy: 0.9654\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1526 - accuracy: 0.9670 - val_loss: 0.1649 - val_accuracy: 0.9654\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1497 - accuracy: 0.9666 - val_loss: 0.1629 - val_accuracy: 0.9645\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1471 - accuracy: 0.9681 - val_loss: 0.1608 - val_accuracy: 0.9654\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1446 - accuracy: 0.9681 - val_loss: 0.1590 - val_accuracy: 0.9654\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1422 - accuracy: 0.9696 - val_loss: 0.1569 - val_accuracy: 0.9654\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9696 - val_loss: 0.1553 - val_accuracy: 0.9654\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1382 - accuracy: 0.9700 - val_loss: 0.1541 - val_accuracy: 0.9672\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1364 - accuracy: 0.9708 - val_loss: 0.1525 - val_accuracy: 0.9672\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1345 - accuracy: 0.9711 - val_loss: 0.1505 - val_accuracy: 0.9654\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1331 - accuracy: 0.9700 - val_loss: 0.1495 - val_accuracy: 0.9663\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.9708 - val_loss: 0.1485 - val_accuracy: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1300 - accuracy: 0.9708 - val_loss: 0.1471 - val_accuracy: 0.9672\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1286 - accuracy: 0.9711 - val_loss: 0.1463 - val_accuracy: 0.9672\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1273 - accuracy: 0.9715 - val_loss: 0.1454 - val_accuracy: 0.9672\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9719 - val_loss: 0.1438 - val_accuracy: 0.9672\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1247 - accuracy: 0.9715 - val_loss: 0.1429 - val_accuracy: 0.9672\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1238 - accuracy: 0.9711 - val_loss: 0.1422 - val_accuracy: 0.9672\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1227 - accuracy: 0.9715 - val_loss: 0.1413 - val_accuracy: 0.9672\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1217 - accuracy: 0.9719 - val_loss: 0.1406 - val_accuracy: 0.9672\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1208 - accuracy: 0.9708 - val_loss: 0.1401 - val_accuracy: 0.9672\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1199 - accuracy: 0.9723 - val_loss: 0.1398 - val_accuracy: 0.9690\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1190 - accuracy: 0.9719 - val_loss: 0.1392 - val_accuracy: 0.9690\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1182 - accuracy: 0.9723 - val_loss: 0.1382 - val_accuracy: 0.9672\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1175 - accuracy: 0.9719 - val_loss: 0.1380 - val_accuracy: 0.9690\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1168 - accuracy: 0.9727 - val_loss: 0.1373 - val_accuracy: 0.9690\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1161 - accuracy: 0.9719 - val_loss: 0.1367 - val_accuracy: 0.9690\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1155 - accuracy: 0.9723 - val_loss: 0.1364 - val_accuracy: 0.9690\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1147 - accuracy: 0.9727 - val_loss: 0.1359 - val_accuracy: 0.9690\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1141 - accuracy: 0.9727 - val_loss: 0.1354 - val_accuracy: 0.9690\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1135 - accuracy: 0.9727 - val_loss: 0.1349 - val_accuracy: 0.9690\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1129 - accuracy: 0.9727 - val_loss: 0.1352 - val_accuracy: 0.9699\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.9730 - val_loss: 0.1349 - val_accuracy: 0.9699\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.9738 - val_loss: 0.1342 - val_accuracy: 0.9699\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1113 - accuracy: 0.9727 - val_loss: 0.1338 - val_accuracy: 0.9699\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1109 - accuracy: 0.9727 - val_loss: 0.1335 - val_accuracy: 0.9699\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1104 - accuracy: 0.9734 - val_loss: 0.1335 - val_accuracy: 0.9699\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1100 - accuracy: 0.9730 - val_loss: 0.1330 - val_accuracy: 0.9699\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1095 - accuracy: 0.9738 - val_loss: 0.1324 - val_accuracy: 0.9699\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1092 - accuracy: 0.9738 - val_loss: 0.1323 - val_accuracy: 0.9699\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1088 - accuracy: 0.9738 - val_loss: 0.1323 - val_accuracy: 0.9699\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1084 - accuracy: 0.9734 - val_loss: 0.1324 - val_accuracy: 0.9707\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1081 - accuracy: 0.9738 - val_loss: 0.1322 - val_accuracy: 0.9707\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1077 - accuracy: 0.9746 - val_loss: 0.1316 - val_accuracy: 0.9699\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1075 - accuracy: 0.9738 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1071 - accuracy: 0.9734 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1068 - accuracy: 0.9738 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1064 - accuracy: 0.9746 - val_loss: 0.1308 - val_accuracy: 0.9699\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1062 - accuracy: 0.9734 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1059 - accuracy: 0.9746 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1057 - accuracy: 0.9738 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1054 - accuracy: 0.9746 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.1052 - accuracy: 0.9749 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1047 - accuracy: 0.9742 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1045 - accuracy: 0.9749 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1043 - accuracy: 0.9746 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1041 - accuracy: 0.9746 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1038 - accuracy: 0.9746 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1037 - accuracy: 0.9749 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1035 - accuracy: 0.9746 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1032 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1032 - accuracy: 0.9746 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1030 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1028 - accuracy: 0.9746 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1027 - accuracy: 0.9749 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9749 - val_loss: 0.1299 - val_accuracy: 0.9716\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1023 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1022 - accuracy: 0.9749 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1021 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1020 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9707\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1018 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9707\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1018 - accuracy: 0.9746 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1014 - accuracy: 0.9749 - val_loss: 0.1296 - val_accuracy: 0.9716\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1016 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.9749 - val_loss: 0.1295 - val_accuracy: 0.9716\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9707\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9707\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1010 - accuracy: 0.9742 - val_loss: 0.1294 - val_accuracy: 0.9716\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1009 - accuracy: 0.9749 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1008 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9725\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1008 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9716\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1006 - accuracy: 0.9746 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1005 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1005 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9725\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1003 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1003 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9716\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9716\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1001 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1000 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1000 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9725\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0998 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0997 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0997 - accuracy: 0.9749 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0996 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9725\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0997 - accuracy: 0.9749 - val_loss: 0.1286 - val_accuracy: 0.9716\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0996 - accuracy: 0.9749 - val_loss: 0.1285 - val_accuracy: 0.9707\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0995 - accuracy: 0.9749 - val_loss: 0.1286 - val_accuracy: 0.9716\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0995 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0994 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9753 - val_loss: 0.1285 - val_accuracy: 0.9707\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9707\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9749 - val_loss: 0.1288 - val_accuracy: 0.9716\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0991 - accuracy: 0.9749 - val_loss: 0.1288 - val_accuracy: 0.9716\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0990 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9716\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0989 - accuracy: 0.9753 - val_loss: 0.1286 - val_accuracy: 0.9725\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0989 - accuracy: 0.9753 - val_loss: 0.1285 - val_accuracy: 0.9707\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9749 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0988 - accuracy: 0.9753 - val_loss: 0.1285 - val_accuracy: 0.9716\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0988 - accuracy: 0.9749 - val_loss: 0.1287 - val_accuracy: 0.9725\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0987 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0987 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0986 - accuracy: 0.9749 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9749 - val_loss: 0.1288 - val_accuracy: 0.9716\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0986 - accuracy: 0.9746 - val_loss: 0.1289 - val_accuracy: 0.9707\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.9749 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.9749 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9761 - val_loss: 0.1286 - val_accuracy: 0.9725\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9749 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0984 - accuracy: 0.9749 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0983 - accuracy: 0.9757 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0983 - accuracy: 0.9746 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9749 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9753 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9749 - val_loss: 0.1292 - val_accuracy: 0.9707\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9753 - val_loss: 0.1289 - val_accuracy: 0.9716\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0980 - accuracy: 0.9749 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0980 - accuracy: 0.9749 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0980 - accuracy: 0.9749 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9749 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9757 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0979 - accuracy: 0.9749 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0979 - accuracy: 0.9749 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9757 - val_loss: 0.1291 - val_accuracy: 0.9707\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9749 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0978 - accuracy: 0.9753 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.9757 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0978 - accuracy: 0.9746 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0977 - accuracy: 0.9753 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0977 - accuracy: 0.9749 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.9753 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0977 - accuracy: 0.9749 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9757 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9757 - val_loss: 0.1294 - val_accuracy: 0.9707\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9746 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9761 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9753 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9753 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9749 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9757 - val_loss: 0.1293 - val_accuracy: 0.9707\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9749 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9749 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0975 - accuracy: 0.9749 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9757 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0975 - accuracy: 0.9761 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9753 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9757 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9749 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0973 - accuracy: 0.9753 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9757 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9761 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.1296 - val_accuracy: 0.9707\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9757 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9746 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1297 - val_accuracy: 0.9707\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0973 - accuracy: 0.9746 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0973 - accuracy: 0.9757 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9757 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9757 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9761 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0972 - accuracy: 0.9761 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0972 - accuracy: 0.9761 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9753 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0973 - accuracy: 0.9749 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9749 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9753 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0971 - accuracy: 0.9761 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1306 - val_accuracy: 0.9707\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1299 - val_accuracy: 0.9707\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0972 - accuracy: 0.9753 - val_loss: 0.1302 - val_accuracy: 0.9707\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0971 - accuracy: 0.9746 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0971 - accuracy: 0.9757 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0970 - accuracy: 0.9749 - val_loss: 0.1306 - val_accuracy: 0.9707\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9761 - val_loss: 0.1300 - val_accuracy: 0.9707\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0970 - accuracy: 0.9749 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9761 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0970 - accuracy: 0.9753 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9761 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9768 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0970 - accuracy: 0.9749 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9749 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9761 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0969 - accuracy: 0.9761 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9753 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9749 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1306 - val_accuracy: 0.9707\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.1304 - val_accuracy: 0.9707\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9765 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1303 - val_accuracy: 0.9707\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9746 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1306 - val_accuracy: 0.9707\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9749 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9761 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1306 - val_accuracy: 0.9707\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.9753 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0968 - accuracy: 0.9761 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0968 - accuracy: 0.9765 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0967 - accuracy: 0.9765 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9765 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9765 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9753 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9765 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9749 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9768 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9765 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9768 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9772 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9765 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1308 - val_accuracy: 0.9707\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9749 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0967 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1323 - val_accuracy: 0.9716\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9765 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9768 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9765 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9707\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9707\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9749 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9768 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1321 - val_accuracy: 0.9707\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0964 - accuracy: 0.9768 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9749 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0965 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9749 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1321 - val_accuracy: 0.9707\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9768 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9768 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9749 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9749 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9765 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0963 - accuracy: 0.9757 - val_loss: 0.1312 - val_accuracy: 0.9707\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9765 - val_loss: 0.1314 - val_accuracy: 0.9707\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9753 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9761 - val_loss: 0.1320 - val_accuracy: 0.9707\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9765 - val_loss: 0.1313 - val_accuracy: 0.9707\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1316 - val_accuracy: 0.9707\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1317 - val_accuracy: 0.9707\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9707\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9753 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0963 - accuracy: 0.9757 - val_loss: 0.1323 - val_accuracy: 0.9716\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1319 - val_accuracy: 0.9707\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1321 - val_accuracy: 0.9707\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.1]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9914089347079038\n",
      "0.956882255389718\n",
      "0.9738396624472574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978448275862069\n",
      "0.9517819706498952\n",
      "0.9649309245483528\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
