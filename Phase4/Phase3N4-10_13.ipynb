{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  5.0  208.8 ...  2.2  1.0  0.0]\n",
      " [ 0.0  11.1  1032.2 ...  3.8  1.0  0.0]\n",
      " [ 0.0  9.2  365.2 ...  2.8  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  2.7  353.6 ...  8.7  0.9  0.0]\n",
      " [ 0.0  1.0  54.4 ...  4.3  0.9  0.0]\n",
      " [ 0.0  7.9  626.0 ...  3.7  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  208.8  14.5 ...  0.0  0.6  2.2]\n",
      " [ 0.0  1032.2  32.1 ...  0.2  0.6  3.8]\n",
      " [ 0.0  365.2  19.1 ...  0.1  0.6  2.8]\n",
      " ...\n",
      " [ 1.0  353.6  18.8 ...  0.0  0.4  8.7]\n",
      " [ 0.0  54.4  7.4 ...  0.2  0.6  4.3]\n",
      " [ 0.0  626.0  25.0 ...  0.2  0.7  3.7]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 14.1317 - accuracy: 0.5023 - val_loss: 2.2653 - val_accuracy: 0.4060\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6097 - accuracy: 0.3641 - val_loss: 1.1888 - val_accuracy: 0.2730\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.3675 - val_loss: 0.8953 - val_accuracy: 0.4504\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.4514 - val_loss: 0.7428 - val_accuracy: 0.5186\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.5254 - val_loss: 0.8036 - val_accuracy: 0.4504\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5778 - val_loss: 0.9903 - val_accuracy: 0.4504\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6443 - val_loss: 0.6909 - val_accuracy: 0.5230\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6834 - val_loss: 0.6206 - val_accuracy: 0.6525\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7012 - val_loss: 0.7300 - val_accuracy: 0.6489\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7320 - val_loss: 0.5402 - val_accuracy: 0.8067\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7460 - val_loss: 0.8084 - val_accuracy: 0.5230\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7536 - val_loss: 0.6117 - val_accuracy: 0.7012\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.8174\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7730 - val_loss: 0.5496 - val_accuracy: 0.7837\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7931 - val_loss: 0.4787 - val_accuracy: 0.8502\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8056 - val_loss: 0.6179 - val_accuracy: 0.7145\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8064 - val_loss: 0.4891 - val_accuracy: 0.8475\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.8147 - val_loss: 0.4752 - val_accuracy: 0.8573\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.8200 - val_loss: 0.5327 - val_accuracy: 0.7394\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8147 - val_loss: 0.4662 - val_accuracy: 0.8785\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.8326 - val_loss: 1.0093 - val_accuracy: 0.6144\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8292 - val_loss: 0.6475 - val_accuracy: 0.6995\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8394 - val_loss: 0.4287 - val_accuracy: 0.8874\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8299 - val_loss: 0.4225 - val_accuracy: 0.8617\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8375 - val_loss: 0.4728 - val_accuracy: 0.8617\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8398 - val_loss: 0.6711 - val_accuracy: 0.7004\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8565 - val_loss: 0.4067 - val_accuracy: 0.8759\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8466 - val_loss: 0.4895 - val_accuracy: 0.7660\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8550 - val_loss: 0.4375 - val_accuracy: 0.8129\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8535 - val_loss: 0.4157 - val_accuracy: 0.8972\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8554 - val_loss: 0.5084 - val_accuracy: 0.7553\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8629 - val_loss: 0.5250 - val_accuracy: 0.8271\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8546 - val_loss: 0.4751 - val_accuracy: 0.7757\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8645 - val_loss: 0.4180 - val_accuracy: 0.8324\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8595 - val_loss: 0.4657 - val_accuracy: 0.7863\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8569 - val_loss: 0.5172 - val_accuracy: 0.8351\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8675 - val_loss: 0.3867 - val_accuracy: 0.9060\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8679 - val_loss: 0.5948 - val_accuracy: 0.7872\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8614 - val_loss: 0.4656 - val_accuracy: 0.7855\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8770 - val_loss: 0.3913 - val_accuracy: 0.9069\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8705 - val_loss: 0.3782 - val_accuracy: 0.8750\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8755 - val_loss: 0.6230 - val_accuracy: 0.7775\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8721 - val_loss: 0.3727 - val_accuracy: 0.9113\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8736 - val_loss: 0.5131 - val_accuracy: 0.7633\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8804 - val_loss: 0.4638 - val_accuracy: 0.7899\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8698 - val_loss: 0.3646 - val_accuracy: 0.9087\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8785 - val_loss: 0.5071 - val_accuracy: 0.7677\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8827 - val_loss: 0.3623 - val_accuracy: 0.8865\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8785 - val_loss: 0.7384 - val_accuracy: 0.6817\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8755 - val_loss: 0.3830 - val_accuracy: 0.9051\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8808 - val_loss: 0.5394 - val_accuracy: 0.7509\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8781 - val_loss: 0.4199 - val_accuracy: 0.8183\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8827 - val_loss: 0.5710 - val_accuracy: 0.8112\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8853 - val_loss: 0.3562 - val_accuracy: 0.9202\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8926 - val_loss: 0.5827 - val_accuracy: 0.8067\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8812 - val_loss: 0.3517 - val_accuracy: 0.9220\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8781 - val_loss: 0.4259 - val_accuracy: 0.8839\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8861 - val_loss: 0.5452 - val_accuracy: 0.8236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8979 - val_loss: 0.4814 - val_accuracy: 0.7890\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8899 - val_loss: 0.3787 - val_accuracy: 0.8590\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8918 - val_loss: 0.6135 - val_accuracy: 0.7934\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8933 - val_loss: 0.4481 - val_accuracy: 0.8697\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8846 - val_loss: 0.3657 - val_accuracy: 0.9087\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8880 - val_loss: 0.3446 - val_accuracy: 0.8927\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8846 - val_loss: 0.3628 - val_accuracy: 0.9131\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8903 - val_loss: 0.3350 - val_accuracy: 0.9158\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8952 - val_loss: 0.3604 - val_accuracy: 0.9167\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8876 - val_loss: 0.3545 - val_accuracy: 0.9184\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8926 - val_loss: 0.3397 - val_accuracy: 0.9273\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8945 - val_loss: 0.3330 - val_accuracy: 0.9087\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8975 - val_loss: 0.4432 - val_accuracy: 0.8715\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8910 - val_loss: 0.3510 - val_accuracy: 0.9184\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9002 - val_loss: 0.4746 - val_accuracy: 0.8564\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.9024 - val_loss: 0.4748 - val_accuracy: 0.7943\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8967 - val_loss: 0.3749 - val_accuracy: 0.9043\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8986 - val_loss: 0.5616 - val_accuracy: 0.8191\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8926 - val_loss: 0.4114 - val_accuracy: 0.8910\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.9013 - val_loss: 0.3345 - val_accuracy: 0.9238\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.9036 - val_loss: 0.4813 - val_accuracy: 0.8546\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.9005 - val_loss: 0.3489 - val_accuracy: 0.9176\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8952 - val_loss: 0.4769 - val_accuracy: 0.8555\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.9043 - val_loss: 0.3575 - val_accuracy: 0.8661\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.9036 - val_loss: 0.3147 - val_accuracy: 0.9193\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.9002 - val_loss: 0.3111 - val_accuracy: 0.9291\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8990 - val_loss: 0.3486 - val_accuracy: 0.9184\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.9100 - val_loss: 0.3088 - val_accuracy: 0.9211\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.9062 - val_loss: 0.4469 - val_accuracy: 0.8723\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8998 - val_loss: 0.3086 - val_accuracy: 0.9317\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.9043 - val_loss: 0.3764 - val_accuracy: 0.8413\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.9104 - val_loss: 0.5505 - val_accuracy: 0.8218\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.9013 - val_loss: 0.4223 - val_accuracy: 0.8156\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.9032 - val_loss: 0.3058 - val_accuracy: 0.9140\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.9077 - val_loss: 0.3684 - val_accuracy: 0.8484\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.9058 - val_loss: 0.2973 - val_accuracy: 0.9335\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9100 - val_loss: 0.3381 - val_accuracy: 0.9193\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.9070 - val_loss: 0.3165 - val_accuracy: 0.9034\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.9112 - val_loss: 0.3387 - val_accuracy: 0.8794\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.9081 - val_loss: 0.3502 - val_accuracy: 0.8652\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.9039 - val_loss: 0.2930 - val_accuracy: 0.9344\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.9176 - val_loss: 0.3936 - val_accuracy: 0.8936\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.9081 - val_loss: 0.6118 - val_accuracy: 0.7438\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.9119 - val_loss: 0.2919 - val_accuracy: 0.9388\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.9188 - val_loss: 0.5577 - val_accuracy: 0.7589\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.9119 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.9157 - val_loss: 0.3409 - val_accuracy: 0.9122\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.9142 - val_loss: 0.2885 - val_accuracy: 0.9264\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.9153 - val_loss: 0.3171 - val_accuracy: 0.9291\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9085 - val_loss: 0.2839 - val_accuracy: 0.9371\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.9157 - val_loss: 0.2911 - val_accuracy: 0.9371\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9176 - val_loss: 0.2872 - val_accuracy: 0.9388\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.9104 - val_loss: 0.3047 - val_accuracy: 0.9362\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.9199 - val_loss: 0.3028 - val_accuracy: 0.9379\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.9195 - val_loss: 0.2968 - val_accuracy: 0.9371\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.9165 - val_loss: 0.2780 - val_accuracy: 0.9335\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.9176 - val_loss: 0.3354 - val_accuracy: 0.9131\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.9210 - val_loss: 0.5862 - val_accuracy: 0.8085\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.9222 - val_loss: 0.3156 - val_accuracy: 0.9282\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.9180 - val_loss: 0.3627 - val_accuracy: 0.8972\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9199 - val_loss: 0.3027 - val_accuracy: 0.9025\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9169 - val_loss: 0.3719 - val_accuracy: 0.8440\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9172 - val_loss: 0.2744 - val_accuracy: 0.9317\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.9191 - val_loss: 0.3082 - val_accuracy: 0.9246\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.9241 - val_loss: 0.5391 - val_accuracy: 0.7660\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9222 - val_loss: 0.3572 - val_accuracy: 0.9025\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9229 - val_loss: 0.5279 - val_accuracy: 0.8324\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9153 - val_loss: 0.3377 - val_accuracy: 0.9131\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.9191 - val_loss: 0.2647 - val_accuracy: 0.9450\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9279 - val_loss: 0.3177 - val_accuracy: 0.8883\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9207 - val_loss: 0.2896 - val_accuracy: 0.9105\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9256 - val_loss: 0.2831 - val_accuracy: 0.9193\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.9210 - val_loss: 0.2585 - val_accuracy: 0.9424\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9233 - val_loss: 0.2922 - val_accuracy: 0.9096\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9256 - val_loss: 0.3828 - val_accuracy: 0.8369\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9275 - val_loss: 0.3333 - val_accuracy: 0.8741\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9195 - val_loss: 0.3678 - val_accuracy: 0.8963\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9233 - val_loss: 0.3681 - val_accuracy: 0.8954\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.9294 - val_loss: 0.2741 - val_accuracy: 0.9193\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.9263 - val_loss: 0.2494 - val_accuracy: 0.9450\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9267 - val_loss: 0.2724 - val_accuracy: 0.9371\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9279 - val_loss: 0.2522 - val_accuracy: 0.9344\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9222 - val_loss: 0.3443 - val_accuracy: 0.9025\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.9275 - val_loss: 0.3283 - val_accuracy: 0.9113\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9267 - val_loss: 0.3149 - val_accuracy: 0.9176\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9241 - val_loss: 0.2504 - val_accuracy: 0.9371\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9282 - val_loss: 0.3871 - val_accuracy: 0.8927\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9263 - val_loss: 0.3069 - val_accuracy: 0.9184\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.9294 - val_loss: 0.2431 - val_accuracy: 0.9495\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.9317 - val_loss: 0.3511 - val_accuracy: 0.8998\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9301 - val_loss: 0.2597 - val_accuracy: 0.9264\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9263 - val_loss: 0.3310 - val_accuracy: 0.8741\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9305 - val_loss: 0.2471 - val_accuracy: 0.9477\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9324 - val_loss: 0.3141 - val_accuracy: 0.8865\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9343 - val_loss: 0.5614 - val_accuracy: 0.7677\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9324 - val_loss: 0.2365 - val_accuracy: 0.9504\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.9336 - val_loss: 0.2417 - val_accuracy: 0.9495\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9347 - val_loss: 0.2401 - val_accuracy: 0.9486\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.9320 - val_loss: 0.2865 - val_accuracy: 0.9087\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9317 - val_loss: 0.2994 - val_accuracy: 0.9220\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9298 - val_loss: 0.2505 - val_accuracy: 0.9424\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2286 - accuracy: 0.9370 - val_loss: 0.3020 - val_accuracy: 0.8945\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.9286 - val_loss: 0.2438 - val_accuracy: 0.9468\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9336 - val_loss: 0.3863 - val_accuracy: 0.8856\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2329 - accuracy: 0.9305 - val_loss: 0.2539 - val_accuracy: 0.9282\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2280 - accuracy: 0.9317 - val_loss: 0.2282 - val_accuracy: 0.9477\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9309 - val_loss: 0.3737 - val_accuracy: 0.8910\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9313 - val_loss: 0.8480 - val_accuracy: 0.7092\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9347 - val_loss: 0.2235 - val_accuracy: 0.9530\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9377 - val_loss: 0.2894 - val_accuracy: 0.9025\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9317 - val_loss: 0.2291 - val_accuracy: 0.9521\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9370 - val_loss: 0.4076 - val_accuracy: 0.8768\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9347 - val_loss: 0.2374 - val_accuracy: 0.9362\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9355 - val_loss: 0.2214 - val_accuracy: 0.9530\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9343 - val_loss: 0.2472 - val_accuracy: 0.9300\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9355 - val_loss: 0.2347 - val_accuracy: 0.9468\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9317 - val_loss: 0.2419 - val_accuracy: 0.9379\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9355 - val_loss: 0.2314 - val_accuracy: 0.9433\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9393 - val_loss: 0.2728 - val_accuracy: 0.9158\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2197 - accuracy: 0.9339 - val_loss: 0.2225 - val_accuracy: 0.9530\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.9434 - val_loss: 0.3306 - val_accuracy: 0.8697\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9374 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9374 - val_loss: 0.2155 - val_accuracy: 0.9548\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9377 - val_loss: 0.2160 - val_accuracy: 0.9557\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9374 - val_loss: 0.2311 - val_accuracy: 0.9388\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9427 - val_loss: 0.2386 - val_accuracy: 0.9326\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9400 - val_loss: 0.2167 - val_accuracy: 0.9566\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9355 - val_loss: 0.2208 - val_accuracy: 0.9530\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9347 - val_loss: 0.2418 - val_accuracy: 0.9362\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2088 - accuracy: 0.9438 - val_loss: 0.2111 - val_accuracy: 0.9512\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9408 - val_loss: 0.2100 - val_accuracy: 0.9530\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2118 - accuracy: 0.9415 - val_loss: 0.2631 - val_accuracy: 0.9335\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2092 - accuracy: 0.9374 - val_loss: 0.2253 - val_accuracy: 0.9468\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2090 - accuracy: 0.9389 - val_loss: 0.2097 - val_accuracy: 0.9539\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2102 - accuracy: 0.9377 - val_loss: 0.3160 - val_accuracy: 0.9087\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2092 - accuracy: 0.9366 - val_loss: 0.2301 - val_accuracy: 0.9379\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2044 - accuracy: 0.9453 - val_loss: 0.2141 - val_accuracy: 0.9566\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.9412 - val_loss: 0.2215 - val_accuracy: 0.9486\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9453 - val_loss: 0.2059 - val_accuracy: 0.9539\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2077 - accuracy: 0.9412 - val_loss: 0.2047 - val_accuracy: 0.9566\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9434 - val_loss: 0.3676 - val_accuracy: 0.8502\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9385 - val_loss: 0.2181 - val_accuracy: 0.9477\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9438 - val_loss: 0.2671 - val_accuracy: 0.9273\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.9431 - val_loss: 0.2930 - val_accuracy: 0.9176\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.9457 - val_loss: 0.3479 - val_accuracy: 0.8954\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9423 - val_loss: 0.2295 - val_accuracy: 0.9379\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9400 - val_loss: 0.2005 - val_accuracy: 0.9548\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9400 - val_loss: 0.2748 - val_accuracy: 0.9238\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9396 - val_loss: 0.2121 - val_accuracy: 0.9468\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9438 - val_loss: 0.1987 - val_accuracy: 0.9583\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9487 - val_loss: 0.2001 - val_accuracy: 0.9539\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1985 - accuracy: 0.9415 - val_loss: 0.2083 - val_accuracy: 0.9530\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9396 - val_loss: 0.2683 - val_accuracy: 0.9282\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.9461 - val_loss: 0.2080 - val_accuracy: 0.9504\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.9450 - val_loss: 0.7827 - val_accuracy: 0.7296\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9427 - val_loss: 0.1966 - val_accuracy: 0.9557\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9480 - val_loss: 0.2009 - val_accuracy: 0.9521\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9495 - val_loss: 0.2365 - val_accuracy: 0.9335\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9415 - val_loss: 0.2003 - val_accuracy: 0.9557\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.9408 - val_loss: 0.2191 - val_accuracy: 0.9371\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9465 - val_loss: 0.2270 - val_accuracy: 0.9397\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9450 - val_loss: 0.3989 - val_accuracy: 0.8387\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9400 - val_loss: 0.2232 - val_accuracy: 0.9371\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9465 - val_loss: 0.1912 - val_accuracy: 0.9566\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.9468 - val_loss: 0.2331 - val_accuracy: 0.9388\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9472 - val_loss: 0.2010 - val_accuracy: 0.9557\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9453 - val_loss: 0.2167 - val_accuracy: 0.9424\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9457 - val_loss: 0.2620 - val_accuracy: 0.9158\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9427 - val_loss: 0.2071 - val_accuracy: 0.9459\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9446 - val_loss: 0.3131 - val_accuracy: 0.9060\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9506 - val_loss: 0.3384 - val_accuracy: 0.8679\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9442 - val_loss: 0.1940 - val_accuracy: 0.9530\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9442 - val_loss: 0.2452 - val_accuracy: 0.9335\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9415 - val_loss: 0.3214 - val_accuracy: 0.9034\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9434 - val_loss: 0.1873 - val_accuracy: 0.9601\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9450 - val_loss: 0.1870 - val_accuracy: 0.9601\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9514 - val_loss: 0.2042 - val_accuracy: 0.9450\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9450 - val_loss: 0.2085 - val_accuracy: 0.9424\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9461 - val_loss: 0.3350 - val_accuracy: 0.8954\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9476 - val_loss: 0.1896 - val_accuracy: 0.9592\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9472 - val_loss: 0.2193 - val_accuracy: 0.9406\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9438 - val_loss: 0.2127 - val_accuracy: 0.9424\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9472 - val_loss: 0.4450 - val_accuracy: 0.8227\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9453 - val_loss: 0.1827 - val_accuracy: 0.9610\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9472 - val_loss: 0.2036 - val_accuracy: 0.9441\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9487 - val_loss: 0.3565 - val_accuracy: 0.8590\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9514 - val_loss: 0.5617 - val_accuracy: 0.8121\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9468 - val_loss: 0.1881 - val_accuracy: 0.9592\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9468 - val_loss: 0.1829 - val_accuracy: 0.9610\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9487 - val_loss: 0.1836 - val_accuracy: 0.9530\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9457 - val_loss: 0.1865 - val_accuracy: 0.9574\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9541 - val_loss: 0.2172 - val_accuracy: 0.9344\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9480 - val_loss: 0.2546 - val_accuracy: 0.9317\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9465 - val_loss: 0.1791 - val_accuracy: 0.9583\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9499 - val_loss: 0.1907 - val_accuracy: 0.9504\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9476 - val_loss: 0.1762 - val_accuracy: 0.9583\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9533 - val_loss: 0.1758 - val_accuracy: 0.9619\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9453 - val_loss: 0.1761 - val_accuracy: 0.9610\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9514 - val_loss: 0.1756 - val_accuracy: 0.9619\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9442 - val_loss: 0.1918 - val_accuracy: 0.9530\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9476 - val_loss: 0.1776 - val_accuracy: 0.9592\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9476 - val_loss: 0.1787 - val_accuracy: 0.9610\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9552 - val_loss: 0.1775 - val_accuracy: 0.9619\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9506 - val_loss: 0.1830 - val_accuracy: 0.9521\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9446 - val_loss: 0.1735 - val_accuracy: 0.9601\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.9495 - val_loss: 0.1713 - val_accuracy: 0.9601\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9510 - val_loss: 0.1823 - val_accuracy: 0.9521\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9491 - val_loss: 0.1771 - val_accuracy: 0.9619\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9533 - val_loss: 0.1930 - val_accuracy: 0.9486\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9461 - val_loss: 0.1778 - val_accuracy: 0.9628\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9552 - val_loss: 0.1821 - val_accuracy: 0.9557\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9522 - val_loss: 0.2592 - val_accuracy: 0.9149\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.9446 - val_loss: 0.2019 - val_accuracy: 0.9441\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9514 - val_loss: 0.2484 - val_accuracy: 0.9317\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9499 - val_loss: 0.1916 - val_accuracy: 0.9495\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9472 - val_loss: 0.1745 - val_accuracy: 0.9548\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9563 - val_loss: 0.1689 - val_accuracy: 0.9637\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9465 - val_loss: 0.1714 - val_accuracy: 0.9574\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9522 - val_loss: 0.2065 - val_accuracy: 0.9388\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9510 - val_loss: 0.2025 - val_accuracy: 0.9468\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9563 - val_loss: 0.1741 - val_accuracy: 0.9557\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9503 - val_loss: 0.2399 - val_accuracy: 0.9229\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9503 - val_loss: 0.2905 - val_accuracy: 0.9113\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9499 - val_loss: 0.3197 - val_accuracy: 0.9016\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9499 - val_loss: 0.2330 - val_accuracy: 0.9344\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9537 - val_loss: 0.2832 - val_accuracy: 0.9016\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9518 - val_loss: 0.1674 - val_accuracy: 0.9637\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9503 - val_loss: 0.2105 - val_accuracy: 0.9388\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9506 - val_loss: 0.1793 - val_accuracy: 0.9548\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9487 - val_loss: 0.1672 - val_accuracy: 0.9628\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9552 - val_loss: 0.5602 - val_accuracy: 0.7934\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9552 - val_loss: 0.2151 - val_accuracy: 0.9353\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9563 - val_loss: 0.1694 - val_accuracy: 0.9592\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9503 - val_loss: 0.2081 - val_accuracy: 0.9441\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1616 - accuracy: 0.9506 - val_loss: 0.8029 - val_accuracy: 0.7447\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9495 - val_loss: 0.1775 - val_accuracy: 0.9548\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9552 - val_loss: 0.1696 - val_accuracy: 0.9619\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9499 - val_loss: 0.1929 - val_accuracy: 0.9486\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9503 - val_loss: 0.1654 - val_accuracy: 0.9654\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9556 - val_loss: 0.1869 - val_accuracy: 0.9495\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9537 - val_loss: 0.1719 - val_accuracy: 0.9557\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9541 - val_loss: 0.2217 - val_accuracy: 0.9379\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9541 - val_loss: 0.3209 - val_accuracy: 0.8839\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9533 - val_loss: 0.3536 - val_accuracy: 0.8723\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9582 - val_loss: 0.2088 - val_accuracy: 0.9433\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9552 - val_loss: 0.2189 - val_accuracy: 0.9317\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9548 - val_loss: 0.1752 - val_accuracy: 0.9539\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9594 - val_loss: 0.1975 - val_accuracy: 0.9433\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9548 - val_loss: 0.1593 - val_accuracy: 0.9610\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9525 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9472 - val_loss: 0.1902 - val_accuracy: 0.9468\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9514 - val_loss: 0.3132 - val_accuracy: 0.9025\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9484 - val_loss: 0.1581 - val_accuracy: 0.9628\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.9563 - val_loss: 0.1736 - val_accuracy: 0.9548\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9518 - val_loss: 0.1641 - val_accuracy: 0.9601\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9560 - val_loss: 0.2997 - val_accuracy: 0.8918\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9560 - val_loss: 0.2054 - val_accuracy: 0.9397\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9563 - val_loss: 0.2493 - val_accuracy: 0.9193\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9548 - val_loss: 0.1587 - val_accuracy: 0.9619\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9541 - val_loss: 0.3302 - val_accuracy: 0.8821\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9552 - val_loss: 0.1604 - val_accuracy: 0.9637\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9579 - val_loss: 0.1654 - val_accuracy: 0.9628\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9560 - val_loss: 0.1692 - val_accuracy: 0.9574\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9548 - val_loss: 0.3376 - val_accuracy: 0.8777\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9541 - val_loss: 0.1861 - val_accuracy: 0.9486\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9556 - val_loss: 0.1593 - val_accuracy: 0.9637\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9571 - val_loss: 0.2663 - val_accuracy: 0.9078\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9567 - val_loss: 0.2870 - val_accuracy: 0.9122\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9579 - val_loss: 0.2987 - val_accuracy: 0.8918\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9541 - val_loss: 0.1621 - val_accuracy: 0.9610\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9552 - val_loss: 0.2073 - val_accuracy: 0.9459\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9571 - val_loss: 0.1746 - val_accuracy: 0.9548\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9548 - val_loss: 0.1684 - val_accuracy: 0.9574\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9598 - val_loss: 0.1732 - val_accuracy: 0.9539\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9541 - val_loss: 0.1541 - val_accuracy: 0.9619\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9594 - val_loss: 0.4048 - val_accuracy: 0.8679\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9582 - val_loss: 0.1634 - val_accuracy: 0.9592\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9575 - val_loss: 0.2512 - val_accuracy: 0.9255\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9529 - val_loss: 0.1829 - val_accuracy: 0.9468\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9636 - val_loss: 0.1582 - val_accuracy: 0.9628\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9563 - val_loss: 0.1635 - val_accuracy: 0.9592\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9639 - val_loss: 0.3024 - val_accuracy: 0.9069\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9548 - val_loss: 0.3657 - val_accuracy: 0.8803\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9575 - val_loss: 0.1524 - val_accuracy: 0.9654\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9514 - val_loss: 0.1560 - val_accuracy: 0.9645\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9544 - val_loss: 0.2271 - val_accuracy: 0.9282\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9586 - val_loss: 0.1723 - val_accuracy: 0.9557\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9571 - val_loss: 0.1830 - val_accuracy: 0.9486\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9579 - val_loss: 0.1580 - val_accuracy: 0.9610\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9571 - val_loss: 0.1854 - val_accuracy: 0.9477\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9563 - val_loss: 0.2186 - val_accuracy: 0.9344\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9590 - val_loss: 0.2994 - val_accuracy: 0.9051\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9575 - val_loss: 0.1617 - val_accuracy: 0.9592\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9586 - val_loss: 0.1588 - val_accuracy: 0.9601\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9594 - val_loss: 0.1518 - val_accuracy: 0.9681\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9605 - val_loss: 0.1914 - val_accuracy: 0.9486\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9605 - val_loss: 0.3037 - val_accuracy: 0.9034\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9590 - val_loss: 0.1543 - val_accuracy: 0.9637\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.1557 - val_accuracy: 0.9637\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9601 - val_loss: 0.1500 - val_accuracy: 0.9645\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9586 - val_loss: 0.2880 - val_accuracy: 0.9087\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9560 - val_loss: 0.1636 - val_accuracy: 0.9574\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9586 - val_loss: 0.2652 - val_accuracy: 0.9184\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9582 - val_loss: 0.1682 - val_accuracy: 0.9530\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9590 - val_loss: 0.1463 - val_accuracy: 0.9628\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9632 - val_loss: 0.1509 - val_accuracy: 0.9628\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9590 - val_loss: 0.1498 - val_accuracy: 0.9637\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9632 - val_loss: 0.1497 - val_accuracy: 0.9610\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9605 - val_loss: 0.1780 - val_accuracy: 0.9512\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9567 - val_loss: 0.1485 - val_accuracy: 0.9628\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9571 - val_loss: 0.1501 - val_accuracy: 0.9654\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9601 - val_loss: 0.1558 - val_accuracy: 0.9601\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9601 - val_loss: 0.1528 - val_accuracy: 0.9645\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9636 - val_loss: 0.1701 - val_accuracy: 0.9566\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9582 - val_loss: 0.1850 - val_accuracy: 0.9486\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9571 - val_loss: 0.2754 - val_accuracy: 0.9167\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9666 - val_loss: 0.1701 - val_accuracy: 0.9583\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9651 - val_loss: 0.4790 - val_accuracy: 0.8369\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9575 - val_loss: 0.1500 - val_accuracy: 0.9681\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9582 - val_loss: 0.1530 - val_accuracy: 0.9645\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9582 - val_loss: 0.3202 - val_accuracy: 0.9016\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9613 - val_loss: 0.1489 - val_accuracy: 0.9645\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9617 - val_loss: 0.1787 - val_accuracy: 0.9521\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9636 - val_loss: 0.4874 - val_accuracy: 0.8449\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9605 - val_loss: 0.1734 - val_accuracy: 0.9530\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9601 - val_loss: 0.1969 - val_accuracy: 0.9406\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9563 - val_loss: 0.1927 - val_accuracy: 0.9424\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9563 - val_loss: 0.1465 - val_accuracy: 0.9610\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1412 - accuracy: 0.9609 - val_loss: 0.1574 - val_accuracy: 0.9601\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9613 - val_loss: 0.2437 - val_accuracy: 0.9264\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9636 - val_loss: 0.2963 - val_accuracy: 0.9078\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9560 - val_loss: 0.1841 - val_accuracy: 0.9477\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9613 - val_loss: 0.1437 - val_accuracy: 0.9619\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.9674 - val_loss: 0.3382 - val_accuracy: 0.8812\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9620 - val_loss: 0.1564 - val_accuracy: 0.9619\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9582 - val_loss: 0.2305 - val_accuracy: 0.9326\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9613 - val_loss: 0.1600 - val_accuracy: 0.9592\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9632 - val_loss: 0.1618 - val_accuracy: 0.9601\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.9579 - val_loss: 0.1480 - val_accuracy: 0.9663\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9643 - val_loss: 0.1931 - val_accuracy: 0.9441\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9609 - val_loss: 0.2163 - val_accuracy: 0.9397\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9601 - val_loss: 0.1527 - val_accuracy: 0.9663\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9605 - val_loss: 0.2850 - val_accuracy: 0.9043\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9639 - val_loss: 0.1497 - val_accuracy: 0.9654\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9571 - val_loss: 0.2053 - val_accuracy: 0.9459\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9605 - val_loss: 0.1418 - val_accuracy: 0.9637\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9617 - val_loss: 0.1601 - val_accuracy: 0.9628\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9651 - val_loss: 0.2499 - val_accuracy: 0.9176\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9609 - val_loss: 0.1491 - val_accuracy: 0.9610\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9582 - val_loss: 0.1752 - val_accuracy: 0.9495\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9609 - val_loss: 0.1411 - val_accuracy: 0.9628\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9609 - val_loss: 0.2195 - val_accuracy: 0.9335\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9647 - val_loss: 0.1407 - val_accuracy: 0.9681\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9655 - val_loss: 0.3304 - val_accuracy: 0.8963\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9639 - val_loss: 0.1445 - val_accuracy: 0.9637\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9636 - val_loss: 0.1496 - val_accuracy: 0.9672\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9582 - val_loss: 0.1385 - val_accuracy: 0.9645\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9586 - val_loss: 0.1381 - val_accuracy: 0.9681\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9613 - val_loss: 0.1880 - val_accuracy: 0.9441\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9628 - val_loss: 0.3424 - val_accuracy: 0.8821\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9590 - val_loss: 0.2880 - val_accuracy: 0.9034\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9658 - val_loss: 0.1546 - val_accuracy: 0.9601\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9601 - val_loss: 0.1402 - val_accuracy: 0.9681\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9605 - val_loss: 0.1644 - val_accuracy: 0.9566\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9624 - val_loss: 0.1486 - val_accuracy: 0.9610\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9613 - val_loss: 0.1384 - val_accuracy: 0.9690\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9605 - val_loss: 0.1799 - val_accuracy: 0.9459\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9636 - val_loss: 0.1364 - val_accuracy: 0.9637\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9636 - val_loss: 0.1839 - val_accuracy: 0.9495\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9647 - val_loss: 0.2181 - val_accuracy: 0.9379\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9647 - val_loss: 0.1483 - val_accuracy: 0.9619\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9662 - val_loss: 0.1537 - val_accuracy: 0.9592\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9666 - val_loss: 0.1875 - val_accuracy: 0.9495\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9647 - val_loss: 0.1352 - val_accuracy: 0.9681\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9647 - val_loss: 0.2227 - val_accuracy: 0.9335\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9666 - val_loss: 0.1364 - val_accuracy: 0.9619\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9651 - val_loss: 0.1619 - val_accuracy: 0.9574\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9624 - val_loss: 0.2583 - val_accuracy: 0.9193\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9662 - val_loss: 0.2082 - val_accuracy: 0.9371\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9620 - val_loss: 0.1374 - val_accuracy: 0.9628\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9639 - val_loss: 0.1415 - val_accuracy: 0.9663\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9632 - val_loss: 0.1956 - val_accuracy: 0.9397\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9613 - val_loss: 0.1475 - val_accuracy: 0.9628\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9670 - val_loss: 0.2838 - val_accuracy: 0.9113\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9643 - val_loss: 0.2508 - val_accuracy: 0.9202\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9655 - val_loss: 0.1314 - val_accuracy: 0.9681\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9655 - val_loss: 0.1521 - val_accuracy: 0.9592\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9605 - val_loss: 0.1479 - val_accuracy: 0.9601\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9651 - val_loss: 0.2670 - val_accuracy: 0.9167\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9658 - val_loss: 0.1887 - val_accuracy: 0.9415\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9628 - val_loss: 0.1807 - val_accuracy: 0.9486\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9647 - val_loss: 0.1370 - val_accuracy: 0.9610\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9658 - val_loss: 0.1427 - val_accuracy: 0.9672\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9639 - val_loss: 0.1685 - val_accuracy: 0.9512\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9689 - val_loss: 0.1547 - val_accuracy: 0.9592\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9639 - val_loss: 0.2276 - val_accuracy: 0.9300\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9639 - val_loss: 0.1493 - val_accuracy: 0.9601\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9613 - val_loss: 0.1474 - val_accuracy: 0.9601\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9632 - val_loss: 0.1842 - val_accuracy: 0.9441\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9609 - val_loss: 0.1465 - val_accuracy: 0.9601\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9674 - val_loss: 0.1355 - val_accuracy: 0.9628\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9643 - val_loss: 0.1505 - val_accuracy: 0.9628\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9670 - val_loss: 0.1338 - val_accuracy: 0.9628\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9639 - val_loss: 0.1364 - val_accuracy: 0.9690\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9639 - val_loss: 0.1298 - val_accuracy: 0.9681\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9666 - val_loss: 0.1634 - val_accuracy: 0.9539\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9624 - val_loss: 0.1337 - val_accuracy: 0.9628\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9624 - val_loss: 0.2325 - val_accuracy: 0.9317\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9639 - val_loss: 0.1306 - val_accuracy: 0.9699\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9636 - val_loss: 0.1324 - val_accuracy: 0.9707\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9620 - val_loss: 0.1491 - val_accuracy: 0.9601\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9674 - val_loss: 0.1288 - val_accuracy: 0.9707\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9620 - val_loss: 0.1621 - val_accuracy: 0.9548\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9628 - val_loss: 0.1769 - val_accuracy: 0.9468\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9658 - val_loss: 0.1282 - val_accuracy: 0.9699\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9685 - val_loss: 0.2351 - val_accuracy: 0.9309\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9662 - val_loss: 0.2002 - val_accuracy: 0.9441\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9685 - val_loss: 0.2232 - val_accuracy: 0.9326\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9632 - val_loss: 0.1514 - val_accuracy: 0.9592\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9681 - val_loss: 0.1414 - val_accuracy: 0.9610\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9655 - val_loss: 0.1298 - val_accuracy: 0.9699\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9632 - val_loss: 0.1440 - val_accuracy: 0.9601\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9651 - val_loss: 0.3059 - val_accuracy: 0.9043\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9651 - val_loss: 0.1933 - val_accuracy: 0.9406\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9643 - val_loss: 0.1614 - val_accuracy: 0.9539\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9632 - val_loss: 0.2321 - val_accuracy: 0.9273\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9666 - val_loss: 0.2053 - val_accuracy: 0.9415\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9651 - val_loss: 0.1809 - val_accuracy: 0.9459\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9681 - val_loss: 0.1487 - val_accuracy: 0.9628\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9674 - val_loss: 0.1276 - val_accuracy: 0.9707\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9632 - val_loss: 0.1407 - val_accuracy: 0.9672\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9662 - val_loss: 0.1337 - val_accuracy: 0.9681\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9670 - val_loss: 0.1258 - val_accuracy: 0.9707\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9677 - val_loss: 0.1255 - val_accuracy: 0.9672\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9658 - val_loss: 0.1409 - val_accuracy: 0.9601\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9681 - val_loss: 0.1245 - val_accuracy: 0.9654\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9704 - val_loss: 0.1404 - val_accuracy: 0.9628\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9647 - val_loss: 0.1357 - val_accuracy: 0.9610\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9605 - val_loss: 0.1593 - val_accuracy: 0.9539\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9655 - val_loss: 0.1580 - val_accuracy: 0.9539\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9639 - val_loss: 0.2249 - val_accuracy: 0.9264\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9636 - val_loss: 0.2416 - val_accuracy: 0.9264\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9279\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 0.1]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694673668417104\n",
      "0.9863829787234043\n",
      "0.9242424242424243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "[[ 0.5]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695652173913043\n",
      "0.984251968503937\n",
      "0.9233610341643583\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
