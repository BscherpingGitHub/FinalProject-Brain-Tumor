{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  16.0  1381.3 ...  4.3  1.0  0.0]\n",
      " [ 0.0  8.3  347.9 ...  2.6  1.0  0.0]\n",
      " [ 0.0  11.6  594.1 ...  4.3  0.9  0.0]\n",
      " ...\n",
      " [ 0.0  4.6  357.6 ...  6.8  0.9  0.0]\n",
      " [ 0.0  7.5  875.0 ...  5.1  1.0  0.0]\n",
      " [ 0.0  6.7  518.7 ...  6.0  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 3]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 3]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 12ms/step - loss: 0.6936 - accuracy: 0.5216 - val_loss: 0.6876 - val_accuracy: 0.6445\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6876 - accuracy: 0.5566 - val_loss: 0.6881 - val_accuracy: 0.4920\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6836 - accuracy: 0.5706 - val_loss: 0.6792 - val_accuracy: 0.6223\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5926 - val_loss: 0.6812 - val_accuracy: 0.5381\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6760 - accuracy: 0.5945 - val_loss: 0.6723 - val_accuracy: 0.6534\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6736 - accuracy: 0.6086 - val_loss: 0.6712 - val_accuracy: 0.5833\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.6044 - val_loss: 0.6665 - val_accuracy: 0.6605\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.6150 - val_loss: 0.6663 - val_accuracy: 0.6090\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.6226 - val_loss: 0.6700 - val_accuracy: 0.5621\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6621 - accuracy: 0.6162 - val_loss: 0.6623 - val_accuracy: 0.6348\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6613 - accuracy: 0.6276 - val_loss: 0.6750 - val_accuracy: 0.5461\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6606 - accuracy: 0.6253 - val_loss: 0.6608 - val_accuracy: 0.6197\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6241 - val_loss: 0.6611 - val_accuracy: 0.6055\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.6355 - val_loss: 0.6581 - val_accuracy: 0.6356\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6436\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.6450 - val_loss: 0.6764 - val_accuracy: 0.5603\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6568 - accuracy: 0.6333 - val_loss: 0.6545 - val_accuracy: 0.6418\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.6446 - val_loss: 0.6530 - val_accuracy: 0.6418\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.6439 - val_loss: 0.6544 - val_accuracy: 0.6445\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.6435 - val_loss: 0.6567 - val_accuracy: 0.6099\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6507 - val_loss: 0.6530 - val_accuracy: 0.6294\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.6378 - val_loss: 0.6550 - val_accuracy: 0.6206\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.6401 - val_loss: 0.6492 - val_accuracy: 0.6631\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.6431 - val_loss: 0.6484 - val_accuracy: 0.6551\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6510 - accuracy: 0.6458 - val_loss: 0.6483 - val_accuracy: 0.6596\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6498 - accuracy: 0.6420 - val_loss: 0.6537 - val_accuracy: 0.6197\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6382 - val_loss: 0.6479 - val_accuracy: 0.6463\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.6465 - val_loss: 0.6496 - val_accuracy: 0.6534\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6424 - val_loss: 0.6572 - val_accuracy: 0.6055\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6431 - val_loss: 0.6516 - val_accuracy: 0.6410\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.6401 - val_loss: 0.6531 - val_accuracy: 0.6241\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6482 - accuracy: 0.6424 - val_loss: 0.6534 - val_accuracy: 0.6436\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6492 - accuracy: 0.6409 - val_loss: 0.6479 - val_accuracy: 0.6622\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6484 - accuracy: 0.6390 - val_loss: 0.6468 - val_accuracy: 0.6640\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6386 - val_loss: 0.6470 - val_accuracy: 0.6631\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6443 - val_loss: 0.6460 - val_accuracy: 0.6569\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6454 - val_loss: 0.6492 - val_accuracy: 0.6383\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6393 - val_loss: 0.6466 - val_accuracy: 0.6640\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6464 - accuracy: 0.6386 - val_loss: 0.6595 - val_accuracy: 0.6011\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6359 - val_loss: 0.6495 - val_accuracy: 0.6401\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.6390 - val_loss: 0.6480 - val_accuracy: 0.6410\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6483 - accuracy: 0.6443 - val_loss: 0.6456 - val_accuracy: 0.6525\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6474 - accuracy: 0.6473 - val_loss: 0.6527 - val_accuracy: 0.6472\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6483 - accuracy: 0.6450 - val_loss: 0.6456 - val_accuracy: 0.6613\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6484 - val_loss: 0.6454 - val_accuracy: 0.6507\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.6431 - val_loss: 0.6479 - val_accuracy: 0.6410\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6481 - val_loss: 0.6568 - val_accuracy: 0.6365\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6473 - val_loss: 0.6456 - val_accuracy: 0.6605\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6469 - val_loss: 0.6454 - val_accuracy: 0.6569\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.6435 - val_loss: 0.6464 - val_accuracy: 0.6454\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6458 - val_loss: 0.6481 - val_accuracy: 0.6569\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.6374 - val_loss: 0.6455 - val_accuracy: 0.6613\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.6496 - val_loss: 0.6467 - val_accuracy: 0.6613\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6488 - accuracy: 0.6488 - val_loss: 0.6461 - val_accuracy: 0.6436\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6466 - accuracy: 0.6507 - val_loss: 0.6455 - val_accuracy: 0.6551\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.6492 - val_loss: 0.6489 - val_accuracy: 0.6401\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6416 - val_loss: 0.6457 - val_accuracy: 0.6649\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6473 - val_loss: 0.6463 - val_accuracy: 0.6454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6409 - val_loss: 0.6463 - val_accuracy: 0.6454\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6473 - val_loss: 0.6455 - val_accuracy: 0.6560\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6500 - val_loss: 0.6469 - val_accuracy: 0.6418\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6481 - accuracy: 0.6435 - val_loss: 0.6475 - val_accuracy: 0.6454\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6481 - accuracy: 0.6409 - val_loss: 0.6457 - val_accuracy: 0.6454\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6476 - accuracy: 0.6435 - val_loss: 0.6453 - val_accuracy: 0.6578\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6482 - accuracy: 0.6382 - val_loss: 0.6477 - val_accuracy: 0.6596\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6443 - val_loss: 0.6452 - val_accuracy: 0.6507\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6485 - accuracy: 0.6431 - val_loss: 0.6486 - val_accuracy: 0.6578\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.6488 - val_loss: 0.6480 - val_accuracy: 0.6401\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6467 - accuracy: 0.6439 - val_loss: 0.6501 - val_accuracy: 0.6374\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6473 - val_loss: 0.6508 - val_accuracy: 0.6321\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.6469 - val_loss: 0.6463 - val_accuracy: 0.6463\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6416 - val_loss: 0.6468 - val_accuracy: 0.6605\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.6435 - val_loss: 0.6464 - val_accuracy: 0.6640\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.6473 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6446 - val_loss: 0.6468 - val_accuracy: 0.6605\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.6465 - val_loss: 0.6461 - val_accuracy: 0.6622\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6492 - val_loss: 0.6482 - val_accuracy: 0.6418\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6488 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6431 - val_loss: 0.6584 - val_accuracy: 0.6064\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6488 - val_loss: 0.6572 - val_accuracy: 0.6401\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6500 - val_loss: 0.6516 - val_accuracy: 0.6294\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6390 - val_loss: 0.6454 - val_accuracy: 0.6596\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6464 - accuracy: 0.6507 - val_loss: 0.6467 - val_accuracy: 0.6445\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6477 - val_loss: 0.6461 - val_accuracy: 0.6436\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6427 - val_loss: 0.6545 - val_accuracy: 0.6197\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6474 - accuracy: 0.6443 - val_loss: 0.6495 - val_accuracy: 0.6392\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.6473 - val_loss: 0.6477 - val_accuracy: 0.6410\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6474 - accuracy: 0.6519 - val_loss: 0.6598 - val_accuracy: 0.6055\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6424 - val_loss: 0.6467 - val_accuracy: 0.6445\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.6473 - val_loss: 0.6465 - val_accuracy: 0.6631\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.6473 - val_loss: 0.6481 - val_accuracy: 0.6401\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6374 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6481 - val_loss: 0.6454 - val_accuracy: 0.6596\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6469 - val_loss: 0.6489 - val_accuracy: 0.6410\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.6465 - val_loss: 0.6526 - val_accuracy: 0.6410\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.6534 - val_loss: 0.6548 - val_accuracy: 0.6454\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6470 - accuracy: 0.6481 - val_loss: 0.6464 - val_accuracy: 0.6436\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.6481 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6424 - val_loss: 0.6454 - val_accuracy: 0.6551\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6496 - val_loss: 0.6462 - val_accuracy: 0.6436\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6480 - accuracy: 0.6465 - val_loss: 0.6511 - val_accuracy: 0.6303\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6476 - accuracy: 0.6443 - val_loss: 0.6562 - val_accuracy: 0.6161\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6483 - accuracy: 0.6469 - val_loss: 0.6471 - val_accuracy: 0.6605\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6473 - accuracy: 0.6496 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6515 - val_loss: 0.6554 - val_accuracy: 0.6206\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.6454 - val_loss: 0.6514 - val_accuracy: 0.6401\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.6435 - val_loss: 0.6457 - val_accuracy: 0.6454\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6458 - val_loss: 0.6469 - val_accuracy: 0.6418\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6450 - val_loss: 0.6461 - val_accuracy: 0.6445\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6478 - accuracy: 0.6454 - val_loss: 0.6520 - val_accuracy: 0.6303\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6488 - val_loss: 0.6460 - val_accuracy: 0.6605\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6470 - accuracy: 0.6500 - val_loss: 0.6609 - val_accuracy: 0.6037\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6488 - accuracy: 0.6431 - val_loss: 0.6454 - val_accuracy: 0.6613\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.6462 - val_loss: 0.6460 - val_accuracy: 0.6445\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6435 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6480 - accuracy: 0.6424 - val_loss: 0.6520 - val_accuracy: 0.6383\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6483 - accuracy: 0.6469 - val_loss: 0.6475 - val_accuracy: 0.6427\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6481 - val_loss: 0.6459 - val_accuracy: 0.6596\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6416 - val_loss: 0.6592 - val_accuracy: 0.6046\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6397 - val_loss: 0.6470 - val_accuracy: 0.6613\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6473 - val_loss: 0.6454 - val_accuracy: 0.6613\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6488 - val_loss: 0.6562 - val_accuracy: 0.6436\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6465 - accuracy: 0.6420 - val_loss: 0.6501 - val_accuracy: 0.6507\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6465 - accuracy: 0.6378 - val_loss: 0.6467 - val_accuracy: 0.6454\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6483 - accuracy: 0.6465 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6458 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6439 - val_loss: 0.6457 - val_accuracy: 0.6640\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6416 - val_loss: 0.6490 - val_accuracy: 0.6569\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6481 - accuracy: 0.6488 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6477 - val_loss: 0.6595 - val_accuracy: 0.6356\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6503 - val_loss: 0.6464 - val_accuracy: 0.6436\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6435 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.6469 - val_loss: 0.6457 - val_accuracy: 0.6454\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6473 - accuracy: 0.6454 - val_loss: 0.6562 - val_accuracy: 0.6170\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6493 - accuracy: 0.6420 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6469 - val_loss: 0.6504 - val_accuracy: 0.6480\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6471 - accuracy: 0.6420 - val_loss: 0.6456 - val_accuracy: 0.6498\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.6462 - val_loss: 0.6466 - val_accuracy: 0.6631\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6450 - val_loss: 0.6458 - val_accuracy: 0.6463\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6464 - accuracy: 0.6390 - val_loss: 0.6463 - val_accuracy: 0.6640\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6466 - accuracy: 0.6462 - val_loss: 0.6463 - val_accuracy: 0.6454\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6450 - val_loss: 0.6496 - val_accuracy: 0.6392\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6503 - val_loss: 0.6461 - val_accuracy: 0.6427\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.6416 - val_loss: 0.6464 - val_accuracy: 0.6649\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6473 - accuracy: 0.6465 - val_loss: 0.6458 - val_accuracy: 0.6658\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6468 - accuracy: 0.6465 - val_loss: 0.6464 - val_accuracy: 0.6640\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.6481 - val_loss: 0.6571 - val_accuracy: 0.6418\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6458 - val_loss: 0.6454 - val_accuracy: 0.6560\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6480 - accuracy: 0.6458 - val_loss: 0.6456 - val_accuracy: 0.6516\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6482 - accuracy: 0.6465 - val_loss: 0.6471 - val_accuracy: 0.6605\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6477 - val_loss: 0.6524 - val_accuracy: 0.6392\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6439 - val_loss: 0.6483 - val_accuracy: 0.6418\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6409 - val_loss: 0.6460 - val_accuracy: 0.6427\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.6511 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6480 - accuracy: 0.6519 - val_loss: 0.6454 - val_accuracy: 0.6569\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6446 - val_loss: 0.6453 - val_accuracy: 0.6578\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6420 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6409 - val_loss: 0.6456 - val_accuracy: 0.6622\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6488 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6484 - val_loss: 0.6506 - val_accuracy: 0.6348\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6393 - val_loss: 0.6460 - val_accuracy: 0.6454\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6458 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6469 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6470 - accuracy: 0.6405 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6474 - accuracy: 0.6454 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6503 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6470 - accuracy: 0.6424 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6503 - val_loss: 0.6452 - val_accuracy: 0.6551\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6465 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6481 - val_loss: 0.6462 - val_accuracy: 0.6436\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6468 - accuracy: 0.6526 - val_loss: 0.6576 - val_accuracy: 0.6108\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6439 - val_loss: 0.6496 - val_accuracy: 0.6392\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6424 - val_loss: 0.6475 - val_accuracy: 0.6427\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6427 - val_loss: 0.6461 - val_accuracy: 0.6445\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6481 - accuracy: 0.6386 - val_loss: 0.6496 - val_accuracy: 0.6392\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6465 - val_loss: 0.6458 - val_accuracy: 0.6463\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6479 - accuracy: 0.6386 - val_loss: 0.6465 - val_accuracy: 0.6427\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6470 - accuracy: 0.6465 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.6515 - val_loss: 0.6509 - val_accuracy: 0.6339\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.6462 - val_loss: 0.6464 - val_accuracy: 0.6436\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6473 - val_loss: 0.6492 - val_accuracy: 0.6392\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6409 - val_loss: 0.6511 - val_accuracy: 0.6436\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6476 - accuracy: 0.6496 - val_loss: 0.6495 - val_accuracy: 0.6392\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6482 - accuracy: 0.6412 - val_loss: 0.6452 - val_accuracy: 0.6507\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6476 - accuracy: 0.6416 - val_loss: 0.6467 - val_accuracy: 0.6631\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6496 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6484 - val_loss: 0.6508 - val_accuracy: 0.6348\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.6439 - val_loss: 0.6476 - val_accuracy: 0.6436\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6439 - val_loss: 0.6455 - val_accuracy: 0.6507\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6473 - val_loss: 0.6469 - val_accuracy: 0.6436\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.6462 - val_loss: 0.6483 - val_accuracy: 0.6418\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6454 - val_loss: 0.6456 - val_accuracy: 0.6445\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6405 - val_loss: 0.6478 - val_accuracy: 0.6613\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6481 - val_loss: 0.6475 - val_accuracy: 0.6427\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6458 - accuracy: 0.6515 - val_loss: 0.6454 - val_accuracy: 0.6551\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6439 - val_loss: 0.6480 - val_accuracy: 0.6569\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6479 - accuracy: 0.6465 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.6439 - val_loss: 0.6458 - val_accuracy: 0.6463\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6478 - accuracy: 0.6488 - val_loss: 0.6510 - val_accuracy: 0.6321\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6454 - val_loss: 0.6482 - val_accuracy: 0.6401\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6367 - val_loss: 0.6471 - val_accuracy: 0.6605\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6483 - accuracy: 0.6465 - val_loss: 0.6484 - val_accuracy: 0.6569\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6465 - accuracy: 0.6526 - val_loss: 0.6471 - val_accuracy: 0.6410\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6469 - val_loss: 0.6464 - val_accuracy: 0.6436\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.6484 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6470 - accuracy: 0.6473 - val_loss: 0.6484 - val_accuracy: 0.6569\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6478 - accuracy: 0.6458 - val_loss: 0.6552 - val_accuracy: 0.6206\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.6420 - val_loss: 0.6488 - val_accuracy: 0.6392\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6476 - accuracy: 0.6481 - val_loss: 0.6524 - val_accuracy: 0.6277\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6424 - val_loss: 0.6481 - val_accuracy: 0.6401\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6393 - val_loss: 0.6461 - val_accuracy: 0.6622\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6470 - accuracy: 0.6443 - val_loss: 0.6455 - val_accuracy: 0.6613\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6446 - val_loss: 0.6558 - val_accuracy: 0.6197\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6443 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6473 - accuracy: 0.6530 - val_loss: 0.6470 - val_accuracy: 0.6418\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6466 - accuracy: 0.6450 - val_loss: 0.6480 - val_accuracy: 0.6410\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6479 - accuracy: 0.6420 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6469 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6484 - val_loss: 0.6540 - val_accuracy: 0.6259\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.6386 - val_loss: 0.6538 - val_accuracy: 0.6250\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.6401 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.6477 - val_loss: 0.6501 - val_accuracy: 0.6383\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6435 - val_loss: 0.6456 - val_accuracy: 0.6480\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6478 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6470 - accuracy: 0.6477 - val_loss: 0.6462 - val_accuracy: 0.6622\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6450 - val_loss: 0.6475 - val_accuracy: 0.6427\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6475 - accuracy: 0.6454 - val_loss: 0.6514 - val_accuracy: 0.6418\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6484 - accuracy: 0.6336 - val_loss: 0.6535 - val_accuracy: 0.6418\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6450 - val_loss: 0.6454 - val_accuracy: 0.6613\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6443 - val_loss: 0.6452 - val_accuracy: 0.6498\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6454 - val_loss: 0.6492 - val_accuracy: 0.6569\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6467 - accuracy: 0.6469 - val_loss: 0.6471 - val_accuracy: 0.6410\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6397 - val_loss: 0.6514 - val_accuracy: 0.6410\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.6465 - val_loss: 0.6459 - val_accuracy: 0.6596\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6462 - val_loss: 0.6563 - val_accuracy: 0.6161\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.6435 - val_loss: 0.6545 - val_accuracy: 0.6232\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6481 - accuracy: 0.6446 - val_loss: 0.6494 - val_accuracy: 0.6569\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6482 - accuracy: 0.6511 - val_loss: 0.6500 - val_accuracy: 0.6383\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6473 - accuracy: 0.6503 - val_loss: 0.6515 - val_accuracy: 0.6312\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6473 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.6465 - val_loss: 0.6458 - val_accuracy: 0.6649\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6449 - accuracy: 0.6435 - val_loss: 0.6565 - val_accuracy: 0.6144\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6473 - val_loss: 0.6452 - val_accuracy: 0.6507\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6503 - val_loss: 0.6465 - val_accuracy: 0.6640\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6483 - accuracy: 0.6458 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6481 - accuracy: 0.6420 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6473 - val_loss: 0.6705 - val_accuracy: 0.5745\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6485 - accuracy: 0.6378 - val_loss: 0.6452 - val_accuracy: 0.6498\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6553 - val_loss: 0.6690 - val_accuracy: 0.5771\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6480 - accuracy: 0.6367 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6481 - accuracy: 0.6458 - val_loss: 0.6469 - val_accuracy: 0.6613\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6431 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6431 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6424 - val_loss: 0.6467 - val_accuracy: 0.6445\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6465 - val_loss: 0.6452 - val_accuracy: 0.6516\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6515 - val_loss: 0.6532 - val_accuracy: 0.6285\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6446 - val_loss: 0.6459 - val_accuracy: 0.6596\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6463 - accuracy: 0.6427 - val_loss: 0.6527 - val_accuracy: 0.6285\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6479 - accuracy: 0.6481 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6465 - accuracy: 0.6545 - val_loss: 0.6520 - val_accuracy: 0.6321\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6471 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6500 - val_loss: 0.6474 - val_accuracy: 0.6436\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6526 - val_loss: 0.6539 - val_accuracy: 0.6250\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.6382 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6481 - accuracy: 0.6431 - val_loss: 0.6461 - val_accuracy: 0.6605\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6481 - accuracy: 0.6450 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6488 - val_loss: 0.6469 - val_accuracy: 0.6436\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6468 - accuracy: 0.6443 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6469 - accuracy: 0.6496 - val_loss: 0.6472 - val_accuracy: 0.6605\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6486 - accuracy: 0.6458 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6471 - accuracy: 0.6469 - val_loss: 0.6523 - val_accuracy: 0.6401\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6481 - accuracy: 0.6435 - val_loss: 0.6483 - val_accuracy: 0.6418\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6468 - accuracy: 0.6530 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6477 - accuracy: 0.6511 - val_loss: 0.6510 - val_accuracy: 0.6330\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6466 - accuracy: 0.6473 - val_loss: 0.6472 - val_accuracy: 0.6605\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6478 - accuracy: 0.6481 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6469 - accuracy: 0.6473 - val_loss: 0.6458 - val_accuracy: 0.6649\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6470 - accuracy: 0.6412 - val_loss: 0.6475 - val_accuracy: 0.6427\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6479 - accuracy: 0.6496 - val_loss: 0.6505 - val_accuracy: 0.6356\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6480 - accuracy: 0.6393 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.6481 - accuracy: 0.6469 - val_loss: 0.6456 - val_accuracy: 0.6498\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6475 - accuracy: 0.6473 - val_loss: 0.6452 - val_accuracy: 0.6498\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6472 - accuracy: 0.6416 - val_loss: 0.6461 - val_accuracy: 0.6613\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6471 - accuracy: 0.6439 - val_loss: 0.6531 - val_accuracy: 0.6410\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6483 - accuracy: 0.6443 - val_loss: 0.6456 - val_accuracy: 0.6489\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6475 - accuracy: 0.6458 - val_loss: 0.6481 - val_accuracy: 0.6410\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6471 - accuracy: 0.6409 - val_loss: 0.6509 - val_accuracy: 0.6454\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6478 - accuracy: 0.6458 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6477 - accuracy: 0.6473 - val_loss: 0.6482 - val_accuracy: 0.6401\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6471 - accuracy: 0.6431 - val_loss: 0.6475 - val_accuracy: 0.6613\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6466 - accuracy: 0.6534 - val_loss: 0.6634 - val_accuracy: 0.5966\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6482 - accuracy: 0.6454 - val_loss: 0.6452 - val_accuracy: 0.6489\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6483 - accuracy: 0.6488 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6482 - accuracy: 0.6409 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6471 - accuracy: 0.6522 - val_loss: 0.6528 - val_accuracy: 0.6294\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6480 - accuracy: 0.6424 - val_loss: 0.6492 - val_accuracy: 0.6569\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6496 - val_loss: 0.6459 - val_accuracy: 0.6631\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6483 - accuracy: 0.6492 - val_loss: 0.6492 - val_accuracy: 0.6383\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6468 - accuracy: 0.6420 - val_loss: 0.6482 - val_accuracy: 0.6569\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6507 - val_loss: 0.6454 - val_accuracy: 0.6560\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6409 - val_loss: 0.6478 - val_accuracy: 0.6410\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6454 - val_loss: 0.6455 - val_accuracy: 0.6622\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6450 - val_loss: 0.6539 - val_accuracy: 0.6250\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.6450 - val_loss: 0.6461 - val_accuracy: 0.6445\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6515 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6507 - val_loss: 0.6476 - val_accuracy: 0.6454\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6487 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6613\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6511 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6435 - val_loss: 0.6473 - val_accuracy: 0.6436\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6469 - val_loss: 0.6497 - val_accuracy: 0.6401\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6465 - val_loss: 0.6502 - val_accuracy: 0.6374\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6515 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6397 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6446 - val_loss: 0.6493 - val_accuracy: 0.6392\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6470 - accuracy: 0.6446 - val_loss: 0.6487 - val_accuracy: 0.6392\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6469 - val_loss: 0.6455 - val_accuracy: 0.6534\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6471 - accuracy: 0.6420 - val_loss: 0.6485 - val_accuracy: 0.6418\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6470 - accuracy: 0.6427 - val_loss: 0.6473 - val_accuracy: 0.6436\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6464 - accuracy: 0.6431 - val_loss: 0.6491 - val_accuracy: 0.6401\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6473 - val_loss: 0.6536 - val_accuracy: 0.6436\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6450 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6503 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6492 - val_loss: 0.6498 - val_accuracy: 0.6401\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6507 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6458 - val_loss: 0.6480 - val_accuracy: 0.6401\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6405 - val_loss: 0.6458 - val_accuracy: 0.6631\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6401 - val_loss: 0.6516 - val_accuracy: 0.6401\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6450 - val_loss: 0.6492 - val_accuracy: 0.6569\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6553 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6471 - accuracy: 0.6462 - val_loss: 0.6479 - val_accuracy: 0.6622\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6481 - val_loss: 0.6558 - val_accuracy: 0.6197\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6483 - accuracy: 0.6450 - val_loss: 0.6468 - val_accuracy: 0.6631\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6473 - val_loss: 0.6507 - val_accuracy: 0.6348\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6431 - val_loss: 0.6516 - val_accuracy: 0.6303\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6511 - val_loss: 0.6524 - val_accuracy: 0.6392\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6431 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6439 - val_loss: 0.6484 - val_accuracy: 0.6569\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6511 - val_loss: 0.6463 - val_accuracy: 0.6631\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6464 - accuracy: 0.6454 - val_loss: 0.6455 - val_accuracy: 0.6622\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6481 - val_loss: 0.6540 - val_accuracy: 0.6259\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6471 - accuracy: 0.6454 - val_loss: 0.6469 - val_accuracy: 0.6605\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6496 - val_loss: 0.6452 - val_accuracy: 0.6507\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6420 - val_loss: 0.6452 - val_accuracy: 0.6551\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6466 - accuracy: 0.6458 - val_loss: 0.6462 - val_accuracy: 0.6622\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6466 - accuracy: 0.6462 - val_loss: 0.6455 - val_accuracy: 0.6613\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6488 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6439 - val_loss: 0.6645 - val_accuracy: 0.6206\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6503 - val_loss: 0.6487 - val_accuracy: 0.6560\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6439 - val_loss: 0.6490 - val_accuracy: 0.6551\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6439 - val_loss: 0.6502 - val_accuracy: 0.6480\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6503 - val_loss: 0.6598 - val_accuracy: 0.6055\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.6431 - val_loss: 0.6455 - val_accuracy: 0.6605\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6431 - val_loss: 0.6467 - val_accuracy: 0.6445\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6435 - val_loss: 0.6536 - val_accuracy: 0.6259\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6424 - val_loss: 0.6483 - val_accuracy: 0.6418\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6458 - accuracy: 0.6435 - val_loss: 0.6497 - val_accuracy: 0.6534\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6541 - val_loss: 0.6517 - val_accuracy: 0.6303\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6443 - val_loss: 0.6455 - val_accuracy: 0.6631\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6458 - val_loss: 0.6471 - val_accuracy: 0.6418\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6405 - val_loss: 0.6529 - val_accuracy: 0.6303\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6469 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6484 - val_loss: 0.6458 - val_accuracy: 0.6463\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6409 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6488 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6522 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6439 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6468 - accuracy: 0.6519 - val_loss: 0.6525 - val_accuracy: 0.6285\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6386 - val_loss: 0.6483 - val_accuracy: 0.6569\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.6473 - val_loss: 0.6464 - val_accuracy: 0.6445\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6470 - accuracy: 0.6420 - val_loss: 0.6520 - val_accuracy: 0.6312\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6482 - accuracy: 0.6439 - val_loss: 0.6453 - val_accuracy: 0.6534\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6461 - accuracy: 0.6473 - val_loss: 0.6498 - val_accuracy: 0.6401\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6420 - val_loss: 0.6452 - val_accuracy: 0.6551\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6484 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6500 - val_loss: 0.6473 - val_accuracy: 0.6427\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6424 - val_loss: 0.6474 - val_accuracy: 0.6436\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6431 - val_loss: 0.6462 - val_accuracy: 0.6436\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.6439 - val_loss: 0.6493 - val_accuracy: 0.6569\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6487 - accuracy: 0.6526 - val_loss: 0.6535 - val_accuracy: 0.6268\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6484 - accuracy: 0.6409 - val_loss: 0.6461 - val_accuracy: 0.6427\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6500 - val_loss: 0.6476 - val_accuracy: 0.6427\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6474 - accuracy: 0.6473 - val_loss: 0.6644 - val_accuracy: 0.5931\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6477 - accuracy: 0.6382 - val_loss: 0.6552 - val_accuracy: 0.6445\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6500 - val_loss: 0.6453 - val_accuracy: 0.6578\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6472 - accuracy: 0.6530 - val_loss: 0.6535 - val_accuracy: 0.6268\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6477 - accuracy: 0.6431 - val_loss: 0.6452 - val_accuracy: 0.6498\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6477 - accuracy: 0.6393 - val_loss: 0.6469 - val_accuracy: 0.6436\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.6443 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6464 - accuracy: 0.6427 - val_loss: 0.6458 - val_accuracy: 0.6463\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6475 - accuracy: 0.6435 - val_loss: 0.6516 - val_accuracy: 0.6401\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6482 - accuracy: 0.6427 - val_loss: 0.6468 - val_accuracy: 0.6445\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6431 - val_loss: 0.6454 - val_accuracy: 0.6560\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6435 - val_loss: 0.6490 - val_accuracy: 0.6578\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6446 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6412 - val_loss: 0.6456 - val_accuracy: 0.6480\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6484 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.6481 - val_loss: 0.6456 - val_accuracy: 0.6507\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6439 - val_loss: 0.6477 - val_accuracy: 0.6596\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6484 - val_loss: 0.6454 - val_accuracy: 0.6560\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6483 - accuracy: 0.6446 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6409 - val_loss: 0.6453 - val_accuracy: 0.6534\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.6409 - val_loss: 0.6467 - val_accuracy: 0.6631\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6468 - accuracy: 0.6446 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6446 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6475 - accuracy: 0.6443 - val_loss: 0.6458 - val_accuracy: 0.6640\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6476 - accuracy: 0.6496 - val_loss: 0.6528 - val_accuracy: 0.6401\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6424 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6472 - accuracy: 0.6488 - val_loss: 0.6457 - val_accuracy: 0.6454\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6386 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.6462 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6443 - val_loss: 0.6473 - val_accuracy: 0.6613\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6443 - val_loss: 0.6472 - val_accuracy: 0.6427\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6507 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6460 - accuracy: 0.6507 - val_loss: 0.6507 - val_accuracy: 0.6454\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6485 - accuracy: 0.6519 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6484 - accuracy: 0.6390 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.6450 - val_loss: 0.6453 - val_accuracy: 0.6543\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6484 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6480 - accuracy: 0.6481 - val_loss: 0.6498 - val_accuracy: 0.6525\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6472 - accuracy: 0.6503 - val_loss: 0.6466 - val_accuracy: 0.6427\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6454 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6480 - accuracy: 0.6443 - val_loss: 0.6468 - val_accuracy: 0.6454\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6443 - val_loss: 0.6455 - val_accuracy: 0.6516\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6526 - val_loss: 0.6515 - val_accuracy: 0.6312\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6431 - val_loss: 0.6459 - val_accuracy: 0.6463\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6468 - accuracy: 0.6481 - val_loss: 0.6460 - val_accuracy: 0.6596\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6466 - accuracy: 0.6481 - val_loss: 0.6574 - val_accuracy: 0.6117\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6473 - accuracy: 0.6439 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6450 - val_loss: 0.6490 - val_accuracy: 0.6560\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6541 - val_loss: 0.6488 - val_accuracy: 0.6401\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6462 - val_loss: 0.6501 - val_accuracy: 0.6374\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6416 - val_loss: 0.6480 - val_accuracy: 0.6569\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6469 - val_loss: 0.6514 - val_accuracy: 0.6401\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6500 - val_loss: 0.6494 - val_accuracy: 0.6560\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6492 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6446 - val_loss: 0.6500 - val_accuracy: 0.6507\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6474 - accuracy: 0.6443 - val_loss: 0.6481 - val_accuracy: 0.6569\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6485 - accuracy: 0.6446 - val_loss: 0.6524 - val_accuracy: 0.6277\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6450 - val_loss: 0.6470 - val_accuracy: 0.6410\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6420 - val_loss: 0.6469 - val_accuracy: 0.6613\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6465 - accuracy: 0.6496 - val_loss: 0.6461 - val_accuracy: 0.6427\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6416 - val_loss: 0.6460 - val_accuracy: 0.6605\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.6511 - val_loss: 0.6496 - val_accuracy: 0.6392\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6469 - accuracy: 0.6367 - val_loss: 0.6452 - val_accuracy: 0.6498\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6471 - accuracy: 0.6458 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6467 - accuracy: 0.6507 - val_loss: 0.6501 - val_accuracy: 0.6374\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6483 - accuracy: 0.6386 - val_loss: 0.6452 - val_accuracy: 0.6489\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6466 - accuracy: 0.6450 - val_loss: 0.6457 - val_accuracy: 0.6454\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6473 - val_loss: 0.6483 - val_accuracy: 0.6569\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6467 - accuracy: 0.6473 - val_loss: 0.6527 - val_accuracy: 0.6294\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6479 - accuracy: 0.6454 - val_loss: 0.6496 - val_accuracy: 0.6543\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6473 - accuracy: 0.6500 - val_loss: 0.6472 - val_accuracy: 0.6418\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6420 - val_loss: 0.6453 - val_accuracy: 0.6551\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6473 - accuracy: 0.6427 - val_loss: 0.6452 - val_accuracy: 0.6551\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6473 - accuracy: 0.6450 - val_loss: 0.6452 - val_accuracy: 0.6551\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6476 - accuracy: 0.6458 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6466 - accuracy: 0.6439 - val_loss: 0.6498 - val_accuracy: 0.6534\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6469 - val_loss: 0.6455 - val_accuracy: 0.6613\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6466 - accuracy: 0.6526 - val_loss: 0.6498 - val_accuracy: 0.6401\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6474 - accuracy: 0.6446 - val_loss: 0.6461 - val_accuracy: 0.6445\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6480 - accuracy: 0.6488 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6474 - accuracy: 0.6427 - val_loss: 0.6479 - val_accuracy: 0.6596\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6455 - accuracy: 0.6477 - val_loss: 0.6453 - val_accuracy: 0.6569\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6568 - val_loss: 0.6453 - val_accuracy: 0.6560\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6526 - val_loss: 0.6452 - val_accuracy: 0.6525\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6462 - val_loss: 0.6477 - val_accuracy: 0.6613\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6469 - val_loss: 0.6454 - val_accuracy: 0.6596\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6481 - val_loss: 0.6490 - val_accuracy: 0.6410\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6435 - val_loss: 0.6455 - val_accuracy: 0.6507\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.6435 - val_loss: 0.6459 - val_accuracy: 0.6613\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6450 - val_loss: 0.6463 - val_accuracy: 0.6454\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.6469 - val_loss: 0.6452 - val_accuracy: 0.6534\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.6481 - val_loss: 0.6500 - val_accuracy: 0.6401\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6472 - accuracy: 0.6420 - val_loss: 0.6472 - val_accuracy: 0.6418\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.6465 - val_loss: 0.6459 - val_accuracy: 0.6596\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6476 - accuracy: 0.6530 - val_loss: 0.6455 - val_accuracy: 0.6507\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6492 - val_loss: 0.6464 - val_accuracy: 0.6445\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6503 - val_loss: 0.6595 - val_accuracy: 0.6037\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6488 - accuracy: 0.6401 - val_loss: 0.6464 - val_accuracy: 0.6640\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.6412 - val_loss: 0.6472 - val_accuracy: 0.6605\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6474 - accuracy: 0.6492 - val_loss: 0.6459 - val_accuracy: 0.6472\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6469 - val_loss: 0.6492 - val_accuracy: 0.6383\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.6446 - val_loss: 0.6459 - val_accuracy: 0.6463\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6401 - val_loss: 0.6546 - val_accuracy: 0.6472\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.6473 - val_loss: 0.6476 - val_accuracy: 0.6454\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6467 - accuracy: 0.6473 - val_loss: 0.6453 - val_accuracy: 0.6534\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6459 - accuracy: 0.6534 - val_loss: 0.6584 - val_accuracy: 0.6082\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6458 - accuracy: 0.6469 - val_loss: 0.6515 - val_accuracy: 0.6312\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6412 - val_loss: 0.6466 - val_accuracy: 0.6427\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.6465 - val_loss: 0.6484 - val_accuracy: 0.6569\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6469 - val_loss: 0.6493 - val_accuracy: 0.6392\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6477 - accuracy: 0.6439 - val_loss: 0.6452 - val_accuracy: 0.6543\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6470 - accuracy: 0.6469 - val_loss: 0.6456 - val_accuracy: 0.6631\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.6500 - val_loss: 0.6457 - val_accuracy: 0.6445\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6479 - accuracy: 0.6393 - val_loss: 0.6454 - val_accuracy: 0.6551\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6476 - accuracy: 0.6481 - val_loss: 0.6509 - val_accuracy: 0.6339\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6480 - accuracy: 0.6473 - val_loss: 0.6464 - val_accuracy: 0.6454\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6475 - accuracy: 0.6427 - val_loss: 0.6481 - val_accuracy: 0.6569\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6482 - accuracy: 0.6462 - val_loss: 0.6464 - val_accuracy: 0.6454\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6431\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.6454\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 0.8]\n",
      " [ 0.7]\n",
      " [ 0.8]\n",
      " [ 0.7]\n",
      " [ 0.4]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6203522504892368\n",
      "0.5345699831365935\n",
      "0.5742753623188407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.7]\n",
      " [ 0.3]\n",
      " [ 0.4]\n",
      " [ 0.3]\n",
      " [ 0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6099773242630385\n",
      "0.5412474849094567\n",
      "0.5735607675906184\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
