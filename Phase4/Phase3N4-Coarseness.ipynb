{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  14.3  1599.2 ...  5.6  1.0  0.0]\n",
      " [ 0.0  12.3  529.3 ...  3.4  1.0  0.0]\n",
      " [ 0.0  20.1  1556.7 ...  5.5  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  5.3  210.0 ...  2.5  1.0  0.0]\n",
      " [ 0.0  2.3  147.5 ...  4.7  0.9  0.0]\n",
      " [ 1.0  5.1  237.4 ...  2.2  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 13]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 13]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 4s 16ms/step - loss: 0.6924 - accuracy: 0.5395 - val_loss: 0.6910 - val_accuracy: 0.5691\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5456 - val_loss: 0.6894 - val_accuracy: 0.5691\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6905 - accuracy: 0.5456 - val_loss: 0.6881 - val_accuracy: 0.5691\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6900 - accuracy: 0.5456 - val_loss: 0.6872 - val_accuracy: 0.5691\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6896 - accuracy: 0.5456 - val_loss: 0.6867 - val_accuracy: 0.5691\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6894 - accuracy: 0.5456 - val_loss: 0.6862 - val_accuracy: 0.5691\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6893 - accuracy: 0.5456 - val_loss: 0.6858 - val_accuracy: 0.5691\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6892 - accuracy: 0.5456 - val_loss: 0.6855 - val_accuracy: 0.5691\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5456 - val_loss: 0.6853 - val_accuracy: 0.5691\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5456 - val_loss: 0.6852 - val_accuracy: 0.5691\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5456 - val_loss: 0.6851 - val_accuracy: 0.5691\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6851 - val_accuracy: 0.5691\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5456 - val_loss: 0.6850 - val_accuracy: 0.5691\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6849 - val_accuracy: 0.5691\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6849 - val_accuracy: 0.5691\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6849 - val_accuracy: 0.5691\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6849 - val_accuracy: 0.5691\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6846 - val_accuracy: 0.5691\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5691\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5456 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhaElEQVR4nO3dfZQV1Z3u8e9jAyJIIgFUBKWJl0Qlg0BajBd1odFcUBTNYOyYZNS8oCQkJpPJSJIb31Zc4xiT+DKOiA6Gu2RCEEVxFhhfghHf6UZARI2oRDog9DACoig0/O4fp7o9HE43p9ou+oXns1avU7VrV52922U/1K6qXYoIzMzMSrVfazfAzMzaFweHmZml4uAwM7NUHBxmZpaKg8PMzFLp1NoN2Bt69+4d5eXlrd0MM7N2pbq6+r8jok9heabBIWk0cBNQBtwZEdcVbB8FPAC8mRTdFxHXSPos8Ie8qp8GroiIGyV9KtlWDqwCvhIR7zTVjvLycqqqqj52f8zM9iWS/lqsPLOhKkllwK3AGOAY4KuSjilSdWFEDE1+rgGIiFfry4DPA+8Dc5L6k4HHImIQ8FiybmZme0mW1zhGACsj4o2I2AbMBMY14zhfBF6PiPrkGwdMT5anA+d83IaamVnpsgyOfsDqvPWapKzQCZKWSpovaXCR7ZXA7/PWD4mItQDJ58Et1WAzM9uzLINDRcoK5zdZDAyIiGOBW4D7dzmA1AU4G7gn9ZdLEyRVSaqqra1Nu7uZmTUiy+CoAQ7PW+8PrMmvEBGbI2JLsjwP6Cypd16VMcDiiFiXV7ZOUl+A5HN9sS+PiKkRURERFX367HZTgJmZNVOWwbEIGCRpYHLmUAnMza8g6VBJSpZHJO3ZkFflq+w6TEVyjAuT5QvJ3ZVlZmZ7SWa340ZEnaRJwB/J3Y47LSJeknRpsn0KMB6YKKkO2ApURjJdr6RuwOnAJQWHvg6YJelbwFvAeVn1wczMdqd9YVr1ioqKaNZzHPMnw9svtnyDzMz2lkP/DsZct+d6RUiqjoiKwnJPOWJmZqnsE1OONFszU9rMrCPzGYeZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapZBockkZLelXSSkmTi2wfJWmTpCXJzxV52w6SNFvSK5JelnRCUn6VpL/l7XNGln0wM7NddcrqwJLKgFuB04EaYJGkuRGxoqDqwogYW+QQNwEPRcR4SV2AbnnbfhsRN2TScDMza1KWZxwjgJUR8UZEbANmAuNK2VHSJ4CTgf8AiIhtEbExq4aamVnpsgyOfsDqvPWapKzQCZKWSpovaXBS9mmgFrhL0guS7pTUPW+fSZKWSZomqWexL5c0QVKVpKra2tqW6I+ZmZFtcKhIWRSsLwYGRMSxwC3A/Ul5J2A4cFtEDAPeA+qvkdwGHAkMBdYCvy725RExNSIqIqKiT58+H6MbZmaWL8vgqAEOz1vvD6zJrxARmyNiS7I8D+gsqXeyb01EPJdUnU0uSIiIdRGxIyJ2AneQGxIzM7O9JMvgWAQMkjQwubhdCczNryDpUElKlkck7dkQEW8DqyV9Nqn6RWBFUq9v3iHOBZZn2AczMyuQ2V1VEVEnaRLwR6AMmBYRL0m6NNk+BRgPTJRUB2wFKiOifjjr+8CMJHTeAC5Oyq+XNJTcsNcq4JKs+mBmZrvTR3+nO66Kioqoqqpq7WaYmbUrkqojoqKw3E+Om5lZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUsk0OCSNlvSqpJWSJhfZPkrSJklLkp8r8rYdJGm2pFckvSzphKT8U5IekfRa8tkzyz6YmdmuMgsOSWXArcAY4Bjgq5KOKVJ1YUQMTX6uySu/CXgoIo4CjgVeTsonA49FxCDgsWTdzMz2kizPOEYAKyPijYjYBswExpWyo6RPACcD/wEQEdsiYmOyeRwwPVmeDpzTgm02M7M9yDI4+gGr89ZrkrJCJ0haKmm+pMFJ2aeBWuAuSS9IulNS92TbIRGxFiD5PLjYl0uaIKlKUlVtbW2LdMjMzLINDhUpi4L1xcCAiDgWuAW4PynvBAwHbouIYcB7pBySioipEVERERV9+vRJ1XAzM2tclsFRAxyet94fWJNfISI2R8SWZHke0FlS72Tfmoh4Lqk6m1yQAKyT1Bcg+VyfXRfMzKxQlsGxCBgkaaCkLkAlMDe/gqRDJSlZHpG0Z0NEvA2slvTZpOoXgRXJ8lzgwmT5QuCBDPtgZmYFOmV14IiokzQJ+CNQBkyLiJckXZpsnwKMByZKqgO2ApURUT+c9X1gRhI6bwAXJ+XXAbMkfQt4Czgvqz6Ymdnu9NHf6Y6roqIiqqqqWrsZZmbtiqTqiKgoLPeT42ZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLZY/BIWmsJAeMmZkBpZ1xVAKvSbpe0tFZN8jMzNq2PQZHRHwdGAa8Tu4d4M8k7/PukXnrzMyszSlpCCoiNgP3AjOBvsC5wGJJ38+wbWZm1gaVco3jLElzgD8BnYERETEGOBb4p4zbZ2ZmbUwpr449D/htRDyRXxgR70v6ZjbNMjOztqqU4LgSWFu/IukA4JCIWBURj2XWMjMza5NKucZxD7Azb31HUmZmZvugUoKjU0Rsq19Jlrtk1yQzM2vLSgmOWkln169IGgf8d3ZNMjOztqyUaxyXAjMk/RsgYDXwD5m2yszM2qw9BkdEvA58QdKBgCLi3eybZWZmbVUpZxxIOhMYDHSVBEBEXFPCfqOBm4Ay4M6IuK5g+yjgAeDNpOi++uNKWgW8S+5ifF1EVCTlVwHfAWqTfX4WEfNK6YeZmX18ewwOSVOAbsApwJ3AeOD5EvYrA24FTgdqgEWS5kbEioKqCyNibCOHOSUiil1P+W1E3LCnNpiZWcsr5eL4/46IfwDeiYirgROAw0vYbwSwMiLeSO7EmgmMa35TzcysLSglOD5IPt+XdBiwHRhYwn79yF1Ir1eTlBU6QdJSSfMlDc4rD+BhSdWSJhTsM0nSMknTJPUsoS1mZtZCSgmOByUdBPwKWAysAn5fwn4qUhYF64uBARFxLHALcH/etpERMRwYA3xP0slJ+W3AkcBQck+0/7rol+dm8K2SVFVbW1usipmZNUOTwZG8wOmxiNgYEfcCA4CjIuKKEo5dw65DWv2BNfkVImJzRGxJlucBnSX1TtbXJJ/rgTnkhr6IiHURsSMidgJ31JcXioipEVERERV9+vQpoblmZlaKJoMj+eP867z1DyNiU4nHXgQMkjRQUhdyL4Sam19B0qFKbtOSNCJpzwZJ3evf9yGpO/AlYHmy3jfvEOfWl5uZ2d5Ryu24D0v6e3K3yhYONTUqIuokTQL+SO523GkR8ZKkS5PtU8jdoTVRUh2wFaiMiJB0CDAnyZROwH9GxEPJoa+XNJTcsNcq4JJS22RmZh+f9pQFkt4FugN15C6UC4iI+ET2zWsZFRUVUVVV1drNMDNrVyRV1z9Dl6+UJ8f9ilgzM2tQygOAJxcrL3yxk5mZ7RtKucbxk7zlruTuYqoGTs2kRWZm1qaVMlR1Vv66pMOB6zNrkZmZtWmlPABYqAb4XEs3xMzM2odSrnHcwkdPfO9H7ontpRm2yczM2rBSrnHk38daB/w+Ip7KqD1mZtbGlRIcs4EPImIH5KZLl9QtIt7PtmlmZtYWlXKN4zHggLz1A4BHs2mOmZm1daUER9f6iQgBkuVu2TXJzMzaslKC4z1Jw+tXJH2e3LxSZma2DyrlGscPgXsk1U+J3hc4P7MWmZlZm1bKA4CLJB0FfJbcBIevRMT2zFtmZmZt0h6HqiR9D+geEcsj4kXgQEnfzb5pZmbWFpVyjeM7EbGxfiUi3gG+k1mLzMysTSslOParf0sf5J7jALpk1yQzM2vLSrk4/kdglqQp5KYeuRSYn2mrzMyszSolOC4HJgATyV0cf4HcnVVmZrYP2uNQVUTsBJ4F3gAqgC8CL2fcLjMza6MaPeOQ9BmgEvgqsAH4A0BEnLJ3mmZmZm1RU0NVrwALgbMiYiWApB/tlVaZmVmb1dRQ1d8DbwMLJN0h6YvkrnGYmdk+rNHgiIg5EXE+cBTwOPAj4BBJt0n60l5qn5mZtTGlXBx/LyJmRMRYoD+wBJicdcPMzKxtSvXO8Yj4n4i4PSJOzapBZmbWtqUKjrQkjZb0qqSVknY7S5E0StImSUuSnyvytq2S9GJSXpVX/ilJj0h6LfnsmWUfzMxsV5kFRzI1ya3AGOAY4KuSjilSdWFEDE1+rinYdkpSXpFXNhl4LCIGkXs7oYfNzMz2oizPOEYAKyPijYjYBswExrXAcccB05Pl6cA5LXBMMzMrUZbB0Q9Ynbdek5QVOkHSUknzJQ3OKw/gYUnVkibklR8SEWsBks+Di325pAmSqiRV1dbWfryemJlZg1LmqmquYs98RMH6YmBARGyRdAZwPzAo2TYyItZIOhh4RNIrEfFEqV8eEVOBqQAVFRWF32tmZs2U5RlHDXB43np/YE1+hYjYHBFbkuV5QGdJvZP1NcnnemAOuaEvgHWS+gIkn+sz7IOZmRXIMjgWAYMkDZTUhdy8V3PzK0g6tP5dH5JGJO3ZIKm7pB5JeXfgS8DyZLe5wIXJ8oXAAxn2wczMCmQ2VBURdZImkXufRxkwLSJeknRpsn0KMB6YKKkO2ApURkRIOgSYk2RKJ+A/I+Kh5NDXkXs/yLeAt4DzsuqDmZntThEdf/i/oqIiqqqq9lzRzMwaSKoueBwCyPgBQDMz63gcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapdGrtBrR1L6/dzOr/eb+1m2Fm1izDjuhJnx77t+gxHRx78JXbn+HdD+pauxlmZs3yu4uPY9RnD27RY2YaHJJGAzcBZcCdEXFdwfZRwAPAm0nRfRFxTd72MqAK+FtEjE3KrgK+A9Qm1X4WEfOy6sOWD+uoPO5wvv6FAVl9hZlZZgb06tbix8wsOJI/+rcCpwM1wCJJcyNiRUHVhfWhUMRlwMvAJwrKfxsRN7Rog4vYuTOIgEM/2ZXP9ftk1l9nZtYuZHlxfASwMiLeiIhtwExgXKk7S+oPnAncmVH79mhHBACd9lNrNcHMrM3JMjj6Aavz1muSskInSFoqab6kwXnlNwL/DOwsss8kScskTZPUs9iXS5ogqUpSVW1tbbEqe7RjZy44yvbzzWdmZvWy/ItY7J/pUbC+GBgQEccCtwD3A0gaC6yPiOoix7gNOBIYCqwFfl3syyNiakRURERFnz59mtWBup0+4zAzK5RlcNQAh+et9wfW5FeIiM0RsSVZngd0ltQbGAmcLWkVuSGuUyXdndRbFxE7ImIncAe5IbFM7NhRf8bh4DAzq5dlcCwCBkkaKKkLUAnMza8g6VBJSpZHJO3ZEBE/jYj+EVGe7PeniPh6Uq9v3iHOBZZn1YG6nblRsk5lDg4zs3qZ3VUVEXWSJgF/JHc77rSIeEnSpcn2KcB4YKKkOmArUBkRhcNZha6XNJTcsNcq4JKMupB3jcPBYWZWL9PnOJLhp3kFZVPylv8N+Lc9HONx4PG89W+0aCObUH+No0wODjOzer5dqAk+4zAz252Down1weFrHGZmH3FwNKHOz3GYme3Gkxw2YYef4zBLZfv27dTU1PDBBx+0dlMsha5du9K/f386d+5cUn0HRxPqb8f1NQ6z0tTU1NCjRw/Ky8uRbyppFyKCDRs2UFNTw8CBA0vax2MwTfAZh1k6H3zwAb169XJotCOS6NWrV6qzRAdHE+qvcezn4DArmUOj/Un738zB0YSdPuMwM9uNg6MJdX6Ow6xd2bhxI//+7//erH3POOMMNm7c2GSdK664gkcffbRZx2/K7373OyZNmtRknccff5ynn366xb+7ORwcTfjoGod/TWbtQVPBsWPHjib3nTdvHgcddFCTda655hpOO+205jbvY2lLweG7qprgMw6z5rv6wZdYsWZzix7zmMM+wZVnDW50++TJk3n99dcZOnQop59+OmeeeSZXX301ffv2ZcmSJaxYsYJzzjmH1atX88EHH3DZZZcxYcIEAMrLy6mqqmLLli2MGTOGE088kaeffpp+/frxwAMPcMABB3DRRRcxduxYxo8fT3l5ORdeeCEPPvgg27dv55577uGoo46itraWCy64gA0bNnDcccfx0EMPUV1dTe/evXdp61133cW//Mu/0LdvXz7zmc+w//77A/Dggw/yy1/+km3bttGrVy9mzJjB1q1bmTJlCmVlZdx9993ccsstbNy4cbd6hxxySIv+vhvjf0o3YUf97LgODrN24brrruPII49kyZIl/OpXvwLg+eef59prr2XFitxbq6dNm0Z1dTVVVVXcfPPNbNiwYbfjvPbaa3zve9/jpZde4qCDDuLee+8t+n29e/dm8eLFTJw4kRtuyL3N+uqrr+bUU09l8eLFnHvuubz11lu77bd27VquvPJKnnrqKR555JGGtgGceOKJPPvss7zwwgtUVlZy/fXXU15ezqWXXsqPfvQjlixZwkknnVS03t7iM44m1Pl9HGbN1tSZwd40YsSIXZ5PuPnmm5kzZw4Aq1ev5rXXXqNXr1677DNw4ECGDh0KwOc//3lWrVpV9Nhf/vKXG+rcd999ADz55JMNxx89ejQ9e+7+ktLnnnuOUaNGUf+SufPPP5+//OUvQO5ZmPPPP5+1a9eybdu2Rp+tKLVeFnzG0QRPcmjW/nXv3r1h+fHHH+fRRx/lmWeeYenSpQwbNqzo8wv1w0YAZWVl1NXVFT12fb38Ont+M0ROY7fAfv/732fSpEm8+OKL3H777Y0+X1FqvSw4OJqwI3w7rll70qNHD959991Gt2/atImePXvSrVs3XnnlFZ599tkWb8OJJ57IrFmzAHj44Yd55513dqtz/PHH8/jjj7Nhw4aG6yP5bezXrx8A06dPbygv7Ftj9fYGB0cTfMZh1r706tWLkSNH8rnPfY6f/OQnu20fPXo0dXV1DBkyhF/84hd84QtfaPE2XHnllTz88MMMHz6c+fPn07dvX3r06LFLnb59+3LVVVdxwgkncNpppzF8+PCGbVdddRXnnXceJ5100i4X1M866yzmzJnD0KFDWbhwYaP19gaVelrVnlVUVERVVVXq/e6truHH9yzliZ+cwhG9umXQMrOO5eWXX+boo49u7Wa0qg8//JCysjI6derEM888w8SJE1myZElrN2uPiv23k1QdERWFdX1xvAkNZxx+H4eZleitt97iK1/5Cjt37qRLly7ccccdrd2kFufgaEKdpxwxs5QGDRrECy+80NrNyJSvcTRhh6dVNzPbjYOjCQ1Pjnu2TzOzBg6OJvgah5nZ7hwcTfCLnMzMdufgaIInOTTr+A488EAA1qxZw/jx44vWGTVqFHu6pf/GG2/k/fffb1gvZZr25qhvb2M+ztTypco0OCSNlvSqpJWSJhfZPkrSJklLkp8rCraXSXpB0n/llX1K0iOSXks+d58IpoV4WnWzfcdhhx3G7Nmzm71/YXCUMk17FvZGcGR2O66kMuBW4HSgBlgkaW5ErCioujAixjZymMuAl4FP5JVNBh6LiOuSMJoMXN6yrc9peHWsTzjM0ps/Gd5+sWWPeejfwZjrGt18+eWXM2DAAL773e8Cuaewe/TowSWXXMK4ceN455132L59O7/85S8ZN27cLvuuWrWKsWPHsnz5crZu3crFF1/MihUrOProo9m6dWtDvYkTJ7Jo0SK2bt3K+PHjufrqq7n55ptZs2YNp5xyCr1792bBggUN07T37t2b3/zmN0ybNg2Ab3/72/zwhz9k1apVjU7fnu/NN9/kggsuoK6ujtGjRzeUb9mypWifCqeWv/LKK/fY97Sy/Kf0CGBlRLwREduAmUDJrZXUHzgTuLNg0zigfmKW6cA5H7+pxe3YuZOy/eR3KJu1E5WVlfzhD39oWJ81axbnnXceXbt2Zc6cOSxevJgFCxbw4x//uMnJCG+77Ta6devGsmXL+PnPf051dXXDtmuvvZaqqiqWLVvGn//8Z5YtW8YPfvADDjvsMBYsWMCCBQt2OVZ1dTV33XUXzz33HM8++yx33HFHw3MepUzfftlllzWE1aGHHtpQ3lifCqeWT9v3UmT5AGA/YHXeeg1wfJF6J0haCqwB/ikiXkrKbwT+GehRUP+QiFgLEBFrJR1c7MslTQAmABxxxBHN6kDdzvD1DbPmauLMICvDhg1j/fr1rFmzhtraWnr27MkRRxzB9u3b+dnPfsYTTzzBfvvtx9/+9jfWrVu3yx/ifE888QQ/+MEPABgyZAhDhgxp2DZr1iymTp1KXV0da9euZcWKFbtsL/Tkk09y7rnnNszS++Uvf5mFCxdy9tlnlzR9+1NPPdUQKN/4xje4/PLcAEtEFO1TocbqNdb3UmQZHMX+4hbG3GJgQERskXQGcD8wSNJYYH1EVEsa1Zwvj4ipwFTIzVXVnGPs3Bm+o8qsnRk/fjyzZ8/m7bffprKyEoAZM2ZQW1tLdXU1nTt3pry8fI/TkBcbaXjzzTe54YYbWLRoET179uSiiy7a43Ga+td94fTt+UNie2pLqX1qTt/3JMuhqhrg8Lz1/uTOKhpExOaI2JIszwM6S+oNjATOlrSK3BDXqZLuTnZbJ6kvQPK5PqsO+IzDrP2prKxk5syZzJ49u+EuqU2bNnHwwQfTuXNnFixYwF//+tcmj3HyySczY8YMAJYvX86yZcsA2Lx5M927d+eTn/wk69atY/78+Q37NDal+8knn8z999/P+++/z3vvvcecOXM46aSTSu7PyJEjmTlzJkBDm5rqU7Hp19P0vRRZBscicmcPAyV1ASqBufkVJB2qJEoljUjasyEifhoR/SOiPNnvTxHx9WS3ucCFyfKFwANZdWCHzzjM2p3Bgwfz7rvv0q9fP/r27QvA1772NaqqqqioqGDGjBkcddRRTR5j4sSJbNmyhSFDhnD99dczYsQIAI499liGDRvG4MGD+eY3v8nIkSMb9pkwYQJjxozhlFNO2eVYw4cP56KLLmLEiBEcf/zxfPvb32bYsGEl9+emm27i1ltv5bjjjmPTpk0N5Y31qXBq+bR9L0Wm06onw083AmXAtIi4VtKlABExRdIkYCJQB2wF/jEini44xihy1z7GJuu9gFnAEcBbwHkR8T9NtaO506rPfP4tXnhrI/86vvHxSzP7iKdVb7/STKvu93GYWYtxcLRfaYLDT7aZmVkqDg4za1H7wihGR5P2v5mDw8xaTNeuXdmwYYPDox2JCDZs2EDXrl1L3sdvADSzFtO/f39qamqora1t7aZYCl27dqV///4l13dwmFmL6dy5MwMHDmztZljGPFRlZmapODjMzCwVB4eZmaWyTzwAKKkWaO4ELb2B/27B5rQH7vO+wX3eN3ycPg+IiD6FhftEcHwckqqKPTnZkbnP+wb3ed+QRZ89VGVmZqk4OMzMLBUHx55Nbe0GtAL3ed/gPu8bWrzPvsZhZmap+IzDzMxScXCYmVkqDo4mSBot6VVJKyVNbu32tBRJ0yStl7Q8r+xTkh6R9Fry2TNv20+T38Grkv5P67S6+SQdLmmBpJclvSTpsqS8I/e5q6TnJS1N+nx1Ut5h+1xPUpmkFyT9V7LeofssaZWkFyUtkVSVlGXb54jwT5Efcq+7fR34NNAFWAoc09rtaqG+nQwMB5bnlV0PTE6WJwP/miwfk/R9f2Bg8jspa+0+pOxvX2B4stwD+EvSr47cZwEHJsudgeeAL3TkPuf1/R+B/wT+K1nv0H0GVgG9C8oy7bPPOBo3AlgZEW9ExDZgJjCuldvUIiLiCaDwPe3jgOnJ8nTgnLzymRHxYUS8Cawk97tpNyJibUQsTpbfBV4G+tGx+xwRsSVZ7Zz8BB24zwCS+gNnAnfmFXfoPjci0z47OBrXD1idt16TlHVUh0TEWsj9oQUOTso71O9BUjkwjNy/wDt0n5MhmyXAeuCRiOjwfQZuBP4Z2JlX1tH7HMDDkqolTUjKMu2z38fROBUp2xfvXe4wvwdJBwL3Aj+MiM1Ssa7lqhYpa3d9jogdwFBJBwFzJH2uiertvs+SxgLrI6Ja0qhSdilS1q76nBgZEWskHQw8IumVJuq2SJ99xtG4GuDwvPX+wJpWasvesE5SX4Dkc31S3iF+D5I6kwuNGRFxX1LcoftcLyI2Ao8Do+nYfR4JnC1pFbmh5VMl3U3H7jMRsSb5XA/MITf0lGmfHRyNWwQMkjRQUhegEpjbym3K0lzgwmT5QuCBvPJKSftLGggMAp5vhfY1m3KnFv8BvBwRv8nb1JH73Cc500DSAcBpwCt04D5HxE8jon9ElJP7//VPEfF1OnCfJXWX1KN+GfgSsJys+9zadwS05R/gDHJ34LwO/Ly129OC/fo9sBbYTu5fIN8CegGPAa8ln5/Kq//z5HfwKjCmtdvfjP6eSO50fBmwJPk5o4P3eQjwQtLn5cAVSXmH7XNB/0fx0V1VHbbP5O76XJr8vFT/dyrrPnvKETMzS8VDVWZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjM2jhJo+pnejVrCxwcZmaWioPDrIVI+nryDowlkm5PJhncIunXkhZLekxSn6TuUEnPSlomaU79+xIk/S9Jjybv0Vgs6cjk8AdKmi3pFUkz1MREW2ZZc3CYtQBJRwPnk5twbiiwA/ga0B1YHBHDgT8DVya7/D/g8ogYAryYVz4DuDUijgX+N7kn/CE3o+8Pyb1P4dPk5mUyaxWeHdesZXwR+DywKDkZOIDcxHI7gT8kde4G7pP0SeCgiPhzUj4duCeZc6hfRMwBiIgPAJLjPR8RNcn6EqAceDLzXpkV4eAwaxkCpkfET3cplH5RUK+pOX6aGn76MG95B/5/11qRh6rMWsZjwPjknQj173weQO7/sfFJnQuAJyNiE/COpJOS8m8Af46IzUCNpHOSY+wvqdve7IRZKfyvFrMWEBErJP1fcm9i24/czMPfA94DBkuqBjaRuw4CuamupyTB8AZwcVL+DeB2SdckxzhvL3bDrCSeHdcsQ5K2RMSBrd0Os5bkoSozM0vFZxxmZpaKzzjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUvn/ow/Fx8OHL2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5456\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5691\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
