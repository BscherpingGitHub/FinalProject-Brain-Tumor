{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  16.7  1688.0 ...  7.2  1.0  0.0]\n",
      " [ 1.0  6.7  1024.3 ...  8.1  0.9  0.0]\n",
      " [ 0.0  16.9  844.7 ...  4.0  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  19.5  1229.0 ...  4.9  1.0  0.0]\n",
      " [ 0.0  7.8  257.5 ...  2.3  1.0  0.0]\n",
      " [ 0.0  10.8  712.3 ...  5.4  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  1688.0  0.0 ...  0.0  0.4  7.2]\n",
      " [ 1.0  1024.3  0.0 ...  0.0  0.4  8.1]\n",
      " [ 0.0  844.7  0.1 ...  0.1  0.5  4.0]\n",
      " ...\n",
      " [ 1.0  1229.0  0.1 ...  0.0  0.5  4.9]\n",
      " [ 0.0  257.5  0.1 ...  0.1  0.6  2.3]\n",
      " [ 0.0  712.3  0.1 ...  0.1  0.5  5.4]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 16.0519 - accuracy: 0.4320 - val_loss: 2.3065 - val_accuracy: 0.4167\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0371 - accuracy: 0.5159 - val_loss: 0.9195 - val_accuracy: 0.4743\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7515 - accuracy: 0.5812 - val_loss: 0.6264 - val_accuracy: 0.7154\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.6648 - val_loss: 0.5921 - val_accuracy: 0.6658\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.7035 - val_loss: 0.6202 - val_accuracy: 0.6170\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.7350 - val_loss: 0.6179 - val_accuracy: 0.6578\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7589 - val_loss: 0.8614 - val_accuracy: 0.5106\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7654 - val_loss: 0.5569 - val_accuracy: 0.6986\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7942 - val_loss: 0.4628 - val_accuracy: 0.8812\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7992 - val_loss: 0.5382 - val_accuracy: 0.6941\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.8307 - val_loss: 0.6118 - val_accuracy: 0.6729\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.8280 - val_loss: 0.4148 - val_accuracy: 0.8794\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.8383 - val_loss: 0.4001 - val_accuracy: 0.8998\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8485 - val_loss: 0.4294 - val_accuracy: 0.8484\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8508 - val_loss: 0.3714 - val_accuracy: 0.9025\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8629 - val_loss: 0.4154 - val_accuracy: 0.8466\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8743 - val_loss: 0.5719 - val_accuracy: 0.6968\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8667 - val_loss: 0.4668 - val_accuracy: 0.7394\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8728 - val_loss: 0.3603 - val_accuracy: 0.8945\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8812 - val_loss: 0.4273 - val_accuracy: 0.8121\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8724 - val_loss: 0.3383 - val_accuracy: 0.9016\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8869 - val_loss: 0.4649 - val_accuracy: 0.7402\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8812 - val_loss: 0.3211 - val_accuracy: 0.9069\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8857 - val_loss: 0.3010 - val_accuracy: 0.9193\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8876 - val_loss: 0.2877 - val_accuracy: 0.9255\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8903 - val_loss: 0.2777 - val_accuracy: 0.9326\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8956 - val_loss: 0.3803 - val_accuracy: 0.8484\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3010 - accuracy: 0.8929 - val_loss: 0.2966 - val_accuracy: 0.8741\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8990 - val_loss: 0.2933 - val_accuracy: 0.9096\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.8994 - val_loss: 0.2611 - val_accuracy: 0.9282\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.9036 - val_loss: 0.2677 - val_accuracy: 0.8918\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.9009 - val_loss: 0.2449 - val_accuracy: 0.9353\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.9058 - val_loss: 0.5030 - val_accuracy: 0.7571\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.9077 - val_loss: 0.2572 - val_accuracy: 0.8883\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.9077 - val_loss: 0.2288 - val_accuracy: 0.9450\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.9093 - val_loss: 0.2246 - val_accuracy: 0.9388\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2532 - accuracy: 0.9169 - val_loss: 0.2279 - val_accuracy: 0.9379\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9104 - val_loss: 0.2174 - val_accuracy: 0.9512\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2402 - accuracy: 0.9207 - val_loss: 0.2144 - val_accuracy: 0.9486\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.9165 - val_loss: 0.2117 - val_accuracy: 0.9477\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9210 - val_loss: 0.3283 - val_accuracy: 0.8679\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2315 - accuracy: 0.9165 - val_loss: 0.3669 - val_accuracy: 0.8174\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2296 - accuracy: 0.9195 - val_loss: 0.1974 - val_accuracy: 0.9504\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2275 - accuracy: 0.9226 - val_loss: 0.3012 - val_accuracy: 0.8821\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9244 - val_loss: 0.2796 - val_accuracy: 0.8963\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2215 - accuracy: 0.9286 - val_loss: 0.2835 - val_accuracy: 0.8573\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2204 - accuracy: 0.9248 - val_loss: 0.1939 - val_accuracy: 0.9379\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9282 - val_loss: 0.2012 - val_accuracy: 0.9238\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2109 - accuracy: 0.9252 - val_loss: 0.1854 - val_accuracy: 0.9512\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2118 - accuracy: 0.9275 - val_loss: 0.2021 - val_accuracy: 0.9353\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9309 - val_loss: 0.2047 - val_accuracy: 0.9105\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2049 - accuracy: 0.9290 - val_loss: 0.1755 - val_accuracy: 0.9530\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9271 - val_loss: 0.2588 - val_accuracy: 0.9016\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2049 - accuracy: 0.9248 - val_loss: 0.2210 - val_accuracy: 0.8972\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2003 - accuracy: 0.9294 - val_loss: 0.1866 - val_accuracy: 0.9300\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2020 - accuracy: 0.9305 - val_loss: 0.2543 - val_accuracy: 0.9025\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9320 - val_loss: 0.2567 - val_accuracy: 0.9007\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1901 - accuracy: 0.9358 - val_loss: 0.1649 - val_accuracy: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9343 - val_loss: 0.2210 - val_accuracy: 0.8963\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9343 - val_loss: 0.1874 - val_accuracy: 0.9379\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9370 - val_loss: 0.1607 - val_accuracy: 0.9592\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1869 - accuracy: 0.9362 - val_loss: 0.1677 - val_accuracy: 0.9441\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9328 - val_loss: 0.2191 - val_accuracy: 0.8989\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9343 - val_loss: 0.1945 - val_accuracy: 0.9273\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1829 - accuracy: 0.9389 - val_loss: 0.1599 - val_accuracy: 0.9521\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.9343 - val_loss: 0.1530 - val_accuracy: 0.9583\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1846 - accuracy: 0.9370 - val_loss: 0.1510 - val_accuracy: 0.9583\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 0.9320 - val_loss: 0.2421 - val_accuracy: 0.9043\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9320 - val_loss: 0.1526 - val_accuracy: 0.9530\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9358 - val_loss: 0.1500 - val_accuracy: 0.9539\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9415 - val_loss: 0.1913 - val_accuracy: 0.9255\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9351 - val_loss: 0.1463 - val_accuracy: 0.9566\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1729 - accuracy: 0.9332 - val_loss: 0.1570 - val_accuracy: 0.9495\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9362 - val_loss: 0.1476 - val_accuracy: 0.9539\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.9362 - val_loss: 0.1420 - val_accuracy: 0.9548\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9370 - val_loss: 0.1412 - val_accuracy: 0.9548\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9400 - val_loss: 0.2065 - val_accuracy: 0.9202\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1693 - accuracy: 0.9366 - val_loss: 0.2190 - val_accuracy: 0.9113\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9419 - val_loss: 0.1393 - val_accuracy: 0.9557\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1675 - accuracy: 0.9393 - val_loss: 0.2357 - val_accuracy: 0.8874\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1637 - accuracy: 0.9393 - val_loss: 0.1500 - val_accuracy: 0.9512\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1602 - accuracy: 0.9446 - val_loss: 0.1509 - val_accuracy: 0.9468\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1591 - accuracy: 0.9393 - val_loss: 0.1511 - val_accuracy: 0.9415\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1651 - accuracy: 0.9389 - val_loss: 0.1407 - val_accuracy: 0.9530\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.9408 - val_loss: 0.2649 - val_accuracy: 0.8892\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9434 - val_loss: 0.1557 - val_accuracy: 0.9441\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1570 - accuracy: 0.9450 - val_loss: 0.1362 - val_accuracy: 0.9557\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1614 - accuracy: 0.9389 - val_loss: 0.1348 - val_accuracy: 0.9557\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1591 - accuracy: 0.9385 - val_loss: 0.1333 - val_accuracy: 0.9548\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1574 - accuracy: 0.9404 - val_loss: 0.1282 - val_accuracy: 0.9574\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1557 - accuracy: 0.9412 - val_loss: 0.1856 - val_accuracy: 0.9158\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1577 - accuracy: 0.9427 - val_loss: 0.2135 - val_accuracy: 0.9140\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1558 - accuracy: 0.9389 - val_loss: 0.1258 - val_accuracy: 0.9610\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9453 - val_loss: 0.1370 - val_accuracy: 0.9512\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1525 - accuracy: 0.9434 - val_loss: 0.1532 - val_accuracy: 0.9433\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1527 - accuracy: 0.9457 - val_loss: 0.1603 - val_accuracy: 0.9309\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9408 - val_loss: 0.1432 - val_accuracy: 0.9459\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1500 - accuracy: 0.9431 - val_loss: 0.1909 - val_accuracy: 0.9158\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1506 - accuracy: 0.9438 - val_loss: 0.2233 - val_accuracy: 0.9087\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1480 - accuracy: 0.9408 - val_loss: 0.1211 - val_accuracy: 0.9610\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9461 - val_loss: 0.1260 - val_accuracy: 0.9583\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9510 - val_loss: 0.1534 - val_accuracy: 0.9424\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1456 - accuracy: 0.9461 - val_loss: 0.1470 - val_accuracy: 0.9415\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1451 - accuracy: 0.9495 - val_loss: 0.2658 - val_accuracy: 0.8821\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1420 - accuracy: 0.9472 - val_loss: 0.2162 - val_accuracy: 0.9113\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9453 - val_loss: 0.1496 - val_accuracy: 0.9441\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9446 - val_loss: 0.1835 - val_accuracy: 0.9246\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9499 - val_loss: 0.1372 - val_accuracy: 0.9512\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1472 - accuracy: 0.9472 - val_loss: 0.1160 - val_accuracy: 0.9610\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9461 - val_loss: 0.1183 - val_accuracy: 0.9610\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9468 - val_loss: 0.1299 - val_accuracy: 0.9477\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1375 - accuracy: 0.9499 - val_loss: 0.1233 - val_accuracy: 0.9592\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1380 - accuracy: 0.9484 - val_loss: 0.1545 - val_accuracy: 0.9335\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9499 - val_loss: 0.1416 - val_accuracy: 0.9495\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1388 - accuracy: 0.9468 - val_loss: 0.1380 - val_accuracy: 0.9504\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1372 - accuracy: 0.9503 - val_loss: 0.1115 - val_accuracy: 0.9637\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9468 - val_loss: 0.2011 - val_accuracy: 0.9149\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9495 - val_loss: 0.1427 - val_accuracy: 0.9468\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9495 - val_loss: 0.2280 - val_accuracy: 0.8945\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.9487 - val_loss: 0.1090 - val_accuracy: 0.9628\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1353 - accuracy: 0.9510 - val_loss: 0.1196 - val_accuracy: 0.9512\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.9491 - val_loss: 0.1732 - val_accuracy: 0.9255\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9491 - val_loss: 0.1117 - val_accuracy: 0.9574\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.9476 - val_loss: 0.1080 - val_accuracy: 0.9601\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9503 - val_loss: 0.1063 - val_accuracy: 0.9637\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9552 - val_loss: 0.1528 - val_accuracy: 0.9397\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9495 - val_loss: 0.1445 - val_accuracy: 0.9424\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9522 - val_loss: 0.1064 - val_accuracy: 0.9610\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1305 - accuracy: 0.9476 - val_loss: 0.1135 - val_accuracy: 0.9548\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9514 - val_loss: 0.1133 - val_accuracy: 0.9539\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1285 - accuracy: 0.9533 - val_loss: 0.1568 - val_accuracy: 0.9388\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1288 - accuracy: 0.9522 - val_loss: 0.1326 - val_accuracy: 0.9433\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9503 - val_loss: 0.1025 - val_accuracy: 0.9681\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1230 - accuracy: 0.9548 - val_loss: 0.1310 - val_accuracy: 0.9459\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.1035 - val_accuracy: 0.9672\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9514 - val_loss: 0.1224 - val_accuracy: 0.9495\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1242 - accuracy: 0.9533 - val_loss: 0.1004 - val_accuracy: 0.9681\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1298 - accuracy: 0.9506 - val_loss: 0.1116 - val_accuracy: 0.9574\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1238 - accuracy: 0.9556 - val_loss: 0.1302 - val_accuracy: 0.9495\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9575 - val_loss: 0.1734 - val_accuracy: 0.9282\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9533 - val_loss: 0.0997 - val_accuracy: 0.9690\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9586 - val_loss: 0.1032 - val_accuracy: 0.9592\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1203 - accuracy: 0.9556 - val_loss: 0.1769 - val_accuracy: 0.9202\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9586 - val_loss: 0.1160 - val_accuracy: 0.9557\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9556 - val_loss: 0.1021 - val_accuracy: 0.9663\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.9503 - val_loss: 0.1051 - val_accuracy: 0.9628\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9544 - val_loss: 0.1859 - val_accuracy: 0.9229\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9563 - val_loss: 0.1658 - val_accuracy: 0.9309\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9579 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9548 - val_loss: 0.1071 - val_accuracy: 0.9645\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9529 - val_loss: 0.0926 - val_accuracy: 0.9654\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9552 - val_loss: 0.0927 - val_accuracy: 0.9699\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9544 - val_loss: 0.0992 - val_accuracy: 0.9672\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9514 - val_loss: 0.1975 - val_accuracy: 0.9167\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9560 - val_loss: 0.0917 - val_accuracy: 0.9699\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9522 - val_loss: 0.1135 - val_accuracy: 0.9539\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9567 - val_loss: 0.1084 - val_accuracy: 0.9574\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.9514 - val_loss: 0.0905 - val_accuracy: 0.9716\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9525 - val_loss: 0.1003 - val_accuracy: 0.9610\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9537 - val_loss: 0.0919 - val_accuracy: 0.9672\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1134 - accuracy: 0.9575 - val_loss: 0.1531 - val_accuracy: 0.9326\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1148 - accuracy: 0.9598 - val_loss: 0.0910 - val_accuracy: 0.9628\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1101 - accuracy: 0.9560 - val_loss: 0.0899 - val_accuracy: 0.9690\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.9556 - val_loss: 0.0996 - val_accuracy: 0.9619\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 0.0886 - val_accuracy: 0.9690\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9575 - val_loss: 0.0872 - val_accuracy: 0.9725\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9522 - val_loss: 0.0967 - val_accuracy: 0.9654\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9563 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9556 - val_loss: 0.0932 - val_accuracy: 0.9707\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9594 - val_loss: 0.1085 - val_accuracy: 0.9557\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1087 - accuracy: 0.9613 - val_loss: 0.0855 - val_accuracy: 0.9725\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9579 - val_loss: 0.0947 - val_accuracy: 0.9681\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1083 - accuracy: 0.9552 - val_loss: 0.0942 - val_accuracy: 0.9619\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1505 - val_accuracy: 0.9326\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1067 - accuracy: 0.9609 - val_loss: 0.0857 - val_accuracy: 0.9716\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1068 - accuracy: 0.9579 - val_loss: 0.1602 - val_accuracy: 0.9317\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1134 - accuracy: 0.9575 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1092 - accuracy: 0.9575 - val_loss: 0.0879 - val_accuracy: 0.9734\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9567 - val_loss: 0.1453 - val_accuracy: 0.9406\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9582 - val_loss: 0.0837 - val_accuracy: 0.9761\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1119 - accuracy: 0.9552 - val_loss: 0.0827 - val_accuracy: 0.9716\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1075 - accuracy: 0.9605 - val_loss: 0.1369 - val_accuracy: 0.9468\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1051 - accuracy: 0.9594 - val_loss: 0.3472 - val_accuracy: 0.8777\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1070 - accuracy: 0.9624 - val_loss: 0.0828 - val_accuracy: 0.9699\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1085 - accuracy: 0.9579 - val_loss: 0.0900 - val_accuracy: 0.9619\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1056 - accuracy: 0.9613 - val_loss: 0.1203 - val_accuracy: 0.9557\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9601 - val_loss: 0.0897 - val_accuracy: 0.9681\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.1306 - val_accuracy: 0.9486\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9598 - val_loss: 0.0798 - val_accuracy: 0.9734\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1036 - accuracy: 0.9586 - val_loss: 0.1740 - val_accuracy: 0.9238\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1017 - accuracy: 0.9617 - val_loss: 0.1167 - val_accuracy: 0.9512\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1060 - accuracy: 0.9571 - val_loss: 0.0796 - val_accuracy: 0.9770\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9609 - val_loss: 0.1148 - val_accuracy: 0.9512\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.1271 - val_accuracy: 0.9486\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.9575 - val_loss: 0.1232 - val_accuracy: 0.9521\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9617 - val_loss: 0.0915 - val_accuracy: 0.9619\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9628 - val_loss: 0.0784 - val_accuracy: 0.9787\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9609 - val_loss: 0.1009 - val_accuracy: 0.9637\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9601 - val_loss: 0.0768 - val_accuracy: 0.9770\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9579 - val_loss: 0.0929 - val_accuracy: 0.9654\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9643 - val_loss: 0.1202 - val_accuracy: 0.9495\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.9586 - val_loss: 0.0854 - val_accuracy: 0.9672\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9601 - val_loss: 0.0818 - val_accuracy: 0.9761\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9601 - val_loss: 0.0759 - val_accuracy: 0.9770\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9601 - val_loss: 0.1279 - val_accuracy: 0.9495\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.9617 - val_loss: 0.0763 - val_accuracy: 0.9796\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9605 - val_loss: 0.1127 - val_accuracy: 0.9539\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9601 - val_loss: 0.0761 - val_accuracy: 0.9707\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.1432 - val_accuracy: 0.9441\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9590 - val_loss: 0.0799 - val_accuracy: 0.9761\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9605 - val_loss: 0.0815 - val_accuracy: 0.9663\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9628 - val_loss: 0.0737 - val_accuracy: 0.9770\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9651 - val_loss: 0.1183 - val_accuracy: 0.9583\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9647 - val_loss: 0.1429 - val_accuracy: 0.9353\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9624 - val_loss: 0.2050 - val_accuracy: 0.9149\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9636 - val_loss: 0.0865 - val_accuracy: 0.9645\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9605 - val_loss: 0.0801 - val_accuracy: 0.9672\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9643 - val_loss: 0.1170 - val_accuracy: 0.9530\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9620 - val_loss: 0.0994 - val_accuracy: 0.9645\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.9617 - val_loss: 0.0710 - val_accuracy: 0.9770\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9639 - val_loss: 0.0827 - val_accuracy: 0.9716\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9609 - val_loss: 0.2288 - val_accuracy: 0.9078\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9613 - val_loss: 0.1323 - val_accuracy: 0.9450\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9620 - val_loss: 0.1714 - val_accuracy: 0.9264\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9598 - val_loss: 0.0804 - val_accuracy: 0.9725\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9609 - val_loss: 0.0737 - val_accuracy: 0.9690\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9647 - val_loss: 0.0713 - val_accuracy: 0.9761\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9636 - val_loss: 0.0721 - val_accuracy: 0.9805\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9639 - val_loss: 0.1232 - val_accuracy: 0.9512\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9632 - val_loss: 0.1224 - val_accuracy: 0.9521\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9643 - val_loss: 0.1070 - val_accuracy: 0.9548\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9613 - val_loss: 0.0702 - val_accuracy: 0.9778\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9636 - val_loss: 0.0745 - val_accuracy: 0.9716\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9601 - val_loss: 0.0700 - val_accuracy: 0.9743\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9647 - val_loss: 0.0732 - val_accuracy: 0.9707\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9658 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9692 - val_loss: 0.1000 - val_accuracy: 0.9583\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0950 - accuracy: 0.9613 - val_loss: 0.0688 - val_accuracy: 0.9770\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9689 - val_loss: 0.0816 - val_accuracy: 0.9663\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0930 - accuracy: 0.9613 - val_loss: 0.1144 - val_accuracy: 0.9539\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0930 - accuracy: 0.9643 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0921 - accuracy: 0.9658 - val_loss: 0.0729 - val_accuracy: 0.9761\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9658 - val_loss: 0.1534 - val_accuracy: 0.9300\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0940 - accuracy: 0.9643 - val_loss: 0.0774 - val_accuracy: 0.9690\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9666 - val_loss: 0.1195 - val_accuracy: 0.9521\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0895 - accuracy: 0.9666 - val_loss: 0.0686 - val_accuracy: 0.9796\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9624 - val_loss: 0.0669 - val_accuracy: 0.9770\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9662 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9658 - val_loss: 0.0765 - val_accuracy: 0.9707\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9636 - val_loss: 0.0778 - val_accuracy: 0.9690\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9655 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9677 - val_loss: 0.0861 - val_accuracy: 0.9690\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9692 - val_loss: 0.0641 - val_accuracy: 0.9778\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9696 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9662 - val_loss: 0.1051 - val_accuracy: 0.9583\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9655 - val_loss: 0.1001 - val_accuracy: 0.9583\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0880 - accuracy: 0.9636 - val_loss: 0.1077 - val_accuracy: 0.9539\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0894 - accuracy: 0.9651 - val_loss: 0.1291 - val_accuracy: 0.9397\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.1599 - val_accuracy: 0.9282\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9647 - val_loss: 0.0747 - val_accuracy: 0.9707\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0850 - accuracy: 0.9685 - val_loss: 0.1202 - val_accuracy: 0.9512\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9647 - val_loss: 0.0658 - val_accuracy: 0.9805\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9662 - val_loss: 0.0646 - val_accuracy: 0.9743\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9655 - val_loss: 0.0658 - val_accuracy: 0.9761\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9666 - val_loss: 0.0668 - val_accuracy: 0.9734\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9681 - val_loss: 0.1980 - val_accuracy: 0.9184\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0889 - accuracy: 0.9643 - val_loss: 0.1321 - val_accuracy: 0.9468\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0876 - accuracy: 0.9658 - val_loss: 0.1484 - val_accuracy: 0.9362\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9677 - val_loss: 0.0665 - val_accuracy: 0.9716\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0848 - accuracy: 0.9715 - val_loss: 0.0656 - val_accuracy: 0.9796\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0857 - accuracy: 0.9666 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0865 - accuracy: 0.9677 - val_loss: 0.0657 - val_accuracy: 0.9787\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0884 - accuracy: 0.9647 - val_loss: 0.0640 - val_accuracy: 0.9832\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0848 - accuracy: 0.9704 - val_loss: 0.1883 - val_accuracy: 0.9184\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0891 - accuracy: 0.9666 - val_loss: 0.0667 - val_accuracy: 0.9823\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0759 - val_accuracy: 0.9690\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.9685 - val_loss: 0.0753 - val_accuracy: 0.9690\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0866 - accuracy: 0.9647 - val_loss: 0.0630 - val_accuracy: 0.9823\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0806 - accuracy: 0.9749 - val_loss: 0.1039 - val_accuracy: 0.9619\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0857 - accuracy: 0.9677 - val_loss: 0.0639 - val_accuracy: 0.9832\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0872 - accuracy: 0.9692 - val_loss: 0.0630 - val_accuracy: 0.9823\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0832 - accuracy: 0.9658 - val_loss: 0.0606 - val_accuracy: 0.9778\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0832 - accuracy: 0.9685 - val_loss: 0.0602 - val_accuracy: 0.9805\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0823 - accuracy: 0.9670 - val_loss: 0.0839 - val_accuracy: 0.9734\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0865 - accuracy: 0.9689 - val_loss: 0.0717 - val_accuracy: 0.9716\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0847 - accuracy: 0.9670 - val_loss: 0.0735 - val_accuracy: 0.9707\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0845 - accuracy: 0.9677 - val_loss: 0.0590 - val_accuracy: 0.9814\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0842 - accuracy: 0.9662 - val_loss: 0.0587 - val_accuracy: 0.9796\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.1373 - val_accuracy: 0.9468\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0840 - accuracy: 0.9689 - val_loss: 0.1160 - val_accuracy: 0.9521\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.0671 - val_accuracy: 0.9823\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0830 - accuracy: 0.9692 - val_loss: 0.0638 - val_accuracy: 0.9752\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0832 - accuracy: 0.9674 - val_loss: 0.0824 - val_accuracy: 0.9681\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0865 - accuracy: 0.9708 - val_loss: 0.0831 - val_accuracy: 0.9645\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0821 - accuracy: 0.9670 - val_loss: 0.1368 - val_accuracy: 0.9450\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0898 - accuracy: 0.9643 - val_loss: 0.0696 - val_accuracy: 0.9716\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0813 - accuracy: 0.9685 - val_loss: 0.1037 - val_accuracy: 0.9583\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 0.1234 - val_accuracy: 0.9486\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9715 - val_loss: 0.0820 - val_accuracy: 0.9734\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9704 - val_loss: 0.1503 - val_accuracy: 0.9397\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9662 - val_loss: 0.1504 - val_accuracy: 0.9397\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0806 - accuracy: 0.9677 - val_loss: 0.0575 - val_accuracy: 0.9805\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9677 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9677 - val_loss: 0.1471 - val_accuracy: 0.9388\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0816 - accuracy: 0.9696 - val_loss: 0.1688 - val_accuracy: 0.9300\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9696 - val_loss: 0.0587 - val_accuracy: 0.9805\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0812 - accuracy: 0.9696 - val_loss: 0.0688 - val_accuracy: 0.9778\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 0.0693 - val_accuracy: 0.9734\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.0830 - val_accuracy: 0.9645\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0811 - accuracy: 0.9704 - val_loss: 0.0618 - val_accuracy: 0.9752\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0798 - accuracy: 0.9674 - val_loss: 0.1055 - val_accuracy: 0.9566\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0794 - accuracy: 0.9681 - val_loss: 0.0875 - val_accuracy: 0.9681\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9723 - val_loss: 0.0572 - val_accuracy: 0.9805\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.9692 - val_loss: 0.0561 - val_accuracy: 0.9796\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.0596 - val_accuracy: 0.9849\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0792 - accuracy: 0.9711 - val_loss: 0.0555 - val_accuracy: 0.9823\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0797 - accuracy: 0.9711 - val_loss: 0.0681 - val_accuracy: 0.9734\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9662 - val_loss: 0.0754 - val_accuracy: 0.9743\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0794 - accuracy: 0.9681 - val_loss: 0.0985 - val_accuracy: 0.9610\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9723 - val_loss: 0.0690 - val_accuracy: 0.9725\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0818 - accuracy: 0.9696 - val_loss: 0.1494 - val_accuracy: 0.9459\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9730 - val_loss: 0.0646 - val_accuracy: 0.9823\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9715 - val_loss: 0.0549 - val_accuracy: 0.9805\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0798 - accuracy: 0.9700 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.1018 - val_accuracy: 0.9557\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9719 - val_loss: 0.1200 - val_accuracy: 0.9530\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9723 - val_loss: 0.0569 - val_accuracy: 0.9796\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9696 - val_loss: 0.0901 - val_accuracy: 0.9628\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0816 - accuracy: 0.9696 - val_loss: 0.0595 - val_accuracy: 0.9761\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9655 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.1359 - val_accuracy: 0.9468\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9719 - val_loss: 0.0702 - val_accuracy: 0.9734\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9708 - val_loss: 0.0634 - val_accuracy: 0.9743\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9681 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9734 - val_loss: 0.0605 - val_accuracy: 0.9823\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9715 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9734 - val_loss: 0.0547 - val_accuracy: 0.9849\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9700 - val_loss: 0.0787 - val_accuracy: 0.9743\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9692 - val_loss: 0.0961 - val_accuracy: 0.9628\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9708 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.0533 - val_accuracy: 0.9849\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0779 - accuracy: 0.9689 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9730 - val_loss: 0.1040 - val_accuracy: 0.9619\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9715 - val_loss: 0.0554 - val_accuracy: 0.9867\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.0748 - val_accuracy: 0.9725\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 0.0657 - val_accuracy: 0.9867\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9730 - val_loss: 0.0722 - val_accuracy: 0.9796\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9730 - val_loss: 0.0551 - val_accuracy: 0.9787\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9700 - val_loss: 0.0567 - val_accuracy: 0.9796\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9734 - val_loss: 0.0757 - val_accuracy: 0.9699\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9727 - val_loss: 0.2144 - val_accuracy: 0.9131\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9696 - val_loss: 0.0521 - val_accuracy: 0.9867\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9757 - val_loss: 0.1381 - val_accuracy: 0.9477\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9719 - val_loss: 0.0540 - val_accuracy: 0.9876\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9711 - val_loss: 0.0557 - val_accuracy: 0.9867\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9738 - val_loss: 0.1090 - val_accuracy: 0.9583\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9719 - val_loss: 0.0656 - val_accuracy: 0.9849\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.0657 - val_accuracy: 0.9743\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9708 - val_loss: 0.0515 - val_accuracy: 0.9858\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9723 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9692 - val_loss: 0.0664 - val_accuracy: 0.9743\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9711 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 0.1806 - val_accuracy: 0.9406\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9723 - val_loss: 0.0634 - val_accuracy: 0.9761\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.0872 - val_accuracy: 0.9672\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9753 - val_loss: 0.0589 - val_accuracy: 0.9876\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9727 - val_loss: 0.0534 - val_accuracy: 0.9832\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9727 - val_loss: 0.0716 - val_accuracy: 0.9734\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9734 - val_loss: 0.2239 - val_accuracy: 0.9238\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0748 - accuracy: 0.9738 - val_loss: 0.0530 - val_accuracy: 0.9840\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9708 - val_loss: 0.0663 - val_accuracy: 0.9805\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9776 - val_loss: 0.1373 - val_accuracy: 0.9512\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0806 - accuracy: 0.9734 - val_loss: 0.0606 - val_accuracy: 0.9787\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9719 - val_loss: 0.1124 - val_accuracy: 0.9566\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0711 - accuracy: 0.9753 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9730 - val_loss: 0.0521 - val_accuracy: 0.9849\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0739 - accuracy: 0.9711 - val_loss: 0.0539 - val_accuracy: 0.9876\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0727 - accuracy: 0.9738 - val_loss: 0.0730 - val_accuracy: 0.9743\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.1866 - val_accuracy: 0.9193\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9761 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9723 - val_loss: 0.0499 - val_accuracy: 0.9840\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9708 - val_loss: 0.0529 - val_accuracy: 0.9876\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9727 - val_loss: 0.0500 - val_accuracy: 0.9867\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9746 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9723 - val_loss: 0.1517 - val_accuracy: 0.9379\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0761 - accuracy: 0.9711 - val_loss: 0.0564 - val_accuracy: 0.9796\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9719 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0716 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9858\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0783 - accuracy: 0.9738 - val_loss: 0.0542 - val_accuracy: 0.9885\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9749 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9734 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9761 - val_loss: 0.0806 - val_accuracy: 0.9690\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.0497 - val_accuracy: 0.9867\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0748 - accuracy: 0.9749 - val_loss: 0.0515 - val_accuracy: 0.9876\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9723 - val_loss: 0.0502 - val_accuracy: 0.9867\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.0547 - val_accuracy: 0.9796\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9787 - val_loss: 0.0546 - val_accuracy: 0.9814\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9738 - val_loss: 0.1069 - val_accuracy: 0.9530\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.1394 - val_accuracy: 0.9415\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0722 - accuracy: 0.9753 - val_loss: 0.0496 - val_accuracy: 0.9876\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9765 - val_loss: 0.0534 - val_accuracy: 0.9885\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0748 - accuracy: 0.9723 - val_loss: 0.0577 - val_accuracy: 0.9787\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9753 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0699 - accuracy: 0.9765 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0741 - accuracy: 0.9734 - val_loss: 0.1580 - val_accuracy: 0.9477\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0737 - accuracy: 0.9723 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9730 - val_loss: 0.0495 - val_accuracy: 0.9858\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9734 - val_loss: 0.0904 - val_accuracy: 0.9663\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9730 - val_loss: 0.0483 - val_accuracy: 0.9840\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9757 - val_loss: 0.0613 - val_accuracy: 0.9787\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9727 - val_loss: 0.0494 - val_accuracy: 0.9858\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.0710 - val_accuracy: 0.9770\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9738 - val_loss: 0.0622 - val_accuracy: 0.9849\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.0642 - val_accuracy: 0.9787\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0756 - accuracy: 0.9715 - val_loss: 0.0758 - val_accuracy: 0.9716\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0733 - accuracy: 0.9730 - val_loss: 0.0636 - val_accuracy: 0.9805\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0726 - accuracy: 0.9757 - val_loss: 0.0492 - val_accuracy: 0.9894\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.0591 - val_accuracy: 0.9787\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0758 - accuracy: 0.9711 - val_loss: 0.0868 - val_accuracy: 0.9690\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0733 - accuracy: 0.9742 - val_loss: 0.0479 - val_accuracy: 0.9849\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9776 - val_loss: 0.0648 - val_accuracy: 0.9805\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0766 - accuracy: 0.9761 - val_loss: 0.0841 - val_accuracy: 0.9681\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0729 - accuracy: 0.9738 - val_loss: 0.0825 - val_accuracy: 0.9690\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0738 - accuracy: 0.9715 - val_loss: 0.0717 - val_accuracy: 0.9752\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0722 - accuracy: 0.9768 - val_loss: 0.0567 - val_accuracy: 0.9805\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9749 - val_loss: 0.0543 - val_accuracy: 0.9840\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.1016 - val_accuracy: 0.9610\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9749 - val_loss: 0.0550 - val_accuracy: 0.9858\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0513 - val_accuracy: 0.9876\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9723 - val_loss: 0.0494 - val_accuracy: 0.9849\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0668 - accuracy: 0.9757 - val_loss: 0.0546 - val_accuracy: 0.9858\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0738 - accuracy: 0.9738 - val_loss: 0.0575 - val_accuracy: 0.9796\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 0.0689 - val_accuracy: 0.9770\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9704 - val_loss: 0.0484 - val_accuracy: 0.9885\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9727 - val_loss: 0.0781 - val_accuracy: 0.9690\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0693 - accuracy: 0.9753 - val_loss: 0.0531 - val_accuracy: 0.9876\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.0925 - val_accuracy: 0.9663\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9738 - val_loss: 0.0733 - val_accuracy: 0.9761\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0704 - accuracy: 0.9715 - val_loss: 0.0707 - val_accuracy: 0.9778\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.0511 - val_accuracy: 0.9876\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0685 - accuracy: 0.9738 - val_loss: 0.0913 - val_accuracy: 0.9654\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0750 - accuracy: 0.9734 - val_loss: 0.0639 - val_accuracy: 0.9787\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.0494 - val_accuracy: 0.9894\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9765 - val_loss: 0.0490 - val_accuracy: 0.9849\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.2045 - val_accuracy: 0.9140\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9727 - val_loss: 0.0491 - val_accuracy: 0.9840\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0711 - accuracy: 0.9761 - val_loss: 0.0606 - val_accuracy: 0.9787\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.0478 - val_accuracy: 0.9885\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0728 - accuracy: 0.9753 - val_loss: 0.0498 - val_accuracy: 0.9885\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9753 - val_loss: 0.0487 - val_accuracy: 0.9849\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9746 - val_loss: 0.0725 - val_accuracy: 0.9725\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9719 - val_loss: 0.0770 - val_accuracy: 0.9707\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9768 - val_loss: 0.0632 - val_accuracy: 0.9796\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9719 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 0.0528 - val_accuracy: 0.9867\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0737 - accuracy: 0.9727 - val_loss: 0.0508 - val_accuracy: 0.9858\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9738 - val_loss: 0.0705 - val_accuracy: 0.9734\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.0811 - val_accuracy: 0.9716\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9749 - val_loss: 0.1337 - val_accuracy: 0.9406\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.0687 - val_accuracy: 0.9734\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0709 - accuracy: 0.9765 - val_loss: 0.0533 - val_accuracy: 0.9867\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0672 - accuracy: 0.9757 - val_loss: 0.0688 - val_accuracy: 0.9743\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0696 - accuracy: 0.9768 - val_loss: 0.1483 - val_accuracy: 0.9326\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0748 - accuracy: 0.9727 - val_loss: 0.0562 - val_accuracy: 0.9858\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0715 - accuracy: 0.9749 - val_loss: 0.0502 - val_accuracy: 0.9867\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0717 - accuracy: 0.9768 - val_loss: 0.0499 - val_accuracy: 0.9867\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.0570 - val_accuracy: 0.9823\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9734 - val_loss: 0.0592 - val_accuracy: 0.9787\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.0484 - val_accuracy: 0.9894\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.0526 - val_accuracy: 0.9867\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9734 - val_loss: 0.0543 - val_accuracy: 0.9849\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0477 - val_accuracy: 0.9885\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.0511 - val_accuracy: 0.9849\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0690 - accuracy: 0.9776 - val_loss: 0.0501 - val_accuracy: 0.9840\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0723 - accuracy: 0.9768 - val_loss: 0.0470 - val_accuracy: 0.9876\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0724 - accuracy: 0.9749 - val_loss: 0.0592 - val_accuracy: 0.9787\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0706 - accuracy: 0.9749 - val_loss: 0.0562 - val_accuracy: 0.9796\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0717 - accuracy: 0.9719 - val_loss: 0.0712 - val_accuracy: 0.9770\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 0.0976 - val_accuracy: 0.9654\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0697 - accuracy: 0.9772 - val_loss: 0.1313 - val_accuracy: 0.9566\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0717 - accuracy: 0.9738 - val_loss: 0.0558 - val_accuracy: 0.9858\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0696 - accuracy: 0.9746 - val_loss: 0.1021 - val_accuracy: 0.9637\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.0596 - val_accuracy: 0.9823\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0682 - accuracy: 0.9768 - val_loss: 0.0492 - val_accuracy: 0.9885\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.0466 - val_accuracy: 0.9858\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.0571 - val_accuracy: 0.9832\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0756 - accuracy: 0.9730 - val_loss: 0.0485 - val_accuracy: 0.9876\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0698 - accuracy: 0.9768 - val_loss: 0.0688 - val_accuracy: 0.9752\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0698 - accuracy: 0.9772 - val_loss: 0.1075 - val_accuracy: 0.9557\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0735 - accuracy: 0.9753 - val_loss: 0.0563 - val_accuracy: 0.9858\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0701 - accuracy: 0.9746 - val_loss: 0.0465 - val_accuracy: 0.9894\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 0.0906 - val_accuracy: 0.9672\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0694 - accuracy: 0.9749 - val_loss: 0.0462 - val_accuracy: 0.9894\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0688 - accuracy: 0.9742 - val_loss: 0.0921 - val_accuracy: 0.9672\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9738 - val_loss: 0.0671 - val_accuracy: 0.9761\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.0584 - val_accuracy: 0.9787\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 1s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963833634719711\n",
      "0.9451114922813036\n",
      "0.9700704225352113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.6]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9535783365570599\n",
      "0.9762376237623763\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
