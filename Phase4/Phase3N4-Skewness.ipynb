{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  0.1  3.3 ...  5.5  0.8  0.0]\n",
      " [ 1.0  10.8  851.2 ...  4.4  1.0  0.0]\n",
      " [ 1.0  3.0  336.1 ...  7.5  0.9  0.0]\n",
      " ...\n",
      " [ 0.0  17.1  1117.6 ...  5.0  1.0  0.0]\n",
      " [ 0.0  4.5  268.9 ...  3.3  1.0  0.0]\n",
      " [ 1.0  4.2  684.5 ...  8.6  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 5]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 5]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 4s 19ms/step - loss: 0.6956 - accuracy: 0.5129 - val_loss: 0.6788 - val_accuracy: 0.5851\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6695 - accuracy: 0.6006 - val_loss: 0.6612 - val_accuracy: 0.6667\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6541 - accuracy: 0.6796 - val_loss: 0.6468 - val_accuracy: 0.6941\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6406 - accuracy: 0.7164 - val_loss: 0.6340 - val_accuracy: 0.7163\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6286 - accuracy: 0.7251 - val_loss: 0.6225 - val_accuracy: 0.7367\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6175 - accuracy: 0.7308 - val_loss: 0.6118 - val_accuracy: 0.7420\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6082 - accuracy: 0.7304 - val_loss: 0.6042 - val_accuracy: 0.7456\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5996 - accuracy: 0.7354 - val_loss: 0.5977 - val_accuracy: 0.7340\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5920 - accuracy: 0.7346 - val_loss: 0.5918 - val_accuracy: 0.7358\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5861 - accuracy: 0.7331 - val_loss: 0.5866 - val_accuracy: 0.7340\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5809 - accuracy: 0.7342 - val_loss: 0.5820 - val_accuracy: 0.7456\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5759 - accuracy: 0.7346 - val_loss: 0.5788 - val_accuracy: 0.7358\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5718 - accuracy: 0.7312 - val_loss: 0.5753 - val_accuracy: 0.7447\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5683 - accuracy: 0.7327 - val_loss: 0.5717 - val_accuracy: 0.7438\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5644 - accuracy: 0.7346 - val_loss: 0.5728 - val_accuracy: 0.7349\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5625 - accuracy: 0.7354 - val_loss: 0.5679 - val_accuracy: 0.7465\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5599 - accuracy: 0.7335 - val_loss: 0.5682 - val_accuracy: 0.7340\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5580 - accuracy: 0.7358 - val_loss: 0.5650 - val_accuracy: 0.7420\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5562 - accuracy: 0.7346 - val_loss: 0.5636 - val_accuracy: 0.7429\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5547 - accuracy: 0.7346 - val_loss: 0.5624 - val_accuracy: 0.7420\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7358 - val_loss: 0.5615 - val_accuracy: 0.7394\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5523 - accuracy: 0.7380 - val_loss: 0.5612 - val_accuracy: 0.7429\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.7339 - val_loss: 0.5611 - val_accuracy: 0.7429\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5506 - accuracy: 0.7327 - val_loss: 0.5605 - val_accuracy: 0.7438\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5499 - accuracy: 0.7354 - val_loss: 0.5610 - val_accuracy: 0.7465\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5493 - accuracy: 0.7308 - val_loss: 0.5590 - val_accuracy: 0.7420\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7350 - val_loss: 0.5586 - val_accuracy: 0.7411\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5484 - accuracy: 0.7354 - val_loss: 0.5590 - val_accuracy: 0.7438\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5479 - accuracy: 0.7346 - val_loss: 0.5596 - val_accuracy: 0.7456\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5476 - accuracy: 0.7327 - val_loss: 0.5586 - val_accuracy: 0.7438\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5474 - accuracy: 0.7346 - val_loss: 0.5594 - val_accuracy: 0.7456\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7331 - val_loss: 0.5597 - val_accuracy: 0.7394\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5469 - accuracy: 0.7346 - val_loss: 0.5588 - val_accuracy: 0.7473\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.7327 - val_loss: 0.5574 - val_accuracy: 0.7411\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5464 - accuracy: 0.7342 - val_loss: 0.5579 - val_accuracy: 0.7429\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5462 - accuracy: 0.7350 - val_loss: 0.5604 - val_accuracy: 0.7358\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5464 - accuracy: 0.7335 - val_loss: 0.5593 - val_accuracy: 0.7447\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5462 - accuracy: 0.7339 - val_loss: 0.5584 - val_accuracy: 0.7429\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5461 - accuracy: 0.7346 - val_loss: 0.5579 - val_accuracy: 0.7429\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7350 - val_loss: 0.5585 - val_accuracy: 0.7482\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7361 - val_loss: 0.5596 - val_accuracy: 0.7385\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5458 - accuracy: 0.7358 - val_loss: 0.5594 - val_accuracy: 0.7385\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5458 - accuracy: 0.7331 - val_loss: 0.5575 - val_accuracy: 0.7420\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5456 - accuracy: 0.7354 - val_loss: 0.5589 - val_accuracy: 0.7385\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5455 - accuracy: 0.7358 - val_loss: 0.5591 - val_accuracy: 0.7340\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5453 - accuracy: 0.7335 - val_loss: 0.5573 - val_accuracy: 0.7473\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5451 - accuracy: 0.7320 - val_loss: 0.5586 - val_accuracy: 0.7367\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5445 - accuracy: 0.7323 - val_loss: 0.5571 - val_accuracy: 0.7456\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5444 - accuracy: 0.7358 - val_loss: 0.5564 - val_accuracy: 0.7456\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5444 - accuracy: 0.7361 - val_loss: 0.5583 - val_accuracy: 0.7358\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5442 - accuracy: 0.7331 - val_loss: 0.5555 - val_accuracy: 0.7429\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5444 - accuracy: 0.7346 - val_loss: 0.5561 - val_accuracy: 0.7456\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5441 - accuracy: 0.7323 - val_loss: 0.5563 - val_accuracy: 0.7394\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.7350 - val_loss: 0.5575 - val_accuracy: 0.7376\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7335 - val_loss: 0.5569 - val_accuracy: 0.7358\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.7331 - val_loss: 0.5553 - val_accuracy: 0.7429\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.7350 - val_loss: 0.5555 - val_accuracy: 0.7473\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.7339 - val_loss: 0.5568 - val_accuracy: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.7327 - val_loss: 0.5573 - val_accuracy: 0.7367\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5441 - accuracy: 0.7331 - val_loss: 0.5569 - val_accuracy: 0.7358\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.7335 - val_loss: 0.5554 - val_accuracy: 0.7456\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5438 - accuracy: 0.7350 - val_loss: 0.5553 - val_accuracy: 0.7456\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5438 - accuracy: 0.7380 - val_loss: 0.5557 - val_accuracy: 0.7438\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5599 - val_accuracy: 0.7332\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5441 - accuracy: 0.7354 - val_loss: 0.5572 - val_accuracy: 0.7358\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7342 - val_loss: 0.5560 - val_accuracy: 0.7385\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7316 - val_loss: 0.5554 - val_accuracy: 0.7447\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7342 - val_loss: 0.5558 - val_accuracy: 0.7385\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7342 - val_loss: 0.5557 - val_accuracy: 0.7385\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5435 - accuracy: 0.7308 - val_loss: 0.5548 - val_accuracy: 0.7465\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7316 - val_loss: 0.5567 - val_accuracy: 0.7358\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5570 - val_accuracy: 0.7349\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7350 - val_loss: 0.5573 - val_accuracy: 0.7349\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5434 - accuracy: 0.7320 - val_loss: 0.5547 - val_accuracy: 0.7456\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5437 - accuracy: 0.7331 - val_loss: 0.5552 - val_accuracy: 0.7385\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5432 - accuracy: 0.7316 - val_loss: 0.5567 - val_accuracy: 0.7349\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5434 - accuracy: 0.7331 - val_loss: 0.5562 - val_accuracy: 0.7367\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.7312 - val_loss: 0.5548 - val_accuracy: 0.7465\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.7327 - val_loss: 0.5561 - val_accuracy: 0.7367\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5435 - accuracy: 0.7301 - val_loss: 0.5552 - val_accuracy: 0.7394\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7327 - val_loss: 0.5554 - val_accuracy: 0.7340\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7320 - val_loss: 0.5565 - val_accuracy: 0.7340\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7331 - val_loss: 0.5560 - val_accuracy: 0.7376\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5553 - val_accuracy: 0.7340\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.7342 - val_loss: 0.5541 - val_accuracy: 0.7482\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.7308 - val_loss: 0.5543 - val_accuracy: 0.7456\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.7297 - val_loss: 0.5543 - val_accuracy: 0.7465\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5550 - val_accuracy: 0.7340\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.7320 - val_loss: 0.5543 - val_accuracy: 0.7456\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5433 - accuracy: 0.7327 - val_loss: 0.5548 - val_accuracy: 0.7385\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7323 - val_loss: 0.5545 - val_accuracy: 0.7411\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7323 - val_loss: 0.5541 - val_accuracy: 0.7465\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5433 - accuracy: 0.7323 - val_loss: 0.5550 - val_accuracy: 0.7358\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5431 - accuracy: 0.7331 - val_loss: 0.5574 - val_accuracy: 0.7358\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.7354 - val_loss: 0.5560 - val_accuracy: 0.7367\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7331 - val_loss: 0.5558 - val_accuracy: 0.7358\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.7312 - val_loss: 0.5551 - val_accuracy: 0.7358\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5432 - accuracy: 0.7297 - val_loss: 0.5546 - val_accuracy: 0.7358\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7327 - val_loss: 0.5552 - val_accuracy: 0.7367\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7358 - val_loss: 0.5558 - val_accuracy: 0.7349\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7339 - val_loss: 0.5553 - val_accuracy: 0.7376\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7327 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5543 - val_accuracy: 0.7385\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7327 - val_loss: 0.5538 - val_accuracy: 0.7456\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7346 - val_loss: 0.5555 - val_accuracy: 0.7367\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.7339 - val_loss: 0.5540 - val_accuracy: 0.7456\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.7339 - val_loss: 0.5542 - val_accuracy: 0.7394\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7354 - val_loss: 0.5546 - val_accuracy: 0.7340\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7335 - val_loss: 0.5564 - val_accuracy: 0.7358\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7304 - val_loss: 0.5539 - val_accuracy: 0.7456\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7327 - val_loss: 0.5547 - val_accuracy: 0.7358\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7320 - val_loss: 0.5549 - val_accuracy: 0.7358\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5431 - accuracy: 0.7320 - val_loss: 0.5546 - val_accuracy: 0.7340\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7331 - val_loss: 0.5542 - val_accuracy: 0.7402\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7316 - val_loss: 0.5537 - val_accuracy: 0.7456\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5425 - accuracy: 0.7323 - val_loss: 0.5567 - val_accuracy: 0.7358\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7320 - val_loss: 0.5547 - val_accuracy: 0.7358\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7335 - val_loss: 0.5546 - val_accuracy: 0.7358\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7331 - val_loss: 0.5538 - val_accuracy: 0.7447\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7335 - val_loss: 0.5556 - val_accuracy: 0.7349\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7323 - val_loss: 0.5537 - val_accuracy: 0.7394\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7358 - val_loss: 0.5539 - val_accuracy: 0.7402\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7323 - val_loss: 0.5538 - val_accuracy: 0.7420\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7339 - val_loss: 0.5546 - val_accuracy: 0.7340\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7342 - val_loss: 0.5562 - val_accuracy: 0.7358\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7342 - val_loss: 0.5545 - val_accuracy: 0.7385\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7354 - val_loss: 0.5551 - val_accuracy: 0.7376\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5428 - accuracy: 0.7312 - val_loss: 0.5538 - val_accuracy: 0.7456\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7323 - val_loss: 0.5553 - val_accuracy: 0.7358\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7339 - val_loss: 0.5541 - val_accuracy: 0.7385\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.5565 - val_accuracy: 0.7358\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7304 - val_loss: 0.5551 - val_accuracy: 0.7358\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7323 - val_loss: 0.5540 - val_accuracy: 0.7358\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7327 - val_loss: 0.5540 - val_accuracy: 0.7358\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5539 - val_accuracy: 0.7385\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7384 - val_loss: 0.5554 - val_accuracy: 0.7349\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7316 - val_loss: 0.5545 - val_accuracy: 0.7367\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7339 - val_loss: 0.5566 - val_accuracy: 0.7358\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7331 - val_loss: 0.5557 - val_accuracy: 0.7349\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7335 - val_loss: 0.5547 - val_accuracy: 0.7376\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7331 - val_loss: 0.5535 - val_accuracy: 0.7465\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7350 - val_loss: 0.5546 - val_accuracy: 0.7376\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7320 - val_loss: 0.5543 - val_accuracy: 0.7358\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7327 - val_loss: 0.5537 - val_accuracy: 0.7394\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5428 - accuracy: 0.7320 - val_loss: 0.5549 - val_accuracy: 0.7340\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5539 - val_accuracy: 0.7340\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5553 - val_accuracy: 0.7349\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7323 - val_loss: 0.5550 - val_accuracy: 0.7349\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7342 - val_loss: 0.5534 - val_accuracy: 0.7456\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7335 - val_loss: 0.5542 - val_accuracy: 0.7340\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7350 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5538 - val_accuracy: 0.7358\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7327 - val_loss: 0.5533 - val_accuracy: 0.7438\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7346 - val_loss: 0.5541 - val_accuracy: 0.7367\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7339 - val_loss: 0.5531 - val_accuracy: 0.7411\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7327 - val_loss: 0.5545 - val_accuracy: 0.7358\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7335 - val_loss: 0.5543 - val_accuracy: 0.7376\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5429 - accuracy: 0.7304 - val_loss: 0.5536 - val_accuracy: 0.7340\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5428 - accuracy: 0.7331 - val_loss: 0.5543 - val_accuracy: 0.7376\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7320 - val_loss: 0.5534 - val_accuracy: 0.7447\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5429 - accuracy: 0.7327 - val_loss: 0.5545 - val_accuracy: 0.7376\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5425 - accuracy: 0.7331 - val_loss: 0.5564 - val_accuracy: 0.7358\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7327 - val_loss: 0.5533 - val_accuracy: 0.7447\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7331 - val_loss: 0.5552 - val_accuracy: 0.7349\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7316 - val_loss: 0.5529 - val_accuracy: 0.7465\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7323 - val_loss: 0.5533 - val_accuracy: 0.7385\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.5529 - val_accuracy: 0.7465\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5424 - accuracy: 0.7354 - val_loss: 0.5542 - val_accuracy: 0.7376\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5427 - accuracy: 0.7323 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.7312 - val_loss: 0.5529 - val_accuracy: 0.7473\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5428 - accuracy: 0.7365 - val_loss: 0.5554 - val_accuracy: 0.7358\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5428 - accuracy: 0.7327 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5528 - val_accuracy: 0.7465\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7358 - val_loss: 0.5542 - val_accuracy: 0.7376\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7361 - val_loss: 0.5555 - val_accuracy: 0.7358\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7297 - val_loss: 0.5530 - val_accuracy: 0.7456\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7354 - val_loss: 0.5533 - val_accuracy: 0.7394\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7301 - val_loss: 0.5534 - val_accuracy: 0.7358\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7308 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7354 - val_loss: 0.5542 - val_accuracy: 0.7358\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5536 - val_accuracy: 0.7358\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7339 - val_loss: 0.5550 - val_accuracy: 0.7358\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.5535 - val_accuracy: 0.7367\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.7361 - val_loss: 0.5557 - val_accuracy: 0.7367\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7361 - val_loss: 0.5532 - val_accuracy: 0.7394\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7327 - val_loss: 0.5533 - val_accuracy: 0.7385\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7335 - val_loss: 0.5540 - val_accuracy: 0.7367\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7320 - val_loss: 0.5529 - val_accuracy: 0.7447\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7354 - val_loss: 0.5533 - val_accuracy: 0.7340\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7327 - val_loss: 0.5540 - val_accuracy: 0.7358\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.5547 - val_accuracy: 0.7349\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7308 - val_loss: 0.5529 - val_accuracy: 0.7385\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7342 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7331 - val_loss: 0.5532 - val_accuracy: 0.7358\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7320 - val_loss: 0.5565 - val_accuracy: 0.7332\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7335 - val_loss: 0.5524 - val_accuracy: 0.7465\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5529 - val_accuracy: 0.7385\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5530 - val_accuracy: 0.7385\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5425 - accuracy: 0.7339 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7346 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7327 - val_loss: 0.5534 - val_accuracy: 0.7367\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7308 - val_loss: 0.5522 - val_accuracy: 0.7456\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7323 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5425 - accuracy: 0.7308 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7331 - val_loss: 0.5543 - val_accuracy: 0.7349\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7312 - val_loss: 0.5539 - val_accuracy: 0.7340\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7289 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7331 - val_loss: 0.5529 - val_accuracy: 0.7394\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7316 - val_loss: 0.5523 - val_accuracy: 0.7465\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7312 - val_loss: 0.5551 - val_accuracy: 0.7358\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.7320 - val_loss: 0.5523 - val_accuracy: 0.7447\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5545 - val_accuracy: 0.7358\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7342 - val_loss: 0.5533 - val_accuracy: 0.7367\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5541 - val_accuracy: 0.7349\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7304 - val_loss: 0.5535 - val_accuracy: 0.7376\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7331 - val_loss: 0.5541 - val_accuracy: 0.7349\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7327 - val_loss: 0.5521 - val_accuracy: 0.7456\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7297 - val_loss: 0.5528 - val_accuracy: 0.7349\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7342 - val_loss: 0.5541 - val_accuracy: 0.7349\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7327 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7312 - val_loss: 0.5523 - val_accuracy: 0.7438\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7316 - val_loss: 0.5540 - val_accuracy: 0.7349\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7339 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7323 - val_loss: 0.5530 - val_accuracy: 0.7367\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7335 - val_loss: 0.5530 - val_accuracy: 0.7367\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7323 - val_loss: 0.5523 - val_accuracy: 0.7438\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5526 - val_accuracy: 0.7358\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7316 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7323 - val_loss: 0.5525 - val_accuracy: 0.7385\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7320 - val_loss: 0.5526 - val_accuracy: 0.7340\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7316 - val_loss: 0.5529 - val_accuracy: 0.7358\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7316 - val_loss: 0.5528 - val_accuracy: 0.7340\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7339 - val_loss: 0.5525 - val_accuracy: 0.7385\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7342 - val_loss: 0.5536 - val_accuracy: 0.7349\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7365 - val_loss: 0.5539 - val_accuracy: 0.7349\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7320 - val_loss: 0.5527 - val_accuracy: 0.7385\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7304 - val_loss: 0.5519 - val_accuracy: 0.7429\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7358 - val_loss: 0.5549 - val_accuracy: 0.7358\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7293 - val_loss: 0.5542 - val_accuracy: 0.7358\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7301 - val_loss: 0.5549 - val_accuracy: 0.7358\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7350 - val_loss: 0.5520 - val_accuracy: 0.7402\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7331 - val_loss: 0.5522 - val_accuracy: 0.7367\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7327 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7339 - val_loss: 0.5521 - val_accuracy: 0.7358\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7331 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7316 - val_loss: 0.5521 - val_accuracy: 0.7385\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7342 - val_loss: 0.5548 - val_accuracy: 0.7358\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7323 - val_loss: 0.5529 - val_accuracy: 0.7367\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7369 - val_loss: 0.5539 - val_accuracy: 0.7358\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7320 - val_loss: 0.5541 - val_accuracy: 0.7358\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7354 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7335 - val_loss: 0.5552 - val_accuracy: 0.7349\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7312 - val_loss: 0.5542 - val_accuracy: 0.7358\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7323 - val_loss: 0.5528 - val_accuracy: 0.7367\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7331 - val_loss: 0.5529 - val_accuracy: 0.7376\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7308 - val_loss: 0.5526 - val_accuracy: 0.7367\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5422 - accuracy: 0.7331 - val_loss: 0.5524 - val_accuracy: 0.7367\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7346 - val_loss: 0.5528 - val_accuracy: 0.7376\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7316 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7312 - val_loss: 0.5517 - val_accuracy: 0.7456\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7323 - val_loss: 0.5516 - val_accuracy: 0.7465\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7339 - val_loss: 0.5517 - val_accuracy: 0.7456\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7342 - val_loss: 0.5527 - val_accuracy: 0.7367\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7327 - val_loss: 0.5520 - val_accuracy: 0.7385\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7339 - val_loss: 0.5534 - val_accuracy: 0.7349\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7323 - val_loss: 0.5513 - val_accuracy: 0.7438\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5522 - val_accuracy: 0.7358\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7304 - val_loss: 0.5515 - val_accuracy: 0.7465\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7331 - val_loss: 0.5517 - val_accuracy: 0.7438\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7320 - val_loss: 0.5524 - val_accuracy: 0.7358\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7342 - val_loss: 0.5527 - val_accuracy: 0.7358\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7342 - val_loss: 0.5519 - val_accuracy: 0.7385\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7304 - val_loss: 0.5521 - val_accuracy: 0.7358\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7320 - val_loss: 0.5527 - val_accuracy: 0.7358\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7312 - val_loss: 0.5510 - val_accuracy: 0.7429\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7331 - val_loss: 0.5511 - val_accuracy: 0.7482\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7365 - val_loss: 0.5559 - val_accuracy: 0.7278\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7327 - val_loss: 0.5531 - val_accuracy: 0.7349\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7308 - val_loss: 0.5511 - val_accuracy: 0.7456\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7327 - val_loss: 0.5512 - val_accuracy: 0.7456\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7342 - val_loss: 0.5523 - val_accuracy: 0.7367\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7316 - val_loss: 0.5519 - val_accuracy: 0.7340\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5522 - val_accuracy: 0.7367\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7278 - val_loss: 0.5514 - val_accuracy: 0.7394\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7335 - val_loss: 0.5527 - val_accuracy: 0.7349\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7308 - val_loss: 0.5548 - val_accuracy: 0.7349\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7373 - val_loss: 0.5510 - val_accuracy: 0.7473\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5518 - val_accuracy: 0.7340\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7312 - val_loss: 0.5530 - val_accuracy: 0.7349\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7312 - val_loss: 0.5510 - val_accuracy: 0.7438\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5521 - val_accuracy: 0.7358\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7327 - val_loss: 0.5526 - val_accuracy: 0.7376\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7297 - val_loss: 0.5514 - val_accuracy: 0.7394\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7323 - val_loss: 0.5520 - val_accuracy: 0.7367\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7331 - val_loss: 0.5518 - val_accuracy: 0.7358\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7335 - val_loss: 0.5521 - val_accuracy: 0.7367\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7320 - val_loss: 0.5510 - val_accuracy: 0.7465\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7327 - val_loss: 0.5517 - val_accuracy: 0.7358\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7331 - val_loss: 0.5529 - val_accuracy: 0.7349\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.7350 - val_loss: 0.5510 - val_accuracy: 0.7456\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5422 - accuracy: 0.7346 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7323 - val_loss: 0.5514 - val_accuracy: 0.7385\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7331 - val_loss: 0.5515 - val_accuracy: 0.7376\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7361 - val_loss: 0.5520 - val_accuracy: 0.7376\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7339 - val_loss: 0.5516 - val_accuracy: 0.7340\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7342 - val_loss: 0.5519 - val_accuracy: 0.7367\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5417 - accuracy: 0.7320 - val_loss: 0.5523 - val_accuracy: 0.7358\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7312 - val_loss: 0.5520 - val_accuracy: 0.7376\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5417 - accuracy: 0.7331 - val_loss: 0.5510 - val_accuracy: 0.7438\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7335 - val_loss: 0.5507 - val_accuracy: 0.7465\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7342 - val_loss: 0.5528 - val_accuracy: 0.7349\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7308 - val_loss: 0.5547 - val_accuracy: 0.7349\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7316 - val_loss: 0.5514 - val_accuracy: 0.7394\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7335 - val_loss: 0.5515 - val_accuracy: 0.7376\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5421 - accuracy: 0.7342 - val_loss: 0.5521 - val_accuracy: 0.7367\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.5421 - accuracy: 0.7327 - val_loss: 0.5512 - val_accuracy: 0.7438\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5421 - accuracy: 0.7327 - val_loss: 0.5515 - val_accuracy: 0.7358\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5536 - val_accuracy: 0.7358\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5419 - accuracy: 0.7308 - val_loss: 0.5511 - val_accuracy: 0.7447\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5414 - accuracy: 0.7346 - val_loss: 0.5560 - val_accuracy: 0.7270\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5423 - accuracy: 0.7297 - val_loss: 0.5543 - val_accuracy: 0.7349\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7312 - val_loss: 0.5518 - val_accuracy: 0.7358\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7320 - val_loss: 0.5518 - val_accuracy: 0.7367\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5419 - accuracy: 0.7339 - val_loss: 0.5535 - val_accuracy: 0.7358\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7308 - val_loss: 0.5511 - val_accuracy: 0.7402\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5421 - accuracy: 0.7342 - val_loss: 0.5520 - val_accuracy: 0.7367\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7323 - val_loss: 0.5527 - val_accuracy: 0.7349\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.7331 - val_loss: 0.5538 - val_accuracy: 0.7358\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7316 - val_loss: 0.5516 - val_accuracy: 0.7358\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7301 - val_loss: 0.5512 - val_accuracy: 0.7385\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7327 - val_loss: 0.5514 - val_accuracy: 0.7340\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7323 - val_loss: 0.5515 - val_accuracy: 0.7358\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7346 - val_loss: 0.5532 - val_accuracy: 0.7358\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5510 - val_accuracy: 0.7394\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7335 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7335 - val_loss: 0.5517 - val_accuracy: 0.7376\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7320 - val_loss: 0.5513 - val_accuracy: 0.7358\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7342 - val_loss: 0.5517 - val_accuracy: 0.7376\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5523 - val_accuracy: 0.7340\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5512 - val_accuracy: 0.7358\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5523 - val_accuracy: 0.7349\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7346 - val_loss: 0.5510 - val_accuracy: 0.7385\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7320 - val_loss: 0.5518 - val_accuracy: 0.7376\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7327 - val_loss: 0.5525 - val_accuracy: 0.7349\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7320 - val_loss: 0.5516 - val_accuracy: 0.7376\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5513 - val_accuracy: 0.7358\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7312 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5508 - val_accuracy: 0.7394\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7342 - val_loss: 0.5510 - val_accuracy: 0.7358\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7335 - val_loss: 0.5515 - val_accuracy: 0.7367\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5515 - val_accuracy: 0.7367\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7339 - val_loss: 0.5528 - val_accuracy: 0.7358\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7312 - val_loss: 0.5504 - val_accuracy: 0.7482\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7327 - val_loss: 0.5526 - val_accuracy: 0.7358\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7293 - val_loss: 0.5511 - val_accuracy: 0.7358\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5517 - val_accuracy: 0.7376\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5508 - val_accuracy: 0.7385\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7361 - val_loss: 0.5523 - val_accuracy: 0.7349\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7301 - val_loss: 0.5513 - val_accuracy: 0.7376\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7342 - val_loss: 0.5510 - val_accuracy: 0.7358\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.7331 - val_loss: 0.5508 - val_accuracy: 0.7340\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.5509 - val_accuracy: 0.7349\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7339 - val_loss: 0.5517 - val_accuracy: 0.7340\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5418 - accuracy: 0.7301 - val_loss: 0.5505 - val_accuracy: 0.7394\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7346 - val_loss: 0.5522 - val_accuracy: 0.7358\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7320 - val_loss: 0.5512 - val_accuracy: 0.7358\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7301 - val_loss: 0.5515 - val_accuracy: 0.7376\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7316 - val_loss: 0.5514 - val_accuracy: 0.7376\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5510 - val_accuracy: 0.7340\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7335 - val_loss: 0.5510 - val_accuracy: 0.7358\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.5521 - val_accuracy: 0.7349\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7331 - val_loss: 0.5501 - val_accuracy: 0.7429\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7335 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7308 - val_loss: 0.5516 - val_accuracy: 0.7376\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7320 - val_loss: 0.5506 - val_accuracy: 0.7394\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7293 - val_loss: 0.5507 - val_accuracy: 0.7385\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7327 - val_loss: 0.5543 - val_accuracy: 0.7323\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7335 - val_loss: 0.5530 - val_accuracy: 0.7358\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7304 - val_loss: 0.5511 - val_accuracy: 0.7358\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7339 - val_loss: 0.5515 - val_accuracy: 0.7376\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7346 - val_loss: 0.5533 - val_accuracy: 0.7358\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7308 - val_loss: 0.5508 - val_accuracy: 0.7340\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5514 - val_accuracy: 0.7376\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7320 - val_loss: 0.5518 - val_accuracy: 0.7358\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5517 - val_accuracy: 0.7358\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7339 - val_loss: 0.5506 - val_accuracy: 0.7394\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7327 - val_loss: 0.5505 - val_accuracy: 0.7394\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7327 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7312 - val_loss: 0.5504 - val_accuracy: 0.7411\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7335 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7323 - val_loss: 0.5510 - val_accuracy: 0.7367\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5418 - accuracy: 0.7312 - val_loss: 0.5505 - val_accuracy: 0.7385\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7335 - val_loss: 0.5508 - val_accuracy: 0.7340\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7323 - val_loss: 0.5517 - val_accuracy: 0.7340\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7320 - val_loss: 0.5513 - val_accuracy: 0.7367\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7316 - val_loss: 0.5508 - val_accuracy: 0.7358\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7327 - val_loss: 0.5509 - val_accuracy: 0.7358\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7342 - val_loss: 0.5515 - val_accuracy: 0.7358\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7312 - val_loss: 0.5507 - val_accuracy: 0.7358\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7335 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7350 - val_loss: 0.5531 - val_accuracy: 0.7358\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5506 - val_accuracy: 0.7385\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7327 - val_loss: 0.5509 - val_accuracy: 0.7358\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7339 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7323 - val_loss: 0.5516 - val_accuracy: 0.7358\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7342 - val_loss: 0.5509 - val_accuracy: 0.7358\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7350 - val_loss: 0.5509 - val_accuracy: 0.7358\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7339 - val_loss: 0.5503 - val_accuracy: 0.7394\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7354 - val_loss: 0.5501 - val_accuracy: 0.7456\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5509 - val_accuracy: 0.7367\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7308 - val_loss: 0.5517 - val_accuracy: 0.7349\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7335 - val_loss: 0.5519 - val_accuracy: 0.7349\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7316 - val_loss: 0.5522 - val_accuracy: 0.7358\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7289 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.5513 - val_accuracy: 0.7340\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7304 - val_loss: 0.5498 - val_accuracy: 0.7473\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7323 - val_loss: 0.5510 - val_accuracy: 0.7376\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7293 - val_loss: 0.5503 - val_accuracy: 0.7358\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7342 - val_loss: 0.5545 - val_accuracy: 0.7270\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7346 - val_loss: 0.5501 - val_accuracy: 0.7385\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7342 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7331 - val_loss: 0.5528 - val_accuracy: 0.7358\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5507 - val_accuracy: 0.7367\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7331 - val_loss: 0.5499 - val_accuracy: 0.7465\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7331 - val_loss: 0.5522 - val_accuracy: 0.7358\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7327 - val_loss: 0.5508 - val_accuracy: 0.7358\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7312 - val_loss: 0.5513 - val_accuracy: 0.7358\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7335 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7323 - val_loss: 0.5526 - val_accuracy: 0.7358\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7320 - val_loss: 0.5503 - val_accuracy: 0.7340\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5511 - val_accuracy: 0.7367\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7323 - val_loss: 0.5501 - val_accuracy: 0.7385\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7323 - val_loss: 0.5521 - val_accuracy: 0.7358\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7320 - val_loss: 0.5509 - val_accuracy: 0.7367\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7346 - val_loss: 0.5537 - val_accuracy: 0.7323\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7327 - val_loss: 0.5509 - val_accuracy: 0.7376\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7308 - val_loss: 0.5516 - val_accuracy: 0.7349\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7335 - val_loss: 0.5505 - val_accuracy: 0.7349\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7323 - val_loss: 0.5498 - val_accuracy: 0.7447\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7327 - val_loss: 0.5507 - val_accuracy: 0.7367\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7316 - val_loss: 0.5500 - val_accuracy: 0.7358\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7304 - val_loss: 0.5497 - val_accuracy: 0.7438\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7308 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7331 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7323 - val_loss: 0.5519 - val_accuracy: 0.7358\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7301 - val_loss: 0.5494 - val_accuracy: 0.7456\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7331 - val_loss: 0.5493 - val_accuracy: 0.7456\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7361 - val_loss: 0.5500 - val_accuracy: 0.7340\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5512 - val_accuracy: 0.7349\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7339 - val_loss: 0.5513 - val_accuracy: 0.7358\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.5510 - val_accuracy: 0.7349\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7327 - val_loss: 0.5496 - val_accuracy: 0.7456\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5516 - val_accuracy: 0.7358\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7342 - val_loss: 0.5511 - val_accuracy: 0.7349\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7335 - val_loss: 0.5494 - val_accuracy: 0.7429\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5503 - val_accuracy: 0.7358\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7331 - val_loss: 0.5511 - val_accuracy: 0.7358\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7323 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7339 - val_loss: 0.5523 - val_accuracy: 0.7358\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7320 - val_loss: 0.5521 - val_accuracy: 0.7358\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7304 - val_loss: 0.5506 - val_accuracy: 0.7367\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7354 - val_loss: 0.5512 - val_accuracy: 0.7340\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5511 - val_accuracy: 0.7349\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7335 - val_loss: 0.5512 - val_accuracy: 0.7349\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7331 - val_loss: 0.5500 - val_accuracy: 0.7349\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7331 - val_loss: 0.5497 - val_accuracy: 0.7385\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7327 - val_loss: 0.5498 - val_accuracy: 0.7367\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7323 - val_loss: 0.5514 - val_accuracy: 0.7358\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5502 - val_accuracy: 0.7358\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.7346 - val_loss: 0.5508 - val_accuracy: 0.7340\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7346 - val_loss: 0.5507 - val_accuracy: 0.7358\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7346 - val_loss: 0.5501 - val_accuracy: 0.7349\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7320 - val_loss: 0.5523 - val_accuracy: 0.7358\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7320 - val_loss: 0.5505 - val_accuracy: 0.7376\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7289 - val_loss: 0.5491 - val_accuracy: 0.7429\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7331 - val_loss: 0.5492 - val_accuracy: 0.7429\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7323 - val_loss: 0.5504 - val_accuracy: 0.7367\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7320 - val_loss: 0.5519 - val_accuracy: 0.7358\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7320 - val_loss: 0.5493 - val_accuracy: 0.7429\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7346 - val_loss: 0.5503 - val_accuracy: 0.7376\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7301 - val_loss: 0.5499 - val_accuracy: 0.7358\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7308 - val_loss: 0.5496 - val_accuracy: 0.7402\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7304 - val_loss: 0.5506 - val_accuracy: 0.7376\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7316 - val_loss: 0.5494 - val_accuracy: 0.7438\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7339 - val_loss: 0.5500 - val_accuracy: 0.7358\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.5499 - val_accuracy: 0.7358\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7316 - val_loss: 0.5539 - val_accuracy: 0.7270\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7320 - val_loss: 0.5500 - val_accuracy: 0.7367\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7377 - val_loss: 0.5514 - val_accuracy: 0.7358\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7308 - val_loss: 0.5503 - val_accuracy: 0.7358\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7312 - val_loss: 0.5496 - val_accuracy: 0.7385\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7316 - val_loss: 0.5516 - val_accuracy: 0.7358\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7331 - val_loss: 0.5503 - val_accuracy: 0.7367\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7339 - val_loss: 0.5505 - val_accuracy: 0.7376\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7331\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7376\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "[[ 0.3]\n",
      " [ 0.2]\n",
      " [ 0.8]\n",
      " [ 0.9]\n",
      " [ 0.7]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7497425334706488\n",
      "0.6127946127946128\n",
      "0.6743862899490505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 0.4]\n",
      " [ 0.9]\n",
      " [ 0.2]\n",
      " [ 0.7]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735224586288416\n",
      "0.6282828282828283\n",
      "0.6775599128540306\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
