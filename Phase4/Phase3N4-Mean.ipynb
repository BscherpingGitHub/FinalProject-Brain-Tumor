{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  8.6  1156.4 ...  6.6  1.0  0.0]\n",
      " [ 1.0  0.7  70.6 ...  2.5  0.9  0.0]\n",
      " [ 0.0  14.2  842.2 ...  3.3  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  14.8  833.2 ...  4.5  0.9  0.0]\n",
      " [ 0.0  11.9  315.0 ...  2.6  1.0  0.0]\n",
      " [ 1.0  17.7  1875.4 ...  5.4  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.5228 - accuracy: 0.4841 - val_loss: 1.2101 - val_accuracy: 0.7172\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6566 - accuracy: 0.4913 - val_loss: 0.8113 - val_accuracy: 0.7154\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9437 - accuracy: 0.5315 - val_loss: 0.6645 - val_accuracy: 0.6161\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6861 - accuracy: 0.5976 - val_loss: 0.7189 - val_accuracy: 0.4078\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6802 - accuracy: 0.5782 - val_loss: 0.7173 - val_accuracy: 0.4167\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.5797 - val_loss: 0.7190 - val_accuracy: 0.4122\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.5881 - val_loss: 0.7339 - val_accuracy: 0.3839\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.5816 - val_loss: 0.7257 - val_accuracy: 0.4034\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5858 - val_loss: 0.7107 - val_accuracy: 0.4344\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.5866 - val_loss: 0.7499 - val_accuracy: 0.3582\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5797 - val_loss: 0.7181 - val_accuracy: 0.4184\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5824 - val_loss: 0.7305 - val_accuracy: 0.4051\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5854 - val_loss: 0.7320 - val_accuracy: 0.4043\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5767 - val_loss: 0.7223 - val_accuracy: 0.4211\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5858 - val_loss: 0.7374 - val_accuracy: 0.3945\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5809 - val_loss: 0.7449 - val_accuracy: 0.3732\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5786 - val_loss: 0.7385 - val_accuracy: 0.3945\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5850 - val_loss: 0.7542 - val_accuracy: 0.3626\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5786 - val_loss: 0.7452 - val_accuracy: 0.3777\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5763 - val_loss: 0.7234 - val_accuracy: 0.4211\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.5828 - val_loss: 0.7290 - val_accuracy: 0.4078\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5839 - val_loss: 0.7305 - val_accuracy: 0.4078\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5881 - val_loss: 0.7286 - val_accuracy: 0.4113\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5858 - val_loss: 0.7638 - val_accuracy: 0.3466\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5710 - val_loss: 0.7243 - val_accuracy: 0.4211\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5805 - val_loss: 0.7228 - val_accuracy: 0.4176\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5805 - val_loss: 0.7402 - val_accuracy: 0.3954\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5812 - val_loss: 0.7372 - val_accuracy: 0.4034\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5805 - val_loss: 0.7317 - val_accuracy: 0.4078\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5797 - val_loss: 0.7252 - val_accuracy: 0.4211\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5850 - val_loss: 0.7315 - val_accuracy: 0.4078\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5831 - val_loss: 0.7366 - val_accuracy: 0.4060\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5809 - val_loss: 0.7494 - val_accuracy: 0.3741\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5740 - val_loss: 0.7242 - val_accuracy: 0.4211\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5847 - val_loss: 0.7284 - val_accuracy: 0.4158\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5843 - val_loss: 0.7353 - val_accuracy: 0.4060\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5740 - val_loss: 0.7390 - val_accuracy: 0.4007\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5843 - val_loss: 0.7350 - val_accuracy: 0.4060\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5782 - val_loss: 0.7415 - val_accuracy: 0.3945\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5782 - val_loss: 0.7326 - val_accuracy: 0.4078\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5873 - val_loss: 0.7520 - val_accuracy: 0.3723\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5926 - val_loss: 0.7580 - val_accuracy: 0.3635\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5793 - val_loss: 0.7661 - val_accuracy: 0.3440\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5737 - val_loss: 0.7413 - val_accuracy: 0.3963\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5843 - val_loss: 0.7454 - val_accuracy: 0.3856\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5797 - val_loss: 0.7395 - val_accuracy: 0.4016\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5756 - val_loss: 0.7458 - val_accuracy: 0.3856\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5824 - val_loss: 0.7370 - val_accuracy: 0.4060\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5759 - val_loss: 0.7277 - val_accuracy: 0.4202\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5843 - val_loss: 0.7489 - val_accuracy: 0.3777\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5790 - val_loss: 0.7395 - val_accuracy: 0.4007\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.5839 - val_loss: 0.7249 - val_accuracy: 0.4211\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5854 - val_loss: 0.7384 - val_accuracy: 0.4034\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5793 - val_loss: 0.7439 - val_accuracy: 0.3927\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6781 - accuracy: 0.5797 - val_loss: 0.7498 - val_accuracy: 0.3777\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5820 - val_loss: 0.7588 - val_accuracy: 0.3635\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5771 - val_loss: 0.7412 - val_accuracy: 0.3963\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5820 - val_loss: 0.7439 - val_accuracy: 0.3945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5816 - val_loss: 0.7532 - val_accuracy: 0.3723\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5778 - val_loss: 0.7620 - val_accuracy: 0.3582\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5782 - val_loss: 0.7771 - val_accuracy: 0.3236\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5767 - val_loss: 0.7509 - val_accuracy: 0.3741\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5793 - val_loss: 0.7405 - val_accuracy: 0.4007\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5820 - val_loss: 0.7341 - val_accuracy: 0.4069\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5888 - val_loss: 0.7230 - val_accuracy: 0.4264\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5896 - val_loss: 0.7276 - val_accuracy: 0.4211\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5877 - val_loss: 0.7616 - val_accuracy: 0.3608\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5710 - val_loss: 0.7253 - val_accuracy: 0.4202\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5801 - val_loss: 0.7495 - val_accuracy: 0.3803\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5824 - val_loss: 0.7499 - val_accuracy: 0.3794\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5756 - val_loss: 0.7359 - val_accuracy: 0.4043\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5854 - val_loss: 0.7291 - val_accuracy: 0.4176\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5892 - val_loss: 0.7510 - val_accuracy: 0.3768\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5774 - val_loss: 0.7360 - val_accuracy: 0.4043\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5835 - val_loss: 0.7314 - val_accuracy: 0.4087\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5835 - val_loss: 0.7360 - val_accuracy: 0.4043\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6784 - accuracy: 0.5805 - val_loss: 0.7386 - val_accuracy: 0.4043\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5820 - val_loss: 0.7377 - val_accuracy: 0.4060\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5831 - val_loss: 0.7519 - val_accuracy: 0.3741\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5778 - val_loss: 0.7289 - val_accuracy: 0.4193\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5835 - val_loss: 0.7497 - val_accuracy: 0.3821\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5771 - val_loss: 0.7544 - val_accuracy: 0.3723\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6790 - accuracy: 0.5782 - val_loss: 0.7433 - val_accuracy: 0.3954\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6793 - accuracy: 0.5812 - val_loss: 0.7465 - val_accuracy: 0.3927\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6790 - accuracy: 0.5763 - val_loss: 0.7355 - val_accuracy: 0.4078\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6791 - accuracy: 0.5866 - val_loss: 0.7445 - val_accuracy: 0.3945\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5858 - val_loss: 0.7310 - val_accuracy: 0.4122\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.5934 - val_loss: 0.7411 - val_accuracy: 0.4025\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5816 - val_loss: 0.7328 - val_accuracy: 0.4078\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6791 - accuracy: 0.5828 - val_loss: 0.7336 - val_accuracy: 0.4078\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5771 - val_loss: 0.7523 - val_accuracy: 0.3741\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5809 - val_loss: 0.7517 - val_accuracy: 0.3741\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5812 - val_loss: 0.7669 - val_accuracy: 0.3475\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6794 - accuracy: 0.5733 - val_loss: 0.7487 - val_accuracy: 0.3830\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5767 - val_loss: 0.7381 - val_accuracy: 0.4051\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5828 - val_loss: 0.7441 - val_accuracy: 0.3945\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5752 - val_loss: 0.7311 - val_accuracy: 0.4096\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5881 - val_loss: 0.7339 - val_accuracy: 0.4069\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5858 - val_loss: 0.7411 - val_accuracy: 0.3963\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5812 - val_loss: 0.7363 - val_accuracy: 0.4060\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.5839 - val_loss: 0.7538 - val_accuracy: 0.3741\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5816 - val_loss: 0.7295 - val_accuracy: 0.4158\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5869 - val_loss: 0.7499 - val_accuracy: 0.3777\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5847 - val_loss: 0.7250 - val_accuracy: 0.4202\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5839 - val_loss: 0.7403 - val_accuracy: 0.4007\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5782 - val_loss: 0.7321 - val_accuracy: 0.4078\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5816 - val_loss: 0.7346 - val_accuracy: 0.4078\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5854 - val_loss: 0.7393 - val_accuracy: 0.4034\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5847 - val_loss: 0.7279 - val_accuracy: 0.4211\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5816 - val_loss: 0.7477 - val_accuracy: 0.3865\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.7272 - val_accuracy: 0.4202\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5835 - val_loss: 0.7480 - val_accuracy: 0.3865\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5812 - val_loss: 0.7359 - val_accuracy: 0.4043\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5816 - val_loss: 0.7473 - val_accuracy: 0.3883\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5748 - val_loss: 0.7370 - val_accuracy: 0.4060\n",
      "Epoch 116/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5843 - val_loss: 0.7358 - val_accuracy: 0.4043\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5843 - val_loss: 0.7524 - val_accuracy: 0.3750\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5850 - val_loss: 0.7480 - val_accuracy: 0.3848\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5774 - val_loss: 0.7263 - val_accuracy: 0.4202\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5809 - val_loss: 0.7345 - val_accuracy: 0.4069\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5820 - val_loss: 0.7535 - val_accuracy: 0.3723\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5839 - val_loss: 0.7450 - val_accuracy: 0.3927\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5805 - val_loss: 0.7455 - val_accuracy: 0.3927\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5824 - val_loss: 0.7479 - val_accuracy: 0.3830\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5843 - val_loss: 0.7505 - val_accuracy: 0.3777\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5809 - val_loss: 0.7506 - val_accuracy: 0.3777\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5767 - val_loss: 0.7415 - val_accuracy: 0.3980\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5809 - val_loss: 0.7392 - val_accuracy: 0.4034\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5763 - val_loss: 0.7196 - val_accuracy: 0.4282\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5858 - val_loss: 0.7379 - val_accuracy: 0.4051\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5847 - val_loss: 0.7350 - val_accuracy: 0.4078\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6786 - accuracy: 0.5763 - val_loss: 0.7619 - val_accuracy: 0.3635\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5748 - val_loss: 0.7485 - val_accuracy: 0.3839\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5733 - val_loss: 0.7127 - val_accuracy: 0.4592\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.7271 - val_accuracy: 0.4202\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5816 - val_loss: 0.7290 - val_accuracy: 0.4193\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5885 - val_loss: 0.7661 - val_accuracy: 0.3475\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5756 - val_loss: 0.7435 - val_accuracy: 0.3945\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5812 - val_loss: 0.7488 - val_accuracy: 0.3830\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5778 - val_loss: 0.7341 - val_accuracy: 0.4060\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5892 - val_loss: 0.7655 - val_accuracy: 0.3475\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5737 - val_loss: 0.7422 - val_accuracy: 0.3963\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5771 - val_loss: 0.7324 - val_accuracy: 0.4078\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5850 - val_loss: 0.7450 - val_accuracy: 0.3945\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5820 - val_loss: 0.7301 - val_accuracy: 0.4158\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5801 - val_loss: 0.7453 - val_accuracy: 0.3927\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5820 - val_loss: 0.7554 - val_accuracy: 0.3741\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5835 - val_loss: 0.7448 - val_accuracy: 0.3945\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5854 - val_loss: 0.7275 - val_accuracy: 0.4202\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5793 - val_loss: 0.7476 - val_accuracy: 0.3856\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.7359 - val_accuracy: 0.4043\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5763 - val_loss: 0.7403 - val_accuracy: 0.4043\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5801 - val_loss: 0.7600 - val_accuracy: 0.3635\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5699 - val_loss: 0.7434 - val_accuracy: 0.3954\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5721 - val_loss: 0.7392 - val_accuracy: 0.4051\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5786 - val_loss: 0.7466 - val_accuracy: 0.3927\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5778 - val_loss: 0.7199 - val_accuracy: 0.4300\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5900 - val_loss: 0.7511 - val_accuracy: 0.3777\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5816 - val_loss: 0.7451 - val_accuracy: 0.3945\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5828 - val_loss: 0.7437 - val_accuracy: 0.3954\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5805 - val_loss: 0.7499 - val_accuracy: 0.3830\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5729 - val_loss: 0.7245 - val_accuracy: 0.4229\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.5869 - val_loss: 0.7342 - val_accuracy: 0.4078\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5774 - val_loss: 0.7369 - val_accuracy: 0.4043\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5847 - val_loss: 0.7462 - val_accuracy: 0.3927\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5824 - val_loss: 0.7304 - val_accuracy: 0.4158\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5858 - val_loss: 0.7468 - val_accuracy: 0.3910\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5820 - val_loss: 0.7257 - val_accuracy: 0.4202\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5793 - val_loss: 0.7217 - val_accuracy: 0.4291\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5828 - val_loss: 0.7570 - val_accuracy: 0.3732\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5725 - val_loss: 0.7386 - val_accuracy: 0.4060\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5900 - val_loss: 0.7551 - val_accuracy: 0.3723\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5786 - val_loss: 0.7659 - val_accuracy: 0.3457\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5695 - val_loss: 0.7439 - val_accuracy: 0.3945\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5756 - val_loss: 0.7284 - val_accuracy: 0.4211\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5805 - val_loss: 0.7512 - val_accuracy: 0.3777\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5820 - val_loss: 0.7508 - val_accuracy: 0.3803\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5847 - val_loss: 0.7471 - val_accuracy: 0.3918\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5763 - val_loss: 0.7338 - val_accuracy: 0.4078\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5843 - val_loss: 0.7487 - val_accuracy: 0.3839\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5767 - val_loss: 0.7557 - val_accuracy: 0.3741\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5759 - val_loss: 0.7371 - val_accuracy: 0.4051\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5831 - val_loss: 0.7681 - val_accuracy: 0.3466\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5638 - val_loss: 0.7458 - val_accuracy: 0.3927\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.7405 - val_accuracy: 0.4016\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5782 - val_loss: 0.7337 - val_accuracy: 0.4078\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5816 - val_loss: 0.7474 - val_accuracy: 0.3856\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.5748 - val_loss: 0.7509 - val_accuracy: 0.3777\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5835 - val_loss: 0.7450 - val_accuracy: 0.3945\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5824 - val_loss: 0.7564 - val_accuracy: 0.3741\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5740 - val_loss: 0.7279 - val_accuracy: 0.4211\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5869 - val_loss: 0.7409 - val_accuracy: 0.4007\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.5839 - val_loss: 0.7140 - val_accuracy: 0.4521\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.5907 - val_loss: 0.7471 - val_accuracy: 0.3883\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5816 - val_loss: 0.7480 - val_accuracy: 0.3848\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.5793 - val_loss: 0.7329 - val_accuracy: 0.4078\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.5892 - val_loss: 0.7520 - val_accuracy: 0.3741\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5725 - val_loss: 0.7193 - val_accuracy: 0.4335\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5850 - val_loss: 0.7423 - val_accuracy: 0.3980\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5786 - val_loss: 0.7664 - val_accuracy: 0.3457\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5816 - val_loss: 0.7429 - val_accuracy: 0.3963\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5809 - val_loss: 0.7578 - val_accuracy: 0.3715\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5771 - val_loss: 0.7479 - val_accuracy: 0.3892\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.5801 - val_loss: 0.7310 - val_accuracy: 0.4158\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5744 - val_loss: 0.7267 - val_accuracy: 0.4202\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5858 - val_loss: 0.7399 - val_accuracy: 0.4034\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5771 - val_loss: 0.7350 - val_accuracy: 0.4069\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5858 - val_loss: 0.7361 - val_accuracy: 0.4069\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5801 - val_loss: 0.7429 - val_accuracy: 0.3963\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5725 - val_loss: 0.7581 - val_accuracy: 0.3652\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5812 - val_loss: 0.7303 - val_accuracy: 0.4158\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5896 - val_loss: 0.7487 - val_accuracy: 0.3856\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5790 - val_loss: 0.7322 - val_accuracy: 0.4087\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5797 - val_loss: 0.7372 - val_accuracy: 0.4043\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5873 - val_loss: 0.7366 - val_accuracy: 0.4043\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5831 - val_loss: 0.7463 - val_accuracy: 0.3936\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5786 - val_loss: 0.7289 - val_accuracy: 0.4211\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.5854 - val_loss: 0.7643 - val_accuracy: 0.3590\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5763 - val_loss: 0.7457 - val_accuracy: 0.3936\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5782 - val_loss: 0.7547 - val_accuracy: 0.3750\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5767 - val_loss: 0.7538 - val_accuracy: 0.3750\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5843 - val_loss: 0.7499 - val_accuracy: 0.3821\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5786 - val_loss: 0.7441 - val_accuracy: 0.3945\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5850 - val_loss: 0.7584 - val_accuracy: 0.3652\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5812 - val_loss: 0.7486 - val_accuracy: 0.3874\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5805 - val_loss: 0.7372 - val_accuracy: 0.4043\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5809 - val_loss: 0.7511 - val_accuracy: 0.3803\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5820 - val_loss: 0.7353 - val_accuracy: 0.4069\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5843 - val_loss: 0.7634 - val_accuracy: 0.3599\n",
      "Epoch 230/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5718 - val_loss: 0.7267 - val_accuracy: 0.4211\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5885 - val_loss: 0.7632 - val_accuracy: 0.3608\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5824 - val_loss: 0.7598 - val_accuracy: 0.3635\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5759 - val_loss: 0.7473 - val_accuracy: 0.3910\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5797 - val_loss: 0.7317 - val_accuracy: 0.4122\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5820 - val_loss: 0.7514 - val_accuracy: 0.3803\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5778 - val_loss: 0.7361 - val_accuracy: 0.4069\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5812 - val_loss: 0.7364 - val_accuracy: 0.4069\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.5790 - val_loss: 0.7494 - val_accuracy: 0.3839\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5801 - val_loss: 0.7329 - val_accuracy: 0.4096\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5835 - val_loss: 0.7424 - val_accuracy: 0.3998\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5759 - val_loss: 0.7278 - val_accuracy: 0.4202\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5854 - val_loss: 0.7602 - val_accuracy: 0.3635\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6790 - accuracy: 0.5786 - val_loss: 0.7448 - val_accuracy: 0.3945\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.5816 - val_loss: 0.7612 - val_accuracy: 0.3635\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6786 - accuracy: 0.5801 - val_loss: 0.7347 - val_accuracy: 0.4069\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6788 - accuracy: 0.5824 - val_loss: 0.7456 - val_accuracy: 0.3918\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5824 - val_loss: 0.7418 - val_accuracy: 0.4007\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5797 - val_loss: 0.7486 - val_accuracy: 0.3848\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5812 - val_loss: 0.7440 - val_accuracy: 0.3945\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5847 - val_loss: 0.7496 - val_accuracy: 0.3821\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6791 - accuracy: 0.5774 - val_loss: 0.7385 - val_accuracy: 0.4043\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5782 - val_loss: 0.7354 - val_accuracy: 0.4069\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5801 - val_loss: 0.7436 - val_accuracy: 0.3954\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5911 - val_loss: 0.7575 - val_accuracy: 0.3706\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.5752 - val_loss: 0.7476 - val_accuracy: 0.3892\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.5896 - val_loss: 0.7456 - val_accuracy: 0.3927\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5771 - val_loss: 0.7451 - val_accuracy: 0.3945\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5774 - val_loss: 0.7425 - val_accuracy: 0.3963\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5790 - val_loss: 0.7256 - val_accuracy: 0.4202\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5839 - val_loss: 0.7390 - val_accuracy: 0.4051\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5805 - val_loss: 0.7226 - val_accuracy: 0.4282\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5801 - val_loss: 0.7505 - val_accuracy: 0.3812\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5733 - val_loss: 0.7333 - val_accuracy: 0.4078\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5831 - val_loss: 0.7629 - val_accuracy: 0.3635\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5725 - val_loss: 0.7474 - val_accuracy: 0.3901\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5847 - val_loss: 0.7482 - val_accuracy: 0.3856\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5831 - val_loss: 0.7384 - val_accuracy: 0.4043\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5839 - val_loss: 0.7453 - val_accuracy: 0.3927\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5782 - val_loss: 0.7271 - val_accuracy: 0.4202\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5809 - val_loss: 0.7363 - val_accuracy: 0.4043\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5858 - val_loss: 0.7459 - val_accuracy: 0.3927\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5733 - val_loss: 0.7493 - val_accuracy: 0.3821\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5778 - val_loss: 0.7375 - val_accuracy: 0.4043\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5850 - val_loss: 0.7614 - val_accuracy: 0.3608\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5691 - val_loss: 0.7239 - val_accuracy: 0.4220\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5862 - val_loss: 0.7432 - val_accuracy: 0.3945\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5828 - val_loss: 0.7303 - val_accuracy: 0.4131\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5774 - val_loss: 0.7420 - val_accuracy: 0.3963\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5809 - val_loss: 0.7395 - val_accuracy: 0.4034\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6783 - accuracy: 0.5828 - val_loss: 0.7227 - val_accuracy: 0.4282\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5843 - val_loss: 0.7458 - val_accuracy: 0.3927\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5797 - val_loss: 0.7299 - val_accuracy: 0.4167\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6786 - accuracy: 0.5797 - val_loss: 0.7313 - val_accuracy: 0.4122\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5850 - val_loss: 0.7515 - val_accuracy: 0.3768\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5850 - val_loss: 0.7466 - val_accuracy: 0.3910\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5793 - val_loss: 0.7377 - val_accuracy: 0.4051\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6791 - accuracy: 0.5793 - val_loss: 0.7420 - val_accuracy: 0.3980\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5892 - val_loss: 0.7413 - val_accuracy: 0.4007\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5854 - val_loss: 0.7346 - val_accuracy: 0.4060\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6785 - accuracy: 0.5824 - val_loss: 0.7498 - val_accuracy: 0.3821\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6777 - accuracy: 0.5752 - val_loss: 0.7216 - val_accuracy: 0.4291\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6793 - accuracy: 0.5843 - val_loss: 0.7420 - val_accuracy: 0.3998\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5812 - val_loss: 0.7375 - val_accuracy: 0.4060\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5805 - val_loss: 0.7544 - val_accuracy: 0.3723\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5805 - val_loss: 0.7513 - val_accuracy: 0.3777\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5816 - val_loss: 0.7425 - val_accuracy: 0.3980\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5809 - val_loss: 0.7492 - val_accuracy: 0.3865\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5809 - val_loss: 0.7248 - val_accuracy: 0.4220\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6788 - accuracy: 0.5858 - val_loss: 0.7560 - val_accuracy: 0.3741\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5774 - val_loss: 0.7236 - val_accuracy: 0.4264\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6781 - accuracy: 0.5847 - val_loss: 0.7313 - val_accuracy: 0.4122\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6789 - accuracy: 0.5873 - val_loss: 0.7499 - val_accuracy: 0.3821\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6780 - accuracy: 0.5828 - val_loss: 0.7647 - val_accuracy: 0.3528\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6783 - accuracy: 0.5793 - val_loss: 0.7278 - val_accuracy: 0.4202\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5896 - val_loss: 0.7451 - val_accuracy: 0.3945\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5782 - val_loss: 0.7471 - val_accuracy: 0.3910\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5782 - val_loss: 0.7477 - val_accuracy: 0.3892\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5835 - val_loss: 0.7534 - val_accuracy: 0.3741\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5771 - val_loss: 0.7376 - val_accuracy: 0.4051\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5786 - val_loss: 0.7387 - val_accuracy: 0.4043\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.5843 - val_loss: 0.7483 - val_accuracy: 0.3856\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5786 - val_loss: 0.7533 - val_accuracy: 0.3750\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5801 - val_loss: 0.7415 - val_accuracy: 0.4025\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.5756 - val_loss: 0.7278 - val_accuracy: 0.4202\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6783 - accuracy: 0.5873 - val_loss: 0.7527 - val_accuracy: 0.3732\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5740 - val_loss: 0.7264 - val_accuracy: 0.4211\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6793 - accuracy: 0.5862 - val_loss: 0.7318 - val_accuracy: 0.4113\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5843 - val_loss: 0.7330 - val_accuracy: 0.4078\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5793 - val_loss: 0.7327 - val_accuracy: 0.4078\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5778 - val_loss: 0.7369 - val_accuracy: 0.4043\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5835 - val_loss: 0.7387 - val_accuracy: 0.4043\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5809 - val_loss: 0.7412 - val_accuracy: 0.4043\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5839 - val_loss: 0.7480 - val_accuracy: 0.3892\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5835 - val_loss: 0.7517 - val_accuracy: 0.3777\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6791 - accuracy: 0.5771 - val_loss: 0.7550 - val_accuracy: 0.3759\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.5820 - val_loss: 0.7621 - val_accuracy: 0.3635\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5793 - val_loss: 0.7616 - val_accuracy: 0.3626\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.7301 - val_accuracy: 0.4158\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5797 - val_loss: 0.7492 - val_accuracy: 0.3830\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.5862 - val_loss: 0.7333 - val_accuracy: 0.4078\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5869 - val_loss: 0.7701 - val_accuracy: 0.3422\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5744 - val_loss: 0.7400 - val_accuracy: 0.4043\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5850 - val_loss: 0.7640 - val_accuracy: 0.3590\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5725 - val_loss: 0.7341 - val_accuracy: 0.4078\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6787 - accuracy: 0.5790 - val_loss: 0.7290 - val_accuracy: 0.4211\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6788 - accuracy: 0.5847 - val_loss: 0.7253 - val_accuracy: 0.4184\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5869 - val_loss: 0.7344 - val_accuracy: 0.4078\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6787 - accuracy: 0.5771 - val_loss: 0.7336 - val_accuracy: 0.4078\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6786 - accuracy: 0.5797 - val_loss: 0.7247 - val_accuracy: 0.4220\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6794 - accuracy: 0.5839 - val_loss: 0.7346 - val_accuracy: 0.4060\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5835 - val_loss: 0.7568 - val_accuracy: 0.3741\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5771 - val_loss: 0.7502 - val_accuracy: 0.3803\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5801 - val_loss: 0.7514 - val_accuracy: 0.3777\n",
      "Epoch 344/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5786 - val_loss: 0.7338 - val_accuracy: 0.4078\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6789 - accuracy: 0.5881 - val_loss: 0.7540 - val_accuracy: 0.3741\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5915 - val_loss: 0.7607 - val_accuracy: 0.3635\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5774 - val_loss: 0.7476 - val_accuracy: 0.3892\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5812 - val_loss: 0.7509 - val_accuracy: 0.3803\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5740 - val_loss: 0.7491 - val_accuracy: 0.3839\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6778 - accuracy: 0.5869 - val_loss: 0.7677 - val_accuracy: 0.3475\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5733 - val_loss: 0.7559 - val_accuracy: 0.3732\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5843 - val_loss: 0.7498 - val_accuracy: 0.3821\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5873 - val_loss: 0.7310 - val_accuracy: 0.4140\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6775 - accuracy: 0.5756 - val_loss: 0.7316 - val_accuracy: 0.4122\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5809 - val_loss: 0.7198 - val_accuracy: 0.4326\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5892 - val_loss: 0.7426 - val_accuracy: 0.3998\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.5797 - val_loss: 0.7564 - val_accuracy: 0.3741\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.5828 - val_loss: 0.7642 - val_accuracy: 0.3582\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5759 - val_loss: 0.7426 - val_accuracy: 0.3980\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5831 - val_loss: 0.7553 - val_accuracy: 0.3732\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5748 - val_loss: 0.7298 - val_accuracy: 0.4158\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5862 - val_loss: 0.7421 - val_accuracy: 0.3980\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5778 - val_loss: 0.7335 - val_accuracy: 0.4078\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5809 - val_loss: 0.7446 - val_accuracy: 0.3945\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6786 - accuracy: 0.5801 - val_loss: 0.7515 - val_accuracy: 0.3777\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5816 - val_loss: 0.7251 - val_accuracy: 0.4184\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5816 - val_loss: 0.7550 - val_accuracy: 0.3732\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6783 - accuracy: 0.5759 - val_loss: 0.7254 - val_accuracy: 0.4202\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5888 - val_loss: 0.7373 - val_accuracy: 0.4060\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5797 - val_loss: 0.7251 - val_accuracy: 0.4193\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5888 - val_loss: 0.7409 - val_accuracy: 0.4007\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5820 - val_loss: 0.7547 - val_accuracy: 0.3741\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5774 - val_loss: 0.7508 - val_accuracy: 0.3777\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6783 - accuracy: 0.5816 - val_loss: 0.7420 - val_accuracy: 0.3963\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6786 - accuracy: 0.5843 - val_loss: 0.7590 - val_accuracy: 0.3635\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6780 - accuracy: 0.5778 - val_loss: 0.7770 - val_accuracy: 0.3254\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5752 - val_loss: 0.7744 - val_accuracy: 0.3262\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6794 - accuracy: 0.5774 - val_loss: 0.7400 - val_accuracy: 0.4025\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5824 - val_loss: 0.7331 - val_accuracy: 0.4078\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6785 - accuracy: 0.5820 - val_loss: 0.7294 - val_accuracy: 0.4167\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6789 - accuracy: 0.5843 - val_loss: 0.7387 - val_accuracy: 0.4051\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 0.6787 - accuracy: 0.5835 - val_loss: 0.7364 - val_accuracy: 0.4043\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6788 - accuracy: 0.5790 - val_loss: 0.7405 - val_accuracy: 0.4034\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6789 - accuracy: 0.5835 - val_loss: 0.7329 - val_accuracy: 0.4078\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6789 - accuracy: 0.5831 - val_loss: 0.7365 - val_accuracy: 0.4043\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6789 - accuracy: 0.5774 - val_loss: 0.7244 - val_accuracy: 0.4211\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6790 - accuracy: 0.5786 - val_loss: 0.7490 - val_accuracy: 0.3821\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6787 - accuracy: 0.5801 - val_loss: 0.7306 - val_accuracy: 0.4140\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5885 - val_loss: 0.7456 - val_accuracy: 0.3918\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6786 - accuracy: 0.5828 - val_loss: 0.7703 - val_accuracy: 0.3404\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6793 - accuracy: 0.5718 - val_loss: 0.7383 - val_accuracy: 0.4051\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5831 - val_loss: 0.7414 - val_accuracy: 0.4007\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5847 - val_loss: 0.7368 - val_accuracy: 0.4034\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6787 - accuracy: 0.5805 - val_loss: 0.7288 - val_accuracy: 0.4202\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5866 - val_loss: 0.7388 - val_accuracy: 0.4051\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6792 - accuracy: 0.5862 - val_loss: 0.7460 - val_accuracy: 0.3927\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6784 - accuracy: 0.5854 - val_loss: 0.7639 - val_accuracy: 0.3582\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5748 - val_loss: 0.7473 - val_accuracy: 0.3910\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5873 - val_loss: 0.7571 - val_accuracy: 0.3741\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6781 - accuracy: 0.5824 - val_loss: 0.7507 - val_accuracy: 0.3803\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6781 - accuracy: 0.5714 - val_loss: 0.7247 - val_accuracy: 0.4220\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5797 - val_loss: 0.7274 - val_accuracy: 0.4202\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6788 - accuracy: 0.5866 - val_loss: 0.7477 - val_accuracy: 0.3856\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6781 - accuracy: 0.5839 - val_loss: 0.7679 - val_accuracy: 0.3457\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6792 - accuracy: 0.5763 - val_loss: 0.7606 - val_accuracy: 0.3635\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5805 - val_loss: 0.7510 - val_accuracy: 0.3777\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5877 - val_loss: 0.7530 - val_accuracy: 0.3750\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5729 - val_loss: 0.7401 - val_accuracy: 0.4034\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5850 - val_loss: 0.7418 - val_accuracy: 0.3972\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5809 - val_loss: 0.7446 - val_accuracy: 0.3945\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5759 - val_loss: 0.7306 - val_accuracy: 0.4149\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6782 - accuracy: 0.5737 - val_loss: 0.7368 - val_accuracy: 0.4034\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6785 - accuracy: 0.5801 - val_loss: 0.7507 - val_accuracy: 0.3803\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5793 - val_loss: 0.7371 - val_accuracy: 0.4034\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.5797 - val_loss: 0.7440 - val_accuracy: 0.3945\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5805 - val_loss: 0.7274 - val_accuracy: 0.4211\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6792 - accuracy: 0.5919 - val_loss: 0.7470 - val_accuracy: 0.3927\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5812 - val_loss: 0.7582 - val_accuracy: 0.3661\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5752 - val_loss: 0.7462 - val_accuracy: 0.3927\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5869 - val_loss: 0.7466 - val_accuracy: 0.3918\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5809 - val_loss: 0.7683 - val_accuracy: 0.3449\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6791 - accuracy: 0.5771 - val_loss: 0.7470 - val_accuracy: 0.3865\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5668 - val_loss: 0.7406 - val_accuracy: 0.4016\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6786 - accuracy: 0.5786 - val_loss: 0.7447 - val_accuracy: 0.3927\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5854 - val_loss: 0.7376 - val_accuracy: 0.4043\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5820 - val_loss: 0.7323 - val_accuracy: 0.4078\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5756 - val_loss: 0.7270 - val_accuracy: 0.4202\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6788 - accuracy: 0.5881 - val_loss: 0.7453 - val_accuracy: 0.3927\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6788 - accuracy: 0.5790 - val_loss: 0.7434 - val_accuracy: 0.3945\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6786 - accuracy: 0.5733 - val_loss: 0.7327 - val_accuracy: 0.4078\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.5831 - val_loss: 0.7432 - val_accuracy: 0.3954\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6789 - accuracy: 0.5839 - val_loss: 0.7348 - val_accuracy: 0.4078\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6777 - accuracy: 0.5809 - val_loss: 0.7229 - val_accuracy: 0.4282\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5888 - val_loss: 0.7476 - val_accuracy: 0.3883\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5797 - val_loss: 0.7395 - val_accuracy: 0.4043\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5828 - val_loss: 0.7364 - val_accuracy: 0.4043\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5869 - val_loss: 0.7348 - val_accuracy: 0.4069\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5847 - val_loss: 0.7368 - val_accuracy: 0.4043\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6782 - accuracy: 0.5782 - val_loss: 0.7340 - val_accuracy: 0.4078\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5873 - val_loss: 0.7460 - val_accuracy: 0.3918\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6792 - accuracy: 0.5843 - val_loss: 0.7485 - val_accuracy: 0.3839\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6784 - accuracy: 0.5809 - val_loss: 0.7193 - val_accuracy: 0.4326\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5858 - val_loss: 0.7326 - val_accuracy: 0.4105\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.5828 - val_loss: 0.7447 - val_accuracy: 0.3945\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6781 - accuracy: 0.5721 - val_loss: 0.7268 - val_accuracy: 0.4202\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5831 - val_loss: 0.7443 - val_accuracy: 0.3945\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.5809 - val_loss: 0.7707 - val_accuracy: 0.3422\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6793 - accuracy: 0.5831 - val_loss: 0.7635 - val_accuracy: 0.3590\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.5790 - val_loss: 0.7503 - val_accuracy: 0.3821\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6783 - accuracy: 0.5801 - val_loss: 0.7202 - val_accuracy: 0.4300\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5866 - val_loss: 0.7643 - val_accuracy: 0.3599\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6792 - accuracy: 0.5763 - val_loss: 0.7529 - val_accuracy: 0.3741\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6791 - accuracy: 0.5793 - val_loss: 0.7429 - val_accuracy: 0.3963\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6780 - accuracy: 0.5866 - val_loss: 0.7254 - val_accuracy: 0.4184\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5828 - val_loss: 0.7470 - val_accuracy: 0.3910\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5866 - val_loss: 0.7524 - val_accuracy: 0.3732\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5816 - val_loss: 0.7411 - val_accuracy: 0.4025\n",
      "Epoch 458/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6788 - accuracy: 0.5828 - val_loss: 0.7454 - val_accuracy: 0.3936\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5729 - val_loss: 0.7458 - val_accuracy: 0.3918\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5793 - val_loss: 0.7411 - val_accuracy: 0.4025\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5888 - val_loss: 0.7595 - val_accuracy: 0.3635\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5786 - val_loss: 0.7542 - val_accuracy: 0.3723\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5801 - val_loss: 0.7559 - val_accuracy: 0.3732\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5756 - val_loss: 0.7288 - val_accuracy: 0.4211\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6779 - accuracy: 0.5763 - val_loss: 0.7419 - val_accuracy: 0.3980\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6781 - accuracy: 0.5699 - val_loss: 0.7177 - val_accuracy: 0.4353\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6791 - accuracy: 0.5873 - val_loss: 0.7577 - val_accuracy: 0.3670\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6784 - accuracy: 0.5797 - val_loss: 0.7500 - val_accuracy: 0.3777\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5786 - val_loss: 0.7341 - val_accuracy: 0.4069\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5869 - val_loss: 0.7432 - val_accuracy: 0.3945\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6782 - accuracy: 0.5824 - val_loss: 0.7513 - val_accuracy: 0.3768\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.5892 - val_loss: 0.7520 - val_accuracy: 0.3741\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.5740 - val_loss: 0.7373 - val_accuracy: 0.4060\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.5748 - val_loss: 0.7408 - val_accuracy: 0.4034\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.5809 - val_loss: 0.7455 - val_accuracy: 0.3936\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6786 - accuracy: 0.5809 - val_loss: 0.7423 - val_accuracy: 0.3980\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5816 - val_loss: 0.7394 - val_accuracy: 0.4051\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5824 - val_loss: 0.7556 - val_accuracy: 0.3732\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5752 - val_loss: 0.7410 - val_accuracy: 0.4034\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5866 - val_loss: 0.7497 - val_accuracy: 0.3839\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6775 - accuracy: 0.5801 - val_loss: 0.7160 - val_accuracy: 0.4450\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.5915 - val_loss: 0.7534 - val_accuracy: 0.3741\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5774 - val_loss: 0.7509 - val_accuracy: 0.3812\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.5733 - val_loss: 0.7530 - val_accuracy: 0.3741\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.5816 - val_loss: 0.7365 - val_accuracy: 0.4069\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5782 - val_loss: 0.7348 - val_accuracy: 0.4060\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6782 - accuracy: 0.5877 - val_loss: 0.7617 - val_accuracy: 0.3635\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.5759 - val_loss: 0.7390 - val_accuracy: 0.4051\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6787 - accuracy: 0.5835 - val_loss: 0.7467 - val_accuracy: 0.3927\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.5782 - val_loss: 0.7542 - val_accuracy: 0.3741\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6782 - accuracy: 0.5759 - val_loss: 0.7274 - val_accuracy: 0.4211\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6793 - accuracy: 0.5862 - val_loss: 0.7414 - val_accuracy: 0.4034\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6783 - accuracy: 0.5816 - val_loss: 0.7573 - val_accuracy: 0.3741\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.5797 - val_loss: 0.7390 - val_accuracy: 0.4043\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6781 - accuracy: 0.5907 - val_loss: 0.7605 - val_accuracy: 0.3661\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.5778 - val_loss: 0.7355 - val_accuracy: 0.4060\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6787 - accuracy: 0.5797 - val_loss: 0.7493 - val_accuracy: 0.3856\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.5778 - val_loss: 0.7261 - val_accuracy: 0.4184\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.5812 - val_loss: 0.7296 - val_accuracy: 0.4211\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6781 - accuracy: 0.5828 - val_loss: 0.7574 - val_accuracy: 0.3741\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5642\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.3741\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 0.5]\n",
      " [ 0.7]\n",
      " [ 0.4]\n",
      " [ 0.4]\n",
      " [ 0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.558982683982684\n",
      "0.7562225475841874\n",
      "0.64281269446173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.6]\n",
      " [ 0.6]\n",
      " [ 0.6]\n",
      " [ 0.6]\n",
      " [ 0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27304550758459745\n",
      "0.7381703470031545\n",
      "0.3986371379897785\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
