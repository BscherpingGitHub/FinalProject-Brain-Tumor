{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  5.7  222.1 ...  2.2  1.0  0.0]\n",
      " [ 1.0  10.5  1588.6 ...  5.6  1.0  0.0]\n",
      " [ 0.0  9.4  697.1 ...  6.9  0.9  0.0]\n",
      " ...\n",
      " [ 0.0  13.4  644.9 ...  2.8  1.0  0.0]\n",
      " [ 0.0  7.8  257.5 ...  2.3  1.0  0.0]\n",
      " [ 0.0  17.5  1393.5 ...  5.6  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 7]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 7]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 15ms/step - loss: 45.3492 - accuracy: 0.5607 - val_loss: 40.3144 - val_accuracy: 0.5337\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 33.9593 - accuracy: 0.5607 - val_loss: 29.4875 - val_accuracy: 0.5337\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 23.8628 - accuracy: 0.5607 - val_loss: 20.1335 - val_accuracy: 0.5337\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 15.9692 - accuracy: 0.5607 - val_loss: 12.9445 - val_accuracy: 0.5337\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 9.6960 - accuracy: 0.5604 - val_loss: 7.2733 - val_accuracy: 0.5328\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 5.0741 - accuracy: 0.5604 - val_loss: 3.3979 - val_accuracy: 0.5266\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1355 - accuracy: 0.5535 - val_loss: 1.3680 - val_accuracy: 0.5177\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0147 - accuracy: 0.4765 - val_loss: 0.8110 - val_accuracy: 0.3794\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7785 - accuracy: 0.3759 - val_loss: 0.7451 - val_accuracy: 0.4433\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7518 - accuracy: 0.4241 - val_loss: 0.7356 - val_accuracy: 0.4441\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7422 - accuracy: 0.4244 - val_loss: 0.7283 - val_accuracy: 0.4433\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7337 - accuracy: 0.4237 - val_loss: 0.7222 - val_accuracy: 0.4424\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.7260 - accuracy: 0.4214 - val_loss: 0.7151 - val_accuracy: 0.4548\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.7183 - accuracy: 0.4294 - val_loss: 0.7091 - val_accuracy: 0.4592\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7114 - accuracy: 0.4298 - val_loss: 0.7038 - val_accuracy: 0.4610\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.7053 - accuracy: 0.4347 - val_loss: 0.6991 - val_accuracy: 0.4663\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.4389 - val_loss: 0.6949 - val_accuracy: 0.4663\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6954 - accuracy: 0.4393 - val_loss: 0.6913 - val_accuracy: 0.4663\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6909 - accuracy: 0.4818 - val_loss: 0.6874 - val_accuracy: 0.5417\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6867 - accuracy: 0.5995 - val_loss: 0.6833 - val_accuracy: 0.5869\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6831 - accuracy: 0.6147 - val_loss: 0.6809 - val_accuracy: 0.6277\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6801 - accuracy: 0.6291 - val_loss: 0.6787 - val_accuracy: 0.6215\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6771 - accuracy: 0.6226 - val_loss: 0.6763 - val_accuracy: 0.6197\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6743 - accuracy: 0.6272 - val_loss: 0.6738 - val_accuracy: 0.6206\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6720 - accuracy: 0.6230 - val_loss: 0.6726 - val_accuracy: 0.6046\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6699 - accuracy: 0.6203 - val_loss: 0.6701 - val_accuracy: 0.6197\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6678 - accuracy: 0.6234 - val_loss: 0.6692 - val_accuracy: 0.5931\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6660 - accuracy: 0.6177 - val_loss: 0.6689 - val_accuracy: 0.5949\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6644 - accuracy: 0.6143 - val_loss: 0.6672 - val_accuracy: 0.5984\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6629 - accuracy: 0.6169 - val_loss: 0.6651 - val_accuracy: 0.5993\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6619 - accuracy: 0.6188 - val_loss: 0.6648 - val_accuracy: 0.6002\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6606 - accuracy: 0.6222 - val_loss: 0.6662 - val_accuracy: 0.5789\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6595 - accuracy: 0.6109 - val_loss: 0.6612 - val_accuracy: 0.6197\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6586 - accuracy: 0.6215 - val_loss: 0.6617 - val_accuracy: 0.5940\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6579 - accuracy: 0.6196 - val_loss: 0.6617 - val_accuracy: 0.6002\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6569 - accuracy: 0.6215 - val_loss: 0.6623 - val_accuracy: 0.5940\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6569 - accuracy: 0.6169 - val_loss: 0.6617 - val_accuracy: 0.5966\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6562 - accuracy: 0.6162 - val_loss: 0.6596 - val_accuracy: 0.5931\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6556 - accuracy: 0.6207 - val_loss: 0.6628 - val_accuracy: 0.5824\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6553 - accuracy: 0.6093 - val_loss: 0.6588 - val_accuracy: 0.5993\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6551 - accuracy: 0.6131 - val_loss: 0.6586 - val_accuracy: 0.5966\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6547 - accuracy: 0.6215 - val_loss: 0.6588 - val_accuracy: 0.5931\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6548 - accuracy: 0.6105 - val_loss: 0.6591 - val_accuracy: 0.5993\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6543 - accuracy: 0.6185 - val_loss: 0.6575 - val_accuracy: 0.6082\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6542 - accuracy: 0.6185 - val_loss: 0.6592 - val_accuracy: 0.6011\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6540 - accuracy: 0.6173 - val_loss: 0.6601 - val_accuracy: 0.5957\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6536 - accuracy: 0.6120 - val_loss: 0.6606 - val_accuracy: 0.5887\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6534 - accuracy: 0.6169 - val_loss: 0.6585 - val_accuracy: 0.5993\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6532 - accuracy: 0.6162 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6621 - val_accuracy: 0.5816\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6533 - accuracy: 0.6139 - val_loss: 0.6574 - val_accuracy: 0.5966\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6531 - accuracy: 0.6124 - val_loss: 0.6566 - val_accuracy: 0.6135\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6534 - accuracy: 0.6185 - val_loss: 0.6587 - val_accuracy: 0.6002\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.6162 - val_loss: 0.6612 - val_accuracy: 0.5842\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6530 - accuracy: 0.6131 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6530 - accuracy: 0.6188 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.6143 - val_loss: 0.6573 - val_accuracy: 0.5957\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6143 - val_loss: 0.6569 - val_accuracy: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6147 - val_loss: 0.6598 - val_accuracy: 0.5940\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6112 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6124 - val_loss: 0.6565 - val_accuracy: 0.6135\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6527 - accuracy: 0.6219 - val_loss: 0.6581 - val_accuracy: 0.5993\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6150 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6131 - val_loss: 0.6584 - val_accuracy: 0.6002\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6605 - val_accuracy: 0.5895\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6093 - val_loss: 0.6585 - val_accuracy: 0.5993\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6517 - accuracy: 0.6135 - val_loss: 0.6566 - val_accuracy: 0.6073\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6588 - val_accuracy: 0.6011\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6120 - val_loss: 0.6572 - val_accuracy: 0.5949\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6593 - val_accuracy: 0.5957\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6150 - val_loss: 0.6600 - val_accuracy: 0.5949\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6181 - val_loss: 0.6573 - val_accuracy: 0.5949\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6215 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6520 - accuracy: 0.6169 - val_loss: 0.6614 - val_accuracy: 0.5851\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6097 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6169 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6101 - val_loss: 0.6566 - val_accuracy: 0.6073\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6181 - val_loss: 0.6566 - val_accuracy: 0.6082\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6147 - val_loss: 0.6597 - val_accuracy: 0.6002\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6614 - val_accuracy: 0.5860\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6135 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6158 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6192 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6131 - val_loss: 0.6574 - val_accuracy: 0.5949\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6185 - val_loss: 0.6599 - val_accuracy: 0.6002\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6139 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6128 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6517 - accuracy: 0.6162 - val_loss: 0.6647 - val_accuracy: 0.5754\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.6097 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6158 - val_loss: 0.6567 - val_accuracy: 0.6073\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6158 - val_loss: 0.6574 - val_accuracy: 0.5931\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6128 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6188 - val_loss: 0.6566 - val_accuracy: 0.6170\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6530 - accuracy: 0.6188 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6131 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6143 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6139 - val_loss: 0.6635 - val_accuracy: 0.5789\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6105 - val_loss: 0.6605 - val_accuracy: 0.5904\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.6196 - val_loss: 0.6607 - val_accuracy: 0.5895\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6135 - val_loss: 0.6594 - val_accuracy: 0.5975\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6162 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6169 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6135 - val_loss: 0.6595 - val_accuracy: 0.5957\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6101 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6166 - val_loss: 0.6605 - val_accuracy: 0.5913\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6570 - val_accuracy: 0.6020\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6517 - accuracy: 0.6116 - val_loss: 0.6566 - val_accuracy: 0.6152\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6150 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6162 - val_loss: 0.6584 - val_accuracy: 0.6002\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6173 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6154 - val_loss: 0.6580 - val_accuracy: 0.5966\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6185 - val_loss: 0.6599 - val_accuracy: 0.6011\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6520 - accuracy: 0.6105 - val_loss: 0.6566 - val_accuracy: 0.6108\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6200 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6520 - accuracy: 0.6181 - val_loss: 0.6617 - val_accuracy: 0.5851\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6528 - accuracy: 0.6112 - val_loss: 0.6579 - val_accuracy: 0.5940\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6120 - val_loss: 0.6568 - val_accuracy: 0.6064\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6203 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6147 - val_loss: 0.6569 - val_accuracy: 0.6028\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6578 - val_accuracy: 0.5931\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6600 - val_accuracy: 0.5966\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6150 - val_loss: 0.6588 - val_accuracy: 0.6011\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6566 - val_accuracy: 0.6099\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6523 - accuracy: 0.6150 - val_loss: 0.6566 - val_accuracy: 0.6179\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6177 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6124 - val_loss: 0.6570 - val_accuracy: 0.6020\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6169 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6177 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6527 - accuracy: 0.6166 - val_loss: 0.6586 - val_accuracy: 0.6002\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6177 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6524 - accuracy: 0.6181 - val_loss: 0.6570 - val_accuracy: 0.6037\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6109 - val_loss: 0.6570 - val_accuracy: 0.6037\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6143 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6185 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6097 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6128 - val_loss: 0.6605 - val_accuracy: 0.5913\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6529 - accuracy: 0.6131 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6525 - accuracy: 0.6120 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6528 - accuracy: 0.6188 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6599 - val_accuracy: 0.5993\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6527 - accuracy: 0.6139 - val_loss: 0.6574 - val_accuracy: 0.5949\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6599 - val_accuracy: 0.5984\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6128 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6527 - accuracy: 0.6169 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6526 - accuracy: 0.6192 - val_loss: 0.6602 - val_accuracy: 0.5949\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6528 - accuracy: 0.6139 - val_loss: 0.6601 - val_accuracy: 0.5940\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6520 - accuracy: 0.6203 - val_loss: 0.6598 - val_accuracy: 0.6002\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6162 - val_loss: 0.6566 - val_accuracy: 0.6126\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6181 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6139 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6527 - accuracy: 0.6131 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6526 - accuracy: 0.6181 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6527 - accuracy: 0.6109 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6158 - val_loss: 0.6601 - val_accuracy: 0.5940\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6526 - accuracy: 0.6112 - val_loss: 0.6594 - val_accuracy: 0.5975\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6158 - val_loss: 0.6598 - val_accuracy: 0.6002\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6579 - val_accuracy: 0.5949\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6162 - val_loss: 0.6599 - val_accuracy: 0.5993\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6135 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6147 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6116 - val_loss: 0.6611 - val_accuracy: 0.5878\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6166 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6150 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6520 - accuracy: 0.6207 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6597 - val_accuracy: 0.6011\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6101 - val_loss: 0.6587 - val_accuracy: 0.5993\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6173 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6139 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6139 - val_loss: 0.6573 - val_accuracy: 0.5957\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6128 - val_loss: 0.6601 - val_accuracy: 0.5940\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6135 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6522 - accuracy: 0.6124 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6519 - accuracy: 0.6093 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6139 - val_loss: 0.6591 - val_accuracy: 0.5984\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6520 - accuracy: 0.6215 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6162 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6124 - val_loss: 0.6571 - val_accuracy: 0.5993\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6566 - val_accuracy: 0.6117\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6594 - val_accuracy: 0.5957\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6169 - val_loss: 0.6618 - val_accuracy: 0.5833\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6528 - accuracy: 0.6112 - val_loss: 0.6602 - val_accuracy: 0.5949\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6574 - val_accuracy: 0.5949\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6566 - val_accuracy: 0.6117\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6169 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6162 - val_loss: 0.6566 - val_accuracy: 0.6170\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6150 - val_loss: 0.6603 - val_accuracy: 0.5931\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6526 - accuracy: 0.6124 - val_loss: 0.6596 - val_accuracy: 0.5966\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6519 - accuracy: 0.6196 - val_loss: 0.6613 - val_accuracy: 0.5878\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6603 - val_accuracy: 0.5931\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6169 - val_loss: 0.6594 - val_accuracy: 0.5975\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6147 - val_loss: 0.6569 - val_accuracy: 0.6028\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6166 - val_loss: 0.6577 - val_accuracy: 0.5940\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6139 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6166 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6177 - val_loss: 0.6600 - val_accuracy: 0.5966\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6105 - val_loss: 0.6595 - val_accuracy: 0.5949\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6147 - val_loss: 0.6615 - val_accuracy: 0.5860\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6131 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6135 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6215 - val_loss: 0.6568 - val_accuracy: 0.6037\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6188 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6124 - val_loss: 0.6597 - val_accuracy: 0.6011\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6135 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6063 - val_loss: 0.6566 - val_accuracy: 0.6073\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6139 - val_loss: 0.6574 - val_accuracy: 0.5940\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6143 - val_loss: 0.6629 - val_accuracy: 0.5816\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6109 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6158 - val_loss: 0.6616 - val_accuracy: 0.5833\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6090 - val_loss: 0.6566 - val_accuracy: 0.6117\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6177 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6522 - accuracy: 0.6226 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6519 - accuracy: 0.6093 - val_loss: 0.6566 - val_accuracy: 0.6135\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6173 - val_loss: 0.6597 - val_accuracy: 0.6011\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6166 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6162 - val_loss: 0.6610 - val_accuracy: 0.5887\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6135 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6520 - accuracy: 0.6162 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6188 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6101 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6147 - val_loss: 0.6600 - val_accuracy: 0.5966\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6044 - val_loss: 0.6566 - val_accuracy: 0.6099\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6147 - val_loss: 0.6596 - val_accuracy: 0.5993\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6150 - val_loss: 0.6574 - val_accuracy: 0.5949\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6518 - accuracy: 0.6124 - val_loss: 0.6567 - val_accuracy: 0.6046\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6169 - val_loss: 0.6601 - val_accuracy: 0.5940\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6572 - val_accuracy: 0.5949\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6522 - accuracy: 0.6124 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6572 - val_accuracy: 0.5940\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6515 - accuracy: 0.6188 - val_loss: 0.6630 - val_accuracy: 0.5816\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6518 - accuracy: 0.6120 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6188 - val_loss: 0.6591 - val_accuracy: 0.5993\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6128 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6566 - val_accuracy: 0.6144\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6219 - val_loss: 0.6579 - val_accuracy: 0.5949\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6516 - accuracy: 0.6097 - val_loss: 0.6566 - val_accuracy: 0.6144\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6169 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6162 - val_loss: 0.6572 - val_accuracy: 0.5975\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6527 - accuracy: 0.6162 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6135 - val_loss: 0.6593 - val_accuracy: 0.5984\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6600 - val_accuracy: 0.5966\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6147 - val_loss: 0.6606 - val_accuracy: 0.5895\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6607 - val_accuracy: 0.5887\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6131 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6181 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6177 - val_loss: 0.6575 - val_accuracy: 0.5931\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6177 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6147 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6520 - accuracy: 0.6185 - val_loss: 0.6633 - val_accuracy: 0.5789\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6086 - val_loss: 0.6578 - val_accuracy: 0.5931\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6588 - val_accuracy: 0.6011\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6143 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6120 - val_loss: 0.6575 - val_accuracy: 0.5931\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6200 - val_loss: 0.6603 - val_accuracy: 0.5931\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6116 - val_loss: 0.6584 - val_accuracy: 0.6002\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6097 - val_loss: 0.6594 - val_accuracy: 0.5949\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6594 - val_accuracy: 0.5957\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6124 - val_loss: 0.6572 - val_accuracy: 0.5957\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6173 - val_loss: 0.6597 - val_accuracy: 0.6011\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6522 - accuracy: 0.6139 - val_loss: 0.6566 - val_accuracy: 0.6099\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6192 - val_loss: 0.6567 - val_accuracy: 0.6037\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6188 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6112 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6143 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6120 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6519 - accuracy: 0.6181 - val_loss: 0.6588 - val_accuracy: 0.6002\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6109 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6584 - val_accuracy: 0.6002\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6143 - val_loss: 0.6574 - val_accuracy: 0.5949\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6143 - val_loss: 0.6574 - val_accuracy: 0.5940\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6177 - val_loss: 0.6586 - val_accuracy: 0.6002\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6131 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6109 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6570 - val_accuracy: 0.6037\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6203 - val_loss: 0.6572 - val_accuracy: 0.5984\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6158 - val_loss: 0.6601 - val_accuracy: 0.5940\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6181 - val_loss: 0.6567 - val_accuracy: 0.6090\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6169 - val_loss: 0.6573 - val_accuracy: 0.5949\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6177 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6116 - val_loss: 0.6569 - val_accuracy: 0.6028\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6135 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6177 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6166 - val_loss: 0.6581 - val_accuracy: 0.5975\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6116 - val_loss: 0.6580 - val_accuracy: 0.5975\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6128 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6116 - val_loss: 0.6567 - val_accuracy: 0.6082\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6519 - accuracy: 0.6147 - val_loss: 0.6626 - val_accuracy: 0.5816\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6529 - accuracy: 0.6101 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6569 - val_accuracy: 0.6046\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6577 - val_accuracy: 0.5940\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6116 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6524 - accuracy: 0.6154 - val_loss: 0.6570 - val_accuracy: 0.6037\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6158 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6520 - accuracy: 0.6143 - val_loss: 0.6591 - val_accuracy: 0.5984\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6188 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6516 - accuracy: 0.6200 - val_loss: 0.6606 - val_accuracy: 0.5904\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6120 - val_loss: 0.6571 - val_accuracy: 0.5993\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6527 - accuracy: 0.6166 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6520 - accuracy: 0.6169 - val_loss: 0.6566 - val_accuracy: 0.6126\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6150 - val_loss: 0.6620 - val_accuracy: 0.5824\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6112 - val_loss: 0.6570 - val_accuracy: 0.6020\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6162 - val_loss: 0.6597 - val_accuracy: 0.6002\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6162 - val_loss: 0.6566 - val_accuracy: 0.6073\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6181 - val_loss: 0.6606 - val_accuracy: 0.5887\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6571 - val_accuracy: 0.5993\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6139 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6521 - accuracy: 0.6124 - val_loss: 0.6631 - val_accuracy: 0.5807\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.6082 - val_loss: 0.6566 - val_accuracy: 0.6197\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6177 - val_loss: 0.6588 - val_accuracy: 0.6011\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6135 - val_loss: 0.6587 - val_accuracy: 0.5993\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6522 - accuracy: 0.6192 - val_loss: 0.6578 - val_accuracy: 0.5949\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6143 - val_loss: 0.6575 - val_accuracy: 0.5931\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6135 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6139 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6150 - val_loss: 0.6577 - val_accuracy: 0.5940\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.6169 - val_loss: 0.6580 - val_accuracy: 0.5975\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6139 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6097 - val_loss: 0.6570 - val_accuracy: 0.6028\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6578 - val_accuracy: 0.5931\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6169 - val_loss: 0.6591 - val_accuracy: 0.5984\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6525 - accuracy: 0.6147 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6166 - val_loss: 0.6573 - val_accuracy: 0.5931\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6523 - accuracy: 0.6188 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6143 - val_loss: 0.6572 - val_accuracy: 0.5993\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6124 - val_loss: 0.6569 - val_accuracy: 0.6028\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6150 - val_loss: 0.6580 - val_accuracy: 0.5975\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6112 - val_loss: 0.6567 - val_accuracy: 0.6064\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6524 - accuracy: 0.6226 - val_loss: 0.6603 - val_accuracy: 0.5931\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6109 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6522 - accuracy: 0.6166 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6162 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6181 - val_loss: 0.6596 - val_accuracy: 0.5993\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6529 - accuracy: 0.6124 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6520 - accuracy: 0.6071 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6150 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6566 - val_accuracy: 0.6117\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6528 - accuracy: 0.6139 - val_loss: 0.6573 - val_accuracy: 0.5957\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6135 - val_loss: 0.6569 - val_accuracy: 0.6020\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6523 - accuracy: 0.6150 - val_loss: 0.6574 - val_accuracy: 0.5940\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6162 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6526 - accuracy: 0.6112 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6185 - val_loss: 0.6581 - val_accuracy: 0.5975\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6131 - val_loss: 0.6579 - val_accuracy: 0.5940\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6515 - accuracy: 0.6135 - val_loss: 0.6573 - val_accuracy: 0.6223\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6234 - val_loss: 0.6574 - val_accuracy: 0.5940\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6173 - val_loss: 0.6596 - val_accuracy: 0.5966\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6135 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6203 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6147 - val_loss: 0.6566 - val_accuracy: 0.6099\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6528 - accuracy: 0.6177 - val_loss: 0.6577 - val_accuracy: 0.5940\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6517 - accuracy: 0.6188 - val_loss: 0.6567 - val_accuracy: 0.6179\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6150 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6196 - val_loss: 0.6606 - val_accuracy: 0.5904\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6602 - val_accuracy: 0.5949\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6154 - val_loss: 0.6568 - val_accuracy: 0.6046\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6566 - val_accuracy: 0.6179\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6181 - val_loss: 0.6597 - val_accuracy: 0.5993\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6112 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6523 - accuracy: 0.6135 - val_loss: 0.6579 - val_accuracy: 0.5966\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6169 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6222 - val_loss: 0.6602 - val_accuracy: 0.5931\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6105 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6162 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6139 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6105 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6158 - val_loss: 0.6585 - val_accuracy: 0.6002\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6185 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6109 - val_loss: 0.6581 - val_accuracy: 0.6002\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6158 - val_loss: 0.6606 - val_accuracy: 0.5913\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6188 - val_loss: 0.6601 - val_accuracy: 0.5949\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6147 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6527 - accuracy: 0.6177 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6520 - accuracy: 0.6173 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6207 - val_loss: 0.6607 - val_accuracy: 0.5895\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6135 - val_loss: 0.6569 - val_accuracy: 0.6028\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6177 - val_loss: 0.6570 - val_accuracy: 0.6020\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.6090 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6154 - val_loss: 0.6607 - val_accuracy: 0.5887\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6158 - val_loss: 0.6578 - val_accuracy: 0.5931\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6521 - accuracy: 0.6162 - val_loss: 0.6573 - val_accuracy: 0.5957\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6128 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6521 - accuracy: 0.6109 - val_loss: 0.6566 - val_accuracy: 0.6144\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6154 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6169 - val_loss: 0.6566 - val_accuracy: 0.6073\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6523 - accuracy: 0.6166 - val_loss: 0.6581 - val_accuracy: 0.5975\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6131 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6166 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6124 - val_loss: 0.6577 - val_accuracy: 0.5931\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6158 - val_loss: 0.6573 - val_accuracy: 0.5957\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6521 - accuracy: 0.6166 - val_loss: 0.6572 - val_accuracy: 0.5984\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6109 - val_loss: 0.6571 - val_accuracy: 0.6011\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6135 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6112 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6131 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6518 - accuracy: 0.6139 - val_loss: 0.6566 - val_accuracy: 0.6188\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6530 - accuracy: 0.6196 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6517 - accuracy: 0.6147 - val_loss: 0.6566 - val_accuracy: 0.6170\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6181 - val_loss: 0.6568 - val_accuracy: 0.6206\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6188 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6150 - val_loss: 0.6623 - val_accuracy: 0.5807\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6143 - val_loss: 0.6588 - val_accuracy: 0.6002\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6131 - val_loss: 0.6581 - val_accuracy: 0.5984\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6595 - val_accuracy: 0.5957\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6526 - accuracy: 0.6162 - val_loss: 0.6581 - val_accuracy: 0.5975\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6528 - accuracy: 0.6154 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6181 - val_loss: 0.6579 - val_accuracy: 0.5949\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6154 - val_loss: 0.6575 - val_accuracy: 0.5940\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6143 - val_loss: 0.6603 - val_accuracy: 0.5931\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6528 - accuracy: 0.6124 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6578 - val_accuracy: 0.5931\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6173 - val_loss: 0.6599 - val_accuracy: 0.6002\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6211 - val_loss: 0.6610 - val_accuracy: 0.5887\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6120 - val_loss: 0.6592 - val_accuracy: 0.5984\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6124 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6158 - val_loss: 0.6609 - val_accuracy: 0.5887\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6063 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6158 - val_loss: 0.6582 - val_accuracy: 0.6002\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6521 - accuracy: 0.6116 - val_loss: 0.6603 - val_accuracy: 0.5922\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6595 - val_accuracy: 0.5949\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6566 - val_accuracy: 0.6108\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6181 - val_loss: 0.6586 - val_accuracy: 0.5984\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6177 - val_loss: 0.6590 - val_accuracy: 0.6002\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6147 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6516 - accuracy: 0.6166 - val_loss: 0.6567 - val_accuracy: 0.6188\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6529 - accuracy: 0.6173 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6576 - val_accuracy: 0.5931\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6519 - accuracy: 0.6166 - val_loss: 0.6613 - val_accuracy: 0.5878\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6082 - val_loss: 0.6602 - val_accuracy: 0.5949\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6101 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6526 - accuracy: 0.6169 - val_loss: 0.6596 - val_accuracy: 0.5966\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6124 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6135 - val_loss: 0.6578 - val_accuracy: 0.5940\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6524 - accuracy: 0.6185 - val_loss: 0.6566 - val_accuracy: 0.6144\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6131 - val_loss: 0.6597 - val_accuracy: 0.6011\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6612 - val_accuracy: 0.5878\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6166 - val_loss: 0.6587 - val_accuracy: 0.5993\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6154 - val_loss: 0.6577 - val_accuracy: 0.5940\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6516 - accuracy: 0.6139 - val_loss: 0.6624 - val_accuracy: 0.5816\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6523 - accuracy: 0.6101 - val_loss: 0.6588 - val_accuracy: 0.6011\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6109 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6139 - val_loss: 0.6617 - val_accuracy: 0.5833\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6124 - val_loss: 0.6571 - val_accuracy: 0.6020\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6525 - accuracy: 0.6150 - val_loss: 0.6574 - val_accuracy: 0.5940\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6128 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6131 - val_loss: 0.6589 - val_accuracy: 0.6002\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6162 - val_loss: 0.6569 - val_accuracy: 0.6037\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6139 - val_loss: 0.6575 - val_accuracy: 0.5931\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6131 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6135 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6158 - val_loss: 0.6565 - val_accuracy: 0.6144\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6215 - val_loss: 0.6586 - val_accuracy: 0.5993\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6116 - val_loss: 0.6598 - val_accuracy: 0.6002\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6512 - accuracy: 0.6052 - val_loss: 0.6570 - val_accuracy: 0.6197\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.6120 - val_loss: 0.6567 - val_accuracy: 0.6188\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6584 - val_accuracy: 0.6002\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6154 - val_loss: 0.6566 - val_accuracy: 0.6082\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.6166 - val_loss: 0.6574 - val_accuracy: 0.5931\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6147 - val_loss: 0.6566 - val_accuracy: 0.6082\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6139 - val_loss: 0.6566 - val_accuracy: 0.6197\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6203 - val_loss: 0.6635 - val_accuracy: 0.5789\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6530 - accuracy: 0.6143 - val_loss: 0.6595 - val_accuracy: 0.5966\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6158 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6120 - val_loss: 0.6580 - val_accuracy: 0.5984\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6527 - accuracy: 0.6150 - val_loss: 0.6584 - val_accuracy: 0.5993\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6181 - val_loss: 0.6608 - val_accuracy: 0.5895\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6093 - val_loss: 0.6589 - val_accuracy: 0.6011\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.6166 - val_loss: 0.6566 - val_accuracy: 0.6188\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6527 - accuracy: 0.6131 - val_loss: 0.6591 - val_accuracy: 0.5984\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.6120 - val_loss: 0.6566 - val_accuracy: 0.6197\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6200 - val_loss: 0.6572 - val_accuracy: 0.5966\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6514 - accuracy: 0.6158 - val_loss: 0.6569 - val_accuracy: 0.6197\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6530 - accuracy: 0.6139 - val_loss: 0.6576 - val_accuracy: 0.5940\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.6173 - val_loss: 0.6583 - val_accuracy: 0.5993\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6147 - val_loss: 0.6568 - val_accuracy: 0.6028\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6518 - accuracy: 0.6139 - val_loss: 0.6633 - val_accuracy: 0.5789\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6135 - val_loss: 0.6582 - val_accuracy: 0.5993\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6120 - val_loss: 0.6566 - val_accuracy: 0.6117\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6181 - val_loss: 0.6579 - val_accuracy: 0.5957\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6522 - accuracy: 0.6211 - val_loss: 0.6573 - val_accuracy: 0.5940\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.6158 - val_loss: 0.6588 - val_accuracy: 0.6002\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6522 - accuracy: 0.6150 - val_loss: 0.6600 - val_accuracy: 0.5957\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 5ms/step - loss: 0.6522 - accuracy: 0.6086\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.5957\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 0.4]\n",
      " [ 0.4]\n",
      " [ 0.6]\n",
      " [ 0.4]\n",
      " [ 0.3]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6137184115523465\n",
      "0.2938634399308557\n",
      "0.3974284044418469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.3]\n",
      " [ 0.4]\n",
      " [ 0.6]\n",
      " [ 0.4]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6458333333333334\n",
      "0.2946768060836502\n",
      "0.40469973890339433\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
