{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  11.6  594.1 ...  4.3  0.9  0.0]\n",
      " [ 1.0  1.2  164.5 ...  9.5  0.9  0.0]\n",
      " [ 1.0  11.0  797.8 ...  4.3  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  2.6  299.4 ...  6.3  1.0  0.0]\n",
      " [ 0.0  10.6  861.4 ...  5.5  0.9  0.0]\n",
      " [ 0.0  5.1  265.2 ...  2.2  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  0.1  0.2  0.1  0.5  4.3]\n",
      " [ 1.0  0.0  0.1  0.0  0.3  9.5]\n",
      " [ 1.0  0.1  0.2  0.0  0.5  4.3]\n",
      " ...\n",
      " [ 1.0  0.0  0.0  0.0  0.3  6.3]\n",
      " [ 0.0  0.1  0.3  0.1  0.6  5.5]\n",
      " [ 0.0  0.2  0.4  0.2  0.7  2.2]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 6, axis = 1)\n",
    "brainT = np.delete(brainT, 5, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 2, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 14ms/step - loss: 1.4796 - accuracy: 0.4450 - val_loss: 1.2155 - val_accuracy: 0.4530\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0327 - accuracy: 0.4450 - val_loss: 0.8693 - val_accuracy: 0.4530\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.7669 - accuracy: 0.4453 - val_loss: 0.6865 - val_accuracy: 0.4619\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6450 - accuracy: 0.5289 - val_loss: 0.6171 - val_accuracy: 0.6445\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6031 - accuracy: 0.7456 - val_loss: 0.5922 - val_accuracy: 0.8227\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5807 - accuracy: 0.8470 - val_loss: 0.5723 - val_accuracy: 0.8387\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5602 - accuracy: 0.8550 - val_loss: 0.5519 - val_accuracy: 0.8528\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.8679 - val_loss: 0.5325 - val_accuracy: 0.8537\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5196 - accuracy: 0.8667 - val_loss: 0.5126 - val_accuracy: 0.8537\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.8713 - val_loss: 0.4934 - val_accuracy: 0.8555\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.8721 - val_loss: 0.4728 - val_accuracy: 0.8546\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.8751 - val_loss: 0.4538 - val_accuracy: 0.8555\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.8785 - val_loss: 0.4366 - val_accuracy: 0.8590\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4234 - accuracy: 0.8827 - val_loss: 0.4202 - val_accuracy: 0.8590\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4063 - accuracy: 0.8842 - val_loss: 0.4037 - val_accuracy: 0.8652\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3907 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8652\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3758 - accuracy: 0.8895 - val_loss: 0.3757 - val_accuracy: 0.8732\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3627 - accuracy: 0.8960 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8971 - val_loss: 0.3500 - val_accuracy: 0.8803\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.9032 - val_loss: 0.3377 - val_accuracy: 0.8821\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3249 - accuracy: 0.9058 - val_loss: 0.3272 - val_accuracy: 0.8812\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3146 - accuracy: 0.9051 - val_loss: 0.3173 - val_accuracy: 0.8865\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3044 - accuracy: 0.9066 - val_loss: 0.3078 - val_accuracy: 0.8954\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2948 - accuracy: 0.9115 - val_loss: 0.2988 - val_accuracy: 0.8874\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2860 - accuracy: 0.9123 - val_loss: 0.2902 - val_accuracy: 0.8980\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2775 - accuracy: 0.9131 - val_loss: 0.2827 - val_accuracy: 0.9043\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2695 - accuracy: 0.9165 - val_loss: 0.2750 - val_accuracy: 0.9060\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2616 - accuracy: 0.9172 - val_loss: 0.2677 - val_accuracy: 0.9060\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.9203 - val_loss: 0.2605 - val_accuracy: 0.9069\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2478 - accuracy: 0.9207 - val_loss: 0.2546 - val_accuracy: 0.9078\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2414 - accuracy: 0.9241 - val_loss: 0.2489 - val_accuracy: 0.9096\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2353 - accuracy: 0.9248 - val_loss: 0.2426 - val_accuracy: 0.9113\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2298 - accuracy: 0.9263 - val_loss: 0.2372 - val_accuracy: 0.9113\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2242 - accuracy: 0.9275 - val_loss: 0.2321 - val_accuracy: 0.9113\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2185 - accuracy: 0.9290 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2131 - accuracy: 0.9317 - val_loss: 0.2218 - val_accuracy: 0.9167\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2078 - accuracy: 0.9324 - val_loss: 0.2170 - val_accuracy: 0.9220\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2028 - accuracy: 0.9347 - val_loss: 0.2118 - val_accuracy: 0.9238\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1977 - accuracy: 0.9370 - val_loss: 0.2069 - val_accuracy: 0.9246\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1930 - accuracy: 0.9377 - val_loss: 0.2036 - val_accuracy: 0.9246\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1886 - accuracy: 0.9400 - val_loss: 0.1983 - val_accuracy: 0.9273\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1839 - accuracy: 0.9415 - val_loss: 0.1958 - val_accuracy: 0.9282\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1800 - accuracy: 0.9427 - val_loss: 0.1912 - val_accuracy: 0.9273\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1761 - accuracy: 0.9446 - val_loss: 0.1866 - val_accuracy: 0.9326\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.9438 - val_loss: 0.1838 - val_accuracy: 0.9309\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1686 - accuracy: 0.9457 - val_loss: 0.1795 - val_accuracy: 0.9353\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1650 - accuracy: 0.9472 - val_loss: 0.1772 - val_accuracy: 0.9371\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1615 - accuracy: 0.9468 - val_loss: 0.1727 - val_accuracy: 0.9388\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1583 - accuracy: 0.9476 - val_loss: 0.1700 - val_accuracy: 0.9424\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1549 - accuracy: 0.9495 - val_loss: 0.1674 - val_accuracy: 0.9433\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1518 - accuracy: 0.9506 - val_loss: 0.1652 - val_accuracy: 0.9468\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1487 - accuracy: 0.9529 - val_loss: 0.1612 - val_accuracy: 0.9459\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1458 - accuracy: 0.9522 - val_loss: 0.1595 - val_accuracy: 0.9468\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1430 - accuracy: 0.9529 - val_loss: 0.1563 - val_accuracy: 0.9459\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9544 - val_loss: 0.1535 - val_accuracy: 0.9495\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1376 - accuracy: 0.9548 - val_loss: 0.1511 - val_accuracy: 0.9512\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 0.1489 - val_accuracy: 0.9539\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1319 - accuracy: 0.9556 - val_loss: 0.1475 - val_accuracy: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1293 - accuracy: 0.9567 - val_loss: 0.1450 - val_accuracy: 0.9557\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1267 - accuracy: 0.9567 - val_loss: 0.1433 - val_accuracy: 0.9557\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1241 - accuracy: 0.9571 - val_loss: 0.1413 - val_accuracy: 0.9557\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1216 - accuracy: 0.9594 - val_loss: 0.1395 - val_accuracy: 0.9557\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1196 - accuracy: 0.9590 - val_loss: 0.1370 - val_accuracy: 0.9566\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1173 - accuracy: 0.9598 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1149 - accuracy: 0.9613 - val_loss: 0.1329 - val_accuracy: 0.9601\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 0.1321 - val_accuracy: 0.9583\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1118 - accuracy: 0.9639 - val_loss: 0.1309 - val_accuracy: 0.9601\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1098 - accuracy: 0.9639 - val_loss: 0.1282 - val_accuracy: 0.9601\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1079 - accuracy: 0.9647 - val_loss: 0.1284 - val_accuracy: 0.9619\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1064 - accuracy: 0.9643 - val_loss: 0.1268 - val_accuracy: 0.9619\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1048 - accuracy: 0.9643 - val_loss: 0.1252 - val_accuracy: 0.9628\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9651 - val_loss: 0.1241 - val_accuracy: 0.9628\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1017 - accuracy: 0.9651 - val_loss: 0.1219 - val_accuracy: 0.9619\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1002 - accuracy: 0.9658 - val_loss: 0.1206 - val_accuracy: 0.9619\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0991 - accuracy: 0.9670 - val_loss: 0.1196 - val_accuracy: 0.9628\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.9681 - val_loss: 0.1199 - val_accuracy: 0.9628\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0965 - accuracy: 0.9658 - val_loss: 0.1179 - val_accuracy: 0.9628\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0953 - accuracy: 0.9685 - val_loss: 0.1179 - val_accuracy: 0.9654\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 0.1163 - val_accuracy: 0.9637\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.9685 - val_loss: 0.1157 - val_accuracy: 0.9645\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0921 - accuracy: 0.9696 - val_loss: 0.1151 - val_accuracy: 0.9645\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0913 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9654\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0905 - accuracy: 0.9708 - val_loss: 0.1144 - val_accuracy: 0.9645\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0898 - accuracy: 0.9711 - val_loss: 0.1132 - val_accuracy: 0.9654\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0891 - accuracy: 0.9723 - val_loss: 0.1134 - val_accuracy: 0.9645\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0884 - accuracy: 0.9723 - val_loss: 0.1122 - val_accuracy: 0.9645\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0875 - accuracy: 0.9734 - val_loss: 0.1120 - val_accuracy: 0.9654\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9730 - val_loss: 0.1114 - val_accuracy: 0.9645\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0863 - accuracy: 0.9734 - val_loss: 0.1113 - val_accuracy: 0.9645\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9730 - val_loss: 0.1104 - val_accuracy: 0.9645\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9738 - val_loss: 0.1103 - val_accuracy: 0.9637\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.1100 - val_accuracy: 0.9645\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9742 - val_loss: 0.1100 - val_accuracy: 0.9645\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0835 - accuracy: 0.9738 - val_loss: 0.1100 - val_accuracy: 0.9645\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0831 - accuracy: 0.9746 - val_loss: 0.1099 - val_accuracy: 0.9645\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0826 - accuracy: 0.9757 - val_loss: 0.1093 - val_accuracy: 0.9645\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9749 - val_loss: 0.1083 - val_accuracy: 0.9637\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9742 - val_loss: 0.1081 - val_accuracy: 0.9645\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0816 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9645\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.1082 - val_accuracy: 0.9645\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9645\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0801 - accuracy: 0.9765 - val_loss: 0.1093 - val_accuracy: 0.9628\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9645\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9749 - val_loss: 0.1082 - val_accuracy: 0.9628\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0795 - accuracy: 0.9749 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.1086 - val_accuracy: 0.9628\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0787 - accuracy: 0.9753 - val_loss: 0.1081 - val_accuracy: 0.9628\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0778 - accuracy: 0.9765 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0783 - accuracy: 0.9772 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0780 - accuracy: 0.9761 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.1077 - val_accuracy: 0.9628\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9765 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9761 - val_loss: 0.1074 - val_accuracy: 0.9628\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9765 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.1072 - val_accuracy: 0.9637\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9749 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 0.1061 - val_accuracy: 0.9645\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9768 - val_loss: 0.1059 - val_accuracy: 0.9654\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.1090 - val_accuracy: 0.9637\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.1059 - val_accuracy: 0.9654\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9780 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0761 - accuracy: 0.9768 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0764 - accuracy: 0.9765 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9791 - val_loss: 0.1080 - val_accuracy: 0.9645\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0761 - accuracy: 0.9757 - val_loss: 0.1068 - val_accuracy: 0.9645\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9761 - val_loss: 0.1062 - val_accuracy: 0.9645\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9761 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9776 - val_loss: 0.1075 - val_accuracy: 0.9645\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9772 - val_loss: 0.1060 - val_accuracy: 0.9645\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9772 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9757 - val_loss: 0.1066 - val_accuracy: 0.9637\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9768 - val_loss: 0.1058 - val_accuracy: 0.9645\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.1057 - val_accuracy: 0.9645\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9765 - val_loss: 0.1057 - val_accuracy: 0.9645\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9772 - val_loss: 0.1057 - val_accuracy: 0.9654\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9784 - val_loss: 0.1059 - val_accuracy: 0.9637\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9761 - val_loss: 0.1064 - val_accuracy: 0.9637\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9780 - val_loss: 0.1057 - val_accuracy: 0.9654\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9780 - val_loss: 0.1060 - val_accuracy: 0.9637\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9776 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.1057 - val_accuracy: 0.9637\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9772 - val_loss: 0.1059 - val_accuracy: 0.9637\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9776 - val_loss: 0.1062 - val_accuracy: 0.9637\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9772 - val_loss: 0.1059 - val_accuracy: 0.9637\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0747 - accuracy: 0.9776 - val_loss: 0.1059 - val_accuracy: 0.9645\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0744 - accuracy: 0.9765 - val_loss: 0.1060 - val_accuracy: 0.9637\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9768 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9784 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0741 - accuracy: 0.9784 - val_loss: 0.1059 - val_accuracy: 0.9654\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9780 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9772 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.1059 - val_accuracy: 0.9654\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9780 - val_loss: 0.1059 - val_accuracy: 0.9645\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0741 - accuracy: 0.9768 - val_loss: 0.1059 - val_accuracy: 0.9645\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 0.1071 - val_accuracy: 0.9645\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.1062 - val_accuracy: 0.9637\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9784 - val_loss: 0.1075 - val_accuracy: 0.9645\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0741 - accuracy: 0.9772 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9784 - val_loss: 0.1064 - val_accuracy: 0.9637\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0740 - accuracy: 0.9776 - val_loss: 0.1060 - val_accuracy: 0.9645\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9784 - val_loss: 0.1062 - val_accuracy: 0.9637\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.1064 - val_accuracy: 0.9637\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9784 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9772 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9776 - val_loss: 0.1072 - val_accuracy: 0.9637\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9780 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9784 - val_loss: 0.1063 - val_accuracy: 0.9637\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0737 - accuracy: 0.9776 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9780 - val_loss: 0.1065 - val_accuracy: 0.9637\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0736 - accuracy: 0.9784 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0729 - accuracy: 0.9799 - val_loss: 0.1081 - val_accuracy: 0.9645\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9776 - val_loss: 0.1067 - val_accuracy: 0.9637\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9772 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9637\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9772 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.1066 - val_accuracy: 0.9637\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0736 - accuracy: 0.9784 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9776 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9637\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0736 - accuracy: 0.9784 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0733 - accuracy: 0.9780 - val_loss: 0.1077 - val_accuracy: 0.9637\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9637\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9776 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9791 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1075 - val_accuracy: 0.9637\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.1077 - val_accuracy: 0.9637\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9772 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1073 - val_accuracy: 0.9645\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9795 - val_loss: 0.1071 - val_accuracy: 0.9645\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0730 - accuracy: 0.9772 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9776 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1075 - val_accuracy: 0.9645\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0733 - accuracy: 0.9784 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9795 - val_loss: 0.1073 - val_accuracy: 0.9645\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.1090 - val_accuracy: 0.9645\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9776 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.1078 - val_accuracy: 0.9637\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9780 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 0.1071 - val_accuracy: 0.9645\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0726 - accuracy: 0.9799 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9784 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9795 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9791 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9791 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9791 - val_loss: 0.1073 - val_accuracy: 0.9645\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1078 - val_accuracy: 0.9645\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.1094 - val_accuracy: 0.9645\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9780 - val_loss: 0.1079 - val_accuracy: 0.9645\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9791 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9791 - val_loss: 0.1077 - val_accuracy: 0.9645\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9780 - val_loss: 0.1077 - val_accuracy: 0.9645\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1080 - val_accuracy: 0.9645\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9784 - val_loss: 0.1084 - val_accuracy: 0.9645\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1082 - val_accuracy: 0.9645\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1077 - val_accuracy: 0.9654\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.1091 - val_accuracy: 0.9637\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9791 - val_loss: 0.1077 - val_accuracy: 0.9654\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.1077 - val_accuracy: 0.9654\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1077 - val_accuracy: 0.9654\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9784 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9776 - val_loss: 0.1080 - val_accuracy: 0.9672\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9787 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1086 - val_accuracy: 0.9637\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0730 - accuracy: 0.9776 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.1076 - val_accuracy: 0.9654\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1072 - val_accuracy: 0.9663\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9791 - val_loss: 0.1093 - val_accuracy: 0.9637\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.1095 - val_accuracy: 0.9637\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1078 - val_accuracy: 0.9645\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1079 - val_accuracy: 0.9645\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9776 - val_loss: 0.1082 - val_accuracy: 0.9645\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.1079 - val_accuracy: 0.9645\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1086 - val_accuracy: 0.9637\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.1083 - val_accuracy: 0.9637\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9799 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.1077 - val_accuracy: 0.9654\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.1081 - val_accuracy: 0.9645\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.1086 - val_accuracy: 0.9637\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.1077 - val_accuracy: 0.9663\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9795 - val_loss: 0.1090 - val_accuracy: 0.9637\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9784 - val_loss: 0.1079 - val_accuracy: 0.9645\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9791 - val_loss: 0.1087 - val_accuracy: 0.9637\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9791 - val_loss: 0.1076 - val_accuracy: 0.9654\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9780 - val_loss: 0.1078 - val_accuracy: 0.9654\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9799 - val_loss: 0.1075 - val_accuracy: 0.9654\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1076 - val_accuracy: 0.9654\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1086 - val_accuracy: 0.9637\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 0.1076 - val_accuracy: 0.9654\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 0.1079 - val_accuracy: 0.9654\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9791 - val_loss: 0.1083 - val_accuracy: 0.9637\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9799 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1077 - val_accuracy: 0.9645\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9787 - val_loss: 0.1075 - val_accuracy: 0.9645\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0731 - accuracy: 0.9791 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9799 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9654\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.1079 - val_accuracy: 0.9645\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1076 - val_accuracy: 0.9645\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9791 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9791 - val_loss: 0.1074 - val_accuracy: 0.9637\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9784 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.9791 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1073 - val_accuracy: 0.9645\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9791 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0728 - accuracy: 0.9791 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9795 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9791 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.1070 - val_accuracy: 0.9645\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.1063 - val_accuracy: 0.9663\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9787 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0724 - accuracy: 0.9791 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1064 - val_accuracy: 0.9663\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9795 - val_loss: 0.1062 - val_accuracy: 0.9663\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1059 - val_accuracy: 0.9654\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9637\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9787 - val_loss: 0.1059 - val_accuracy: 0.9663\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.1060 - val_accuracy: 0.9663\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1062 - val_accuracy: 0.9637\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.1056 - val_accuracy: 0.9654\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9787 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9791 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1062 - val_accuracy: 0.9637\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9784 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.1062 - val_accuracy: 0.9645\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9791 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9791 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.1057 - val_accuracy: 0.9654\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9799 - val_loss: 0.1057 - val_accuracy: 0.9654\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.1059 - val_accuracy: 0.9645\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9799 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9637\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9663\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1061 - val_accuracy: 0.9663\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9803 - val_loss: 0.1063 - val_accuracy: 0.9637\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9776 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9637\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1062 - val_accuracy: 0.9663\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1068 - val_accuracy: 0.9637\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9795 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1066 - val_accuracy: 0.9663\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9663\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1062 - val_accuracy: 0.9654\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.1066 - val_accuracy: 0.9645\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9795 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.1066 - val_accuracy: 0.9663\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9799 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9663\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9780 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9803 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1061 - val_accuracy: 0.9654\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9787 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9780 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9806 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9803 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1065 - val_accuracy: 0.9645\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.1064 - val_accuracy: 0.9645\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9810 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9803 - val_loss: 0.1072 - val_accuracy: 0.9645\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1066 - val_accuracy: 0.9663\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9791 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1070 - val_accuracy: 0.9663\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9799 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1070 - val_accuracy: 0.9663\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1069 - val_accuracy: 0.9663\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9654\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.1073 - val_accuracy: 0.9663\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.1071 - val_accuracy: 0.9654\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9803 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9810 - val_loss: 0.1066 - val_accuracy: 0.9663\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.1068 - val_accuracy: 0.9663\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.1073 - val_accuracy: 0.9654\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.1072 - val_accuracy: 0.9663\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1069 - val_accuracy: 0.9663\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9806 - val_loss: 0.1066 - val_accuracy: 0.9654\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9806 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 0.1065 - val_accuracy: 0.9654\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1071 - val_accuracy: 0.9645\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9803 - val_loss: 0.1067 - val_accuracy: 0.9663\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9803 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9814 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9810 - val_loss: 0.1069 - val_accuracy: 0.9654\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9806 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx3klEQVR4nO3deZhcVbXw/++qoed5SNJJJ+kQAgmBkEAMIIOMGpBBMEJARPBykSgIXq8vXO9VROW9XKdXUBRBEZBcEIEo+GMSDDJD0iEJmSAhU3e6k/Q8DzWs3x+7uqnudCeVodLpPuvzPP10nbHWPlV11jl7n7OPqCrGGGO8yzfUARhjjBlalgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8LpCsFYvIA8D5wE5VPXqA6QLcBZwHtANXq+qyPa23qKhIy8rKDnC0xhgzspWXl9eqavFA05KWCIAHgV8BDw8y/VxgSuzvBOA3sf+7VVZWxtKlSw9QiMYY4w0ismWwaUmrGlLVV4H63cxyEfCwOm8DeSJSkqx4jDHGDGwo2wjGARVxw5WxcbsQketEZKmILK2pqTkowRljjFcMZSKQAcYN2N+Fqt6nqrNVdXZx8YBVXMYYY/bRUCaCSmB83HApUDVEsRhjjGcNZSJ4GrhKnBOBJlWtHsJ4jDHGk5J5+eijwOlAkYhUArcBQQBVvRd4Fnfp6Abc5aPXJCsWY4wxg0taIlDVy/cwXYGvJ+v9jTHGJCaZ9xEYYxIQjkTx+wR3j+X+ryvgHz4dBnSFI6T4fb1l7w5Hae0Kk5nqJ+jzEVFle1Mno3PSSAm4crV2hekKRSjMSu1dT3c4yhsf1TKnrIDM1ACq2md79myXcCTKtsYOxualU9/WTVrQT2aKn+qmTsYXZFBR3057d4QjRmchIoQiUbbUtTOpKJNQJEpa0A9AU3uINdXNTCrKJByNsqO5k8zUAEeOziYSVbbWtxP0+yjJTev9PKJRZUNNK+PzMxCBivp2djR3Mb4gnYmFmVTUt7OzpROfCEePyyUUieITYXlFI1vq2igrzOTwUVl9yn2gWCIwu4hGlY21rXSHlX+s28HXTj+c9lCEcCRKXkYKqkpUYWdLJ1WNHQR8Pvw+IT3FT1FmKori8wk5aUFeW19DfVs3Jx1WSFRBBFo6w1Q1duATobUrRGfI/ZDG5qUzuyyfD7a3kBrwU9HQjk+E0vx0/vj2FqJR5TPTx6AooYiSkeJHEMq3NFBWlEFhZiqrq5oYX5BBZyhCZYP7wTe1dzMqJ42X1u5g/ifGU5iVysaaVtq6ImSlBegKRahu6mRbYwdBv4/pY3MI+n3kpgcBWFHRyAtrtjO9JJexeemEIlFGZadSlJ3Ku5vqqW7qICXgZ1xeOm1dYUZlp7K9uZOt9e1MG5NDfXs3NS1dTCvJobKhnU9OLiIvI0htSxcAv/zHBiYVZfLFEyeQ4vexo7mL7kgEQahp6UJRNuxsJRRRPnl4IVvr2mntCnNsaR7dkSirq5oIRZR3N9WTmx7kE2X5hCLK6JxUBGHplnq6wlEOH5VFbWsXRVmpVNS3M2tCPh2hCO9XNjGpKJPc9CABn4BAaV46fp+Pmla3YwpFlEjU7aQBIlGlvTtCVJWNNW3MKM2lsT1EZmqA1s4wneEIaUE/AozJTSMzNcCGna10dEfY0dxJRoqfsqJM3vqojoLMFGaOz2Pd9hYqG9oJRdzFg+ML0gn6fWysaQMgNeDjiNHZbKpto7UrzJicNCYUZlDf1k1XOEJFfQcAKX4fqQEfh4/OoqM7QlVjB23dESYWZFARt36AzBQ/o3PS2FjbxmHFmWypaycSVSYUZBCKRGlsD9ERiuD3CVFVJhVmUt/eTWN7aMDfTnF2Ks0dIbrCUQACPulNHqFItHd8fykBH91x03wC0QGuofziCRO44+JjEvod7w0Zbk8omz17ttqdxYNraOumfEsDM8bnsrO5i0hUeWxJBWdOHcWyrQ3saOrs3YFt2NlKQWYKx0/Mp707zISCDN7b2sjG2jbq27p71zmtJIfNtW10hCKkB/34BNq6I7uNI+ATjhyTzeqq5mQX+YAY7IfXX2rARygS7TNvQWYKGSl+Khs6dplfBOJ/YnkZwQF3IoONTw346I5ECfikzw6sJDeNnS3u8x1IetBPZzhCasBHZ8jtYKaOySY14OP9bU2U5KZT29pFVmqAtu4w2WlBUvyubAA7Y0kqOzWAAuGo24lNKsxEBBrbQxRnp7Klrp1QJEpeRpCCzBQEcTvp3DTCUQVValu7qWvroqwwkw07W0kJ+HoTaigcpbq5k0lFmYzOTmPmhDwKM1Oobe1mbXVz75F2+ZYGAGaOz2NsXhoZKQF2tnSxs7mTlIAPnwiHFWXyUW0baQGfS0hdYVIDPoqyUomq0hmKMCo7jT++7W6wPXpcDhkpASrq3QHHtsYOTjm8iDOmjqJ8Sz0Bn4+g38eEWALJSg2wrbGDrNQA4/LSKchMoa0rTGFWKmPz0qiob2fJ5gYKMlPYVNvG9qZOpo/NIT8zpfdzKc1PZ2NNG2lBtw1y04NUN3Wy8O0tzD26hE8dWUx1YwdLNjdQmp9OZyhCa1eYGaW5rN/RyjfOnkJOWnDAz3xPRKRcVWcPOM0SwfC0s6WTF1bvYEdTJ+3dETbXuS9eRUM7LZ3hPS4/ZVQWLZ1hMlL9NHeECEWUpo4QJblpTC7OorUrjN/njraDfuGYcbmcfdRoXli1na317cwozSM96GdFZSNnTxvN7LJ8alu76QxFCPqF7U1drKhs5IRJBZx3TAl/XlrBtsZOjhidRdDvY0xuGvVt3ZTkpjG+IIOGtm5WVDYCUJjpflhTx+TQ2hXuPXpdtrWBivp2RGB2WQF1rd0UZqUwZVQW25s6aewIcWxpHqurmoiq2/G1d0do6Qzx2vpappXk8OGOFoqzUxmTk0ZWWgC/uDOZ4qxUOsMR2roiNHV00xmKUtvaRUFmCqNz0ohElfyMFNJT/HR0R4io0twRIic9SFasKqIrHGVzXRul+RmkB/1srGnlsOIsGtpdUs1I8ZOREqC+zW2nnPQgDW3dVNS3M2N8HpWxzy4vPUhNSxcTCjMYm5tOKBolNeCnKxxBFV5fX8tpRxQTjkZp747Q3hUhLzPIqm1NHFuaR0VDO0eOzqYr7KoyNtW2MS4vvbdqJZHqo8b2blq7wpTmZ/SO6wxFeo9u48cFfJJwdVRzZ4j2rghjctN6x7V1hclM3X3lxI7mTnY2d3FMaW5C77M7LZ0hIlElL+PjHbSqO+uaXJyFz7f/VXSHIksEI0RTR4jLfvsW0diXNv5gcFJRJiW5aeRlBDlpchEV9e1MKMggJz3IrNhpt6oyeVQWAhxWnNVn3e3dYd76qI6TDy/q82MPRaII9P7QVV21TM9OxRgzPOwuEVgbwSHupTU7WPzBTnY0d7Kxpo2NtW1kpvi5dPZ4Lpo5jlkT8vD7hMAeGhvHF2QMOg0gIyXAWdNG7zI+2O9IT0RICYzMI6ZDQutOEB9kFg11JOZQE+5y9YzBtD3Pu5csERxCOkMRVlc10RWKsqGmlTc31PH86u2UUMf8wGImFBzL7z7RyGEZHZAzDqrCUJ8DeRMhoxDaYv0wpWSBRiHU7oYLD4dICMIdsPEV6GqBrlbIGQufuBZq1sGmV2HUUbDlDehuc5Xb4S4oOxW6mqG7FYqnQSDFrb91B1S8C1M+DZv+CZ+8EdJy3Re1MnbG1t0C656FaAh8QcgeA5PPhI56SMuHUJtbpmAybH0bVj/llgukAgJjZ0IgHSrecePGHAPbyt26Iq4OG1/AxRtIcztQjUI0DJFYG0fZqTBqKqx5GrJLXDk0Ck0VMOlT7n/dRzDpNEjNdsuEOlyZ8ie57eBPhfQ8qF7htl00AqmxM6quVkDd+wd6fqAKo6e7z2T7++5/8zbobofCyW7bdbWCRmKxx8ob7oQPnnVlmnaB2/6tO2HHajjiM+Dzw7jZbrt1tcD0S+Dd+6CjIbYt/DD6aFjyOyg+Eo78LFS958oMblt3NkNGvit7V7P73CNxbRP5ZS6Whk19v5yBNEjJcPFues1trzHHQO162LkGaj6AspPBn+K2Z+0HUHDYx9+ZD190233SaW44kO6GSz8B21fGtmsYUjJh3PGw+XX3+S95wH2vs0dDeoH7vMpOcd8BEajf5L6HwXQ44tMuVvFBSjZ0Nbnv1eijXVwV78DRl7j1VbwLRUe4bdJf7YfuMyg47ONxmcVQvxE2/tOVs6vFlVMj7ntdvwnGzoLmKvd9C2bA5jegs9F9LinZ7ven6uar/dC9DrW772ogLfY/FcLdkD8R2mphwomubBp122T2NXDqt3azF9k3VjV0iCjf0sC/PLSEvI6tnOV7j6N8m1nnO4LzxzQwrrGcoq6tyXnjUdPdD3mgbp4C6e7LmwhfAMTvfhjRPbdR9CXu/dPzXZJpqtjjEnuUO97tWNsG6aQwkOam93+9J/5Ut7PqiHWsm57vtlPLPvaOkln8cYy5492Pv2ebZ49177O72MTvEjq4nXxX067z5I53O/COekjN7TtPSpYrA7gE11OO7LFuB9Z/fI+BtllqrkuQzVVuJ+vzQ1OlSzj5ZdCw2c3nC7qDg3j+VMga1bf8icgdD4ed7rbhh89DWp5LoD3rKJj88UFBz/cqJcsdFES6+rbk98YSdON7vseqrvwahYknu/WIz22DmnWu3FPOgW1LXcIJdQLqkv6o6dC0Feo2QlpO7OBgpYsB3PCoae4gI3c8NG5x/9f9zcWdG9cLT24pnPEdl0z3gVUNHaJUlZfW7mTt2lUUvncP/+Nv45y0pfg0TDSYiS/0OtRnuB/6UVe6o9uJn3Q73VCH+6F1t0FztTuCK5kJPp87SvMFoGCSO/J8+QfuyDQahtxx7sv56R+6BPCPO2DM0TDhJDjsDMgogLoN7sg9owh2rnY/0mC625E0bXNHOaOmuy/qhpfcD7g5bkdRMMn9eNpq3HJHnhdbvtEdgeaMhfZaSM1xcXe3u53rnOvcj6V6hTvCLJgMW98EBEpmQPVKdxToC0JWMYyZARtehqM/784+PnzRxXT4We7HpQprn3FlP2KuO6VOyXQ7tuwxsR9xjvux9U+GhVNg5Z/c0VtKptveuePdEVtKFrRuj1XhFLvPoWWHG+7RvM0lxcxR7og9s9h9Jq3b3Y/fF3CfR3bJxzuwiSe5ZXeuharlcOx8V961f4OWareO/DK3o4pGYM1f3OdUdopbLtQBKx5zrzOL3edVPBXGz3Hb+L1H4Jh57qyqvc7trIunuiP9HvWb3HaIPxpWddsib6I7axo93e3c6ze5M9OUjNiZRqE72m+ucu/vD0JbHax6EmZdCRsXu88+o9B9b8YcC9tXwNQL3HZNy3GJYMVjMP1iqF7uEt2k02D5QvfZTrvAvdeOVe6sJieu5/qWHW7dkS5XXo26M4kekZA7uyo6om+ZE9Fc5bZv4eS+49vr3WeZlrN369uT1hoXY0rmgV3vIOyMYAioKovXbecfq6t4tXwFjwT/LxN8saPCSafBWbe5HVDNOsib8HGVhTHG7CM7IzhEbK5t4+6XPiSy+i/c6nuYM6UeUiEazIRzfurq8ief8fECo6cPXbDGGM+wRHAQvLOxjmsfXkpbV5gvBl/hh/77AOg86VukZeXiO+qiWCOdMcYcfJYIkuz19bUseKSclq4wN0xt5d8qHoZgHsz7PWmHnz3U4RljjCWCZHn1wxp++Lc1bKxt47acv/GFsmrSN//DXQJ3wxK7TtwYc8iwRHCAraho5GsLl7GtsYOctAC3TG/mqvULYUtshlO/ZUnAGHNIsURwAL2+vpbr/riU9u4Ip04p4u7PjiH/9ye567RvKHf/D0BXw8YYcyBZIjhAyrc0cO3DSygrzOThr8xhVHYqPHOTu+nmX1+GzMKhDtEYYwZkPYcdAG9sqOXS375FdlrQJYGcNHjjF7DsIThxgbu5yRhjDlF2RrCfNuxs5eY/LaesMIPHv3oShZkp8Nav4aXvu7sgz/nhUIdojDG7ZYlgP1Q2tHPRr15HgYeumeMeIbf1bXjhP9wMp33bdflgjDGHMNtL7aOK+na+8uASFHjmxlM4amwOvHEXPPAZN8MZ/+X6wjHGmEOcnRHsg+dXVfOfi1YRikS5/6rZTA7UwZPfhPcfd1cGHT0PPvXtoQ7TGGMSYolgL62sbOT6R5YxuTiT+6+azWHBerjvTNcj5+Sz4PJHY/3LG2PM8GCJYC+srGzkkl+/SXZqgKe+djK56UF46Weum+GvveUeBmKMMcOMJYIEbaxp5Yb/fY/0FD8Lrz3BJYFICNY+7Z5YZEnAGDNMWWNxAiJR5Xt/XU1NSxe/vHwWM0rz3IR//Mg9xOX4q4cyPGOM2S92RrAHlQ3tfOn377Kpto3/PG8apx85CirL4Y3/B+tfgmMudU/IMsaYYcoSwR48+u5Wtta3c88Vx3HeMWPcY/7+eDH4A+4Rj5+6ZahDNMaY/ZLURCAic4G7AD/wO1W9s9/0fOABYDLQCXxFVVclM6ZEdXRH+OH/t4bHl1TwycmFfDZzLTz4L7DlTfec1q885x4jaYwxw1zS2ghExA/cA5wLHAVcLiJH9ZvtO8ByVZ0BXIVLGoeEexZv4H/f2QrAv59aDI9e4Z4hfPJNcP1rlgSMMSNGMhuL5wAbVHWjqnYDjwEX9ZvnKOBlAFVdB5SJyOgkxpQQVeWJ8krOmjqK97//GY4NrYBwB1z+GJxzO2QUDHWIxhhzwCQzEYwDKuKGK2Pj4q0ALgEQkTnARKC0/4pE5DoRWSoiS2tqapIU7sfe39bE9uZOzjlqNOkpftj4CqTmwNjjkv7exhhzsCUzEQz0BBbtN3wnkC8iy4EbgfeA8C4Lqd6nqrNVdXZxcfEBDzReNKrc+Oh7pAV97gqh526F8gdh7CzXQGyMMSNMMvdslcD4uOFSoCp+BlVtBq4BEBEBNsX+hsza7c1sqWvnR587mjHpEXjnN26C3TBmjBmhknlGsASYIiKTRCQFmA88HT+DiOTFpgFcC7waSw5D5o0NtQCcPW007Fjz8YTCKUMUkTHGJFfSzghUNSwiNwAv4C4ffUBVV4vI9bHp9wLTgIdFJAKsAf4lWfEkojMU4eG3tjCjNJcxuWnw4cqPJ9qjJo0xI1RSK71V9Vng2X7j7o17/RZwSBxqR6PK7c+sprKhg//5fOw5AptfB38qnPwNmHrB0AZojDFJYn0NxTy2pIJH361gwemTOXlSLjzxFVj9FBx7GZz5XxBI2fNKjDFmGLJEgLtv4I9vb2H62Bz+z2eOhBWPwqonIZgBx1091OEZY0xSWSIAXvmwhrXVzXzpxImICKx9BvImwneqoPT4oQ7PGGOSyvOJIBpVfvrCB5Tmp3PJcaWw4WX3d9SFIAPdCmGMMSOL5xPBVx8pZ3VVMzedNYWUgA/K/wBZo61XUWOMZ3j2VllV5eY/Lefva3Zw5YkTmHd8rGeLbe/BxJMgNXtoAzTGmIPEs2cElQ0d/HW5u9H5hjOmuLaB134GzZXWp5AxxlM8mwgqGtoB+OkXjnU3j0Uj8EasF+yp5w1hZMYYc3B5NhFU1ncAMKcs1qX0qz+Bzib4/O+h4LAhjMwYYw4uzyaCioZ2fAIlWUD1Snjlv92Ew84Y0riMMeZg82xjcXVtAwsy/0nwV9+ClmrXlcRNy61PIWOM53g2EZy26RdcGH4OWv1w+DnuEZQ5Y4c6LGOMOeg8mQhau8KUdq1ne840xnzzdXvgjDHG0zzZRrC2upkxUo8WTbUkYIzxPE8mgpa2DkbRiC+v/yOUjTHGezyZCHwdtQQkSiSrZKhDMcaYIefJRBBsqwYgmm1nBMYY48lEkNK2HQDNtjMCY4zxZCJIbXdnBOTYGYExxngyEaS0b6dTg0hGwVCHYowxQ86TiSC9YwfVWkDA7x/qUIwxZsh5NBFsZ7sW4vfZE8iMMcabiaBzB9vJJ2CJwBhjvJkI/NFuOjSFgN8SgTHGeDIRoFEUHwGfN4tvjDHxPLknFKJE8FkbgTHG4NVEoFGiiLURGGMMHk0ErmpI8FkiMMaY5CYCEZkrIh+IyAYRuXWA6bki8oyIrBCR1SJyTTLj6X1foqjYPQTGGANJTAQi4gfuAc4FjgIuF5Gj+s32dWCNqh4LnA78TERSkhVTb2waBbGzAWOMgeSeEcwBNqjqRlXtBh4DLuo3jwLZIiJAFlAPhJMYE9CTCOyMwBhjILmJYBxQETdcGRsX71fANKAKeB+4SVWj/VckIteJyFIRWVpTU7PfgQmKijebR4wxpr9k7g0HqnvRfsOfAZYDY4GZwK9EJGeXhVTvU9XZqjq7uLh4/wPTKGKJwBhjgOQmgkpgfNxwKe7IP941wFPqbAA2AVOTGBPQ01hsicAYYyC5iWAJMEVEJsUagOcDT/ebZytwFoCIjAaOBDYmMSZQxYdaG4ExxsQEkrViVQ2LyA3AC4AfeEBVV4vI9bHp9wI/BB4UkfdxVUm3qGptsmJygcWaIKx7CWOMAZKYCABU9Vng2X7j7o17XQV8Opkx7BpULBFY1ZAxxgBevLM4lgissdgYYxzv7Q2jEfffZ20ExhgDXkwEVjVkjDF9eG9vaInAGGP68N7eUF3VkLURGGOM4729ocZubrY2AmOMARJIBCJyvoykw+eeq4YsERhjDJDYGcF8YL2I/FhEpiU7oKTruWpoBOU2Y4zZH3vcG6rqlcAs4CPgDyLyVqw30OykR5cMvWcElgiMMQYSbCNQ1WbgSdwzBUqAi4FlInJjEmNLDmssNsaYPhJpI7hARBYB/wCCwBxVPRc4Fvj3JMd34PX2NWRtBMYYA4n1NfQF4P+p6qvxI1W1XUS+kpywksgai40xpo9EEsFtQHXPgIikA6NVdbOqvpy0yJIl1ljsszYCY4wBEmsj+DMQ//jISGzc8NRzH4E9j8AYY4DEEkEg9vB5AGKvU5IXUpJZ76PGGNNHInvDGhG5sGdARC4CkvvwmGTSnt5HLREYYwwk1kZwPbBQRH6Fe4pYBXBVUqNKpt5O56xqyBhjIIFEoKofASeKSBYgqtqS/LCSyHofNcaYPhJ6VKWIfBaYDqSJCACq+oMkxpU81sWEMcb0kcgNZfcClwE34qqGvgBMTHJcyWM3lBljTB+JHBZ/UlWvAhpU9XbgJGB8csNKot7LR+2MwBhjILFE0Bn73y4iY4EQMCl5ISVZz1VDsSouY4zxukTaCJ4RkTzgJ8AyQIH7kxlUUlnVkDHG9LHbRBB7IM3LqtoIPCkifwPSVLXpYASXFHbVkDHG9LHbvaGqRoGfxQ13DeskAHFXDdkZgTHGQGJtBC+KyOdFRkiluj2Yxhhj+kikjeDfgEwgLCKduEtIVVVzkhpZslhfQ8YY00cidxYPz0dSDiZ21ZBa1ZAxxgAJJAIROW2g8f0fVDPIsnOBuwA/8DtVvbPf9G8DX4yLZRpQrKr1e1r3vtJoFMGqhowxpkciVUPfjnudBswByoEzd7eQiPiBe4BzgEpgiYg8rapreuZR1Z/gLktFRC4AvpnMJAAQjUbxg101ZIwxMYlUDV0QPywi44EfJ7DuOcAGVd0YW+4x4CJgzSDzXw48msB694tGw7h4rGrIGGMgsauG+qsEjk5gvnG4Lqvjlxs30IwikgHMBZ4cZPp1IrJURJbW1NTsZbh9aU8XE1Y1ZIwxQGJtBL/E3U0MLnHMBFYksO6BLjfVAcYBXAC8MVi1kKreB9wHMHv27MHWkZCeMwKrGjLGGCeRNoKlca/DwKOq+kYCy1XSt3O6UqBqkHnncxCqhcA1FgOIdTFhjDFAYongCaBT1V13KSJ+EclQ1fY9LLcEmCIik4BtuJ39Ff1nEpFc4FPAlXsV+T7qTQR2RmCMMUBibQQvA+lxw+nAS3taSFXDwA3AC8Ba4HFVXS0i14vI9XGzXgy8qKptiYe976xqyBhj+krkjCBNVVt7BlS1Nda4u0eq+izwbL9x9/YbfhB4MJH1HQgau7NYrWrIGGOAxM4I2kTkuJ4BETke6EheSMllVUPGGNNXImcENwN/FpGeht4S3KMrhyWN9T5qjcXGGOMkckPZEhGZChyJuyR0naqGkh5Zkqh1OmeMMX0k8vD6rwOZqrpKVd8HskTka8kPLTl6zgjshjJjjHES2Rv+a+wJZQCoagPwr0mLKNl67yNIpFbMGGNGvkQSgS/+oTSxzuRSkhdScsVuh2CkPGfHGGP2VyKHxS8Aj4vIvbguIq4HnktqVElkdxYbY0xfiSSCW4DrgAW4xuL3cFcODUu9bQTWWGyMMUACVUOxB9i/DWwEZgNn4e4UHp7sjMAYY/oY9IxARI7A9Q90OVAH/AlAVc84OKElR8/loz67asgYY4DdVw2tA14DLlDVDQAi8s2DElUS2Q1lxhjT1+4Oiz8PbAcWi8j9InIWAz9jYFjpOSPAEoExxgC7SQSqukhVLwOmAq8A3wRGi8hvROTTBym+A6+3jWDY5zRjjDkgEmksblPVhap6Pu7hMsuBW5MdWNL03EdgN5QZYwywl88sVtV6Vf2tqp6ZrICSrec+Ap9dPmqMMcC+Pbx+eOvpdM6uGjLGGMCDiUCjEcLqw2ddTBhjDODBRIBGiSJYW7ExxjjeSwTRCFHsjMAYY3p4LhGoRoniw/KAMcY4nksEH1cNWSYwxhjwYiKwqiFjjOnDc4lArbHYGGP68Fwi6KkasieUGWOM48FEECGCz84IjDEmxnuJIBpF8eGzTGCMMYAHE4G1ERhjTF+eSwRolAg+RsCjFYwx5oBIaiIQkbki8oGIbBCRAbuuFpHTRWS5iKwWkX8mMx4ANILaGYExxvRKWqf8IuIH7gHOASqBJSLytKquiZsnD/g1MFdVt4rIqGTF00ujRNVuKDPGmB7JPCOYA2xQ1Y2q2g08BlzUb54rgKdUdSuAqu5MYjxONBq7asgSgTHGQHITwTigIm64MjYu3hFAvoi8IiLlInLVQCsSketEZKmILK2pqdm/qKyvIWOM6SOZiWCgXa32Gw4AxwOfBT4DfFdEjthlIdX7VHW2qs4uLi7ev6hiicDOCIwxxknmg3srgfFxw6VA1QDz1KpqG9AmIq8CxwIfJiso0Yi7fNR710sZY8yAkrk7XAJMEZFJIpICzAee7jfPX4FTRSQgIhnACcDaJMYEqtb7qDHGxEnaGYGqhkXkBuAFwA88oKqrReT62PR7VXWtiDwPrASiwO9UdVWyYnKBuaqhoOUBY4wBkls1hKo+Czzbb9y9/YZ/AvwkmXH0EY1Yp3PGGBPHgzXl1lhsjDHxvJcIeq8aGupAjDHm0OC5RCBRe1SlMcbE81wicFVDYjeUGWNMjOcSgdgzi40xpg/PJQKIElVLBMYY08N7iaD3hrKhDsQYYw4NnksEEntmsd1HYIwxjucSARq1B9MYY0wczyUCUbt81Bhj4nkuEfQ8s9gSgTHGOJ5LBKJRFB/iuZIbY8zAPLg7tDMCY4yJ57lE8HEbwVBHYowxhwbPJQKssdgYY/rwXCIQe3i9Mcb04b1EgJ0RGGNMPO8lArUH0xhjTDzPJQLX15A9mMYYY3p4LhGIRoiqPbPYGGN6eC8RoKglAWOM6eW5RIBGUfEPdRTGGHPI8FwiEI0g1r+EMcb0Cgx1AAeboFhHQ8bsWSgUorKyks7OzqEOxeyFtLQ0SktLCQaDCS/jvURgVUPGJKSyspLs7GzKysrs4ophQlWpq6ujsrKSSZMmJbyc5w6NRaOIXTtqzB51dnZSWFhoSWAYEREKCwv3+izOe4kAOyMwJlGWBIafffnMkpoIRGSuiHwgIhtE5NYBpp8uIk0isjz2971kxgOxMwJrIzDGmF5J2yOKiB+4BzgXOAq4XESOGmDW11R1ZuzvB8mKpzcuotZYbMww0NjYyK9//et9Wva8886jsbFxt/N873vf46WXXtqn9e/Ogw8+yA033LDbeV555RXefPPNA/7e+yqZe8Q5wAZV3aiq3cBjwEVJfL+EiCr4rGrImEPd7hJBJBLZ7bLPPvsseXl5u53nBz/4AWefffa+hrdfDrVEkMyrhsYBFXHDlcAJA8x3koisAKqAf1fV1UmMCR92H4Exe+v2Z1azpqr5gK7zqLE53HbB9EGn33rrrXz00UfMnDmTc845h89+9rPcfvvtlJSUsHz5ctasWcPnPvc5Kioq6Ozs5KabbuK6664DoKysjKVLl9La2sq5557LKaecwptvvsm4ceP461//Snp6OldffTXnn38+8+bNo6ysjC9/+cs888wzhEIh/vznPzN16lRqamq44oorqKur4xOf+ATPP/885eXlFBUV9Yn1D3/4A//93/9NSUkJRxxxBKmpqQA888wz/OhHP6K7u5vCwkIWLlxIR0cH9957L36/n0ceeYRf/vKXNDY27jLf6NGjD+j23p1k7hEHarHQfsPLgImqeizwS+AvA65I5DoRWSoiS2tqavYzKEV8lgiMOdTdeeedTJ48meXLl/OTn/wEgHfffZc77riDNWvWAPDAAw9QXl7O0qVLufvuu6mrq9tlPevXr+frX/86q1evJi8vjyeffHLA9ysqKmLZsmUsWLCAn/70pwDcfvvtnHnmmSxbtoyLL76YrVu37rJcdXU1t912G2+88QZ///vfe2MDOOWUU3j77bd57733mD9/Pj/+8Y8pKyvj+uuv55vf/CbLly/n1FNPHXC+gymZZwSVwPi44VLcUX8vVW2Oe/2siPxaRIpUtbbffPcB9wHMnj27fzJJnCo+FOyqIWP2yu6O3A+mOXPm9Lk+/u6772bRokUAVFRUsH79egoLC/ssM2nSJGbOnAnA8ccfz+bNmwdc9yWXXNI7z1NPPQXA66+/3rv+uXPnkp+fv8ty77zzDqeffjrFxcUAXHbZZXz44YeAuxfjsssuo7q6mu7u7kGv7U90vmRJ5qHxEmCKiEwSkRRgPvB0/AwiMkZi1zqJyJxYPLum9ANFo+597YzAmGEpMzOz9/Urr7zCSy+9xFtvvcWKFSuYNWvWgNfP91TTAPj9fsLh8IDr7pkvfh7VxI47B7tk88Ybb+SGG27g/fff57e//e2g1/cnOl+yJG2PqKph4AbgBWAt8LiqrhaR60Xk+ths84BVsTaCu4H5muiW36egLBEYM1xkZ2fT0tIy6PSmpiby8/PJyMhg3bp1vP322wc8hlNOOYXHH38cgBdffJGGhoZd5jnhhBN45ZVXqKur621fiI9x3LhxADz00EO94/uXbbD5Dpak7hFV9VlVPUJVJ6vqHbFx96rqvbHXv1LV6ap6rKqeqKrJbUaPJQJ8nutZw5hhp7CwkJNPPpmjjz6ab3/727tMnzt3LuFwmBkzZvDd736XE0888YDHcNttt/Hiiy9y3HHH8dxzz1FSUkJ2dnafeUpKSvj+97/PSSedxNlnn81xxx3XO+373/8+X/jCFzj11FP7NDBfcMEFLFq0iJkzZ/Laa68NOt/BIsk8AE+G2bNn69KlS/dt4e52+L8lLCq8jotv/MmBDcyYEWbt2rVMmzZtqMMYUl1dXfj9fgKBAG+99RYLFixg+fLlQx3WHg302YlIuarOHmh+bx0aW9WQMWYvbN26lUsvvZRoNEpKSgr333//UIeUFJ5MBHZDmTEmEVOmTOG9994b6jCSzluHxuruRvTZ5aPGGNPLY4nAtYdY1ZAxxnzMW3vEWNWQz29nBMYY08NbiSDqqoasryFjjPmYt/aIPVcN+b3VRm6MV2RlZQFQVVXFvHnzBpzn9NNPZ0+XoP/iF7+gvb29dziRbq33RU+8g9mfrrj3hrcSQaQbAJ9dNWTMiDZ27FieeOKJfV6+fyJIpFvrZDhYicBTh8aRmg/xAy0Z4/c4rzEmznO3wvb3D+w6xxwD59456ORbbrmFiRMn8rWvfQ1wd+lmZ2fz1a9+lYsuuoiGhgZCoRA/+tGPuOiivo862bx5M+effz6rVq2io6ODa665hjVr1jBt2jQ6Ojp651uwYAFLliyho6ODefPmcfvtt3P33XdTVVXFGWecQVFREYsXL+7t1rqoqIif//znPPDAAwBce+213HzzzWzevHnQ7q7jbdq0iSuuuIJwOMzcuXN7x7e2tg5Ypv5dcd922217LPu+8FQiiFavxA805Bw51KEYY/Zg/vz53Hzzzb2J4PHHH+f5558nLS2NRYsWkZOTQ21tLSeeeCIXXnjhoB2//eY3vyEjI4OVK1eycuXKPl1A3HHHHRQUFBCJRDjrrLNYuXIl3/jGN/j5z3/O4sWLd+nuoby8nD/84Q+88847qConnHACn/rUp8jPz2f9+vU8+uij3H///Vx66aU8+eSTXHnllX2Wv+mmm1iwYAFXXXUV99xzT+/4wcp05513smrVqt67mcPh8F6VPVHeSQQf/YPg4h9QqUVoas5QR2PM8LKbI/dkmTVrFjt37qSqqoqamhry8/OZMGECoVCI73znO7z66qv4fD62bdvGjh07GDNmzIDrefXVV/nGN74BwIwZM5gxY0bvtMcff5z77ruPcDhMdXU1a9as6TO9v9dff52LL764txfUSy65hNdee40LL7wwoe6u33jjjd7nIXzpS1/illtuAVwvpwOVqb/B5hus7InyTiIIpBOa/Bl+uW4CR9p9BMYMC/PmzeOJJ55g+/btzJ8/H4CFCxdSU1NDeXk5wWCQsrKyPXbbPNAR86ZNm/jpT3/KkiVLyM/P5+qrr97jenbXN1v/7q7jq6D2FEuiZdqXsifCO3vEiSfR8LmH+VPkDIL+/TuNMsYcHPPnz+exxx7jiSee6L0KqKmpiVGjRhEMBlm8eDFbtmzZ7TpOO+00Fi5cCMCqVatYuXIlAM3NzWRmZpKbm8uOHTt47rnnepcZrAvs0047jb/85S+0t7fT1tbGokWLOPXUUxMuz8knn8xjjz0G0BvT7so0UHfVe1P2RHnmjOCfH9bwrceXA5AS8E7+M2Y4mz59Oi0tLYwbN46SkhIAvvjFL3LBBRcwe/ZsZs6cydSpU3e7jgULFnDNNdcwY8YMZs6cyZw5cwA49thjmTVrFtOnT+ewww7j5JNP7l3muuuu49xzz6WkpITFixf3jj/uuOO4+uqre9dx7bXXMmvWrEGfetbfXXfdxRVXXMFdd93F5z//+d7xg5Upvivuc889l1tuuWWvyp4oz3RDXb6lgd+/vpFR2WnceObhFGal7nkhYzzMuqEevqwb6kEcPzGf4yceP9RhGGPMIcfqSIwxxuMsERhjBjXcqo7Nvn1mlgiMMQNKS0ujrq7OksEwoqrU1dWRlpa2V8t5po3AGLN3SktLqayspKamZqhDMXshLS2N0tLSvVrGEoExZkDBYJBJkyYNdRjmILCqIWOM8ThLBMYY43GWCIwxxuOG3Z3FIlID7GsHG0VA7QEMZziwMnuDldkb9qfME1W1eKAJwy4R7A8RWTrYLdYjlZXZG6zM3pCsMlvVkDHGeJwlAmOM8TivJYL7hjqAIWBl9gYrszckpcyeaiMwxhizK6+dERhjjOnHEoExxnicZxKBiMwVkQ9EZIOI3DrU8RwoIvKAiOwUkVVx4wpE5O8isj72Pz9u2n/EtsEHIvKZoYl6/4jIeBFZLCJrRWS1iNwUGz9iyy0iaSLyroisiJX59tj4EVtmABHxi8h7IvK32PCILi+AiGwWkfdFZLmILI2NS265VXXE/wF+4CPgMCAFWAEcNdRxHaCynQYcB6yKG/dj4NbY61uB/4m9PipW9lRgUmyb+Ie6DPtQ5hLguNjrbODDWNlGbLkBAbJir4PAO8CJI7nMsXL8G/C/wN9iwyO6vLGybAaK+o1Larm9ckYwB9igqhtVtRt4DLhoiGM6IFT1VaC+3+iLgIdirx8CPhc3/jFV7VLVTcAG3LYZVlS1WlWXxV63AGuBcYzgcqvTGhsMxv6UEVxmESkFPgv8Lm70iC3vHiS13F5JBOOAirjhyti4kWq0qlaD22kCo2LjR9x2EJEyYBbuCHlElztWTbIc2An8XVVHepl/AfwfIBo3biSXt4cCL4pIuYhcFxuX1HJ75XkEMsA4L143O6K2g4hkAU8CN6tqs8hAxXOzDjBu2JVbVSPATBHJAxaJyNG7mX1Yl1lEzgd2qmq5iJyeyCIDjBs25e3nZFWtEpFRwN9FZN1u5j0g5fbKGUElMD5uuBSoGqJYDoYdIlICEPu/MzZ+xGwHEQniksBCVX0qNnrElxtAVRuBV4C5jNwynwxcKCKbcVW5Z4rII4zc8vZS1arY/53AIlxVT1LL7ZVEsASYIiKTRCQFmA88PcQxJdPTwJdjr78M/DVu/HwRSRWRScAU4N0hiG+/iDv0/z2wVlV/HjdpxJZbRIpjZwKISDpwNrCOEVpmVf0PVS1V1TLc7/UfqnolI7S8PUQkU0Sye14DnwZWkexyD3UL+UFsiT8Pd3XJR8B/DnU8B7BcjwLVQAh3dPAvQCHwMrA+9r8gbv7/jG2DD4Bzhzr+fSzzKbjT35XA8tjfeSO53MAM4L1YmVcB34uNH7FljivH6Xx81dCILi/uysYVsb/VPfuqZJfbupgwxhiP80rVkDHGmEFYIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjDiIROb2nJ01jDhWWCIwxxuMsERgzABG5Mtb//3IR+W2sw7dWEfmZiCwTkZdFpDg270wReVtEVorIop6+4kXkcBF5KfYMgWUiMjm2+iwReUJE1onIQtlNJ0nGHAyWCIzpR0SmAZfhOv+aCUSALwKZwDJVPQ74J3BbbJGHgVtUdQbwftz4hcA9qnos8EncHeDgeku9GdeX/GG4fnWMGTJe6X3UmL1xFnA8sCR2sJ6O6+QrCvwpNs8jwFMikgvkqeo/Y+MfAv4c6y9mnKouAlDVToDY+t5V1crY8HKgDHg96aUyZhCWCIzZlQAPqep/9Bkp8t1+8+2uf5bdVfd0xb2OYL9DM8SsasiYXb0MzIv1B9/zvNiJuN/LvNg8VwCvq2oT0CAip8bGfwn4p6o2A5Ui8rnYOlJFJONgFsKYRNmRiDH9qOoaEfkv3FOifLieXb8OtAHTRaQcaMK1I4DrFvje2I5+I3BNbPyXgN+KyA9i6/jCQSyGMQmz3keNSZCItKpq1lDHYcyBZlVDxhjjcXZGYIwxHmdnBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR73/wN6vSi8DGKDNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9663\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9861111111111112\n",
      "0.9692832764505119\n",
      "0.9776247848537005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.5]\n",
      " [ 0.0]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797160243407708\n",
      "0.9452054794520548\n",
      "0.9621513944223108\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
