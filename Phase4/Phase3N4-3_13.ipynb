{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  19.9  1166.1 ...  4.0  1.0  0.0]\n",
      " [ 0.0  3.5  189.2 ...  3.7  0.9  0.0]\n",
      " [ 0.0  10.3  673.7 ...  3.2  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  12.7  961.4 ...  4.0  1.0  0.0]\n",
      " [ 1.0  0.8  164.8 ...  8.6  0.9  0.0]\n",
      " [ 0.0  13.5  766.9 ...  3.7  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  0.1  0.3  0.1]\n",
      " [ 0.0  0.1  0.3  0.1]\n",
      " [ 0.0  0.2  0.4  0.2]\n",
      " ...\n",
      " [ 0.0  0.2  0.4  0.2]\n",
      " [ 1.0  0.0  0.1  0.0]\n",
      " [ 0.0  0.1  0.3  0.1]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 11, axis = 1)\n",
    "brainT = np.delete(brainT, 10, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 6, axis = 1)\n",
    "brainT = np.delete(brainT, 5, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 2, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 12ms/step - loss: 0.7080 - accuracy: 0.2942 - val_loss: 0.6864 - val_accuracy: 0.5452\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.5558 - val_loss: 0.6589 - val_accuracy: 0.5452\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6499 - accuracy: 0.6014 - val_loss: 0.6436 - val_accuracy: 0.6206\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6583 - val_loss: 0.6274 - val_accuracy: 0.7996\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.8330 - val_loss: 0.6087 - val_accuracy: 0.8794\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.8694 - val_loss: 0.5892 - val_accuracy: 0.9078\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.9150 - val_loss: 0.5688 - val_accuracy: 0.9229\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5550 - accuracy: 0.9294 - val_loss: 0.5475 - val_accuracy: 0.9326\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5324 - accuracy: 0.9427 - val_loss: 0.5241 - val_accuracy: 0.9433\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5087 - accuracy: 0.9522 - val_loss: 0.5009 - val_accuracy: 0.9450\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.9552 - val_loss: 0.4772 - val_accuracy: 0.9521\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4612 - accuracy: 0.9609 - val_loss: 0.4531 - val_accuracy: 0.9592\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.9639 - val_loss: 0.4293 - val_accuracy: 0.9610\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.9670 - val_loss: 0.4057 - val_accuracy: 0.9610\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.9666 - val_loss: 0.3828 - val_accuracy: 0.9637\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.9674 - val_loss: 0.3602 - val_accuracy: 0.9690\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.9681 - val_loss: 0.3389 - val_accuracy: 0.9699\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.9692 - val_loss: 0.3186 - val_accuracy: 0.9699\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.9708 - val_loss: 0.2993 - val_accuracy: 0.9699\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.9711 - val_loss: 0.2816 - val_accuracy: 0.9699\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.9708 - val_loss: 0.2646 - val_accuracy: 0.9690\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.9715 - val_loss: 0.2488 - val_accuracy: 0.9699\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2392 - accuracy: 0.9715 - val_loss: 0.2341 - val_accuracy: 0.9716\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9715 - val_loss: 0.2201 - val_accuracy: 0.9716\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9711 - val_loss: 0.2078 - val_accuracy: 0.9716\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9711 - val_loss: 0.1966 - val_accuracy: 0.9716\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9715 - val_loss: 0.1866 - val_accuracy: 0.9716\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1821 - accuracy: 0.9715 - val_loss: 0.1773 - val_accuracy: 0.9716\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.9719 - val_loss: 0.1690 - val_accuracy: 0.9716\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9711 - val_loss: 0.1618 - val_accuracy: 0.9716\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9715 - val_loss: 0.1548 - val_accuracy: 0.9716\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9719 - val_loss: 0.1488 - val_accuracy: 0.9743\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9727 - val_loss: 0.1433 - val_accuracy: 0.9725\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9730 - val_loss: 0.1385 - val_accuracy: 0.9716\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9719 - val_loss: 0.1346 - val_accuracy: 0.9743\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9727 - val_loss: 0.1308 - val_accuracy: 0.9725\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9723 - val_loss: 0.1275 - val_accuracy: 0.9725\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9727 - val_loss: 0.1245 - val_accuracy: 0.9743\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9723 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9727 - val_loss: 0.1195 - val_accuracy: 0.9743\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9727 - val_loss: 0.1172 - val_accuracy: 0.9725\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9727 - val_loss: 0.1152 - val_accuracy: 0.9734\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9727 - val_loss: 0.1133 - val_accuracy: 0.9752\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9727 - val_loss: 0.1117 - val_accuracy: 0.9761\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9727 - val_loss: 0.1102 - val_accuracy: 0.9752\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9727 - val_loss: 0.1088 - val_accuracy: 0.9761\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9727 - val_loss: 0.1076 - val_accuracy: 0.9761\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9727 - val_loss: 0.1065 - val_accuracy: 0.9761\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9727 - val_loss: 0.1053 - val_accuracy: 0.9761\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9727 - val_loss: 0.1043 - val_accuracy: 0.9761\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9727 - val_loss: 0.1034 - val_accuracy: 0.9743\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9727 - val_loss: 0.1026 - val_accuracy: 0.9761\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9723 - val_loss: 0.1017 - val_accuracy: 0.9743\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9730 - val_loss: 0.1010 - val_accuracy: 0.9752\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9727 - val_loss: 0.1004 - val_accuracy: 0.9743\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1083 - accuracy: 0.9727 - val_loss: 0.0998 - val_accuracy: 0.9761\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9723 - val_loss: 0.0992 - val_accuracy: 0.9761\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9727 - val_loss: 0.0987 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9727 - val_loss: 0.0983 - val_accuracy: 0.9761\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9734 - val_loss: 0.0978 - val_accuracy: 0.9761\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9730 - val_loss: 0.0973 - val_accuracy: 0.9761\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9761\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9761\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9734 - val_loss: 0.0961 - val_accuracy: 0.9761\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9727 - val_loss: 0.0958 - val_accuracy: 0.9761\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9730 - val_loss: 0.0955 - val_accuracy: 0.9761\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9730 - val_loss: 0.0952 - val_accuracy: 0.9761\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9730 - val_loss: 0.0949 - val_accuracy: 0.9761\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.9730 - val_loss: 0.0947 - val_accuracy: 0.9761\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 0.0944 - val_accuracy: 0.9761\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9723 - val_loss: 0.0942 - val_accuracy: 0.9761\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9727 - val_loss: 0.0939 - val_accuracy: 0.9761\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9730 - val_loss: 0.0936 - val_accuracy: 0.9761\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9730 - val_loss: 0.0934 - val_accuracy: 0.9761\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9734 - val_loss: 0.0932 - val_accuracy: 0.9761\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.0930 - val_accuracy: 0.9761\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9730 - val_loss: 0.0928 - val_accuracy: 0.9761\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9727 - val_loss: 0.0926 - val_accuracy: 0.9761\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.0924 - val_accuracy: 0.9761\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9730 - val_loss: 0.0922 - val_accuracy: 0.9761\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9730 - val_loss: 0.0920 - val_accuracy: 0.9761\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9734 - val_loss: 0.0919 - val_accuracy: 0.9761\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9734 - val_loss: 0.0917 - val_accuracy: 0.9761\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9730 - val_loss: 0.0916 - val_accuracy: 0.9761\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9730 - val_loss: 0.0915 - val_accuracy: 0.9761\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9727 - val_loss: 0.0914 - val_accuracy: 0.9761\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9727 - val_loss: 0.0912 - val_accuracy: 0.9761\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9730 - val_loss: 0.0911 - val_accuracy: 0.9761\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9727 - val_loss: 0.0910 - val_accuracy: 0.9761\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9730 - val_loss: 0.0909 - val_accuracy: 0.9761\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9730 - val_loss: 0.0907 - val_accuracy: 0.9761\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.0906 - val_accuracy: 0.9761\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9727 - val_loss: 0.0905 - val_accuracy: 0.9761\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9730 - val_loss: 0.0904 - val_accuracy: 0.9761\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9730 - val_loss: 0.0902 - val_accuracy: 0.9761\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9727 - val_loss: 0.0901 - val_accuracy: 0.9761\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9727 - val_loss: 0.0900 - val_accuracy: 0.9761\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9730 - val_loss: 0.0900 - val_accuracy: 0.9761\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9738 - val_loss: 0.0898 - val_accuracy: 0.9761\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9727 - val_loss: 0.0897 - val_accuracy: 0.9761\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9727 - val_loss: 0.0896 - val_accuracy: 0.9761\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9734 - val_loss: 0.0896 - val_accuracy: 0.9761\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9730 - val_loss: 0.0894 - val_accuracy: 0.9761\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9727 - val_loss: 0.0893 - val_accuracy: 0.9761\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9727 - val_loss: 0.0893 - val_accuracy: 0.9761\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9730 - val_loss: 0.0892 - val_accuracy: 0.9761\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9727 - val_loss: 0.0891 - val_accuracy: 0.9761\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9727 - val_loss: 0.0890 - val_accuracy: 0.9761\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9730 - val_loss: 0.0889 - val_accuracy: 0.9761\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9730 - val_loss: 0.0889 - val_accuracy: 0.9761\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9730 - val_loss: 0.0888 - val_accuracy: 0.9761\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9730 - val_loss: 0.0887 - val_accuracy: 0.9761\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9730 - val_loss: 0.0887 - val_accuracy: 0.9761\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9727 - val_loss: 0.0886 - val_accuracy: 0.9761\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9723 - val_loss: 0.0885 - val_accuracy: 0.9761\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9730 - val_loss: 0.0885 - val_accuracy: 0.9761\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9727 - val_loss: 0.0884 - val_accuracy: 0.9761\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9727 - val_loss: 0.0884 - val_accuracy: 0.9761\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9734 - val_loss: 0.0882 - val_accuracy: 0.9761\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0983 - accuracy: 0.9730 - val_loss: 0.0882 - val_accuracy: 0.9761\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.0881 - val_accuracy: 0.9761\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.0881 - val_accuracy: 0.9761\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9727 - val_loss: 0.0880 - val_accuracy: 0.9761\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9730 - val_loss: 0.0880 - val_accuracy: 0.9761\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9734 - val_loss: 0.0879 - val_accuracy: 0.9761\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9730 - val_loss: 0.0879 - val_accuracy: 0.9761\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9727 - val_loss: 0.0878 - val_accuracy: 0.9761\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9727 - val_loss: 0.0878 - val_accuracy: 0.9761\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9730 - val_loss: 0.0877 - val_accuracy: 0.9761\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9730 - val_loss: 0.0877 - val_accuracy: 0.9761\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9727 - val_loss: 0.0877 - val_accuracy: 0.9761\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9734 - val_loss: 0.0877 - val_accuracy: 0.9761\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9727 - val_loss: 0.0876 - val_accuracy: 0.9761\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9727 - val_loss: 0.0876 - val_accuracy: 0.9761\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9727 - val_loss: 0.0876 - val_accuracy: 0.9761\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9727 - val_loss: 0.0875 - val_accuracy: 0.9761\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9723 - val_loss: 0.0875 - val_accuracy: 0.9761\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9727 - val_loss: 0.0874 - val_accuracy: 0.9761\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9730 - val_loss: 0.0874 - val_accuracy: 0.9761\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9727 - val_loss: 0.0874 - val_accuracy: 0.9761\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9727 - val_loss: 0.0874 - val_accuracy: 0.9761\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9727 - val_loss: 0.0873 - val_accuracy: 0.9761\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9727 - val_loss: 0.0873 - val_accuracy: 0.9761\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.0873 - val_accuracy: 0.9761\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.0873 - val_accuracy: 0.9761\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9727 - val_loss: 0.0873 - val_accuracy: 0.9761\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.0872 - val_accuracy: 0.9761\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9730 - val_loss: 0.0872 - val_accuracy: 0.9761\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9727 - val_loss: 0.0872 - val_accuracy: 0.9761\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9730 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9727 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9727 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9730 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9730 - val_loss: 0.0870 - val_accuracy: 0.9761\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9727 - val_loss: 0.0870 - val_accuracy: 0.9761\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9727 - val_loss: 0.0870 - val_accuracy: 0.9761\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9730 - val_loss: 0.0870 - val_accuracy: 0.9761\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9727 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9727 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9727 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9727 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9727 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9727 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9734 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9730 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9730 - val_loss: 0.0867 - val_accuracy: 0.9761\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9734 - val_loss: 0.0866 - val_accuracy: 0.9761\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: 0.0866 - val_accuracy: 0.9761\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.0866 - val_accuracy: 0.9761\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9734 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9727 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9734 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9730 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9727 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9727 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9738 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9723 - val_loss: 0.0864 - val_accuracy: 0.9761\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9761\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9761\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9761\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9727 - val_loss: 0.0863 - val_accuracy: 0.9761\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9734 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0966 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9734 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9734 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9723 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9738 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9761\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9738 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9723 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9723 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9723 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9723 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9738 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9723 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9723 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9723 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9738 - val_loss: 0.0858 - val_accuracy: 0.9761\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlqUlEQVR4nO3deZxU5Z3v8c+vqnoDmkVoFMHYJCFxuwiImIzLqDEJuAR1MKLZNOMwEjUmMzdXk9xEzZgbY5YxRhOiM6i5YYIrUXMxGh3cNxpEFNxQCbSgtMjW0FtV/e4fdbqtrq7uLpo+XXSf7/v16lfXOec5p35PQZ9fPc9zznPM3RERkeiKFTsAEREpLiUCEZGIUyIQEYk4JQIRkYhTIhARiTglAhGRiEuEdWAzmw+cCmxy98PybDfgV8DJwC7gPHdf3t1xR40a5dXV1b0crYjIwLZs2bL33b0q37bQEgFwK3AD8PtOts8AJgQ/RwG/DX53qbq6mpqaml4KUUQkGszsb51tC61ryN0fBz7ooshM4Pee8Sww3MzGhBWPiIjkV8wxgrHA+qzl2mBdB2Y2x8xqzKymrq6uT4ITEYmKYiYCy7Mu73wX7n6Tu09196lVVXm7uEREpIeKmQhqgQOylscBG4oUi4hIZBUzEdwHfNUyPgVsc/eNRYxHRCSSwrx89I/A8cAoM6sFrgBKANx9HrCYzKWja8hcPnp+WLGIiEjnQksE7n5ON9sduCis9xcRkcKEeR9BNO14D1b/CVoaoHlnZl3pYEiUw7ipsHUdbHqlqCGKSP+UPuBTxCZ8ptePq0TQieZkmsZkig3r3sK2ryeVhmQ6TSrlDN30PPu9/l/sYBAlpEjFy6mqf5XGxFBi3kJZale3x3cs/yVSAaP9JVS5yz2VfZzWy7Zyj9vVe+W71GtPFFKnzt4zrEcq9bSO2Z9rvs90T465J3bnvfO9X2f/Twairv4m8q3fk/fI1tX/nWwvVZ/P4UoEIUun2bnkF7z70n+z/oMG6r2Mk2LLKLeWvMUHB7+3+yD+b+okPuPLed9HcXXqq2zxStaSuT/uJFvKOKsjTpomSrk9fSJJS1A9cjCptFNWEmf9B7sYUpZg+KAStu5q4d3tjYwaUsb+w8vZ3tDCe9ubGD6ohES8sD/rmBn1jUmak2n2G1bOu9sbKUvE2NmUYnBZnHjM2NWUor45SUVJHAP2G1ZOfVOSHY1JqirLqCiJ887WBuIxI5124jFjR2OyFz7oD1WWJ0imnXTaGTmkjFTaSaWdZDpNOviL2N6Q//MfUp5gUEmcHU1JmlrSNKfS7De0nETcaH3wnrvjgDs4Hvwm2J69nFUueE2+bVn7ECwDtKScj1YNJmbGu9saGTWklPfrmxlcFqckHuPdbY09+nxGV5bR0JIi7TCoNE5zMk0y7ZTEYzQlUxiw79ByzDL/5pt2NDFiUAkOlCfibNrRyNZd+T+/fMoSMcyMyvIEqbTTnErT1JKmoSXFPoNLGVwW71E9CjG4NEFTMk0yne7V4za1pNm6q4VP7lfJug92UZqIMWZYOTubkjSnPnwvd3h3WyOJuJGIxSgvidGSckZXlrX9+w2tKGHfoWWs2VSPmbGjsYWhFSWk0s5H9hlESTzGpu2NDK0oob4pSTrtpNxJOx++TmeWU8FySyrNPoNKKU3EqG9MMrSihMFlcTZsbaS8JEYq7ew7tJyK0jhfnzyew3v108lQIgg8+tomliz6T65qvIZEejQfrRjG/s2r+KDqKF7/5JeJJcqIxYxEDCxeSuwj0xjbso7tww+ioiTO6bE4FYkYYxNx7uxw9JPbLV3ZTSzptNOUTFNRGt4fXavGlhSJmJGI9//5B1NBsiqGXa0J1Yrz/mFraE5RlogRK9Lnu6cK/b/R2JKiJB4rqKx7JlGWJfbs77QpmSIRK+w9w6JEALxf38SPbn+S65J3sK1sNC3/uJSP7zccgNHBT35VlIcQTyxmfZIEAMpL+uZ9+kIx/5AGlQ7sP6W++v8YlkL/b+zO34OZ7XESAHrlGHtqYP/vLdC9d/2ev6QuozSWghk3MCxIAiIiURD5RLCrOcnkt29mR+loRp59I3y89wdiRET2Zv2/Y3gP3fyXGg7ndZoO/aKSgIhEUqQTQTrtvLf8z8TN2f/I04sdjohIUUQ6Ebz1fj3HpJ6joWwUjJlU7HBERIoi0omg7tk/cnL8eRoPOhNikf4oRCTCIn32G/S3Jbzvwxh22v8pdigiIkUT6UQwavsq3iyZQCxRUuxQRESKJrqJoGkHY1rW8f7Qw4odiYhIUUU2EbTUriCG07RvGDN3iIj0H5FNBNvefA6AsgOnFjkSEZHiimwiaFn/ArU+inFjP1LsUEREiiqyiSC+5U3WpMcyvmpw94VFRAawaCYCdyp3rWdTYgxDy3XFkIhEWzQTwa4PqEjXs7XigGJHIiJSdKEmAjObbmavmdkaM7s8z/YRZrbIzFaa2fNm1jfXcm55O/OrbGyfvJ2IyN4stERgZnHgRmAGcAhwjpkdklPse8AKd58IfBX4VVjxtLN9AwA7y/ftk7cTEdmbhdkimAascfe33L0ZWAjMzClzCPAIgLu/ClSbWfhn54YPAEiV7RP6W4mI7O3CTARjgfVZy7XBumwvAmcCmNk04EBgXO6BzGyOmdWYWU1dXd2eR7Yrkwi8YsSeH0tEpJ8LMxHke0io5yxfA4wwsxXAJcALQLLDTu43uftUd59aVVW155E1fEADpZRWDNnzY4mI9HNhPqqyFsi+LGccsCG7gLtvB84HMDMD3g5+wrVrC1t9SL9/ILeISG8Is0WwFJhgZuPNrBSYDdyXXcDMhgfbAC4AHg+SQ6jSuzazxSsZrEQgIhJei8Ddk2Z2MfAgEAfmu/sqM7sw2D4POBj4vZmlgNXAP4YVT7b0zs1s8SEMKg2zQSQi0j+EeiZ098XA4px187JePwNMCDOGvHHt2sIW9mFwmVoEIiKRvLPYmraz3QepRSAiQkQTAakmmilhkMYIRESimQgs1RwkArUIREQinAgSGiMQESGKiSCdJuZJmr2ESk1BLSISwUSQagaghQSV5eoaEhGJYCJoAqBZiUBEBIhiIkhmWgSpWCllCY0RiIhELxEELYJYoqzIgYiI7B0imAgyLYJ4SWk3BUVEoiF6iSDoGkqUVhQ5EBGRvUP0EkHQNZQoVdeQiAhEMREELYKSsvIiByIisneIXiJItXYNKRGIiEAkE0HrVUMaLBYRgSgmgqBrKB3TGIGICEQxEQQtAo+rRSAiApFMBC0AeFwTzomIQBQTQTJoEahrSEQEiGIiUNeQiEg7oSYCM5tuZq+Z2RozuzzP9mFmdr+ZvWhmq8zs/DDjAT7sGtJVQyIiQIiJwMziwI3ADOAQ4BwzOySn2EXAanc/HDge+IWZhXuGDrqGiCkRiIhAuC2CacAad3/L3ZuBhcDMnDIOVJqZAUOAD4BkiDHhrWMEcY0RiIhAuIlgLLA+a7k2WJftBuBgYAPwEnCpu6dzD2Rmc8ysxsxq6urq9igoD+4stpgeSiMiAuEmAsuzznOWPw+sAPYHJgE3mNnQDju53+TuU919alVV1R4F5akUSY8Rj+cLT0QkesJMBLXAAVnL48h88892PnCPZ6wB3gYOCjEm3FOkiBGLKRGIiEC4iWApMMHMxgcDwLOB+3LKrAM+A2Bm+wKfBN4KMSbSqRRpYiSUCEREAAito9zdk2Z2MfAgEAfmu/sqM7sw2D4P+DfgVjN7iUxX0mXu/n5YMQF4OplpEZgSgYgIhJgIANx9MbA4Z928rNcbgM+FGUOHmNKZFkFcLQIRESCCdxZ7KtMiUCIQEcmIXiJIp9Q1JCKSJXKJAHUNiYi0E7lE0NoiiKtFICICRDgR6D4CEZGMyCUCPEXajXj0ai4iklfkTocaLBYRaS9yiaB1sDgRi17VRUTyidzZsG2wOHI1FxHJL3qnQ3UNiYi0E71E4LqPQEQkW+QSgS4fFRFpL3KJoO3OYnUNiYgAUUwEntKkcyIiWaKXCDRYLCLSTvQSgac1WCwikiWCiSBFynUfgYhIq+idDttuKIte1UVE8one2dB11ZCISLboJYJ0OriPoNiBiIjsHUI9HZrZdDN7zczWmNnlebZ/x8xWBD8vm1nKzPYJNSbdWSwi0k5oicDM4sCNwAzgEOAcMzsku4y7/8zdJ7n7JOC7wGPu/kFYMWXeVE8oExHJ1m0iMLNTzawnCWMasMbd33L3ZmAhMLOL8ucAf+zB++wW8xQpTFNMiIgECjnBzwbeMLNrzezg3Tj2WGB91nJtsK4DMxsETAfu7mT7HDOrMbOaurq63Qghj3Rag8UiIlm6TQTu/mVgMvAmcIuZPROcmCu72TXfmdY7KXsa8FRn3ULufpO7T3X3qVVVVd2F3HVQmmJCRKSdgrp83H07mW/rC4ExwBnAcjO7pIvdaoEDspbHARs6KTubPugWAsDTmn1URCRLIWMEp5nZIuC/gRJgmrvPAA4H/mcXuy4FJpjZeDMrJXOyvy/P8YcBfw/c24P4d5t5irTHSCgRiIgAkCigzFnAv7v749kr3X2XmX29s53cPWlmFwMPAnFgvruvMrMLg+3zgqJnAA+5+84e1WA3WWuLQGMEIiJAYYngCmBj64KZVQD7uvtad3+kqx3dfTGwOGfdvJzlW4FbC4x3j+k+AhGR9goZI7gTSGctp4J1/VPQItBVQyIiGYUkgkRwHwAAwevS8EIKV+tVQ5piQkQko5DTYZ2ZfaF1wcxmAu+HF1K4TM8jEBFpp5AxgguBBWZ2A5l7A9YDXw01qhDFXE8oExHJ1m0icPc3gU+Z2RDA3H1H+GGFx0jrhjIRkSyFtAgws1OAQ4FyC75Ju/uPQowrNKbnEYiItFPIDWXzgLOBS8h0DZ0FHBhyXKFpHSPQncUiIhmFDBb/nbt/Fdji7lcBn6b91BH9hzsx0sTi8WJHIiKy1ygkETQGv3eZ2f5ACzA+vJBC5JnbISxWUI+YiEgkFHJGvN/MhgM/A5aTmUH05jCDCk06BUAsrkQgItKqyzNi8ECaR9x9K3C3mf0ZKHf3bX0RXK/zTCKwmLqGRERaddk15O5p4BdZy039NglAW4sgrhaBiEibQsYIHjKzfzAbANdburqGRERyFXJG/BdgMJA0s0Yyl5C6uw8NNbIwtLUI1DUkItKqkDuLu3skZf/RmggSahGIiLTq9oxoZsflW5/7oJp+QV1DIiIdFHJG/E7W63JgGrAMODGUiMIUtAgSSgQiIm0K6Ro6LXvZzA4Arg0tojClkwDEExojEBFp1ZPHs9QCh/V2IH0ilXm+TqykvMiBiIjsPQoZI/g1mbuJIZM4JgEvhhhTaDzZiKFEICKSrZDO8pqs10ngj+7+VCEHN7PpwK+AOPAf7n5NnjLHA9cBJcD77v73hRy7J1qaGykFYiVlYb2FiEi/U0giuAtodM9ccmNmcTMb5O67utrJzOLAjcBnyXQnLTWz+9x9dVaZ4cBvgOnuvs7MRvewHgVpbsokgrhaBCIibQoZI3gEqMhargAeLmC/acAad38reOD9QmBmTplzgXvcfR2Au28q4Lg91tLUAECiVC0CEZFWhSSCcnevb10IXg8qYL+xZJ5v3Ko2WJftE8AIM3vUzJaZWd5nIZvZHDOrMbOaurq6At46v+bGzIzaJaUV3ZQUEYmOQhLBTjOb0rpgZkcADQXsl29uIs9ZTgBHAKcAnwd+YGaf6LCT+03uPtXdp1ZVVRXw1vk1BS2C0nIlAhGRVoWMEXwLuNPMNgTLY8g8urI7tbR/ktk4YEOeMu+7+04yCedx4HDg9QKOv9tau4bKypQIRERaFXJD2VIzOwj4JJlv+a+6e0sBx14KTDCz8cA7wGwyYwLZ7gVuMLMEUAocBfz7bsS/W9oSQUUhPVsiItFQyMPrLwIGu/vL7v4SMMTMvtHdfu6eBC4GHgReAe5w91VmdqGZXRiUeQX4C7ASeJ7MJaYv97w6XWtpzowRlKtrSESkTSFdQ//k7je2Lrj7FjP7JzKXfXbJ3RcDi3PWzctZ/hmZx2CGLhkkggolAhGRNoUMFseyH0oT3B9QGl5I4Uk1NwFQXqFEICLSqpAWwYPAHWY2j8xVPxcCD4QaVUhSLZlEMHjQ4CJHIiKy9ygkEVwGzAHmkhksfoHMlUP9TjrZSNqNstJ+2aAREQlFt11DwQPsnwXeAqYCnyEz+NvveEsjzSSwWE8mXRURGZg6bREEN3bNBs4BNgO3A7j7CX0TWu/zZBPNVopmGhIR+VBXXUOvAk8Ap7n7GgAz+3afRBUSTzaTtJJihyEislfpqo/kH4B3gSVmdrOZfYb800b0G5ZsUiIQEcnRaSJw90XufjZwEPAo8G1gXzP7rZl9ro/i61UxV4tARCRXIYPFO919gbufSma+oBXA5WEHFoZEuoUW0xVDIiLZduvyGXf/wN1/5+4nhhVQaDa8wJGNT5FELQIRkWzRuY5yx7tsiw1jVdnEYkciIrJXKeSGsoHhkzO4YPRCErEYXyh2LCIie5HotAiAtEM81q8vfBIR6XURSwSOKQ+IiLQTsUQAMWUCEZF2IpUI3B31DImItBepRJB2V4tARCRHtBJBGkyJQESknWglAnUNiYh0EKlE4BosFhHpINREYGbTzew1M1tjZh3mJzKz481sm5mtCH5+GGY8aXf0TBoRkfZCu7M4eMj9jcBngVpgqZnd5+6rc4o+EUxoF7rMfQRqEYiIZAvz+/E0YI27v+XuzcBCYGaI79ctdQ2JiHQUZiIYC6zPWq4N1uX6tJm9aGYPmNmh+Q5kZnPMrMbMaurq6nockAaLRUQ6CjMR5Dvles7ycuBAdz8c+DXwp3wHcveb3H2qu0+tqqrqcUC6s1hEpKMwE0EtcEDW8jhgQ3YBd9/u7vXB68VAiZmNCisgzTUkItJRmIlgKTDBzMabWSkwG7gvu4CZ7WfB6K2ZTQvi2RxWQBojEBHpKLSrhtw9aWYXAw8CcWC+u68yswuD7fOAWcBcM0sCDcBsd8/tPuo1GiMQEeko1AfTBN09i3PWzct6fQNwQ5gxZNNcQyIiHUXq9qqU5hoSEekgUolA01CLiHQUqUSQdtejKkVEckQsEeiqIRGRXBFLBLqPQEQkV6QSge4jEBHpKFKJQPcRiIh0FMFEoEwgIpItYolA9xGIiOSKVCLQfQQiIh1FKhHo8lERkY4ilgjUIhARyRWZRODuuMYIREQ6iFAiyPxW15CISHuRSQTpIBOoa0hEpL0IJYLM75gygYhIOxFKBJlMoJ4hEZH2IpMINEYgIpJfZBKBxghERPKLYCJQJhARyRZqIjCz6Wb2mpmtMbPLuyh3pJmlzGxWWLGk023vFdZbiIj0S6ElAjOLAzcCM4BDgHPM7JBOyv0UeDCsWEBdQyIinQmzRTANWOPub7l7M7AQmJmn3CXA3cCmEGNpSwR6ZrGISHthJoKxwPqs5dpgXRszGwucAczr6kBmNsfMasyspq6urkfBtN5HoK4hEZH2wkwE+c64nrN8HXCZu6e6OpC73+TuU919alVVVY+CcXUNiYjklQjx2LXAAVnL44ANOWWmAguDb+mjgJPNLOnuf+rtYNK6j0BEJK8wE8FSYIKZjQfeAWYD52YXcPfxra/N7Fbgz2EkAdBgscjuamlpoba2lsbGxmKHIruhvLyccePGUVJSUvA+oSUCd0+a2cVkrgaKA/PdfZWZXRhs73JcoLd9OMWEMoFIIWpra6msrKS6ulp/N/2Eu7N582Zqa2sZP3589zsEwmwR4O6LgcU56/ImAHc/L9xYMr/VNSRSmMbGRiWBfsbMGDlyJLt7UU0E7ywuciAi/YiSQP/Tk3+zCCWCzG+1CERE2otQItA01CL9ydatW/nNb37To31PPvlktm7d2mWZH/7whzz88MM9On5Xbr31Vi6++OIuyzz66KM8/fTTvf7ePRWZROCadE6kX+kqEaRSXd56xOLFixk+fHiXZX70ox9x0kkn9TS8PbK3JYJQB4v3JuoaEum5q+5fxeoN23v1mIfsP5QrTju00+2XX345b775JpMmTeKzn/0sp5xyCldddRVjxoxhxYoVrF69mtNPP53169fT2NjIpZdeypw5cwCorq6mpqaG+vp6ZsyYwTHHHMPTTz/N2LFjuffee6moqOC8887j1FNPZdasWVRXV/O1r32N+++/n5aWFu68804OOugg6urqOPfcc9m8eTNHHnkkf/nLX1i2bBmjRo1qF+stt9zCT37yE8aMGcMnPvEJysrKALj//vu5+uqraW5uZuTIkSxYsICGhgbmzZtHPB7nD3/4A7/+9a/ZunVrh3L77rtvr37eXYlMi0CDxSL9yzXXXMPHPvYxVqxYwc9+9jMAnn/+eX784x+zevVqAObPn8+yZcuoqanh+uuvZ/PmzR2O88Ybb3DRRRexatUqhg8fzt133533/UaNGsXy5cuZO3cuP//5zwG46qqrOPHEE1m+fDlnnHEG69at67Dfxo0bueKKK3jqqaf461//2hYbwDHHHMOzzz7LCy+8wOzZs7n22muprq7mwgsv5Nvf/jYrVqzg2GOPzVuuL0WnRaBpqEV6rKtv7n1p2rRp7a6Pv/7661m0aBEA69ev54033mDkyJHt9hk/fjyTJk0C4IgjjmDt2rV5j33mmWe2lbnnnnsAePLJJ9uOP336dEaMGNFhv+eee47jjz+e1ulvzj77bF5//XUgcy/G2WefzcaNG2lubu702v5Cy4VFLQIR6TcGDx7c9vrRRx/l4Ycf5plnnuHFF19k8uTJee+Cbu2mAYjH4ySTybzHbi2XXaZ1bLE7nX3BvOSSS7j44ot56aWX+N3vftfpXdqFlgtLZBKBbigT6V8qKyvZsWNHp9u3bdvGiBEjGDRoEK+++irPPvtsr8dwzDHHcMcddwDw0EMPsWXLlg5ljjrqKB599FE2b97cNr6QHePYsZlJl2+77ba29bl166xcX4lMImhrEUSmxiL928iRIzn66KM57LDD+M53vtNh+/Tp00kmk0ycOJEf/OAHfOpTn+r1GK644goeeughpkyZwgMPPMCYMWOorKxsV2bMmDFceeWVfPrTn+akk05iypQpbduuvPJKzjrrLI499th2A8ynnXYaixYtYtKkSTzxxBOdlusrVmjTZ28xdepUr6mp2e39Xli3hTN+8zS3nH8kJ3xydAiRiQwsr7zyCgcffHCxwyiqpqYm4vE4iUSCZ555hrlz57JixYpih9WtfP92ZrbM3afmKx+dwWLdRyAiu2ndunV88YtfJJ1OU1pays0331zskEIRoUSQ+a3BYhEp1IQJE3jhhReKHUboItNjng4yQVwtAhGRdqKTCPTMYhGRvCKTCPTMYhGR/CKTCNrGCJQJRETaiVAiUItAZKAbMmQIABs2bGDWrFl5yxx//PF0dwn6ddddx65du9qWC5nWuida4+3MnkzFvTsilwg0RiAy8O2///7cddddPd4/NxEUMq11GPoqEUTm8lFNMSGyBx64HN59qXePud//gBnXdLr5sssu48ADD+Qb3/gGkLlLt7Kykn/+539m5syZbNmyhZaWFq6++mpmzpzZbt+1a9dy6qmn8vLLL9PQ0MD555/P6tWrOfjgg2loaGgrN3fuXJYuXUpDQwOzZs3iqquu4vrrr2fDhg2ccMIJjBo1iiVLlrRNaz1q1Ch++ctfMn/+fAAuuOACvvWtb7F27dpOp7vO9vbbb3PuueeSTCaZPn162/r6+vq8dcqdivuKK67otu49EWqLwMymm9lrZrbGzC7Ps32mma00sxVmVmNmx4QVi7qGRPqX2bNnc/vtt7ct33HHHZx11lmUl5ezaNEili9fzpIlS/jXf/3XLieH++1vf8ugQYNYuXIl3//+91m2bFnbth//+MfU1NSwcuVKHnvsMVauXMk3v/lN9t9/f5YsWcKSJUvaHWvZsmXccsstPPfcczz77LPcfPPNbfcZFDLd9aWXXtqWfPbbb7+29Z3VKXcq7t2te6FCaxGYWRy4EfgsUAssNbP73H11VrFHgPvc3c1sInAHcFAY8ejBNCJ7oItv7mGZPHkymzZtYsOGDdTV1TFixAg+8pGP0NLSwve+9z0ef/xxYrEY77zzDu+99167E2u2xx9/nG9+85sATJw4kYkTJ7Ztu+OOO7jppptIJpNs3LiR1atXt9ue68knn+SMM85omwX1zDPP5IknnuALX/hCQdNdP/XUU20J4itf+QqXXXYZkLmqMV+dcnVWrrO6FyrMrqFpwBp3fwvAzBYCM4G2RODu9VnlBwOhTXykZxaL9D+zZs3irrvu4t1332X27NkALFiwgLq6OpYtW0ZJSQnV1dXdTtucb2zw7bff5uc//zlLly5lxIgRnHfeed0ep6tv37nTXWd3QXUXS6F16kndCxFm19BYYH3Wcm2wrh0zO8PMXgX+H/D1fAcyszlB11FNXV1dj4LRM4tF+p/Zs2ezcOFC7rrrrrargLZt28bo0aMpKSlhyZIl/O1vf+vyGMcddxwLFiwA4OWXX2blypUAbN++ncGDBzNs2DDee+89HnjggbZ9OpsC+7jjjuNPf/oTu3btYufOnSxatIhjjz224PocffTRLFy4EKAtpq7qlG+66t2pe6HCTAT5zrgd0qm7L3L3g4DTgX/LdyB3v8ndp7r71NanAO0udQ2J9D+HHnooO3bsYOzYsYwZMwaAL33pS9TU1DB16lQWLFjAQQd13Zs8d+5c6uvrmThxItdeey3Tpk0D4PDDD2fy5MkceuihfP3rX+foo49u22fOnDnMmDGDE044od2xpkyZwnnnnce0adM46qijuOCCC5g8eXLB9fnVr37FjTfeyJFHHsm2bdva1ndWp9ypuHe37oUKbRpqM/s0cKW7fz5Y/i6Au/+ki33eBo509/c7K9PTaaiX/W0L8598m++fcjD7D6/ofgeRiNM01P3X3jQN9VJggpmNB94BZgPn5gT2ceDNYLB4ClAKdHz6dC844sARHHFgx+eNiohEXWiJwN2TZnYx8CAQB+a7+yozuzDYPg/4B+CrZtYCNABne397Uo6ISD8X6g1l7r4YWJyzbl7W658CPw0zBhHpOXfX3fj9TE++S0dmigkR2T3l5eVs3ry5V25Ykr7h7mzevJny8vLd2i8yU0yIyO4ZN24ctbW19PSSbSmO8vJyxo0bt1v7KBGISF4lJSWMHz++2GFIH1DXkIhIxCkRiIhEnBKBiEjEhXZncVjMrA7o6QQbo4BO71oeoFTnaFCdo2FP6nygu+edo6ffJYI9YWY1nd1iPVCpztGgOkdDWHVW15CISMQpEYiIRFzUEsFNxQ6gCFTnaFCdoyGUOkdqjEBERDqKWotARERyKBGIiERcZBKBmU03s9fMbI2ZXV7seHqLmc03s01m9nLWun3M7K9m9kbwe0TWtu8Gn8FrZvb54kS9Z8zsADNbYmavmNkqM7s0WD9g621m5Wb2vJm9GNT5qmD9gK0zgJnFzewFM/tzsDyg6wtgZmvN7CUzW2FmNcG6cOvt7gP+h8yDcd4EPkrmKWgvAocUO65eqttxwBTg5ax11wKXB68vB34avD4kqHsZMD74TOLFrkMP6jwGmBK8rgReD+o2YOtN5hngQ4LXJcBzwKcGcp2DevwL8F/An4PlAV3foC5rgVE560Ktd1RaBNOANe7+lrs3AwuBmUWOqVe4++PABzmrZwK3Ba9vA07PWr/Q3Zvc/W1gDZnPpl9x943uvjx4vQN4BRjLAK63Z9QHiyXBjzOA62xm44BTgP/IWj1g69uNUOsdlUQwFliftVwbrBuo9nX3jZA5aQKjg/UD7nMws2pgMplvyAO63kE3yQpgE/BXdx/odb4O+F9AOmvdQK5vKwceMrNlZjYnWBdqvaPyPIJ8z9qL4nWzA+pzMLMhwN3At9x9exePVBwQ9Xb3FDDJzIYDi8zssC6K9+s6m9mpwCZ3X2ZmxxeyS551/aa+OY529w1mNhr4q5m92kXZXql3VFoEtcABWcvjgA1FiqUvvGdmYwCC35uC9QPmczCzEjJJYIG73xOsHvD1BnD3rcCjwHQGbp2PBr5gZmvJdOWeaGZ/YODWt427bwh+bwIWkenqCbXeUUkES4EJZjbezEqB2cB9RY4pTPcBXwtefw24N2v9bDMrM7PxwATg+SLEt0cs89X/P4FX3P2XWZsGbL3NrCpoCWBmFcBJwKsM0Dq7+3fdfZy7V5P5e/1vd/8yA7S+rcxssJlVtr4GPge8TNj1LvYIeR+OxJ9M5uqSN4HvFzueXqzXH4GNQAuZbwf/CIwEHgHeCH7vk1X++8Fn8Bowo9jx97DOx5Bp/q4EVgQ/Jw/kegMTgReCOr8M/DBYP2DrnFWP4/nwqqEBXV8yVza+GPysaj1XhV1vTTEhIhJxUekaEhGRTigRiIhEnBKBiEjEKRGIiEScEoGISMQpEYj0ITM7vnUmTZG9hRKBiEjEKRGI5GFmXw7m/19hZr8LJnyrN7NfmNlyM3vEzKqCspPM7FkzW2lmi1rnijezj5vZw8EzBJab2ceCww8xs7vM7FUzW2BdTJIk0heUCERymNnBwNlkJv+aBKSALwGDgeXuPgV4DLgi2OX3wGXuPhF4KWv9AuBGdz8c+Dsyd4BDZrbUb5GZS/6jZObVESmaqMw+KrI7PgMcASwNvqxXkJnkKw3cHpT5A3CPmQ0Dhrv7Y8H624A7g/lixrr7IgB3bwQIjve8u9cGyyuAauDJ0Gsl0gklApGODLjN3b/bbqXZD3LKdTU/S1fdPU1Zr1Po71CKTF1DIh09AswK5oNvfV7sgWT+XmYFZc4FnnT3bcAWMzs2WP8V4DF33w7UmtnpwTHKzGxQX1ZCpFD6JiKSw91Xm9n/JvOUqBiZmV0vAnYCh5rZMmAbmXEEyEwLPC840b8FnB+s/wrwOzP7UXCMs/qwGiIF0+yjIgUys3p3H1LsOER6m7qGREQiTi0CEZGIU4tARCTilAhERCJOiUBEJOKUCEREIk6JQEQk4v4/Bd9WVhTS6B4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9761\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875666074600356\n",
      "0.9504273504273504\n",
      "0.9686411149825784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.2]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899193548387096\n",
      "0.9571150097465887\n",
      "0.9732408325074331\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
