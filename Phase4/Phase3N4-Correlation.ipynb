{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  3.5  211.7 ...  3.9  0.9  0.0]\n",
      " [ 0.0  10.1  899.1 ...  3.9  1.0  0.0]\n",
      " [ 1.0  14.2  665.7 ...  3.8  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  5.2  345.9 ...  4.9  0.9  0.0]\n",
      " [ 1.0  9.5  1298.7 ...  5.2  1.0  0.0]\n",
      " [ 0.0  6.4  451.6 ...  7.0  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 12]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 12]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 4s 17ms/step - loss: 0.7267 - accuracy: 0.5467 - val_loss: 0.6967 - val_accuracy: 0.5665\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7015 - accuracy: 0.5467 - val_loss: 0.6870 - val_accuracy: 0.5665\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6929 - accuracy: 0.5467 - val_loss: 0.6838 - val_accuracy: 0.5665\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6894 - accuracy: 0.5467 - val_loss: 0.6834 - val_accuracy: 0.5665\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6885 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5665\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6883 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6882 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6882 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6844 - val_accuracy: 0.5674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6844 - val_accuracy: 0.5674\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6845 - val_accuracy: 0.5674\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6843 - val_accuracy: 0.5683\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5471 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6844 - val_accuracy: 0.5674\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6878 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5683\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.5471 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5674\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5674\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5674\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6876 - accuracy: 0.5467 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5674\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5467 - val_loss: 0.6835 - val_accuracy: 0.5674\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5674\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5482 - val_loss: 0.6839 - val_accuracy: 0.5683\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6834 - val_accuracy: 0.5674\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6834 - val_accuracy: 0.5674\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5467 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5467 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5467 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5471 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5467 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6876 - accuracy: 0.5475 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5478 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6839 - val_accuracy: 0.5700\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5475 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5683\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6837 - val_accuracy: 0.5683\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6836 - val_accuracy: 0.5700\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5475 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6838 - val_accuracy: 0.5700\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5482 - val_loss: 0.6836 - val_accuracy: 0.5700\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6835 - val_accuracy: 0.5683\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5478 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5683\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5478 - val_loss: 0.6839 - val_accuracy: 0.5709\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5494 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5478 - val_loss: 0.6837 - val_accuracy: 0.5700\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6836 - val_accuracy: 0.5700\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5478 - val_loss: 0.6838 - val_accuracy: 0.5709\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6837 - val_accuracy: 0.5709\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5691\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.5482 - val_loss: 0.6830 - val_accuracy: 0.5683\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6830 - val_accuracy: 0.5683\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6873 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5700\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6873 - accuracy: 0.5497 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5709\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6833 - val_accuracy: 0.5709\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5490 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5497 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5482 - val_loss: 0.6833 - val_accuracy: 0.5709\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5700\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5482 - val_loss: 0.6835 - val_accuracy: 0.5718\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5497 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5482 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5497 - val_loss: 0.6830 - val_accuracy: 0.5700\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6872 - accuracy: 0.5486 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5482 - val_loss: 0.6837 - val_accuracy: 0.5718\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5505 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5497 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5494 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6835 - val_accuracy: 0.5718\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5501 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5497 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5501 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5490 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6870 - accuracy: 0.5490 - val_loss: 0.6837 - val_accuracy: 0.5736\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5505 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6835 - val_accuracy: 0.5718\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.5497 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5501 - val_loss: 0.6830 - val_accuracy: 0.5718\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6829 - val_accuracy: 0.5718\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6832 - val_accuracy: 0.5718\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5505 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5501 - val_loss: 0.6834 - val_accuracy: 0.5718\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5505 - val_loss: 0.6830 - val_accuracy: 0.5718\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6830 - val_accuracy: 0.5718\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5494 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6829 - val_accuracy: 0.5718\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5501 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6829 - val_accuracy: 0.5718\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6871 - accuracy: 0.5497 - val_loss: 0.6831 - val_accuracy: 0.5718\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3NklEQVR4nO3deXxU5b348c83y2QHEhL2HRERRZaIaxVFLVgVF6y41KVVFK/7ba+0/dlq29tre+tarVYtXttS91Ktxb3gLrIIyCqrEBISCGQj68x8f3+cM0uSSTIDGRLC9/165TXnPGd7nlHOd57lPEdUFWOMMSZaCR2dAWOMMYcWCxzGGGNiYoHDGGNMTCxwGGOMiYkFDmOMMTFJ6ugMHAy5ubk6ZMiQjs6GMcYcUpYuXbpbVfOaph8WgWPIkCEsWbKko7NhjDGHFBH5JlK6NVUZY4yJiQUOY4wxMbHAYYwxJiYWOIwxxsTEAocxxpiYWOAwxhgTEwscxhhjYmKBwxhjOrtdX8OWjzo6F0GHxQOAxhhzSHv8eOfz3vKOzYfLahzGGGNiYoHDGGNMTCxwGGPMocLX0NE5ACxwGGPMoaN+X0fnALDAYYwxhw4LHMYYY2JigcMYY0xM6qs6OgeABQ5jjOncvPWh5YbqjstHGAscxhjTmYXXMqypyhhjTJvCg4U1VRljjGlTo8DROWocNleVMcZEY8dS2PY5jLsKyrbB5oUw9kpIz4Gv3wFJABSS02HIKc4x9ftg6XPgrXXWc0fA7g2xXbeiMLS8bj7s2x3b8aMvgpyhsR3TBgscxhgTjdduhZLVkNINVr4IWz+ChGQYezn87dLG+wYmI1z/Jrz94wO/dkIy+Bvg6zedv1j0GWOBwxhjOkTNHuezaifU7HWWK4ugoablYyp3Op//+TW8cLlTaxk2CS5/MbZrJyQ6NZr9mXIkMTn2Y9pggcMYY9qiCrVuLaKqxPkLLEfqd/D7nJt9VTEkpkBmL8jq62zL6gvJqfuXj4TE/TuunVnnuDHGtKW+KvQMRUUhVLv9DFXFkQNHIK2qBDJ7gwhk5Dlpmb3in984s8BhjDFtCdQwAErWgPpD6a0GjuJQoEhyaxlpOfHL50FigcMYY9pSVex8puXAns3OcnrP6Gsc4eTQv+0e+iUwxnR99dXw6wGw7l+htKoS+N1I+POF7XutP18I79zTOC0QOPocG0rrMwb2lcDCXzc/x2MT4DdDnFFYgRpHRk/nM7V7++a3A1jgMMZ0fqUboL4SFvxPKK1kjTPCafMC8Pvb71qbF8CnjzZOCzRVhQeOb93lfO5YGvk8gZFXJ9zkfJ58G0z5jfPsxyHOAocxpvMLjGgK/7Ue3u8QuEkfqJaGu1YVgyRCr1GhtP75cMTZjff71g8br/cdC72OcpaTUuDEmyDx0B/MaoHDGNP5VZc6n6ndQmmB5qOmyweipaeyA53cWX2cdU8WeNKb9180XQ+MpOpi4ho4RGSKiKwXkY0iMjvC9kkiUi4iy92/n7npI8PSlotIhYjc4W7LEZF3RWSD+5kdzzIYYzqBql3OZ6MaRxwCR/h5fN6w9BIncAQCQ6DfounQ2qbrcXj4rjOIW+AQkUTgcWAqcDRwuYgcHWHXj1R1rPv3CwBVXR9IAyYA1cA8d//ZwPuqOgJ43103xnRlgRt6cnpYWknk5QO6Tth5qsNqH1XFTtAIBo4mnwFd4BmNaMSzsW0isFFVNwOIyAvANGBNjOeZDGxS1W/c9WnAJHf5OWAhcPeBZtYYE6N9u2H31zD45Lb3Xf+WMwy1uhSOmAyr/wHqg4QkOOYSZ6JAgOI1zq/0HoNh079h5BTY8pEzLxQ4kwUu+4vzQF7hcsg7Cnatg8VPOw/ZpXZ3ntoeORW2fQalm2DUeU4HduVOZ5hsznCnsx0gLdsZVos4aTuWhfL8+ROhpqm93zgd4+k9nXK0VOPoAiOmohHPwNEf2B62XgCcEGG/k0RkBVAI/FBVVzfZPgN4Pmy9t6oWAahqkYgcHiHemM7m2alO4Ph5mXPTbsm2RfD8ZaH10RfD6r+H1r11cPItzvITJzmfJ98Kn/4ernsLXr3eGT0FThBZPjd07ITrnMBRsNj5C7jxQyd/AO/es3+d55883Hi997HOlB/9xkO/cU5aeGc5QPeBzucx02HVK85Mul1QPANHpP+TtMn6MmCwqlaJyLnAP4ARwROIeIALgJinlxSRmcBMgEGDBsV6uDGmLbu/dj69tZCc1vJ+gY7tgLJtTpPTnavht8OgrqL5MaWbQ8fWlsPEG50aSNk2J/2afzo1gNQeMOx0ePnaxseHT0UeKWiMPBfGXAYvXxNKO/4GOPOnTt78PvDVhbZJQqg2ccP7ofReo+Anhc58VIHRUoGZcaf/KdK30SXEs3O8ABgYtj4Ap1YRpKoVqlrlLs8HkkUkN2yXqcAyVQ3v+SoWkb4A7mfExk1VfUpV81U1Py+va45sMKZTiPXlQlUl4Ml0mqc8Ga0frz7w1jhNRJ700M08q6/TzCTifEa6RmvSspv3T6T3dNKTUpxrpWWH/lprgvJkdIkhtrGIZ+BYDIwQkaFuzWEG8Hr4DiLSR8Sp44rIRDc/4T9PLqdxMxXuOQI/E64BXotD3o0x0Wrrdaba5OG8qmLnZgvOr/vWjg8EFU96aK6nwHEBnszmx5UXRD6fJIaOD+QheJ705vubiOIWJlXVKyK3AG8DicAcVV0tIje5258EpgOzRMQL1AAzVFUBRCQdOBu4scmp7wdeEpEfANuAJm9QMcYcVG3VOAJvvwvw1YVu9uE1Dm3akk3ouQpPhlMTCAi/6TcNABCaT6qpzN5QWegc0yxwRDiPiSiu9Su3+Wl+k7Qnw5YfAx5r4dhqoGeE9FKckVbGmM6grcARqUYRuEl7MkPH++qb7xcYhuvJbFzj2N/AkZbtBo7M5jWVSDUXE5E9OW6MOTBtNVVFCizBwJEROj58P/U5n4G+ivAaR2JK4wfrIt3wWwocgU58q3EcEAscxpgD02aNo63A4W4PD0Dh77MI7BeocURzw68ti5yXwJTmnozG/SQtncdEZIHDGHNg9qupKkIfR/h5An0bwRpHZqjG0bSGkeiJLb+B6yY0uf1ZU1XULHAYYw7MAdU4Mp13bUDoE5z3XIR/tlbjaO3hw5ZEChJW44iaBQ5jTOzC338RS+BIcWe3jdjHEVYzCTw0GPhsLXC0JqWF5y8iDb21wBE1CxzGmNh5a0LLsTRVBR7Wa6upqqlGTVUx3OBbmnQwIcKstdZUFbXD63FHc3Dt2QxbPnSWkzNg9EWhJ2y99bDtU+g1Gr5+M/SQWLcBzhQRDTE+jdyaxBRnsrqyb9reN57yRsGgE2DzQhh0MpRvD03e58l0nobuOwa2L3IeVGua39yRzqSAWb2dZp3cEbB6XuQ+hJ5HON+/J9PpBA7M9dRe6sKuWfAFLP2/lvfdvTG0HF7TACd/vjpYMseZtLAlngznvyM0Hpbblozc0ISGbbEaR9QscJj4eeceWPdGaD0zD4ZNcpbfvw8+ewyGng5bPuiQ7B106T3hipfhz9Oc14iWrIWN7+7/+a6dD6/+oP3yt782/dv5i0bv0c4rX7MHO+vZQ5zPN+5s+ZjMPk4HeA93zrmcoc336T7Q6eso2wYjvg0b3nYCZu/Rziy5AAOOh3FXOoEucI6eI0KBJZaAdJizwGHip2IHDPkWTP4Z/OnsxhPPFa9yPouWQ/dB8IO3nV/Pb//ESf/Bu9B9wIHnwVsHj451lk+5PfT+54Nt0ZPwySNQ7k7SV7IGKopg+GQ49U547rzmx5x1H4z5rrP89k+c7ydc4Pu8dn7jm+n8HzUO2ADTHofhZ7ZPWQISPU6NoWZP2/tm9HKHwipMud+pCQCMudSZpNDvvjTJk+ns01AD6blO53hqDycojL3cmZI9Pbf5+e/4yvlUdfatr3Kul5QGp9/d+E18464Ojai6ZXHoifX96WQ/TFngMPFTVQLDjoZe7vu7Ir2lrbbceadCt36Qe2Qovffo9m866HmEc52OkDPc+dyzJZS2rwQGTnTKGknukaH89hjcfHugKav3aEjrEUoP/Irv1t8J3hD6juMhOcbzZjS58UfqhwhMKtg0zy31WQRu+oHPlKyWjwkPECIWMPaDdY6b+PD7Q6/bTHGnd2hpxtJIL8WJR3tzRge+uiUwE+tO95ex3+s8q5DZK/LsruHHNF0OKF7ltPs3nbk18D0GAkh4mjHtwAKHiY/aMvA3NH5Hc3iNwxs2L1FLr+Fsbx158wxcOxA4ygsAddJb+sUbnt9Ied/5lfOdNT0+8D2GPxjXkUHTdDkWOEx8BIJEsDbRu3GNY1/YcuBGF6ntuj3FOzBFc+1AR2zpxsbpEY8Ju9k3bd4JnCNSQEnLaZ6WbB2/pv1YH0e01rwO7/w08tTPpjmv+8KdjLBmqHXz4aFjnPVA2zuEOi7j9TIcT6bTWRreQXqwtXTt1moC4dOIJ7fQdBcpcASCREtNYMYcIAsc0dr0b6dNevRFHZ2TQ0dKljMEEpzRTOEPWIk4o6kqi2Dk1FD6JX+K3BF8IK5/H775BJL2Y06j9pLkgbN/6bwfu8dgZ3RVSrfQu6uve8sZNrp3qzNUtVuTEWX9Jzij0/w+52nqRI/zedyM5tcafCqc8f8g//sw4Vqoq4x36cxhRvQw+AWdn5+vS5YsObCTPH+FM4pl1iftkyljjOnkRGSpquY3Tbc+jmhVFdvIFGOMwQJH9KpKOrZz1RhjOgkLHNFQdWocHdm5aowxnYR1jremYKkz5NFb60zEZjUOY4yxwNGqFX+Dxc+E1nNHdFxejDGmk7DA0ZpJP4YTb3aWk1LaZ9I9Y4w5xFngaE1GbuQndo0x5jBmnePGGGNiYoHDGGNMTCxwGGOMiYkFDmOMMTGxwGGMMSYmcQ0cIjJFRNaLyEYRmR1h+yQRKReR5e7fz8K29RCRV0RknYisFZGT3PR7RWRH2DHnxrMMxhhjGovbcFwRSQQeB84GCoDFIvK6qq5psutHqnpehFM8ArylqtNFxAOkh217SFV/F5eMG2OMaVU8axwTgY2qullV64EXgGnRHCgi3YDTgD8BqGq9qpbFK6PGGGOiF8/A0R/YHrZe4KY1dZKIrBCRN0VktJs2DNgFPCsiX4rIMyIS/gq0W0RkpYjMEZGIrzkTkZkiskREluzatas9ymOMMYb4Bg6JkNb0rVHLgMGqehzwe+AfbnoSMB54QlXHAfuAQB/JE8BwYCxQBDwQ6eKq+pSq5qtqfl6ezWprjDHtJZ6BowAYGLY+ACgM30FVK1S1yl2eDySLSK57bIGqLnJ3fQUnkKCqxarqU1U/8DROk5gxxpiDJJ6BYzEwQkSGup3bM4DXw3cQkT4iIu7yRDc/paq6E9guIiPdXScDa9z9+oad4iJgVRzLYIwxpom4japSVa+I3AK8DSQCc1R1tYjc5G5/EpgOzBIRL1ADzNDQS9BvBea6QWczcJ2b/lsRGYvT7LUVuDFeZTDGGNOchO7TXVd+fr4uWbKko7NhjDGHFBFZqqr5TdPtyXFjjDExscBhjDEmJhY4jDHGxMQChzHGmJhY4DDGGBMTCxzGGGNiYoHDGGNMTCxwGGOMiYkFDmOMMTGxwGGMMSYmbQYOETlPRCzAGGOMAaKrccwANojIb0VkVLwzZIwxpnNrM3Co6lXAOGATzhv5PnPfrpcV99wZY4zpdKJqglLVCuBVnPeG98V5D8YyEbk1jnkzxhjTCUXTx3G+iMwD/g0kAxNVdSpwHPDDOOfPGGNMJxPNi5wuBR5S1Q/DE1W1WkS+H59sGWOM6ayiCRw/B4oCKyKSBvRW1a2q+n7ccmaMMaZTiqaP42XAH7buc9OMMcYchqIJHEmqWh9YcZc98cuSMcaYziyawLFLRC4IrIjINGB3/LJkjDGmM4umj+MmYK6IPAYIsB24Oq65MsYY02m1GThUdRNwoohkAqKqlfHPljHGmM4qmhoHIvIdYDSQKiIAqOov4pgvY4wxnVQ0DwA+CVwG3IrTVHUpMDjO+TLGGNNJRdM5frKqXg3sVdX7gJOAgfHNljHGmM4qmsBR635Wi0g/oAEYGr8sGWOM6cyi6eP4p4j0AP4XWAYo8HQ8M2WMMabzajVwuC9wel9Vy4BXReQNIFVVyw9G5owxxnQ+rTZVqaofeCBsvS6WoCEiU0RkvYhsFJHZEbZPEpFyEVnu/v0sbFsPEXlFRNaJyFoROclNzxGRd0Vkg/uZHW1+jDHGHLho+jjeEZFLJDAON0oikgg8DkwFjgYuF5GjI+z6kaqOdf/Ch/g+ArylqkfhTOG+1k2fjVMLGgG8764bY4w5SKLp47gLyAC8IlKLMyRXVbVbG8dNBDaq6mYAEXkBmAasaeuCItINOA24FoLzYwXmy5oGTHKXnwMWAndHUQ5jjDHtIJpXx2apaoKqelS1m7veVtAA6I8zPUlAgZvW1EkiskJE3hSR0W7aMGAXzqtqvxSRZ0Qkw93WW1WL3LwVAb0iXdx9ve0SEVmya9euKLJrjDEmGtE8AHhapL8ozh2paUubrC8DBqvqccDvgX+46UnAeOAJVR0H7CPGJilVfUpV81U1Py8vL5ZDjTHGtCKapqofhS2n4jRBLQXObOO4Aho/KDgAKAzfwX2XeWB5voj8QURy3WMLVHWRu/kVQoGjWET6qmqRiPQFSqIogzHGmHYSTVPV+WF/ZwPHAMVRnHsxMEJEhoqIB5gBvB6+g4j0CXS6i8hENz+lqroT2C4iI91dJxPqG3kduMZdvgZ4LYq8GGOMaSdRTXLYRAFO8GiVqnpF5BbgbSARmKOqq0XkJnf7k8B0YJaIeIEaYIaqBpqzbsWZzt0DbAauc9PvB14SkR8A23DmzjLGGHOQSOg+3cIOIr8n1DeRAIwFtqrqVfHNWvvJz8/XJUuWdHQ2jDHmkCIiS1U1v2l6NDWO8DuuF3heVT9pt5wZY4w5pEQTOF4BalXVB86DfSKSrqrV8c2aMcaYziiaJ8ffB9LC1tOA9+KTHWOMMZ1dNIEjVVWrAivucnr8smSMMaYziyZw7BOR8YEVEZmAMwLKGGPMYSiaPo47gJdFJPDwXl+cV8kaY4w5DLUZOFR1sYgcBYzEmUZknao2xD1nxhhjOqVo5qr6DyBDVVep6ldApojcHP+sGWOM6Yyi6eO4wX0DIACquhe4IW45MsYY06lFEzgSwl/i5L6gyRO/LBljjOnMoukcfxtnbqgncaYeuQl4M665MsYY02lFEzjuBmYCs3A6x7/EGVlljDHmMBTNtOp+4HOcGWrzcaY4X9vqQcYYY7qsFmscInIkzjs0LgdKgRcBVPWMg5M1Y4wxnVFrTVXrgI+A81V1I4CI3HlQcmWMMabTaq2p6hJgJ7BARJ4WkclEfo+4McaYw0iLgUNV56nqZcBRwELgTqC3iDwhIuccpPwZY4zpZKLpHN+nqnNV9TxgALAcmB3vjBljjOmconkAMEhV96jqH1X1zHhlyBhjTOcWU+AwxhhjLHAYY4yJiQUOY4wxMbHAYYwxJiYWOIwxxsTEAocxxpiYWOAwxhgTEwscxhhjYmKBwxhjTEziGjhEZIqIrBeRjSLSbJoSEZkkIuUistz9+1nYtq0i8pWbviQs/V4R2RF2zLnxLIMxxpjGonkD4H5x303+OHA2UAAsFpHXVXVNk10/cufBiuQMVd0dIf0hVf1dO2bXGGNMlOJZ45gIbFTVzapaD7wATIvj9YwxxhwE8Qwc/YHtYesFblpTJ4nIChF5U0RGh6Ur8I6ILBWRmU2OuUVEVorIHBHJjnRxEZkpIktEZMmuXbsOqCDGGGNC4hk4Ir30SZusLwMGq+pxwO+Bf4RtO0VVxwNTgf8QkdPc9CeA4cBYoAh4INLFVfUpVc1X1fy8vLz9LoQxxpjG4hk4CoCBYesDgMLwHVS1QlWr3OX5QLKI5Lrrhe5nCTAPp+kLVS1WVZ+q+oGnA+nGGGMOjngGjsXACBEZKiIeYAbwevgOItJHRMRdnujmp1REMkQky03PAM4BVrnrfcNOcVEg3RhjzMERt1FVquoVkVuAt4FEYI6qrhaRm9ztTwLTgVki4gVqgBmqqiLSG5jnxpQk4G+q+pZ76t+KyFicZq+twI3xKoMxxpjmRLVpt0PXk5+fr0uWLGl7R2OMMUEislRV85um25PjxhhjYmKBwxhjTEwscBhjjImJBQ5jjDExscBhjDEmJhY4jDHGxMQChzHGmJhY4DDGGBMTCxzGGGNiYoHDGGNMTCxwGGOMiYkFDmOMMTGxwGGMMSYmFjiMMcbExAKHMcaYmFjgMMYYExMLHMYYY2JigcMYY0xMLHAYY4yJiQUOY4wxMbHAYYwxJiYWOIwxxsTEAocxxpiYWOAwxhgTEwscxhhjYmKBwxhjTEwscBhjTAdYsL6EJz/YFNW+qsov31jDqh3lEbd7fX5mv7qSu15azvtri9szmxElxfPkIjIFeARIBJ5R1fubbJ8EvAZscZP+rqq/cLdtBSoBH+BV1Xw3PQd4ERgCbAW+q6p741kOY0x0GhoaKCgooLa2tqOz0ul599YwPBnWrl3b5r5+v3JiTi3F2zaRWJHWbHuDz8/kvl5n3707WLt2T0x5SU1NZcCAASQnJ0e1f9wCh4gkAo8DZwMFwGIReV1V1zTZ9SNVPa+F05yhqrubpM0G3lfV+0Vktrt+d3vm3RizfwoKCsjKymLIkCGISEdnp1NrKCgDYNSAHm3uW+/149tZgYgwqn/3Ztsraxtg977gejTnDFBVSktLKSgoYOjQoVEdE8+mqonARlXdrKr1wAvAtHY47zTgOXf5OeDCdjinMaYd1NbW0rNnTwsaMfCrNkvbUFxJSUUte6vrWVNYjs/v7KNh+3p9fr7eWUl1vZcGXyg9KTGBipoG1u+sxO9vfu6mRISePXvGVEuMZ+DoD2wPWy9w05o6SURWiMibIjI6LF2Bd0RkqYjMDEvvrapFAO5nr/bOuDFm/1nQiE3Tm7uqUtPgY2dFLYV7a/D6lXqfv9lxdV4/tV4fFTUNNIRtTwAK9tZQ5/VR0+CLKg+x/jeLZx9HpJw0DX/LgMGqWiUi5wL/AEa4205R1UIR6QW8KyLrVPXDqC/uBJuZAIMGDYo588YYEy5wg09IcG5tqopfITEhdKvz+v0kJTi/x31+P4kJCU6NQkPHNTuvKn5V1D2XNyyQBMJBvTcUGGrdYBAIJtX1PjxJCSQlJNAjPZk9++oJXGrvvnpSkxMb5bE9xLPGUQAMDFsfABSG76CqFapa5S7PB5JFJNddL3Q/S4B5OE1fAMUi0hfA/SyJdHFVfUpV81U1Py8vr/1KZYzptMrKyvjDH/6wX8eee+65lJWVtbh97c4K/uM/7+a9994DoKi8ltWF5cGmppp6H2sKKyirrqeuwcfqwgr27Kvj652VrCmqaPG8Pj889PhTXPn9mahqo9pDoGmqwedn8Wcfs3zJIr4uruTr4koKy2oAJ3A0+JTkRCEpQfCrBoPPnup6quu9+/V9tCaegWMxMEJEhoqIB5gBvB6+g4j0EbeOJCIT3fyUikiGiGS56RnAOcAq97DXgWvc5WtwRmUZY0yrgcPna73ZZv78+fTo0aPF7T6/Mus/f8JZZ50FwO6qOiBUEwnc8Ev31QdrA2XVDdT7/BH7MQL8qlTXO3mr8/ob9VcE1Hv9LPnsY1Ys+YIeaR5SkhKD/R5+VfbVeUlOTGhUs+jXI41BOemkJie2Wu79EbemKlX1isgtwNs4w3HnqOpqEbnJ3f4kMB2YJSJeoAaYoaoqIr2BeW5MSQL+pqpvuae+H3hJRH4AbAMujVcZjDH7775/rmZNYcu/tPfHkb0z+eWFx7a4ffbs2WzatImxY8dy9tln853vfIf77ruPvn37snz5ctasWcOFF17I9u3bqa2t5fbbb2fmTKcLdciQISxZsoSqqiqmTp3Kqaeeyqeffkr//v157TXn9+k9d97MZZdcyHcvnc7Uk8Zw/vTLWbTwXbzeBub85W+k5A5ke+FOrr/zRnbu2s0xx43nk4Xv8fz8hezJTidRoFtaMiLCP16cy58ef4h+ffvSb/Awkj0eSqvqefvNf/HQ/95PQ0M9PbJz+J9Hn2K3t56X//osCQmJvPP6K9x3/wMUFO/imUcfoN7d78lnnqXHwFA3cnZ6MokJ8akbxPU5Drf5aX6TtCfDlh8DHotw3GbguBbOWQpMbt+cGmM6u9oGH2U1DcG+g0juv/9+Vq1axfLlywFYuHAhX3zxBatWrQoONZ0zZw45OTnU1NRw/PHHc8kll9CzZ89G59mwYQPPP/88Tz/9NN/97nd59dVXGTPJeWqgqLyGr4urAOiR05NPFy3m2Wf+yKMPP8SPfvUgTz70G8ad+C2uvfkOPlnwHq/M/T8ACvZWAzAsN4PKvbt54sH/4fn5C8nK6sb1l53PyNFjKN1Xx5Fj8vnr6+8iIvz9+T/z7BOPcvfP/5tLr7qO9PQM7r/vp1TX+/hq0w5ee2chNQ0+Xpr7HH987GEefOABAFKTEuMWNCDOgcMYc/j6+fmj294pBmsKK/D6/fj8SmIM98SJEyc2ej7h0UcfZd68eQBs376dDRs2NAscQ4cOZezYsQBMmDCBLVu2MGZSaLvX7zRFTZ5yHn5VJkyYwIsvvwLA8sWfc/XTfwXglDPOolv3Ho3Ova/ex6JFi8g/6VRyeuYCcM75F1OxcxtH9cli1a6t3Hr1DygqKqKhoYH+AwfjU0WAPt1TSU5MoHtaAunecmZeOZPtBTuoratn+LChpHmSGNW3G4lxHtlmU44YYzqV2gYfe6vrm6UH7oW+KJ5NCD9XSmp6cH3hwoW89957fPbZZ6xYsYJx48YFn19QhYqaBgBSUlJo8PnZVVlLjddPXX1DxPN7UlLw+RVFqKlz9mnplp2cmEBqUiLFFbWU1zQ0GwKbmCB4khK56847uO6Gm3j1vU+55/6HqK+rdcsvjY65647bufWWW/jg86XufnXB67Q0gqu9WOAwxnQqJRV17Nhb0yw9cCv0thI4srKyqKysDK7vKKuhuiE0qqi8vJzs7GzS09NZt24dn3/+eXCbT5Wi8trgSKaCvTUUlddSWeOlqq7lkUl+VQrLaoLHHX/iybzzhlOj+fzDBVSUl5GckMDA7DR6pDtTegw48liWfPYxZXv3oD4fH7wVGjdUXl7OyOGDSUwQ/vnK84gISQkJ5PTo1qhs5eXl9O/fn+5pycx/9QUSDuLzMxY4jDGdSnW913m2oWmAiKLG0bNnT0455RSOOeYYfvSjHwXTAzf1KVOm4PV6GTNmDPfccw8nnngigPscheL1+4MjosKfnWh6yZG9s0hODDyvodSF7fujH/+Ezz5cwGVTT2ft4g/p27cvE0b0IzM1mV7dUklMEPJ69+GmO2dz3UXf5rarL+aE4/ODx997771cdfkMbrrsPEYM6ke6J5Gj+3Xje5ddwrx58xg7diwfffQR9957L5deeilnnzmJYQP7cjCfuxRtZZhYV5Gfn69Llizp6GwYc8h4bfkOdpTVcPOkI1rd73/mr2X84Gy+PboPD76zntN71zPhuGPx+vzsKKuhb/c0PEkJVNY2UFpVjwgMyE4Ldtzuq/NSVF5LTkYyORlO89Ba95mHo/p0w5OUQL3XT1F5DfvqfHj9fvr3SKOm3kd2hgevX9lVWUdigpCVmkS9109mShLd0pxf9ivd+aCSExNISUrAr9C7WwqqUFJZR6+sFBJEKCqvCT5l3bd7GhW1DVTX+2jp/nhMv+4osLqw+Wy1PVMTKK6qJykpiX3b1zJr1qxgZz3A+p2V1Hmdaw3ITiMnIyXq/y7xtHbtWkaNGtUoTUSWBiaYDWed48aYZm5/YTlAq4GjoraBP364GYD1v5rCo//eyLEX9AWgrKaB8poGEhOEAdnpbAmbgC/dk0ReVkpwv+p6L6pKTkZK8HkGCNUsdlU6fQIBdV4/e6rr2VNdT480T/ABt8paZ5/dVXWMGdCjUY2lwecPPmextzoBv1+prveyZ59QWetF3UktBKGkohafKpkpSXiSEtizz+lvSUpIIDMlieQkISFBGgWVdE9SMB8lOwu4YsYM1O+nW0YaTz/9dKPvbXDPdL4uruRQZoHDGNOiBp8/2CTT1MrtoV/b4e+J8KsGm3l8fm32qz38yehqt++gtsEZLRX+lLPP7wcSm/VphM+/1BBhDidwmqYa/JG3Vdd7CWyqrvcFgwZAekoi++q8JIowNDcDEQkGjiE900lPCd0ywzuqh+dl8JX7HRw76iheesuZHWlMhFlqU5MTyc1MYXdVXav9NZ2ZBQ5juoAfvryC7PRkfvqdo2M67oqnP+fTTaWIOKOKpo3txyMzxgW3L9q8h6v+tAiA+y8+lhkTnXnffjrvK+Yu2hbc75InPgsuhweR8pqG4A01YHdVXfCpa3BupLUNvmCzT6IIPlU2h9VSwu0L66je18J0Gk2vGZCYIMGgFrhugADpHidwpHkSg4EhKTEBr89PqqflJ7DDg0hSFGOFU5KcfQ5mh3Z7ssBhTBfwycbdCMQcOD7dVApAerLTAfvumuJGnc9PfbQ5uPybt9YFA8firXs4sncmJw/P5f8+3QrAaUfm0T0tid7dUgGC/RPgdDQ3HWKb4UkiMzWJ7HQP5TUNwWk5UpMT+KbUeViuV7dUBGceqIraBpISEoLPUAT0zPCQ5knCr0qCOKOuApWcBHFu5JkpSVTWNpCVmsxetwbRI91DmZsnT1JCcDLABBG6pYZujcPzMqjz+iPe5IflZgQDxfC8zOAw2CPyMlselwvkZHgQkeAoq0ONBQ5jDnElFbUUlTtj/XeW1yLiPPOQl5kS/CVcWlXH3up6hudlUlnnJSlBSAubwygvK4UrTxjMHS8u5/PNpcH0L78JvVwzLTmRFdvL6Ns9laLyWi4e15+Zpw0LBo5bzzyCzJriYOAI5/Nrs8DRPT2Z3MyU4PUDwvsm+rjnKq+pp6K2gZ6ZHooraoPHBDrGczI8bX5PgU7oXmH56xUhr03zn5KUSEpS5NpGZmroxp8R1owV3qQViUh0ee6sLHAYcwir9/qZ+Ov3g+u3/G0ZS9yb/c/OO5rvn+o8Mf2dRz9mZ0Utb9x6Kuf9/mP6dU/lX7d9K3hcZmoS4wb1AODKZxYF0yvDmoUKy2uZ9vgnpHsSqa730ad7WqMbfp9uqVQ1f/wCCE09HjgWIDkx8k/ywK/28MCW7klCEGcGWLfpKDMliV2VdXhauKmb+LHnOIw5hAV+fQcsCashvL+uOLi8092vwH2wrrC8lsLy0F0+MyWJQTmhJ6wBbvjWUOZcm8/CH07i+CHZAPTrnhq88fd1p78IiFTTCHdUnyyG5mYG11vqdAcY2SeLYXmN9x3RO5Me6R6O7J3JUX26kZWazIjeWWQfYHNPZqZzncLCQqZPnx5xn0mTJtHWkP6HH36Y6urq4Hpb07Tvr0B+W3IgU8tHy2ocMaht8PHa8h306Z7G9j3VrU6VbKIzpGcG3+ypbnG8PDjV+sE56WwtdTpLu6clk5SQQOm+UAdr726pVNZ6qW3wMTAnnW9KG3esDumZwaCcdGoafIzq2w1wOm7fWFkYbNPPyfCQ7kkk3ZPEsNwMlnyzl91VdZwxshcD3ZtqYVkN2/dUU9Pgw+dXTjsyj+TEBBasLyHD49x8+3QP3UAraht4Y0URE4fmcESv0D/4Bp+fD9bv4vghOawuKqe6zsfkUc7LLN9bW8KZR/Vi064qkhKEYXmZbNpVhc+vDM/LZMG6EiaP6sXqwgo2lISGdWamJDV6wnnR5j38+bOtHBP2jup5XxYEl59YuKnRsU2nwDh2QA/OPKo34PQBAFw+cRAPvPs1QKNyhu/TkkDNQHDe6NZa4IjUNBSYHjxBJPiTN60dpwzv168fr7zyyn4f//DDD3PVVVeRnu78vzJ//vw2joiPQOC4+eab43YNCxwxmP9VEXe/+lVHZ8Psh6SwN6ttvf87APz182/437fXt3nsuceW8ocrJwDw7Yc+bNR8c/vkEZw1qjfXPbsYgP490vhk9pnB7X9fWsC9/1zD+EE9+PvNpwTTn1i4iQfdG3DAry86lqzUJG59/kvuOe9ofvnGmmB+Jz/wAQA/POdIfvfO18y5Np/v/1/jX8CX5g/g2U+2Bte9fuVnr62mV1hz0turQ7WQN1YWBZcDTUl3nX1kMF+j+mQFt0+fMIBPNpby3eMH8txnWymrbmBYXgYAJw7LYfOuCCOg3pwNO5v/exnp81Pv9ZOUkkirPciR9DkWpt7f4ua7776bwYMHB2+a9957L1lZWdx4441MmzaNvXv30tDQwK9+9SumTZvW6NitW7dy3nnnsWrVKmpqarjuuutYs2YNo0aNoqYmVDubNWsWixcvpqamhunTp3Pffffx6KOPUlhYyBlnnEFubi4LFiwITtOem5vLgw8+yJw5cwC4/vrrueOOO9i6dWvE6dvT0tIa5WvLli1cccUVeL1epkyZEkyvqqqKWKamU8v//Oc/b7PssbLAEYNl20LNAINy0pl388kdmJtD3x8/3MxTH27muAHdmXPt8S3ud8XTi1hfXMnNk4Zz8fj+nPWgM0Z+3s0nMygnndWFFVw95wvAaWffWVHLbWcewTUnDwHgs82l3PK3L4PnK62qo2dmCsu+2cuwvAxevvEkCstqOf+xj5tde3S/biz7piy4XtlkzqI1RRWNmmh2lDVu5A+sry2qxOvzB0fgrI3wRrgvt+0N/opf+s2e0DVrQw+/vbvWeeHl3n2NJ91bee85ZKUkcfvkEYz9xbvB9JwMDyWVdTT1nWP78q+vipql33rmEdxyhvPQX/hEeReNG8CFY/sjInwy+0x8fiXd49w+Xph5UrPztMaTmIAnlultYzBjxgzuuOOOYOB46aWXeOutt0hNTWXevHl069aN3bt3c+KJJ3LBBRe0+K7tJ554gvT0dFauXMnKlSsZP358cNt///d/k5OTg8/nY/LkyaxcuZLbbruNBx98kAULFpCbm9voXEuXLuXZZ59l0aJFqConnHACp59+OtnZ2RGnb7/qqqsaHX/77bcza9Ysrr76ah5//PFgektlajq1vNfrjans0bDAEYUGn5/fvLmOt1cXB8e7e5IS6JnZOaYKOFSNHdgDcDo+W/suU5Odm8yEwdkc0Sv0K3jswB6ICCcMywmmdU9LZmdFLROH9gye85Thjf8h3/XSCnIzU1i0ZQ9Tj+lDz8yUiCNcEhOEi8cP4JdvrOGOF75sth3gy21lbG3yvMF/vrQiuPzqMqdpqKbBx+0vLGdobgZF5bWN+iICXl5aEOxneH9t6I3IN/5laXB5xfYy5xovr2h0bDd3dE+P9MblmHJMH/4W9rxFwCUT+kcMHM4MrM3LGdgGkZuRImqlZhAv48aNo6SkhMLCQnbt2kV2djaDBg2ioaGBn/zkJ3z44YckJCSwY8cOiouL6dOnT8TzfPjhh9x2220AjBkzhjFjxgS3vfTSSzz11FN4vV6KiopYs2ZNo+1Nffzxx1x00UVkZDg1tIsvvpiPPvqICy64oNn07Vu3bm12/CeffMKrr74KwPe+9z3uvvtuwHnIMVKZmmppv5bKHg0LHFFY9s1envl4C727pfCrC49h/ldF/Oc5Izs6W4e8b43I5YShOdxzXuvPHvzqwmP59fy1nDjMeWfCf00ZSXWdr9GN7NqThzAsL4Nj+3fnd++sZ8Lg7ODx2RkezhvTl9WFFfhV2VhSxcaSKnIyPJx3XD/AuSneNnkE760pxuv34/Urk4/qxVmjevH8F9tYvNW50Q/LyyApwZmt1K9KVZ2X6nofR/bODL7cZ/5XReRkeKhwawrD8zJITkzg7dU78fqVDE8i2RkejuiVycaSqkZl3bbH6VzNy0ohKcGZRvub0mqG5ma4k/BpsIM74LL8gY3WbzvzCN5ZU8ygnHTyB2c3CxzD8zI49Yg8vj26N5kpycHg1lVMnz6dV155hZ07dzJjxgwA5s6dy65du1i6dCnJyckMGTIkOJ16SyL9It+yZQu/+93vWLx4MdnZ2Vx77bVtnqe1/ruUlNAPpsTExEZNYm3lJdoy7U/Z22KBIwpfur/y3rz9NHIyPFx5wuCOzVAXkZWazIs3tt3MceyA7jw/88TgeqT5k+69IPTSoLnXn9hs+2NXjG+W1tRdZx/JXWcf2Sz9vbtOb/NYgN+/v4EH3v2aSyb051cXHss/vtzBHS8ux5OUyJu3f4uL//AJy7aVcevkEdx0+nDAebBt1M+ctyLnZnrYXVXf6AntSIbM/ldw+Z+3nMqxA7o32n7XOSO5y/1h89mmUpp6647TSE5M4I/fy+etVUVdLnDMmDGDG264gd27d/PBB07fUHl5Ob169SI5OZkFCxbwzTfftHqO0047jblz53LGGWewatUqVq5cCUBFRQUZGRl0796d4uJi3nzzTSZNmgSEpnRv2lR12mmnce211zJ79mxUlXnz5vGXv/wl6vKccsopvPDCC1x11VXMnTs3mN5SmZpOLR9r2aNhgaMVv39/A6+vKKS4opYhPdMP6Qd2TPz53F+WQ3o6TRKBprjAL87AMw9Hu6O6ANLCprHo3S2V3VX1HOceF43e3VtvLu3Xo/kQ2fDRTEnuLLXtOTqpo40ePZrKykr69+9P377OpItXXnkl559/Pvn5+YwdO5ajjjqq1XPMmjWL6667jjFjxjB27FgmTpwIwHHHHce4ceMYPXo0w4YN45RTQgMeZs6cydSpU+nbty8LFiwIpo8fP55rr702eI7rr7+ecePGRWyWiuSRRx7hiiuu4JFHHuGSSy4JprdUpvCp5adOncrdd98dU9mjYdOqt+KFL7bx4YZdAHx7dB+mje3fxhHmcFZe3cBjCzZw19kjSfMkoqo89u+NTDmmDyN6Z7GzvJZnP93CD88Z2ejm/cIX2xiSm0Hvbqn8fVkBd551ZKtvcPvg610s2lxKSlIit00+otVOTr9f+cUba0j3JHLqEbnsKKvh0rCmLa/Pz+/e+ZobvjW0XfrsIk3NbQ4NsUyrboHDGNNuLHAcumIJHPbkuDHGmJhY4DDGtKvDoRWjq4n1v5kFDmNMu0lNTaW0tNSCxyFEVSktLSU1tfW5xsLZqCpjTLsZMGAABQUF7Nq1q6OzYmKQmprKgAEDot7fAocxpt0kJyczdOjQjs6GiTNrqjLGGBMTCxzGGGNiYoHDGGNMTA6LBwBFZBewvxO05AK72zE7hwIr8+HBynx4OJAyD1bVvKaJh0XgOBAisiTSk5NdmZX58GBlPjzEo8zWVGWMMSYmFjiMMcbExAJH257q6Ax0ACvz4cHKfHho9zJbH4cxxpiYWI3DGGNMTCxwGGOMiYkFjlaIyBQRWS8iG0Vkdkfnp72IyBwRKRGRVWFpOSLyrohscD+zw7b92P0O1ovItzsm1/tPRAaKyAIRWSsiq0Xkdje9K5c5VUS+EJEVbpnvc9O7bJkDRCRRRL4UkTfc9S5dZhHZKiJfichyEVnipsW3zKpqfxH+gERgEzAM8AArgKM7Ol/tVLbTgPHAqrC03wKz3eXZwG/c5aPdsqcAQ93vJLGjyxBjefsC493lLOBrt1xducwCZLrLycAi4MSuXOawst8F/A14w13v0mUGtgK5TdLiWmarcbRsIrBRVTeraj3wAjCtg/PULlT1Q2BPk+RpwHPu8nPAhWHpL6hqnapuATbifDeHDFUtUtVl7nIlsBboT9cus6pqlbua7P4pXbjMACIyAPgO8ExYcpcucwviWmYLHC3rD2wPWy9w07qq3qpaBM6NFujlpnep70FEhgDjcH6Bd+kyu002y4ES4F1V7fJlBh4G/gvwh6V19TIr8I6ILBWRmW5aXMts7+NomURIOxzHLneZ70FEMoFXgTtUtUIkUtGcXSOkHXJlVlUfMFZEegDzROSYVnY/5MssIucBJaq6VEQmRXNIhLRDqsyuU1S1UER6Ae+KyLpW9m2XMluNo2UFwMCw9QFAYQfl5WAoFpG+AO5niZveJb4HEUnGCRpzVfXvbnKXLnOAqpYBC4EpdO0ynwJcICJbcZqWzxSRv9K1y4yqFrqfJcA8nKanuJbZAkfLFgMjRGSoiHiAGcDrHZyneHoduMZdvgZ4LSx9hoikiMhQYATwRQfkb7+JU7X4E7BWVR8M29SVy5zn1jQQkTTgLGAdXbjMqvpjVR2gqkNw/r3+W1WvoguXWUQyRCQrsAycA6wi3mXu6BEBnfkPOBdnBM4m4KcdnZ92LNfzQBHQgPML5AdAT+B9YIP7mRO2/0/d72A9MLWj878f5T0Vpzq+Elju/p3bxcs8BvjSLfMq4Gduepctc5PyTyI0qqrLlhln1OcK92914D4V7zLblCPGGGNiYk1VxhhjYmKBwxhjTEwscBhjjImJBQ5jjDExscBhjDEmJhY4jOnkRGRSYKZXYzoDCxzGGGNiYoHDmHYiIle578BYLiJ/dCcZrBKRB0RkmYi8LyJ57r5jReRzEVkpIvMC70sQkSNE5D33PRrLRGS4e/pMEXlFRNaJyFxpZaItY+LNAocx7UBERgGX4Uw4NxbwAVcCGcAyVR0PfAD83D3kz8DdqjoG+CosfS7wuKoeB5yM84Q/ODP63oHzPoVhOPMyGdMhbHZcY9rHZGACsNitDKThTCznB1509/kr8HcR6Q70UNUP3PTngJfdOYf6q+o8AFWtBXDP94WqFrjry4EhwMdxL5UxEVjgMKZ9CPCcqv64UaLIPU32a22On9aan+rCln3Yv13Tgaypypj28T4w3X0nQuCdz4Nx/o1Nd/e5AvhYVcuBvSLyLTf9e8AHqloBFIjIhe45UkQk/WAWwpho2K8WY9qBqq4Rkf+H8ya2BJyZh/8D2AeMFpGlQDlOPwg4U10/6QaGzcB1bvr3gD+KyC/cc1x6EIthTFRsdlxj4khEqlQ1s6PzYUx7sqYqY4wxMbEahzHGmJhYjcMYY0xMLHAYY4yJiQUOY4wxMbHAYYwxJiYWOIwxxsTk/wNQMV1NTy9gwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5497\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5718\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 0s 4ms/step\n",
      "[[ 0.4]\n",
      " [ 0.4]\n",
      " [ 0.5]\n",
      " [ 0.4]\n",
      " [ 0.4]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "0.008375209380234505\n",
      "0.016583747927031506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.5]\n",
      " [ 0.4]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.014314928425357873\n",
      "0.028169014084507043\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
