{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  1.8  80.5 ...  2.7  0.9  0.0]\n",
      " [ 0.0  4.6  239.2 ...  4.9  0.9  0.0]\n",
      " [ 0.0  16.4  1199.6 ...  3.9  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  13.4  1030.7 ...  3.9  1.0  0.0]\n",
      " [ 0.0  9.6  700.2 ...  4.4  1.0  0.0]\n",
      " [ 0.0  4.6  459.4 ...  5.4  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  80.5  9.0 ...  0.1  0.6  2.7]\n",
      " [ 0.0  239.2  15.5 ...  0.1  0.5  4.9]\n",
      " [ 0.0  1199.6  34.6 ...  0.1  0.5  3.9]\n",
      " ...\n",
      " [ 0.0  1030.7  32.1 ...  0.1  0.6  3.9]\n",
      " [ 0.0  700.2  26.5 ...  0.1  0.5  4.4]\n",
      " [ 0.0  459.4  21.4 ...  0.1  0.6  5.4]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 149.7261 - accuracy: 0.5486 - val_loss: 111.8924 - val_accuracy: 0.5656\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 96.8208 - accuracy: 0.5573 - val_loss: 73.7281 - val_accuracy: 0.5691\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 64.5029 - accuracy: 0.5733 - val_loss: 47.1460 - val_accuracy: 0.5842\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 38.7761 - accuracy: 0.5714 - val_loss: 25.6884 - val_accuracy: 0.5904\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 18.7341 - accuracy: 0.5702 - val_loss: 9.8395 - val_accuracy: 0.5957\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 5.1574 - accuracy: 0.5273 - val_loss: 1.2830 - val_accuracy: 0.4397\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.4423 - val_loss: 0.7459 - val_accuracy: 0.4379\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7320 - accuracy: 0.4510 - val_loss: 0.7316 - val_accuracy: 0.4371\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7189 - accuracy: 0.4525 - val_loss: 0.7202 - val_accuracy: 0.4379\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.4537 - val_loss: 0.7109 - val_accuracy: 0.4379\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7011 - accuracy: 0.4537 - val_loss: 0.7040 - val_accuracy: 0.4371\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.4533 - val_loss: 0.6969 - val_accuracy: 0.4388\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.4548 - val_loss: 0.6907 - val_accuracy: 0.4388\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.4886 - val_loss: 0.6854 - val_accuracy: 0.5807\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.5657 - val_loss: 0.6827 - val_accuracy: 0.5816\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.5691 - val_loss: 0.6789 - val_accuracy: 0.5904\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5778 - val_loss: 0.6733 - val_accuracy: 0.5904\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.5862 - val_loss: 0.6637 - val_accuracy: 0.6020\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6559 - accuracy: 0.6086 - val_loss: 0.6359 - val_accuracy: 0.6605\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6617 - val_loss: 0.5521 - val_accuracy: 0.6622\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7942 - val_loss: 0.4576 - val_accuracy: 0.8520\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8333 - val_loss: 0.5354 - val_accuracy: 0.7110\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8512 - val_loss: 0.4266 - val_accuracy: 0.8271\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8561 - val_loss: 0.4101 - val_accuracy: 0.8298\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8614 - val_loss: 0.4497 - val_accuracy: 0.8431\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8618 - val_loss: 0.3975 - val_accuracy: 0.8670\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8599 - val_loss: 0.3961 - val_accuracy: 0.8688\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8664 - val_loss: 0.3662 - val_accuracy: 0.8732\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8743 - val_loss: 0.3924 - val_accuracy: 0.8644\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8740 - val_loss: 0.6433 - val_accuracy: 0.7119\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8762 - val_loss: 0.3072 - val_accuracy: 0.8918\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8808 - val_loss: 0.3028 - val_accuracy: 0.8892\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8823 - val_loss: 0.6124 - val_accuracy: 0.7358\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8793 - val_loss: 0.3202 - val_accuracy: 0.8856\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8759 - val_loss: 0.2869 - val_accuracy: 0.9043\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8823 - val_loss: 0.2849 - val_accuracy: 0.9043\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8834 - val_loss: 0.2897 - val_accuracy: 0.8963\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8861 - val_loss: 0.3334 - val_accuracy: 0.8466\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8823 - val_loss: 0.3856 - val_accuracy: 0.8183\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8880 - val_loss: 0.2866 - val_accuracy: 0.8759\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8907 - val_loss: 0.3424 - val_accuracy: 0.8395\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8895 - val_loss: 0.2599 - val_accuracy: 0.9087\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.8903 - val_loss: 0.2717 - val_accuracy: 0.8830\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8910 - val_loss: 0.2756 - val_accuracy: 0.8741\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8979 - val_loss: 0.2568 - val_accuracy: 0.8980\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.8986 - val_loss: 0.2479 - val_accuracy: 0.9087\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8956 - val_loss: 0.3591 - val_accuracy: 0.8555\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.8914 - val_loss: 0.2594 - val_accuracy: 0.9131\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.8971 - val_loss: 0.2366 - val_accuracy: 0.9113\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9021 - val_loss: 0.2295 - val_accuracy: 0.9229\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9028 - val_loss: 0.2867 - val_accuracy: 0.8599\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9032 - val_loss: 0.2226 - val_accuracy: 0.9273\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9017 - val_loss: 0.2227 - val_accuracy: 0.9176\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.8990 - val_loss: 0.2166 - val_accuracy: 0.9255\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9032 - val_loss: 0.3018 - val_accuracy: 0.8546\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2241 - accuracy: 0.9119 - val_loss: 0.2342 - val_accuracy: 0.9193\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9085 - val_loss: 0.2049 - val_accuracy: 0.9317\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9157 - val_loss: 0.2996 - val_accuracy: 0.8511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9070 - val_loss: 0.2088 - val_accuracy: 0.9317\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.9119 - val_loss: 0.3140 - val_accuracy: 0.8768\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.9157 - val_loss: 0.1956 - val_accuracy: 0.9379\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9184 - val_loss: 0.2769 - val_accuracy: 0.8892\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9161 - val_loss: 0.2178 - val_accuracy: 0.8980\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9150 - val_loss: 0.2054 - val_accuracy: 0.9335\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9195 - val_loss: 0.2023 - val_accuracy: 0.9317\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9180 - val_loss: 0.2652 - val_accuracy: 0.8715\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9244 - val_loss: 0.2062 - val_accuracy: 0.9034\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9180 - val_loss: 0.2731 - val_accuracy: 0.8670\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9188 - val_loss: 0.1748 - val_accuracy: 0.9424\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9252 - val_loss: 0.2243 - val_accuracy: 0.8892\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9233 - val_loss: 0.1951 - val_accuracy: 0.9344\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9226 - val_loss: 0.1676 - val_accuracy: 0.9441\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9248 - val_loss: 0.1667 - val_accuracy: 0.9477\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9260 - val_loss: 0.1794 - val_accuracy: 0.9468\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9317 - val_loss: 0.2581 - val_accuracy: 0.9007\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9309 - val_loss: 0.1762 - val_accuracy: 0.9255\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.9298 - val_loss: 0.1666 - val_accuracy: 0.9530\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9332 - val_loss: 0.2144 - val_accuracy: 0.9211\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9286 - val_loss: 0.1754 - val_accuracy: 0.9220\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9320 - val_loss: 0.1520 - val_accuracy: 0.9495\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9332 - val_loss: 0.1578 - val_accuracy: 0.9548\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9377 - val_loss: 0.1644 - val_accuracy: 0.9495\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9320 - val_loss: 0.1472 - val_accuracy: 0.9539\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9339 - val_loss: 0.1682 - val_accuracy: 0.9300\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9393 - val_loss: 0.2130 - val_accuracy: 0.9149\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9408 - val_loss: 0.4436 - val_accuracy: 0.8475\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9393 - val_loss: 0.2547 - val_accuracy: 0.9007\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9351 - val_loss: 0.2100 - val_accuracy: 0.9176\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1669 - accuracy: 0.9400 - val_loss: 0.2034 - val_accuracy: 0.9202\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9450 - val_loss: 0.2409 - val_accuracy: 0.9078\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9434 - val_loss: 0.2336 - val_accuracy: 0.8892\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9389 - val_loss: 0.1458 - val_accuracy: 0.9433\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9446 - val_loss: 0.2381 - val_accuracy: 0.9087\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9396 - val_loss: 0.1693 - val_accuracy: 0.9255\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9370 - val_loss: 0.1975 - val_accuracy: 0.9229\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9484 - val_loss: 0.3604 - val_accuracy: 0.8360\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9389 - val_loss: 0.1439 - val_accuracy: 0.9397\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9461 - val_loss: 0.1741 - val_accuracy: 0.9371\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9446 - val_loss: 0.3336 - val_accuracy: 0.8821\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9434 - val_loss: 0.1192 - val_accuracy: 0.9628\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9480 - val_loss: 0.2950 - val_accuracy: 0.8936\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9461 - val_loss: 0.1191 - val_accuracy: 0.9663\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9487 - val_loss: 0.1533 - val_accuracy: 0.9539\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9442 - val_loss: 0.2266 - val_accuracy: 0.9149\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9476 - val_loss: 0.1254 - val_accuracy: 0.9663\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9514 - val_loss: 0.1177 - val_accuracy: 0.9681\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9506 - val_loss: 0.1617 - val_accuracy: 0.9317\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9461 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9468 - val_loss: 0.1818 - val_accuracy: 0.9273\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9476 - val_loss: 0.1229 - val_accuracy: 0.9486\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9525 - val_loss: 0.1068 - val_accuracy: 0.9707\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9533 - val_loss: 0.1192 - val_accuracy: 0.9690\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9514 - val_loss: 0.1191 - val_accuracy: 0.9690\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9450 - val_loss: 0.5858 - val_accuracy: 0.7952\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9522 - val_loss: 0.1156 - val_accuracy: 0.9699\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9518 - val_loss: 0.4134 - val_accuracy: 0.8271\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9548 - val_loss: 0.1035 - val_accuracy: 0.9672\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.0996 - val_accuracy: 0.9707\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9525 - val_loss: 0.1320 - val_accuracy: 0.9619\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9506 - val_loss: 0.1429 - val_accuracy: 0.9548\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9552 - val_loss: 0.1349 - val_accuracy: 0.9566\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9541 - val_loss: 0.1946 - val_accuracy: 0.9273\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9522 - val_loss: 0.0964 - val_accuracy: 0.9716\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9575 - val_loss: 0.0959 - val_accuracy: 0.9725\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9510 - val_loss: 0.0940 - val_accuracy: 0.9725\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9567 - val_loss: 0.1285 - val_accuracy: 0.9459\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9567 - val_loss: 0.1371 - val_accuracy: 0.9574\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9575 - val_loss: 0.0980 - val_accuracy: 0.9734\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9575 - val_loss: 0.1707 - val_accuracy: 0.9282\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9575 - val_loss: 0.0941 - val_accuracy: 0.9734\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 0.1177 - val_accuracy: 0.9504\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9579 - val_loss: 0.0956 - val_accuracy: 0.9619\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9548 - val_loss: 0.0990 - val_accuracy: 0.9637\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9560 - val_loss: 0.2287 - val_accuracy: 0.9105\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9548 - val_loss: 0.2844 - val_accuracy: 0.8839\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9605 - val_loss: 0.0922 - val_accuracy: 0.9725\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9567 - val_loss: 0.1013 - val_accuracy: 0.9716\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9579 - val_loss: 0.1045 - val_accuracy: 0.9743\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9643 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9617 - val_loss: 0.2084 - val_accuracy: 0.9229\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9579 - val_loss: 0.1285 - val_accuracy: 0.9601\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9647 - val_loss: 0.0918 - val_accuracy: 0.9743\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9575 - val_loss: 0.1058 - val_accuracy: 0.9699\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9601 - val_loss: 0.1011 - val_accuracy: 0.9725\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9601 - val_loss: 0.1105 - val_accuracy: 0.9663\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9601 - val_loss: 0.2414 - val_accuracy: 0.9096\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9598 - val_loss: 0.1665 - val_accuracy: 0.9388\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9582 - val_loss: 0.0968 - val_accuracy: 0.9743\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9605 - val_loss: 0.1717 - val_accuracy: 0.9362\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9620 - val_loss: 0.0796 - val_accuracy: 0.9752\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9594 - val_loss: 0.1487 - val_accuracy: 0.9362\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1124 - accuracy: 0.9575 - val_loss: 0.1379 - val_accuracy: 0.9433\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 0.0985 - val_accuracy: 0.9743\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9651 - val_loss: 0.1805 - val_accuracy: 0.9255\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9582 - val_loss: 0.2834 - val_accuracy: 0.8936\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9624 - val_loss: 0.1510 - val_accuracy: 0.9433\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9605 - val_loss: 0.0894 - val_accuracy: 0.9663\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9620 - val_loss: 0.1230 - val_accuracy: 0.9557\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9605 - val_loss: 0.3381 - val_accuracy: 0.8785\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9601 - val_loss: 0.1069 - val_accuracy: 0.9672\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9636 - val_loss: 0.1135 - val_accuracy: 0.9663\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9643 - val_loss: 0.1199 - val_accuracy: 0.9583\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9624 - val_loss: 0.1597 - val_accuracy: 0.9406\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9620 - val_loss: 0.0758 - val_accuracy: 0.9778\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9594 - val_loss: 0.0948 - val_accuracy: 0.9628\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9613 - val_loss: 0.1195 - val_accuracy: 0.9601\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9624 - val_loss: 0.1152 - val_accuracy: 0.9539\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9643 - val_loss: 0.1418 - val_accuracy: 0.9441\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.9620 - val_loss: 0.1031 - val_accuracy: 0.9690\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9636 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9605 - val_loss: 0.0730 - val_accuracy: 0.9752\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9647 - val_loss: 0.1818 - val_accuracy: 0.9255\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9605 - val_loss: 0.1146 - val_accuracy: 0.9539\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9647 - val_loss: 0.2014 - val_accuracy: 0.9184\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9601 - val_loss: 0.1817 - val_accuracy: 0.9317\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9598 - val_loss: 0.1852 - val_accuracy: 0.9326\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9685 - val_loss: 0.0890 - val_accuracy: 0.9654\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9685 - val_loss: 0.0740 - val_accuracy: 0.9770\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0998 - accuracy: 0.9647 - val_loss: 0.1094 - val_accuracy: 0.9566\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9658 - val_loss: 0.4226 - val_accuracy: 0.8546\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9598 - val_loss: 0.0709 - val_accuracy: 0.9761\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.9674 - val_loss: 0.3343 - val_accuracy: 0.8785\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9643 - val_loss: 0.0823 - val_accuracy: 0.9707\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 0.0685 - val_accuracy: 0.9778\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9647 - val_loss: 0.0785 - val_accuracy: 0.9734\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.1085 - val_accuracy: 0.9566\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9639 - val_loss: 0.2253 - val_accuracy: 0.9140\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9628 - val_loss: 0.1117 - val_accuracy: 0.9548\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9639 - val_loss: 0.3243 - val_accuracy: 0.8821\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.1074 - val_accuracy: 0.9645\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9624 - val_loss: 0.3084 - val_accuracy: 0.8892\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9708 - val_loss: 0.3626 - val_accuracy: 0.8732\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9655 - val_loss: 0.1022 - val_accuracy: 0.9592\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9639 - val_loss: 0.0695 - val_accuracy: 0.9752\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9655 - val_loss: 0.0723 - val_accuracy: 0.9814\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9696 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9632 - val_loss: 0.0662 - val_accuracy: 0.9778\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9689 - val_loss: 0.0659 - val_accuracy: 0.9796\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.0704 - val_accuracy: 0.9743\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9639 - val_loss: 0.0735 - val_accuracy: 0.9796\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9658 - val_loss: 0.1581 - val_accuracy: 0.9388\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9620 - val_loss: 0.0648 - val_accuracy: 0.9814\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9617 - val_loss: 0.0657 - val_accuracy: 0.9805\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9689 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9685 - val_loss: 0.0755 - val_accuracy: 0.9734\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9632 - val_loss: 0.1012 - val_accuracy: 0.9690\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9647 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9674 - val_loss: 0.0640 - val_accuracy: 0.9805\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9632 - val_loss: 0.0650 - val_accuracy: 0.9796\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9674 - val_loss: 0.1051 - val_accuracy: 0.9654\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9651 - val_loss: 0.1743 - val_accuracy: 0.9326\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9704 - val_loss: 0.0938 - val_accuracy: 0.9619\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9704 - val_loss: 0.0907 - val_accuracy: 0.9637\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0934 - accuracy: 0.9662 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9704 - val_loss: 0.0928 - val_accuracy: 0.9619\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9681 - val_loss: 0.0738 - val_accuracy: 0.9734\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9662 - val_loss: 0.0626 - val_accuracy: 0.9796\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9666 - val_loss: 0.0885 - val_accuracy: 0.9699\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9677 - val_loss: 0.0825 - val_accuracy: 0.9752\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9677 - val_loss: 0.0826 - val_accuracy: 0.9761\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9666 - val_loss: 0.0637 - val_accuracy: 0.9778\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9670 - val_loss: 0.2014 - val_accuracy: 0.9238\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.1177 - val_accuracy: 0.9557\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.0754 - val_accuracy: 0.9787\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9662 - val_loss: 0.1738 - val_accuracy: 0.9344\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9696 - val_loss: 0.0824 - val_accuracy: 0.9752\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9689 - val_loss: 0.0716 - val_accuracy: 0.9743\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9685 - val_loss: 0.0897 - val_accuracy: 0.9707\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9655 - val_loss: 0.0731 - val_accuracy: 0.9805\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 0.0697 - val_accuracy: 0.9752\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9696 - val_loss: 0.0766 - val_accuracy: 0.9770\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9738 - val_loss: 0.0640 - val_accuracy: 0.9778\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0902 - accuracy: 0.9700 - val_loss: 0.0755 - val_accuracy: 0.9787\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9711 - val_loss: 0.1421 - val_accuracy: 0.9486\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9670 - val_loss: 0.1024 - val_accuracy: 0.9574\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9738 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9658 - val_loss: 0.3534 - val_accuracy: 0.8910\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9689 - val_loss: 0.0620 - val_accuracy: 0.9796\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0905 - accuracy: 0.9704 - val_loss: 0.6150 - val_accuracy: 0.8395\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9670 - val_loss: 0.3071 - val_accuracy: 0.8901\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9674 - val_loss: 0.1708 - val_accuracy: 0.9379\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9692 - val_loss: 0.0655 - val_accuracy: 0.9823\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9685 - val_loss: 0.0728 - val_accuracy: 0.9743\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9692 - val_loss: 0.0598 - val_accuracy: 0.9805\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9715 - val_loss: 0.1327 - val_accuracy: 0.9468\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9708 - val_loss: 0.1268 - val_accuracy: 0.9495\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0912 - accuracy: 0.9711 - val_loss: 0.0795 - val_accuracy: 0.9761\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0904 - accuracy: 0.9677 - val_loss: 0.0628 - val_accuracy: 0.9778\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9708 - val_loss: 0.0604 - val_accuracy: 0.9805\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.0869 - val_accuracy: 0.9681\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0925 - accuracy: 0.9711 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0856 - accuracy: 0.9696 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0898 - accuracy: 0.9719 - val_loss: 0.0585 - val_accuracy: 0.9823\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0921 - accuracy: 0.9692 - val_loss: 0.0615 - val_accuracy: 0.9796\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0893 - accuracy: 0.9692 - val_loss: 0.0582 - val_accuracy: 0.9823\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0924 - accuracy: 0.9692 - val_loss: 0.0587 - val_accuracy: 0.9823\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0894 - accuracy: 0.9696 - val_loss: 0.1137 - val_accuracy: 0.9566\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.2704 - val_accuracy: 0.8989\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0867 - accuracy: 0.9761 - val_loss: 0.0683 - val_accuracy: 0.9761\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.9670 - val_loss: 0.0577 - val_accuracy: 0.9823\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0909 - accuracy: 0.9681 - val_loss: 0.0742 - val_accuracy: 0.9725\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0881 - accuracy: 0.9708 - val_loss: 0.0581 - val_accuracy: 0.9814\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 0.0907 - val_accuracy: 0.9690\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0835 - accuracy: 0.9708 - val_loss: 0.0578 - val_accuracy: 0.9832\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0872 - accuracy: 0.9677 - val_loss: 0.0674 - val_accuracy: 0.9805\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0891 - accuracy: 0.9727 - val_loss: 0.1053 - val_accuracy: 0.9610\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0859 - accuracy: 0.9681 - val_loss: 0.1220 - val_accuracy: 0.9539\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.3677 - val_accuracy: 0.8697\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9708 - val_loss: 0.1003 - val_accuracy: 0.9637\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0916 - accuracy: 0.9723 - val_loss: 0.0880 - val_accuracy: 0.9672\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0852 - accuracy: 0.9723 - val_loss: 0.0799 - val_accuracy: 0.9716\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9647 - val_loss: 0.0675 - val_accuracy: 0.9814\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9715 - val_loss: 0.1535 - val_accuracy: 0.9450\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9704 - val_loss: 0.0629 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9674 - val_loss: 0.1444 - val_accuracy: 0.9441\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9696 - val_loss: 0.2929 - val_accuracy: 0.8945\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0885 - accuracy: 0.9708 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0833 - accuracy: 0.9715 - val_loss: 0.1398 - val_accuracy: 0.9504\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9692 - val_loss: 0.2669 - val_accuracy: 0.8998\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9681 - val_loss: 0.0599 - val_accuracy: 0.9787\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9685 - val_loss: 0.1885 - val_accuracy: 0.9326\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0861 - accuracy: 0.9711 - val_loss: 0.1791 - val_accuracy: 0.9344\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9692 - val_loss: 0.0577 - val_accuracy: 0.9823\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 0.2518 - val_accuracy: 0.9078\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0879 - accuracy: 0.9715 - val_loss: 0.0633 - val_accuracy: 0.9778\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0815 - accuracy: 0.9723 - val_loss: 0.0570 - val_accuracy: 0.9832\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9689 - val_loss: 0.2130 - val_accuracy: 0.9273\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.0715 - val_accuracy: 0.9743\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.3682 - val_accuracy: 0.8723\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9708 - val_loss: 0.0606 - val_accuracy: 0.9778\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9723 - val_loss: 0.0635 - val_accuracy: 0.9823\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9730 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9723 - val_loss: 0.0570 - val_accuracy: 0.9814\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 0.0593 - val_accuracy: 0.9787\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9689 - val_loss: 0.0561 - val_accuracy: 0.9840\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9692 - val_loss: 0.1014 - val_accuracy: 0.9601\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9715 - val_loss: 0.1599 - val_accuracy: 0.9397\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9711 - val_loss: 0.1738 - val_accuracy: 0.9353\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9734 - val_loss: 0.0624 - val_accuracy: 0.9823\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9738 - val_loss: 0.0561 - val_accuracy: 0.9814\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9727 - val_loss: 0.0676 - val_accuracy: 0.9761\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9715 - val_loss: 0.0569 - val_accuracy: 0.9814\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9711 - val_loss: 0.0895 - val_accuracy: 0.9681\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9749 - val_loss: 0.0866 - val_accuracy: 0.9699\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0866 - accuracy: 0.9715 - val_loss: 0.0917 - val_accuracy: 0.9654\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0861 - accuracy: 0.9704 - val_loss: 0.0876 - val_accuracy: 0.9699\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9666 - val_loss: 0.0553 - val_accuracy: 0.9832\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9696 - val_loss: 0.0578 - val_accuracy: 0.9805\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0921 - accuracy: 0.9674 - val_loss: 0.0645 - val_accuracy: 0.9770\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9700 - val_loss: 0.0743 - val_accuracy: 0.9761\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9708 - val_loss: 0.0621 - val_accuracy: 0.9823\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9700 - val_loss: 0.0577 - val_accuracy: 0.9796\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9704 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.0845 - val_accuracy: 0.9699\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9708 - val_loss: 0.1014 - val_accuracy: 0.9628\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9696 - val_loss: 0.0565 - val_accuracy: 0.9823\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9655 - val_loss: 0.0673 - val_accuracy: 0.9770\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9696 - val_loss: 0.0775 - val_accuracy: 0.9734\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.0554 - val_accuracy: 0.9849\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9723 - val_loss: 0.0901 - val_accuracy: 0.9690\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9704 - val_loss: 0.0565 - val_accuracy: 0.9814\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9719 - val_loss: 0.2217 - val_accuracy: 0.9255\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9708 - val_loss: 0.1088 - val_accuracy: 0.9583\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9723 - val_loss: 0.6003 - val_accuracy: 0.8333\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9692 - val_loss: 0.1247 - val_accuracy: 0.9521\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9708 - val_loss: 0.0864 - val_accuracy: 0.9681\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9696 - val_loss: 0.1685 - val_accuracy: 0.9441\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9689 - val_loss: 0.1157 - val_accuracy: 0.9574\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0906 - accuracy: 0.9696 - val_loss: 0.0774 - val_accuracy: 0.9734\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9715 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0835 - accuracy: 0.9711 - val_loss: 0.1570 - val_accuracy: 0.9459\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0820 - accuracy: 0.9700 - val_loss: 0.0691 - val_accuracy: 0.9752\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0867 - accuracy: 0.9704 - val_loss: 0.1339 - val_accuracy: 0.9530\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0869 - accuracy: 0.9708 - val_loss: 0.0539 - val_accuracy: 0.9832\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9734 - val_loss: 0.1699 - val_accuracy: 0.9362\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9742 - val_loss: 0.0721 - val_accuracy: 0.9752\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9719 - val_loss: 0.2915 - val_accuracy: 0.8963\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9711 - val_loss: 0.0899 - val_accuracy: 0.9690\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.0872 - val_accuracy: 0.9716\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.4350 - val_accuracy: 0.8626\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9689 - val_loss: 0.0547 - val_accuracy: 0.9840\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9670 - val_loss: 0.0569 - val_accuracy: 0.9787\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9711 - val_loss: 0.0998 - val_accuracy: 0.9637\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0809 - accuracy: 0.9723 - val_loss: 0.0562 - val_accuracy: 0.9796\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0839 - accuracy: 0.9719 - val_loss: 0.0878 - val_accuracy: 0.9690\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0851 - accuracy: 0.9708 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 0.1521 - val_accuracy: 0.9433\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0864 - accuracy: 0.9696 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 0.0772 - val_accuracy: 0.9725\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9730 - val_loss: 0.0619 - val_accuracy: 0.9770\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0917 - accuracy: 0.9711 - val_loss: 0.0577 - val_accuracy: 0.9805\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0905 - accuracy: 0.9696 - val_loss: 0.0552 - val_accuracy: 0.9832\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9723 - val_loss: 0.0826 - val_accuracy: 0.9725\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 0.0954 - val_accuracy: 0.9663\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0863 - accuracy: 0.9719 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0798 - accuracy: 0.9742 - val_loss: 0.2198 - val_accuracy: 0.9282\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9708 - val_loss: 0.0863 - val_accuracy: 0.9716\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9723 - val_loss: 0.1378 - val_accuracy: 0.9459\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9730 - val_loss: 0.1537 - val_accuracy: 0.9486\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9696 - val_loss: 0.0756 - val_accuracy: 0.9725\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 0.0596 - val_accuracy: 0.9814\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9696 - val_loss: 0.0713 - val_accuracy: 0.9743\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9742 - val_loss: 0.1249 - val_accuracy: 0.9521\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9685 - val_loss: 0.0797 - val_accuracy: 0.9743\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9696 - val_loss: 0.0789 - val_accuracy: 0.9716\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9708 - val_loss: 0.0580 - val_accuracy: 0.9778\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9746 - val_loss: 0.0993 - val_accuracy: 0.9628\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9708 - val_loss: 0.1138 - val_accuracy: 0.9557\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9730 - val_loss: 0.0701 - val_accuracy: 0.9743\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9749 - val_loss: 0.1042 - val_accuracy: 0.9592\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9700 - val_loss: 0.2784 - val_accuracy: 0.9007\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9727 - val_loss: 0.0536 - val_accuracy: 0.9823\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9692 - val_loss: 0.0648 - val_accuracy: 0.9761\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9727 - val_loss: 0.0561 - val_accuracy: 0.9787\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9746 - val_loss: 0.0719 - val_accuracy: 0.9752\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9696 - val_loss: 0.0585 - val_accuracy: 0.9778\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0859 - accuracy: 0.9704 - val_loss: 0.0566 - val_accuracy: 0.9796\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9700 - val_loss: 0.0748 - val_accuracy: 0.9743\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9746 - val_loss: 0.0653 - val_accuracy: 0.9761\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 0.0707 - val_accuracy: 0.9770\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9674 - val_loss: 0.1019 - val_accuracy: 0.9601\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9674 - val_loss: 0.0828 - val_accuracy: 0.9725\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9700 - val_loss: 0.0546 - val_accuracy: 0.9832\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9746 - val_loss: 0.0587 - val_accuracy: 0.9805\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9715 - val_loss: 0.0616 - val_accuracy: 0.9770\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9719 - val_loss: 0.0597 - val_accuracy: 0.9814\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9692 - val_loss: 0.0612 - val_accuracy: 0.9814\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9723 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.0591 - val_accuracy: 0.9778\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 0.0547 - val_accuracy: 0.9805\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9727 - val_loss: 0.0574 - val_accuracy: 0.9796\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 0.1191 - val_accuracy: 0.9557\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.2212 - val_accuracy: 0.9282\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 0.0622 - val_accuracy: 0.9805\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9696 - val_loss: 0.0578 - val_accuracy: 0.9787\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9708 - val_loss: 0.0664 - val_accuracy: 0.9761\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 0.1550 - val_accuracy: 0.9415\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9692 - val_loss: 0.0550 - val_accuracy: 0.9805\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9692 - val_loss: 0.0707 - val_accuracy: 0.9752\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9674 - val_loss: 0.0533 - val_accuracy: 0.9823\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9723 - val_loss: 0.0530 - val_accuracy: 0.9840\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9711 - val_loss: 0.0549 - val_accuracy: 0.9805\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.1337 - val_accuracy: 0.9459\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9734 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9734 - val_loss: 0.2208 - val_accuracy: 0.9264\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9715 - val_loss: 0.1671 - val_accuracy: 0.9441\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0888 - accuracy: 0.9704 - val_loss: 0.2734 - val_accuracy: 0.9238\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9727 - val_loss: 0.0908 - val_accuracy: 0.9681\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0818 - accuracy: 0.9704 - val_loss: 0.0666 - val_accuracy: 0.9778\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.0624 - val_accuracy: 0.9778\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0894 - accuracy: 0.9689 - val_loss: 0.0548 - val_accuracy: 0.9796\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9681 - val_loss: 0.0552 - val_accuracy: 0.9805\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0768 - accuracy: 0.9727 - val_loss: 0.0531 - val_accuracy: 0.9823\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9727 - val_loss: 0.0561 - val_accuracy: 0.9796\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0756 - val_accuracy: 0.9761\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9685 - val_loss: 0.0530 - val_accuracy: 0.9858\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9746 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9711 - val_loss: 0.0897 - val_accuracy: 0.9654\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9746 - val_loss: 0.0755 - val_accuracy: 0.9734\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9715 - val_loss: 0.0831 - val_accuracy: 0.9716\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9708 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9715 - val_loss: 0.0554 - val_accuracy: 0.9805\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9738 - val_loss: 0.0536 - val_accuracy: 0.9805\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9704 - val_loss: 0.0686 - val_accuracy: 0.9770\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0854 - accuracy: 0.9700 - val_loss: 0.0887 - val_accuracy: 0.9690\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9685 - val_loss: 0.0677 - val_accuracy: 0.9752\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9704 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9704 - val_loss: 0.0527 - val_accuracy: 0.9858\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9738 - val_loss: 0.0890 - val_accuracy: 0.9672\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9719 - val_loss: 0.1860 - val_accuracy: 0.9335\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9708 - val_loss: 0.0873 - val_accuracy: 0.9716\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9784 - val_loss: 0.1114 - val_accuracy: 0.9583\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9696 - val_loss: 0.0845 - val_accuracy: 0.9716\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9742 - val_loss: 0.0578 - val_accuracy: 0.9778\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9723 - val_loss: 0.1921 - val_accuracy: 0.9317\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0871 - accuracy: 0.9734 - val_loss: 0.0957 - val_accuracy: 0.9663\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9696 - val_loss: 0.1166 - val_accuracy: 0.9566\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0762 - accuracy: 0.9730 - val_loss: 0.2135 - val_accuracy: 0.9273\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.0814 - accuracy: 0.9715 - val_loss: 0.0571 - val_accuracy: 0.9814\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0789 - accuracy: 0.9742 - val_loss: 0.0584 - val_accuracy: 0.9778\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0856 - accuracy: 0.9696 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0807 - accuracy: 0.9708 - val_loss: 0.1039 - val_accuracy: 0.9619\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0845 - accuracy: 0.9704 - val_loss: 0.3049 - val_accuracy: 0.8927\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0772 - accuracy: 0.9757 - val_loss: 0.0535 - val_accuracy: 0.9832\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 0.0761 - val_accuracy: 0.9743\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0795 - accuracy: 0.9727 - val_loss: 0.0535 - val_accuracy: 0.9805\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9734 - val_loss: 0.1422 - val_accuracy: 0.9433\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0845 - accuracy: 0.9742 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0857 - accuracy: 0.9708 - val_loss: 0.0525 - val_accuracy: 0.9832\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0778 - accuracy: 0.9742 - val_loss: 0.0529 - val_accuracy: 0.9858\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0829 - accuracy: 0.9730 - val_loss: 0.0647 - val_accuracy: 0.9761\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0826 - accuracy: 0.9730 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0897 - accuracy: 0.9696 - val_loss: 0.0609 - val_accuracy: 0.9778\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0834 - accuracy: 0.9715 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0832 - accuracy: 0.9708 - val_loss: 0.0633 - val_accuracy: 0.9778\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0732 - accuracy: 0.9761 - val_loss: 0.1449 - val_accuracy: 0.9433\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9730 - val_loss: 0.0720 - val_accuracy: 0.9770\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.0928 - val_accuracy: 0.9663\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0809 - val_accuracy: 0.9725\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0790 - accuracy: 0.9727 - val_loss: 0.0529 - val_accuracy: 0.9805\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9757 - val_loss: 0.0945 - val_accuracy: 0.9663\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0831 - accuracy: 0.9692 - val_loss: 0.0700 - val_accuracy: 0.9770\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0795 - accuracy: 0.9734 - val_loss: 0.0951 - val_accuracy: 0.9654\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.9727 - val_loss: 0.0848 - val_accuracy: 0.9716\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0850 - accuracy: 0.9715 - val_loss: 0.0537 - val_accuracy: 0.9796\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 0.0791 - val_accuracy: 0.9725\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9749 - val_loss: 0.0523 - val_accuracy: 0.9858\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0790 - accuracy: 0.9738 - val_loss: 0.0529 - val_accuracy: 0.9823\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9715 - val_loss: 0.0678 - val_accuracy: 0.9770\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9730 - val_loss: 0.1491 - val_accuracy: 0.9433\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9719 - val_loss: 0.0935 - val_accuracy: 0.9663\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0788 - accuracy: 0.9730 - val_loss: 0.0928 - val_accuracy: 0.9672\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 0.0547 - val_accuracy: 0.9805\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0837 - accuracy: 0.9727 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0756 - accuracy: 0.9734 - val_loss: 0.0811 - val_accuracy: 0.9725\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0791 - accuracy: 0.9700 - val_loss: 0.0627 - val_accuracy: 0.9770\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0831 - accuracy: 0.9727 - val_loss: 0.1224 - val_accuracy: 0.9566\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0807 - accuracy: 0.9704 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9715 - val_loss: 0.0547 - val_accuracy: 0.9796\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0845 - accuracy: 0.9704 - val_loss: 0.0721 - val_accuracy: 0.9761\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 0.0528 - val_accuracy: 0.9823\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0840 - accuracy: 0.9723 - val_loss: 0.1550 - val_accuracy: 0.9495\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0761 - accuracy: 0.9715 - val_loss: 0.0661 - val_accuracy: 0.9778\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0757 - accuracy: 0.9749 - val_loss: 0.0923 - val_accuracy: 0.9672\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0828 - accuracy: 0.9708 - val_loss: 0.0730 - val_accuracy: 0.9761\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 0.0774 - val_accuracy: 0.9725\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0542 - val_accuracy: 0.9796\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0830 - accuracy: 0.9738 - val_loss: 0.0519 - val_accuracy: 0.9832\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0820 - accuracy: 0.9742 - val_loss: 0.0527 - val_accuracy: 0.9849\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0804 - accuracy: 0.9708 - val_loss: 0.0524 - val_accuracy: 0.9858\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9749 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956178790534619\n",
      "0.9546218487394958\n",
      "0.9746889746889746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936708860759493\n",
      "0.9553752535496958\n",
      "0.9741468459152016\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
