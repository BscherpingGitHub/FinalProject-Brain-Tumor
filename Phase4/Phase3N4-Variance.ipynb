{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  11.3  593.6 ...  3.4  1.0  0.0]\n",
      " [ 0.0  5.5  444.8 ...  3.5  1.0  0.0]\n",
      " [ 0.0  6.8  239.0 ...  2.3  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  11.7  1671.1 ...  6.8  1.0  0.0]\n",
      " [ 1.0  8.1  790.7 ...  6.8  0.9  0.0]\n",
      " [ 0.0  10.0  654.4 ...  3.2  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 2]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 2]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470ddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "#model.add(Dense(4, input_dim = len(XTRAIN), activation = 'relu'))\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 13ms/step - loss: 9.5113 - accuracy: 0.4427 - val_loss: 5.1329 - val_accuracy: 0.4592\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.9269 - accuracy: 0.4446 - val_loss: 1.1064 - val_accuracy: 0.4530\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7694 - accuracy: 0.5027 - val_loss: 0.6697 - val_accuracy: 0.5638\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6716 - accuracy: 0.6116 - val_loss: 0.6665 - val_accuracy: 0.5727\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.6181 - val_loss: 0.6692 - val_accuracy: 0.6489\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6654 - accuracy: 0.6355 - val_loss: 0.6610 - val_accuracy: 0.5869\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6626 - accuracy: 0.6317 - val_loss: 0.6605 - val_accuracy: 0.6587\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6598 - accuracy: 0.6401 - val_loss: 0.6574 - val_accuracy: 0.6543\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6580 - accuracy: 0.6397 - val_loss: 0.6579 - val_accuracy: 0.6560\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6557 - accuracy: 0.6427 - val_loss: 0.6533 - val_accuracy: 0.6596\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6535 - accuracy: 0.6469 - val_loss: 0.6508 - val_accuracy: 0.6436\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6530 - accuracy: 0.6481 - val_loss: 0.6526 - val_accuracy: 0.6560\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6506 - accuracy: 0.6534 - val_loss: 0.6538 - val_accuracy: 0.6489\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6498 - accuracy: 0.6519 - val_loss: 0.6476 - val_accuracy: 0.6135\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6482 - accuracy: 0.6435 - val_loss: 0.6460 - val_accuracy: 0.6587\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6468 - accuracy: 0.6511 - val_loss: 0.6441 - val_accuracy: 0.6392\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6455 - accuracy: 0.6503 - val_loss: 0.6435 - val_accuracy: 0.6525\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6456 - accuracy: 0.6507 - val_loss: 0.6427 - val_accuracy: 0.6507\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6444 - accuracy: 0.6477 - val_loss: 0.6456 - val_accuracy: 0.6551\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6437 - accuracy: 0.6549 - val_loss: 0.6438 - val_accuracy: 0.6197\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6437 - accuracy: 0.6534 - val_loss: 0.6446 - val_accuracy: 0.6152\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6429 - accuracy: 0.6500 - val_loss: 0.6403 - val_accuracy: 0.6445\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6424 - accuracy: 0.6515 - val_loss: 0.6411 - val_accuracy: 0.6649\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6421 - accuracy: 0.6557 - val_loss: 0.6419 - val_accuracy: 0.6596\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6419 - accuracy: 0.6481 - val_loss: 0.6402 - val_accuracy: 0.6613\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6420 - accuracy: 0.6511 - val_loss: 0.6409 - val_accuracy: 0.6622\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6416 - accuracy: 0.6572 - val_loss: 0.6388 - val_accuracy: 0.6534\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6407 - accuracy: 0.6534 - val_loss: 0.6386 - val_accuracy: 0.6525\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6404 - accuracy: 0.6511 - val_loss: 0.6389 - val_accuracy: 0.6374\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6407 - accuracy: 0.6545 - val_loss: 0.6388 - val_accuracy: 0.6631\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6406 - accuracy: 0.6564 - val_loss: 0.6383 - val_accuracy: 0.6392\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6398 - accuracy: 0.6595 - val_loss: 0.6396 - val_accuracy: 0.6374\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6488 - val_loss: 0.6378 - val_accuracy: 0.6543\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6397 - accuracy: 0.6553 - val_loss: 0.6380 - val_accuracy: 0.6587\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6394 - accuracy: 0.6595 - val_loss: 0.6376 - val_accuracy: 0.6525\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6396 - accuracy: 0.6595 - val_loss: 0.6379 - val_accuracy: 0.6587\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6560 - val_loss: 0.6395 - val_accuracy: 0.6383\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6401 - accuracy: 0.6496 - val_loss: 0.6427 - val_accuracy: 0.6498\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6560 - val_loss: 0.6386 - val_accuracy: 0.6649\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6397 - accuracy: 0.6522 - val_loss: 0.6386 - val_accuracy: 0.6640\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6587 - val_loss: 0.6390 - val_accuracy: 0.6622\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.6602 - val_loss: 0.6382 - val_accuracy: 0.6649\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6534 - val_loss: 0.6378 - val_accuracy: 0.6622\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6378 - accuracy: 0.6606 - val_loss: 0.6554 - val_accuracy: 0.6383\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6595 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6399 - accuracy: 0.6568 - val_loss: 0.6372 - val_accuracy: 0.6543\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6564 - val_loss: 0.6388 - val_accuracy: 0.6622\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6538 - val_loss: 0.6376 - val_accuracy: 0.6631\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6386 - accuracy: 0.6530 - val_loss: 0.6507 - val_accuracy: 0.6436\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6372 - accuracy: 0.6576 - val_loss: 0.6419 - val_accuracy: 0.6285\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6595 - val_loss: 0.6371 - val_accuracy: 0.6543\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6568 - val_loss: 0.6375 - val_accuracy: 0.6454\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.6553 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6387 - accuracy: 0.6515 - val_loss: 0.6371 - val_accuracy: 0.6534\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6545 - val_loss: 0.6375 - val_accuracy: 0.6463\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6399 - accuracy: 0.6545 - val_loss: 0.6410 - val_accuracy: 0.6543\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6387 - accuracy: 0.6511 - val_loss: 0.6378 - val_accuracy: 0.6649\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6395 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6382 - accuracy: 0.6579 - val_loss: 0.6387 - val_accuracy: 0.6622\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6393 - accuracy: 0.6545 - val_loss: 0.6424 - val_accuracy: 0.6498\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6576 - val_loss: 0.6374 - val_accuracy: 0.6436\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6393 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6498\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.6557 - val_loss: 0.6500 - val_accuracy: 0.6445\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6530 - val_loss: 0.6438 - val_accuracy: 0.6472\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6617 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6557 - val_loss: 0.6446 - val_accuracy: 0.6489\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6399 - accuracy: 0.6557 - val_loss: 0.6405 - val_accuracy: 0.6560\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6568 - val_loss: 0.6382 - val_accuracy: 0.6383\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6572 - val_loss: 0.6411 - val_accuracy: 0.6543\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.6579 - val_loss: 0.6375 - val_accuracy: 0.6463\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.6534 - val_loss: 0.6373 - val_accuracy: 0.6587\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6598 - val_loss: 0.6387 - val_accuracy: 0.6622\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.6557 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6564 - val_loss: 0.6400 - val_accuracy: 0.6578\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6385 - accuracy: 0.6553 - val_loss: 0.6393 - val_accuracy: 0.6605\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6397 - accuracy: 0.6541 - val_loss: 0.6416 - val_accuracy: 0.6534\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6385 - accuracy: 0.6522 - val_loss: 0.6393 - val_accuracy: 0.6622\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6560 - val_loss: 0.6380 - val_accuracy: 0.6383\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.6572 - val_loss: 0.6373 - val_accuracy: 0.6480\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6507 - val_loss: 0.6418 - val_accuracy: 0.6516\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6560 - val_loss: 0.6391 - val_accuracy: 0.6596\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6534 - val_loss: 0.6387 - val_accuracy: 0.6613\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6394 - accuracy: 0.6549 - val_loss: 0.6387 - val_accuracy: 0.6374\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6534 - val_loss: 0.6403 - val_accuracy: 0.6569\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6587 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6541 - val_loss: 0.6383 - val_accuracy: 0.6383\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6617 - val_loss: 0.6406 - val_accuracy: 0.6560\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6400 - accuracy: 0.6545 - val_loss: 0.6389 - val_accuracy: 0.6613\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6549 - val_loss: 0.6441 - val_accuracy: 0.6472\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.6515 - val_loss: 0.6379 - val_accuracy: 0.6649\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6530 - val_loss: 0.6515 - val_accuracy: 0.6463\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6402 - accuracy: 0.6553 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6568 - val_loss: 0.6376 - val_accuracy: 0.6631\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6549 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6503 - val_loss: 0.6393 - val_accuracy: 0.6622\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6388 - accuracy: 0.6568 - val_loss: 0.6418 - val_accuracy: 0.6525\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6396 - accuracy: 0.6576 - val_loss: 0.6371 - val_accuracy: 0.6543\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6568 - val_loss: 0.6372 - val_accuracy: 0.6516\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.6522 - val_loss: 0.6429 - val_accuracy: 0.6489\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6383 - accuracy: 0.6557 - val_loss: 0.6462 - val_accuracy: 0.6463\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6399 - accuracy: 0.6549 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6386 - accuracy: 0.6598 - val_loss: 0.6372 - val_accuracy: 0.6596\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6389 - accuracy: 0.6534 - val_loss: 0.6446 - val_accuracy: 0.6480\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 0.6400 - accuracy: 0.6568 - val_loss: 0.6411 - val_accuracy: 0.6543\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6388 - accuracy: 0.6568 - val_loss: 0.6387 - val_accuracy: 0.6622\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6394 - accuracy: 0.6553 - val_loss: 0.6378 - val_accuracy: 0.6631\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6386 - accuracy: 0.6564 - val_loss: 0.6373 - val_accuracy: 0.6596\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6393 - accuracy: 0.6560 - val_loss: 0.6372 - val_accuracy: 0.6587\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6388 - accuracy: 0.6614 - val_loss: 0.6384 - val_accuracy: 0.6631\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6393 - accuracy: 0.6549 - val_loss: 0.6373 - val_accuracy: 0.6560\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6395 - accuracy: 0.6557 - val_loss: 0.6448 - val_accuracy: 0.6480\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.6526 - val_loss: 0.6405 - val_accuracy: 0.6569\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6534 - val_loss: 0.6396 - val_accuracy: 0.6613\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6386 - accuracy: 0.6530 - val_loss: 0.6461 - val_accuracy: 0.6489\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6541 - val_loss: 0.6393 - val_accuracy: 0.6605\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6568 - val_loss: 0.6376 - val_accuracy: 0.6631\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6560 - val_loss: 0.6374 - val_accuracy: 0.6587\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6515 - val_loss: 0.6379 - val_accuracy: 0.6392\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6583 - val_loss: 0.6374 - val_accuracy: 0.6587\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6385 - accuracy: 0.6564 - val_loss: 0.6378 - val_accuracy: 0.6418\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6534 - val_loss: 0.6415 - val_accuracy: 0.6534\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6534 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6545 - val_loss: 0.6382 - val_accuracy: 0.6383\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6519 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6386 - accuracy: 0.6587 - val_loss: 0.6376 - val_accuracy: 0.6613\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6399 - accuracy: 0.6515 - val_loss: 0.6410 - val_accuracy: 0.6551\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6545 - val_loss: 0.6373 - val_accuracy: 0.6507\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6576 - val_loss: 0.6373 - val_accuracy: 0.6560\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6500 - val_loss: 0.6466 - val_accuracy: 0.6436\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6396 - accuracy: 0.6579 - val_loss: 0.6419 - val_accuracy: 0.6507\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6395 - accuracy: 0.6541 - val_loss: 0.6373 - val_accuracy: 0.6551\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6541 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.6557 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6382 - accuracy: 0.6522 - val_loss: 0.6399 - val_accuracy: 0.6587\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6391 - accuracy: 0.6526 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6387 - accuracy: 0.6519 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6386 - accuracy: 0.6598 - val_loss: 0.6391 - val_accuracy: 0.6392\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6388 - accuracy: 0.6568 - val_loss: 0.6383 - val_accuracy: 0.6640\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6541 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6375 - accuracy: 0.6541 - val_loss: 0.6426 - val_accuracy: 0.6277\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6400 - accuracy: 0.6522 - val_loss: 0.6372 - val_accuracy: 0.6534\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6399 - accuracy: 0.6519 - val_loss: 0.6394 - val_accuracy: 0.6605\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6387 - accuracy: 0.6614 - val_loss: 0.6424 - val_accuracy: 0.6312\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6519 - val_loss: 0.6405 - val_accuracy: 0.6569\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6538 - val_loss: 0.6393 - val_accuracy: 0.6622\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6394 - accuracy: 0.6534 - val_loss: 0.6386 - val_accuracy: 0.6383\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6392 - val_accuracy: 0.6605\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.6496 - val_loss: 0.6378 - val_accuracy: 0.6631\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6390 - accuracy: 0.6557 - val_loss: 0.6409 - val_accuracy: 0.6560\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6386 - accuracy: 0.6579 - val_loss: 0.6410 - val_accuracy: 0.6356\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6391 - accuracy: 0.6507 - val_loss: 0.6373 - val_accuracy: 0.6516\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6389 - accuracy: 0.6545 - val_loss: 0.6424 - val_accuracy: 0.6489\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6553 - val_loss: 0.6391 - val_accuracy: 0.6596\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6376 - val_accuracy: 0.6631\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6386 - accuracy: 0.6549 - val_loss: 0.6374 - val_accuracy: 0.6587\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6538 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6530 - val_loss: 0.6372 - val_accuracy: 0.6587\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6560 - val_loss: 0.6478 - val_accuracy: 0.6463\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6388 - accuracy: 0.6576 - val_loss: 0.6488 - val_accuracy: 0.6454\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6397 - accuracy: 0.6545 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6503 - val_loss: 0.6398 - val_accuracy: 0.6596\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6545 - val_loss: 0.6378 - val_accuracy: 0.6649\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.6519 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6511 - val_loss: 0.6372 - val_accuracy: 0.6587\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.6545 - val_loss: 0.6432 - val_accuracy: 0.6454\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6387 - accuracy: 0.6583 - val_loss: 0.6437 - val_accuracy: 0.6268\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6549 - val_loss: 0.6443 - val_accuracy: 0.6472\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.6515 - val_loss: 0.6433 - val_accuracy: 0.6463\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6394 - accuracy: 0.6530 - val_loss: 0.6392 - val_accuracy: 0.6605\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6381 - accuracy: 0.6568 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6386 - accuracy: 0.6583 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6522 - val_loss: 0.6424 - val_accuracy: 0.6498\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6385 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6516\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6564 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6387 - accuracy: 0.6511 - val_loss: 0.6473 - val_accuracy: 0.6454\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6386 - accuracy: 0.6564 - val_loss: 0.6373 - val_accuracy: 0.6507\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6522 - val_loss: 0.6376 - val_accuracy: 0.6622\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6398 - accuracy: 0.6545 - val_loss: 0.6379 - val_accuracy: 0.6649\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.6553 - val_loss: 0.6434 - val_accuracy: 0.6463\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6384 - accuracy: 0.6579 - val_loss: 0.6384 - val_accuracy: 0.6631\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6519 - val_loss: 0.6377 - val_accuracy: 0.6613\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6385 - accuracy: 0.6572 - val_loss: 0.6393 - val_accuracy: 0.6365\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6389 - accuracy: 0.6568 - val_loss: 0.6388 - val_accuracy: 0.6613\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6621 - val_loss: 0.6409 - val_accuracy: 0.6551\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6386 - accuracy: 0.6557 - val_loss: 0.6389 - val_accuracy: 0.6605\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6515 - val_loss: 0.6404 - val_accuracy: 0.6569\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6576 - val_loss: 0.6447 - val_accuracy: 0.6489\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6395 - accuracy: 0.6617 - val_loss: 0.6405 - val_accuracy: 0.6560\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6545 - val_loss: 0.6380 - val_accuracy: 0.6640\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6395 - accuracy: 0.6522 - val_loss: 0.6378 - val_accuracy: 0.6649\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.6602 - val_loss: 0.6382 - val_accuracy: 0.6374\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6399 - accuracy: 0.6534 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6515 - val_loss: 0.6379 - val_accuracy: 0.6649\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6549 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.6538 - val_loss: 0.6373 - val_accuracy: 0.6560\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6587 - val_loss: 0.6414 - val_accuracy: 0.6534\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6515 - val_loss: 0.6439 - val_accuracy: 0.6472\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6396 - accuracy: 0.6576 - val_loss: 0.6372 - val_accuracy: 0.6596\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6392 - accuracy: 0.6545 - val_loss: 0.6379 - val_accuracy: 0.6649\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6530 - val_loss: 0.6428 - val_accuracy: 0.6489\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6568 - val_loss: 0.6468 - val_accuracy: 0.6445\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6587 - val_loss: 0.6391 - val_accuracy: 0.6392\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6534 - val_loss: 0.6413 - val_accuracy: 0.6543\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6560 - val_loss: 0.6420 - val_accuracy: 0.6498\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6389 - accuracy: 0.6591 - val_loss: 0.6375 - val_accuracy: 0.6445\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6530 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6614 - val_loss: 0.6372 - val_accuracy: 0.6578\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6583 - val_loss: 0.6400 - val_accuracy: 0.6578\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6388 - accuracy: 0.6553 - val_loss: 0.6399 - val_accuracy: 0.6587\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6388 - accuracy: 0.6598 - val_loss: 0.6373 - val_accuracy: 0.6507\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.6583 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6391 - accuracy: 0.6541 - val_loss: 0.6390 - val_accuracy: 0.6613\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6386 - accuracy: 0.6572 - val_loss: 0.6394 - val_accuracy: 0.6348\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6386 - accuracy: 0.6587 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6390 - accuracy: 0.6583 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.6549 - val_loss: 0.6423 - val_accuracy: 0.6507\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6386 - accuracy: 0.6545 - val_loss: 0.6471 - val_accuracy: 0.6454\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6389 - accuracy: 0.6560 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6391 - accuracy: 0.6568 - val_loss: 0.6375 - val_accuracy: 0.6445\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6401 - accuracy: 0.6530 - val_loss: 0.6415 - val_accuracy: 0.6534\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6387 - accuracy: 0.6553 - val_loss: 0.6373 - val_accuracy: 0.6569\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6393 - accuracy: 0.6576 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6389 - accuracy: 0.6576 - val_loss: 0.6372 - val_accuracy: 0.6543\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6382 - accuracy: 0.6591 - val_loss: 0.6426 - val_accuracy: 0.6507\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6384 - accuracy: 0.6598 - val_loss: 0.6388 - val_accuracy: 0.6374\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6379 - accuracy: 0.6591 - val_loss: 0.6437 - val_accuracy: 0.6268\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6389 - accuracy: 0.6522 - val_loss: 0.6407 - val_accuracy: 0.6560\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6394 - accuracy: 0.6530 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6515 - val_loss: 0.6436 - val_accuracy: 0.6463\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6500 - val_loss: 0.6372 - val_accuracy: 0.6596\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6553 - val_loss: 0.6483 - val_accuracy: 0.6436\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6534 - val_loss: 0.6377 - val_accuracy: 0.6463\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6386 - accuracy: 0.6610 - val_loss: 0.6409 - val_accuracy: 0.6551\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6383 - accuracy: 0.6526 - val_loss: 0.6398 - val_accuracy: 0.6596\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6572 - val_loss: 0.6415 - val_accuracy: 0.6534\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6564 - val_loss: 0.6377 - val_accuracy: 0.6613\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6541 - val_loss: 0.6372 - val_accuracy: 0.6516\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6534 - val_loss: 0.6415 - val_accuracy: 0.6534\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6557 - val_loss: 0.6388 - val_accuracy: 0.6613\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6595 - val_loss: 0.6379 - val_accuracy: 0.6649\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6399 - accuracy: 0.6572 - val_loss: 0.6383 - val_accuracy: 0.6640\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6373 - val_accuracy: 0.6551\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6392 - accuracy: 0.6541 - val_loss: 0.6427 - val_accuracy: 0.6489\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6621 - val_loss: 0.6399 - val_accuracy: 0.6587\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6576 - val_loss: 0.6373 - val_accuracy: 0.6551\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6530 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6384 - accuracy: 0.6526 - val_loss: 0.6382 - val_accuracy: 0.6374\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6519 - val_loss: 0.6372 - val_accuracy: 0.6596\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6386 - accuracy: 0.6560 - val_loss: 0.6380 - val_accuracy: 0.6383\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6587\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6394 - accuracy: 0.6614 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6579 - val_loss: 0.6373 - val_accuracy: 0.6551\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6394 - accuracy: 0.6526 - val_loss: 0.6419 - val_accuracy: 0.6507\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.6526 - val_loss: 0.6394 - val_accuracy: 0.6605\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6378 - accuracy: 0.6602 - val_loss: 0.6492 - val_accuracy: 0.6454\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6400 - accuracy: 0.6557 - val_loss: 0.6399 - val_accuracy: 0.6587\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6389 - accuracy: 0.6515 - val_loss: 0.6465 - val_accuracy: 0.6436\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.6640 - val_loss: 0.6387 - val_accuracy: 0.6622\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6404 - val_accuracy: 0.6569\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6534 - val_loss: 0.6373 - val_accuracy: 0.6507\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6560 - val_loss: 0.6401 - val_accuracy: 0.6596\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6388 - accuracy: 0.6557 - val_loss: 0.6442 - val_accuracy: 0.6472\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.6595 - val_loss: 0.6428 - val_accuracy: 0.6489\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6545 - val_loss: 0.6425 - val_accuracy: 0.6285\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6541 - val_loss: 0.6480 - val_accuracy: 0.6445\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6549 - val_loss: 0.6420 - val_accuracy: 0.6498\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6572 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6572 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6621 - val_loss: 0.6380 - val_accuracy: 0.6640\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6583 - val_loss: 0.6373 - val_accuracy: 0.6569\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.6587 - val_loss: 0.6373 - val_accuracy: 0.6587\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6545 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6541 - val_loss: 0.6373 - val_accuracy: 0.6587\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.6553 - val_loss: 0.6391 - val_accuracy: 0.6596\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6553 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6587 - val_loss: 0.6416 - val_accuracy: 0.6543\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.6534 - val_loss: 0.6375 - val_accuracy: 0.6445\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6500 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6530 - val_loss: 0.6372 - val_accuracy: 0.6534\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6560 - val_loss: 0.6421 - val_accuracy: 0.6330\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.6522 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6530 - val_loss: 0.6433 - val_accuracy: 0.6454\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6519 - val_loss: 0.6427 - val_accuracy: 0.6489\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6583 - val_loss: 0.6462 - val_accuracy: 0.6480\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6400 - accuracy: 0.6519 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.6545 - val_loss: 0.6395 - val_accuracy: 0.6613\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6389 - accuracy: 0.6557 - val_loss: 0.6402 - val_accuracy: 0.6383\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6541 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6374 - accuracy: 0.6557 - val_loss: 0.6461 - val_accuracy: 0.6489\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6388 - accuracy: 0.6610 - val_loss: 0.6380 - val_accuracy: 0.6640\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6553 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6387 - accuracy: 0.6591 - val_loss: 0.6397 - val_accuracy: 0.6605\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6386 - accuracy: 0.6568 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6388 - accuracy: 0.6572 - val_loss: 0.6380 - val_accuracy: 0.6640\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.6553 - val_loss: 0.6395 - val_accuracy: 0.6613\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6560 - val_loss: 0.6389 - val_accuracy: 0.6605\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6392 - accuracy: 0.6579 - val_loss: 0.6372 - val_accuracy: 0.6578\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6380 - accuracy: 0.6515 - val_loss: 0.6509 - val_accuracy: 0.6436\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6572 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6522 - val_loss: 0.6405 - val_accuracy: 0.6560\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6530 - val_loss: 0.6402 - val_accuracy: 0.6578\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6579 - val_loss: 0.6408 - val_accuracy: 0.6560\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6576 - val_loss: 0.6387 - val_accuracy: 0.6613\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6557 - val_loss: 0.6400 - val_accuracy: 0.6578\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6583 - val_loss: 0.6371 - val_accuracy: 0.6543\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6553 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6557 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6583 - val_loss: 0.6384 - val_accuracy: 0.6622\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6564 - val_loss: 0.6372 - val_accuracy: 0.6569\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6553 - val_loss: 0.6375 - val_accuracy: 0.6454\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6530 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6534 - val_loss: 0.6407 - val_accuracy: 0.6560\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6519 - val_loss: 0.6409 - val_accuracy: 0.6560\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6557 - val_loss: 0.6440 - val_accuracy: 0.6472\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6541 - val_loss: 0.6371 - val_accuracy: 0.6534\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6560 - val_loss: 0.6382 - val_accuracy: 0.6374\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6553 - val_loss: 0.6411 - val_accuracy: 0.6543\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6545 - val_loss: 0.6376 - val_accuracy: 0.6463\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6583 - val_loss: 0.6464 - val_accuracy: 0.6436\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6549 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6534 - val_loss: 0.6394 - val_accuracy: 0.6605\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6557 - val_loss: 0.6378 - val_accuracy: 0.6649\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.6549 - val_loss: 0.6424 - val_accuracy: 0.6489\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6377 - accuracy: 0.6553 - val_loss: 0.6376 - val_accuracy: 0.6613\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6399 - accuracy: 0.6576 - val_loss: 0.6371 - val_accuracy: 0.6560\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6541 - val_loss: 0.6391 - val_accuracy: 0.6596\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.6568 - val_loss: 0.6401 - val_accuracy: 0.6365\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6564 - val_loss: 0.6374 - val_accuracy: 0.6613\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6591 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6568 - val_loss: 0.6392 - val_accuracy: 0.6605\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6549 - val_loss: 0.6394 - val_accuracy: 0.6605\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.6564 - val_loss: 0.6424 - val_accuracy: 0.6489\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6598 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6545 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6564 - val_loss: 0.6388 - val_accuracy: 0.6613\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.6564 - val_loss: 0.6371 - val_accuracy: 0.6596\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6587 - val_loss: 0.6481 - val_accuracy: 0.6445\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6557 - val_loss: 0.6377 - val_accuracy: 0.6613\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6572 - val_loss: 0.6498 - val_accuracy: 0.6463\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6587 - val_loss: 0.6388 - val_accuracy: 0.6613\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6534 - val_loss: 0.6434 - val_accuracy: 0.6463\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6587 - val_loss: 0.6404 - val_accuracy: 0.6569\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6526 - val_loss: 0.6382 - val_accuracy: 0.6383\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6503 - val_loss: 0.6378 - val_accuracy: 0.6649\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6545 - val_loss: 0.6436 - val_accuracy: 0.6463\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6572 - val_loss: 0.6452 - val_accuracy: 0.6480\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6591 - val_loss: 0.6414 - val_accuracy: 0.6534\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.6595 - val_loss: 0.6407 - val_accuracy: 0.6560\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6553 - val_loss: 0.6379 - val_accuracy: 0.6392\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6587 - val_loss: 0.6385 - val_accuracy: 0.6622\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6530 - val_loss: 0.6389 - val_accuracy: 0.6605\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6591 - val_loss: 0.6402 - val_accuracy: 0.6587\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6541 - val_loss: 0.6418 - val_accuracy: 0.6525\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6549 - val_loss: 0.6389 - val_accuracy: 0.6383\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6522 - val_loss: 0.6384 - val_accuracy: 0.6622\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6541 - val_loss: 0.6377 - val_accuracy: 0.6436\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6503 - val_loss: 0.6375 - val_accuracy: 0.6631\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6538 - val_loss: 0.6379 - val_accuracy: 0.6392\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6549 - val_loss: 0.6374 - val_accuracy: 0.6605\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6530 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6526 - val_loss: 0.6421 - val_accuracy: 0.6507\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6534 - val_loss: 0.6376 - val_accuracy: 0.6613\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6598 - val_loss: 0.6478 - val_accuracy: 0.6454\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6591 - val_loss: 0.6399 - val_accuracy: 0.6356\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.6557 - val_loss: 0.6409 - val_accuracy: 0.6356\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6515 - val_loss: 0.6374 - val_accuracy: 0.6436\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6522 - val_loss: 0.6383 - val_accuracy: 0.6631\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6602 - val_loss: 0.6374 - val_accuracy: 0.6605\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6538 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6583 - val_loss: 0.6375 - val_accuracy: 0.6463\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6541 - val_loss: 0.6371 - val_accuracy: 0.6578\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6549 - val_loss: 0.6437 - val_accuracy: 0.6480\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6545 - val_loss: 0.6381 - val_accuracy: 0.6374\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6541 - val_loss: 0.6378 - val_accuracy: 0.6418\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6519 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6549 - val_loss: 0.6371 - val_accuracy: 0.6534\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6560 - val_loss: 0.6384 - val_accuracy: 0.6622\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6541 - val_loss: 0.6422 - val_accuracy: 0.6507\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6538 - val_loss: 0.6456 - val_accuracy: 0.6498\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6568 - val_loss: 0.6400 - val_accuracy: 0.6578\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.6526 - val_loss: 0.6385 - val_accuracy: 0.6383\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6541 - val_loss: 0.6453 - val_accuracy: 0.6489\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6397 - accuracy: 0.6564 - val_loss: 0.6382 - val_accuracy: 0.6631\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6522 - val_loss: 0.6374 - val_accuracy: 0.6613\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6519 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6538 - val_loss: 0.6374 - val_accuracy: 0.6445\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6530 - val_loss: 0.6384 - val_accuracy: 0.6622\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6598 - val_loss: 0.6374 - val_accuracy: 0.6631\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6579 - val_loss: 0.6382 - val_accuracy: 0.6640\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6380 - accuracy: 0.6576 - val_loss: 0.6375 - val_accuracy: 0.6640\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6541 - val_loss: 0.6476 - val_accuracy: 0.6463\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.6511 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6564 - val_loss: 0.6420 - val_accuracy: 0.6498\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6541 - val_loss: 0.6426 - val_accuracy: 0.6507\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6469 - val_loss: 0.6374 - val_accuracy: 0.6631\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6387 - accuracy: 0.6534 - val_loss: 0.6375 - val_accuracy: 0.6445\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.6538 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6538 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6545 - val_loss: 0.6403 - val_accuracy: 0.6569\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6526 - val_loss: 0.6376 - val_accuracy: 0.6613\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6503 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6576 - val_loss: 0.6372 - val_accuracy: 0.6516\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6389 - accuracy: 0.6541 - val_loss: 0.6392 - val_accuracy: 0.6383\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.6534 - val_loss: 0.6398 - val_accuracy: 0.6596\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6568 - val_loss: 0.6446 - val_accuracy: 0.6489\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6553 - val_loss: 0.6398 - val_accuracy: 0.6596\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6534 - val_loss: 0.6395 - val_accuracy: 0.6622\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6591 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.6595 - val_loss: 0.6374 - val_accuracy: 0.6631\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6557 - val_loss: 0.6411 - val_accuracy: 0.6543\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6568 - val_loss: 0.6433 - val_accuracy: 0.6463\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6538 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6488 - val_loss: 0.6388 - val_accuracy: 0.6613\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6515 - val_loss: 0.6442 - val_accuracy: 0.6472\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6549 - val_loss: 0.6372 - val_accuracy: 0.6525\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6422 - val_accuracy: 0.6507\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6640 - val_loss: 0.6391 - val_accuracy: 0.6392\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6617 - val_loss: 0.6403 - val_accuracy: 0.6569\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6545 - val_loss: 0.6376 - val_accuracy: 0.6613\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6538 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6538 - val_loss: 0.6467 - val_accuracy: 0.6445\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.6526 - val_loss: 0.6454 - val_accuracy: 0.6498\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6541 - val_loss: 0.6447 - val_accuracy: 0.6489\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6572 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6530 - val_loss: 0.6371 - val_accuracy: 0.6534\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.6557 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6392 - accuracy: 0.6553 - val_loss: 0.6372 - val_accuracy: 0.6489\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6507 - val_loss: 0.6395 - val_accuracy: 0.6613\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6568 - val_loss: 0.6414 - val_accuracy: 0.6534\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6553 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6606 - val_loss: 0.6373 - val_accuracy: 0.6463\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6388 - accuracy: 0.6541 - val_loss: 0.6468 - val_accuracy: 0.6445\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.6519 - val_loss: 0.6430 - val_accuracy: 0.6463\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6388 - accuracy: 0.6538 - val_loss: 0.6410 - val_accuracy: 0.6551\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6530 - val_loss: 0.6474 - val_accuracy: 0.6463\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6549 - val_loss: 0.6371 - val_accuracy: 0.6578\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6572 - val_loss: 0.6371 - val_accuracy: 0.6525\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6553 - val_loss: 0.6387 - val_accuracy: 0.6613\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6530 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6576 - val_loss: 0.6478 - val_accuracy: 0.6463\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6507 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6557 - val_loss: 0.6416 - val_accuracy: 0.6534\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6549 - val_loss: 0.6384 - val_accuracy: 0.6622\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6549 - val_loss: 0.6402 - val_accuracy: 0.6569\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6587 - val_loss: 0.6381 - val_accuracy: 0.6374\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6568 - val_loss: 0.6398 - val_accuracy: 0.6348\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6484 - val_loss: 0.6459 - val_accuracy: 0.6489\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6553 - val_loss: 0.6402 - val_accuracy: 0.6569\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6515 - val_loss: 0.6373 - val_accuracy: 0.6578\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6557 - val_loss: 0.6371 - val_accuracy: 0.6543\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6549 - val_loss: 0.6414 - val_accuracy: 0.6534\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6541 - val_loss: 0.6388 - val_accuracy: 0.6605\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6553 - val_loss: 0.6373 - val_accuracy: 0.6454\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6564 - val_loss: 0.6371 - val_accuracy: 0.6596\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6530 - val_loss: 0.6402 - val_accuracy: 0.6578\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6538 - val_loss: 0.6464 - val_accuracy: 0.6445\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6591 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6511 - val_loss: 0.6408 - val_accuracy: 0.6560\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6557 - val_loss: 0.6381 - val_accuracy: 0.6649\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6507 - val_loss: 0.6448 - val_accuracy: 0.6480\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6545 - val_loss: 0.6419 - val_accuracy: 0.6498\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6591 - val_loss: 0.6484 - val_accuracy: 0.6436\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6549 - val_loss: 0.6374 - val_accuracy: 0.6631\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6519 - val_loss: 0.6428 - val_accuracy: 0.6489\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.6560 - val_loss: 0.6467 - val_accuracy: 0.6179\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6503 - val_loss: 0.6374 - val_accuracy: 0.6445\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6519 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6572 - val_loss: 0.6373 - val_accuracy: 0.6587\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6568 - val_loss: 0.6455 - val_accuracy: 0.6498\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6545 - val_loss: 0.6371 - val_accuracy: 0.6534\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6553 - val_loss: 0.6372 - val_accuracy: 0.6587\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6534 - val_loss: 0.6420 - val_accuracy: 0.6498\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6564 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6579 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6511 - val_loss: 0.6400 - val_accuracy: 0.6596\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6538 - val_loss: 0.6412 - val_accuracy: 0.6534\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6564 - val_loss: 0.6386 - val_accuracy: 0.6622\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6549 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6621 - val_loss: 0.6418 - val_accuracy: 0.6507\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6515 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.6503 - val_loss: 0.6372 - val_accuracy: 0.6560\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.6530 - val_loss: 0.6424 - val_accuracy: 0.6489\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6534 - val_loss: 0.6391 - val_accuracy: 0.6392\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6526 - val_loss: 0.6374 - val_accuracy: 0.6640\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6538 - val_loss: 0.6394 - val_accuracy: 0.6613\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6534 - val_loss: 0.6479 - val_accuracy: 0.6454\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.6557 - val_loss: 0.6402 - val_accuracy: 0.6383\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6397 - accuracy: 0.6515 - val_loss: 0.6377 - val_accuracy: 0.6631\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6394 - accuracy: 0.6545 - val_loss: 0.6371 - val_accuracy: 0.6587\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6591 - val_loss: 0.6406 - val_accuracy: 0.6560\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6572 - val_loss: 0.6380 - val_accuracy: 0.6383\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6377 - accuracy: 0.6576 - val_loss: 0.6412 - val_accuracy: 0.6543\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6534 - val_loss: 0.6453 - val_accuracy: 0.6489\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6392 - accuracy: 0.6564 - val_loss: 0.6391 - val_accuracy: 0.6605\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.6598 - val_loss: 0.6450 - val_accuracy: 0.6480\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6398 - accuracy: 0.6553 - val_loss: 0.6373 - val_accuracy: 0.6427\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6549 - val_loss: 0.6406 - val_accuracy: 0.6560\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6384 - accuracy: 0.6591 - val_loss: 0.6380 - val_accuracy: 0.6649\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6388 - accuracy: 0.6564 - val_loss: 0.6385 - val_accuracy: 0.6613\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6614\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6613\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 0.9]\n",
      " [ 0.3]\n",
      " [ 0.4]\n",
      " [ 0.4]\n",
      " [ 0.3]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779661016949152\n",
      "0.44635193133047213\n",
      "0.5383022774327122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "[[ 0.4]\n",
      " [ 0.3]\n",
      " [ 0.3]\n",
      " [ 0.2]\n",
      " [ 0.3]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207792207792207\n",
      "0.42857142857142855\n",
      "0.5375302663438256\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
