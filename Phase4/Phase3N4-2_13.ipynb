{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  21.6  1171.8 ...  4.0  1.0  0.0]\n",
      " [ 0.0  5.8  171.8 ...  2.5  0.9  0.0]\n",
      " [ 1.0  14.4  575.3 ...  3.3  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  9.6  422.6 ...  3.2  1.0  0.0]\n",
      " [ 1.0  10.1  1129.3 ...  6.0  1.0  0.0]\n",
      " [ 0.0  7.2  476.6 ...  3.2  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  0.1  0.1]\n",
      " [ 0.0  0.1  0.0]\n",
      " [ 1.0  0.0  0.0]\n",
      " ...\n",
      " [ 0.0  0.1  0.1]\n",
      " [ 1.0  0.0  0.0]\n",
      " [ 0.0  0.2  0.2]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 11, axis = 1)\n",
    "brainT = np.delete(brainT, 10, axis = 1)\n",
    "brainT = np.delete(brainT, 8, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 6, axis = 1)\n",
    "brainT = np.delete(brainT, 5, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 2, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 0.6869 - accuracy: 0.4989 - val_loss: 0.6768 - val_accuracy: 0.5417\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6688 - accuracy: 0.5573 - val_loss: 0.6664 - val_accuracy: 0.5417\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6583 - accuracy: 0.5573 - val_loss: 0.6572 - val_accuracy: 0.5417\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.5573 - val_loss: 0.6470 - val_accuracy: 0.5417\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.5573 - val_loss: 0.6358 - val_accuracy: 0.5417\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.5573 - val_loss: 0.6234 - val_accuracy: 0.5417\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.5573 - val_loss: 0.6104 - val_accuracy: 0.5417\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.5604 - val_loss: 0.5966 - val_accuracy: 0.5417\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.6572 - val_loss: 0.5825 - val_accuracy: 0.5426\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.7825 - val_loss: 0.5682 - val_accuracy: 0.8227\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.8481 - val_loss: 0.5537 - val_accuracy: 0.8378\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.8724 - val_loss: 0.5390 - val_accuracy: 0.8723\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.8994 - val_loss: 0.5235 - val_accuracy: 0.9060\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.9188 - val_loss: 0.5091 - val_accuracy: 0.9043\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.9275 - val_loss: 0.4930 - val_accuracy: 0.9238\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.9362 - val_loss: 0.4771 - val_accuracy: 0.9344\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.9442 - val_loss: 0.4614 - val_accuracy: 0.9450\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.9472 - val_loss: 0.4465 - val_accuracy: 0.9504\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.9514 - val_loss: 0.4313 - val_accuracy: 0.9495\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.9529 - val_loss: 0.4161 - val_accuracy: 0.9574\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.9548 - val_loss: 0.4017 - val_accuracy: 0.9566\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.9571 - val_loss: 0.3875 - val_accuracy: 0.9574\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.9605 - val_loss: 0.3735 - val_accuracy: 0.9592\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.9617 - val_loss: 0.3600 - val_accuracy: 0.9592\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.9613 - val_loss: 0.3469 - val_accuracy: 0.9663\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.9624 - val_loss: 0.3344 - val_accuracy: 0.9663\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.9643 - val_loss: 0.3222 - val_accuracy: 0.9672\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.9639 - val_loss: 0.3109 - val_accuracy: 0.9672\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.9658 - val_loss: 0.2996 - val_accuracy: 0.9663\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.9666 - val_loss: 0.2891 - val_accuracy: 0.9663\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.9662 - val_loss: 0.2788 - val_accuracy: 0.9672\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9674 - val_loss: 0.2692 - val_accuracy: 0.9672\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.9677 - val_loss: 0.2602 - val_accuracy: 0.9681\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9689 - val_loss: 0.2517 - val_accuracy: 0.9681\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9689 - val_loss: 0.2434 - val_accuracy: 0.9681\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2355 - accuracy: 0.9704 - val_loss: 0.2360 - val_accuracy: 0.9681\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9704 - val_loss: 0.2287 - val_accuracy: 0.9681\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.9704 - val_loss: 0.2217 - val_accuracy: 0.9681\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2144 - accuracy: 0.9708 - val_loss: 0.2154 - val_accuracy: 0.9690\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9715 - val_loss: 0.2095 - val_accuracy: 0.9690\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9711 - val_loss: 0.2037 - val_accuracy: 0.9690\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9723 - val_loss: 0.1985 - val_accuracy: 0.9690\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1922 - accuracy: 0.9723 - val_loss: 0.1937 - val_accuracy: 0.9690\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1875 - accuracy: 0.9723 - val_loss: 0.1892 - val_accuracy: 0.9690\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1830 - accuracy: 0.9723 - val_loss: 0.1850 - val_accuracy: 0.9699\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9730 - val_loss: 0.1810 - val_accuracy: 0.9690\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9738 - val_loss: 0.1775 - val_accuracy: 0.9690\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.9730 - val_loss: 0.1738 - val_accuracy: 0.9690\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1681 - accuracy: 0.9742 - val_loss: 0.1710 - val_accuracy: 0.9690\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9734 - val_loss: 0.1678 - val_accuracy: 0.9699\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.9738 - val_loss: 0.1649 - val_accuracy: 0.9699\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.9738 - val_loss: 0.1622 - val_accuracy: 0.9716\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 0.9746 - val_loss: 0.1603 - val_accuracy: 0.9699\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9742 - val_loss: 0.1582 - val_accuracy: 0.9699\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9746 - val_loss: 0.1561 - val_accuracy: 0.9707\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9746 - val_loss: 0.1541 - val_accuracy: 0.9707\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.9746 - val_loss: 0.1522 - val_accuracy: 0.9716\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9746 - val_loss: 0.1506 - val_accuracy: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9746 - val_loss: 0.1489 - val_accuracy: 0.9716\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9746 - val_loss: 0.1475 - val_accuracy: 0.9716\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9746 - val_loss: 0.1460 - val_accuracy: 0.9725\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9746 - val_loss: 0.1447 - val_accuracy: 0.9716\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1401 - accuracy: 0.9746 - val_loss: 0.1435 - val_accuracy: 0.9716\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.9746 - val_loss: 0.1424 - val_accuracy: 0.9716\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9746 - val_loss: 0.1413 - val_accuracy: 0.9725\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.9746 - val_loss: 0.1405 - val_accuracy: 0.9716\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9746 - val_loss: 0.1392 - val_accuracy: 0.9734\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.9746 - val_loss: 0.1386 - val_accuracy: 0.9716\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9746 - val_loss: 0.1377 - val_accuracy: 0.9725\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.9746 - val_loss: 0.1368 - val_accuracy: 0.9734\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9746 - val_loss: 0.1361 - val_accuracy: 0.9734\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9742 - val_loss: 0.1355 - val_accuracy: 0.9734\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1311 - accuracy: 0.9742 - val_loss: 0.1348 - val_accuracy: 0.9734\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9742 - val_loss: 0.1345 - val_accuracy: 0.9716\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9746 - val_loss: 0.1337 - val_accuracy: 0.9734\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9749 - val_loss: 0.1333 - val_accuracy: 0.9734\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9746 - val_loss: 0.1329 - val_accuracy: 0.9725\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9734\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9742 - val_loss: 0.1318 - val_accuracy: 0.9734\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9738 - val_loss: 0.1312 - val_accuracy: 0.9734\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9742 - val_loss: 0.1307 - val_accuracy: 0.9734\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1264 - accuracy: 0.9746 - val_loss: 0.1303 - val_accuracy: 0.9734\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9738 - val_loss: 0.1299 - val_accuracy: 0.9734\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1254 - accuracy: 0.9746 - val_loss: 0.1299 - val_accuracy: 0.9734\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1253 - accuracy: 0.9742 - val_loss: 0.1294 - val_accuracy: 0.9734\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1250 - accuracy: 0.9742 - val_loss: 0.1290 - val_accuracy: 0.9734\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9742 - val_loss: 0.1288 - val_accuracy: 0.9734\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9738 - val_loss: 0.1286 - val_accuracy: 0.9734\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9742 - val_loss: 0.1283 - val_accuracy: 0.9734\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1238 - accuracy: 0.9746 - val_loss: 0.1281 - val_accuracy: 0.9734\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9742 - val_loss: 0.1278 - val_accuracy: 0.9734\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9738 - val_loss: 0.1276 - val_accuracy: 0.9734\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9742 - val_loss: 0.1272 - val_accuracy: 0.9734\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9746 - val_loss: 0.1271 - val_accuracy: 0.9734\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9746 - val_loss: 0.1267 - val_accuracy: 0.9734\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1224 - accuracy: 0.9746 - val_loss: 0.1265 - val_accuracy: 0.9734\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9746 - val_loss: 0.1264 - val_accuracy: 0.9734\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9746 - val_loss: 0.1262 - val_accuracy: 0.9734\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9746 - val_loss: 0.1261 - val_accuracy: 0.9734\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9746 - val_loss: 0.1259 - val_accuracy: 0.9734\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1215 - accuracy: 0.9746 - val_loss: 0.1258 - val_accuracy: 0.9734\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9746 - val_loss: 0.1256 - val_accuracy: 0.9734\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 0.9746 - val_loss: 0.1256 - val_accuracy: 0.9734\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9742 - val_loss: 0.1256 - val_accuracy: 0.9734\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9746 - val_loss: 0.1254 - val_accuracy: 0.9734\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.9742 - val_loss: 0.1251 - val_accuracy: 0.9734\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9746 - val_loss: 0.1249 - val_accuracy: 0.9734\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9742 - val_loss: 0.1248 - val_accuracy: 0.9743\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9746 - val_loss: 0.1247 - val_accuracy: 0.9734\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9746 - val_loss: 0.1246 - val_accuracy: 0.9734\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9746 - val_loss: 0.1248 - val_accuracy: 0.9734\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9746 - val_loss: 0.1246 - val_accuracy: 0.9734\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9746 - val_loss: 0.1244 - val_accuracy: 0.9734\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9746 - val_loss: 0.1243 - val_accuracy: 0.9734\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9746 - val_loss: 0.1242 - val_accuracy: 0.9734\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9746 - val_loss: 0.1241 - val_accuracy: 0.9734\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9746 - val_loss: 0.1240 - val_accuracy: 0.9734\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9746 - val_loss: 0.1239 - val_accuracy: 0.9743\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9746 - val_loss: 0.1239 - val_accuracy: 0.9734\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9746 - val_loss: 0.1238 - val_accuracy: 0.9734\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.9749 - val_loss: 0.1239 - val_accuracy: 0.9734\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.9746 - val_loss: 0.1237 - val_accuracy: 0.9734\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9746 - val_loss: 0.1237 - val_accuracy: 0.9734\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9746 - val_loss: 0.1236 - val_accuracy: 0.9734\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9746 - val_loss: 0.1235 - val_accuracy: 0.9743\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9746 - val_loss: 0.1235 - val_accuracy: 0.9734\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9746 - val_loss: 0.1234 - val_accuracy: 0.9734\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9742 - val_loss: 0.1237 - val_accuracy: 0.9734\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9738 - val_loss: 0.1233 - val_accuracy: 0.9734\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9746 - val_loss: 0.1233 - val_accuracy: 0.9734\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9746 - val_loss: 0.1232 - val_accuracy: 0.9734\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9749 - val_loss: 0.1233 - val_accuracy: 0.9734\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9746 - val_loss: 0.1231 - val_accuracy: 0.9743\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9746 - val_loss: 0.1231 - val_accuracy: 0.9743\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9746 - val_loss: 0.1230 - val_accuracy: 0.9743\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9749 - val_loss: 0.1230 - val_accuracy: 0.9734\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9746 - val_loss: 0.1230 - val_accuracy: 0.9734\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9746 - val_loss: 0.1229 - val_accuracy: 0.9734\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9749 - val_loss: 0.1229 - val_accuracy: 0.9734\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9749 - val_loss: 0.1230 - val_accuracy: 0.9734\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9746 - val_loss: 0.1229 - val_accuracy: 0.9734\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 0.9746 - val_loss: 0.1228 - val_accuracy: 0.9743\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9749 - val_loss: 0.1228 - val_accuracy: 0.9734\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9746 - val_loss: 0.1228 - val_accuracy: 0.9734\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9746 - val_loss: 0.1227 - val_accuracy: 0.9743\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9757 - val_loss: 0.1227 - val_accuracy: 0.9734\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9757 - val_loss: 0.1230 - val_accuracy: 0.9734\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9746 - val_loss: 0.1229 - val_accuracy: 0.9734\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9746 - val_loss: 0.1226 - val_accuracy: 0.9734\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9746 - val_loss: 0.1226 - val_accuracy: 0.9743\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9743\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1178 - accuracy: 0.9749 - val_loss: 0.1226 - val_accuracy: 0.9734\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1176 - accuracy: 0.9757 - val_loss: 0.1226 - val_accuracy: 0.9734\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1176 - accuracy: 0.9746 - val_loss: 0.1224 - val_accuracy: 0.9743\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9746 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9746 - val_loss: 0.1224 - val_accuracy: 0.9734\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9749 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9753 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9746 - val_loss: 0.1223 - val_accuracy: 0.9743\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9746 - val_loss: 0.1223 - val_accuracy: 0.9743\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9753 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9753 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9753 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9749 - val_loss: 0.1224 - val_accuracy: 0.9734\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9749 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9746 - val_loss: 0.1222 - val_accuracy: 0.9752\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9746 - val_loss: 0.1222 - val_accuracy: 0.9743\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9749 - val_loss: 0.1222 - val_accuracy: 0.9743\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9749 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9746 - val_loss: 0.1222 - val_accuracy: 0.9734\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9749 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9753 - val_loss: 0.1224 - val_accuracy: 0.9734\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9746 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9746 - val_loss: 0.1221 - val_accuracy: 0.9743\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9753 - val_loss: 0.1221 - val_accuracy: 0.9743\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9753 - val_loss: 0.1221 - val_accuracy: 0.9743\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1222 - val_accuracy: 0.9734\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9746 - val_loss: 0.1221 - val_accuracy: 0.9743\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9749 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9746 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1222 - val_accuracy: 0.9734\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1172 - accuracy: 0.9753 - val_loss: 0.1222 - val_accuracy: 0.9734\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1171 - accuracy: 0.9746 - val_loss: 0.1220 - val_accuracy: 0.9752\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9753 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9746 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9746 - val_loss: 0.1220 - val_accuracy: 0.9752\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9765 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9761 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9738 - val_loss: 0.1221 - val_accuracy: 0.9734\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9746 - val_loss: 0.1220 - val_accuracy: 0.9734\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9753 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1220 - val_accuracy: 0.9734\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9757 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9768 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9768 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9753 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.9765 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9765 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9765 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9765 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9765 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1216 - val_accuracy: 0.9752\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9734\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1220 - val_accuracy: 0.9734\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9765 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9743\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9761\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9765 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9765 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9765 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9757 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9765 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9746 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9752\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9757 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9742 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9743\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9765 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9761 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1219 - val_accuracy: 0.9743\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9753 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9749 - val_loss: 0.1220 - val_accuracy: 0.9734\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884444444444445\n",
      "0.9536878216123499\n",
      "0.9707551287647315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "[[ 0.1]\n",
      " [ 0.2]\n",
      " [ 0.6]\n",
      " [ 0.0]\n",
      " [ 0.9]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9860279441117764\n",
      "0.9555125725338491\n",
      "0.9705304518664046\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
