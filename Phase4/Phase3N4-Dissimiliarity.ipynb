{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  23.1  1349.5 ...  5.2  1.0  0.0]\n",
      " [ 1.0  7.7  688.0 ...  6.4  1.0  0.0]\n",
      " [ 0.0  8.0  274.8 ...  2.6  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  5.4  918.0 ...  7.7  1.0  0.0]\n",
      " [ 1.0  5.1  474.1 ...  2.3  1.0  0.0]\n",
      " [ 0.0  5.4  255.3 ...  2.5  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 11]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 11]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 15ms/step - loss: 1.2184 - accuracy: 0.5528 - val_loss: 1.0854 - val_accuracy: 0.5523\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0081 - accuracy: 0.5528 - val_loss: 0.9162 - val_accuracy: 0.5523\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.8687 - accuracy: 0.5505 - val_loss: 0.8122 - val_accuracy: 0.5452\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7882 - accuracy: 0.5292 - val_loss: 0.7581 - val_accuracy: 0.5071\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7463 - accuracy: 0.4210 - val_loss: 0.7326 - val_accuracy: 0.3466\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7273 - accuracy: 0.2361 - val_loss: 0.7191 - val_accuracy: 0.2207\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7154 - accuracy: 0.2984 - val_loss: 0.7101 - val_accuracy: 0.4078\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7070 - accuracy: 0.4370 - val_loss: 0.7029 - val_accuracy: 0.4477\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.4472 - val_loss: 0.6959 - val_accuracy: 0.4477\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6925 - accuracy: 0.4472 - val_loss: 0.6892 - val_accuracy: 0.4477\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.4491 - val_loss: 0.6829 - val_accuracy: 0.4548\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.4765 - val_loss: 0.6758 - val_accuracy: 0.4902\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.5326 - val_loss: 0.6691 - val_accuracy: 0.5496\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.5919 - val_loss: 0.6614 - val_accuracy: 0.6037\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6541 - val_loss: 0.6539 - val_accuracy: 0.6516\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.6765 - val_loss: 0.6461 - val_accuracy: 0.7039\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6415 - accuracy: 0.7274 - val_loss: 0.6386 - val_accuracy: 0.7252\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6344 - accuracy: 0.7498 - val_loss: 0.6316 - val_accuracy: 0.7491\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6276 - accuracy: 0.7616 - val_loss: 0.6249 - val_accuracy: 0.7589\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6204 - accuracy: 0.7650 - val_loss: 0.6179 - val_accuracy: 0.7722\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6135 - accuracy: 0.7813 - val_loss: 0.6106 - val_accuracy: 0.7757\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6061 - accuracy: 0.7828 - val_loss: 0.6036 - val_accuracy: 0.7828\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.7889 - val_loss: 0.5963 - val_accuracy: 0.7872\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5922 - accuracy: 0.7927 - val_loss: 0.5900 - val_accuracy: 0.7952\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5856 - accuracy: 0.7935 - val_loss: 0.5832 - val_accuracy: 0.7943\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5790 - accuracy: 0.7946 - val_loss: 0.5765 - val_accuracy: 0.7943\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5722 - accuracy: 0.7935 - val_loss: 0.5699 - val_accuracy: 0.7934\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5658 - accuracy: 0.7938 - val_loss: 0.5638 - val_accuracy: 0.7943\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5598 - accuracy: 0.7946 - val_loss: 0.5576 - val_accuracy: 0.7926\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5539 - accuracy: 0.7935 - val_loss: 0.5517 - val_accuracy: 0.7890\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7904 - val_loss: 0.5461 - val_accuracy: 0.7899\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5425 - accuracy: 0.7901 - val_loss: 0.5409 - val_accuracy: 0.7899\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.7916 - val_loss: 0.5364 - val_accuracy: 0.7908\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5332 - accuracy: 0.7904 - val_loss: 0.5318 - val_accuracy: 0.7899\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5289 - accuracy: 0.7920 - val_loss: 0.5275 - val_accuracy: 0.7917\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7885 - val_loss: 0.5235 - val_accuracy: 0.7890\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7866 - val_loss: 0.5198 - val_accuracy: 0.7926\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5173 - accuracy: 0.7878 - val_loss: 0.5164 - val_accuracy: 0.7872\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7870 - val_loss: 0.5129 - val_accuracy: 0.7863\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5106 - accuracy: 0.7870 - val_loss: 0.5100 - val_accuracy: 0.7872\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.7870 - val_loss: 0.5072 - val_accuracy: 0.7855\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5047 - accuracy: 0.7859 - val_loss: 0.5043 - val_accuracy: 0.7855\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5022 - accuracy: 0.7840 - val_loss: 0.5018 - val_accuracy: 0.7863\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4998 - accuracy: 0.7855 - val_loss: 0.4995 - val_accuracy: 0.7846\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.7828 - val_loss: 0.4973 - val_accuracy: 0.7855\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.7859 - val_loss: 0.4955 - val_accuracy: 0.7863\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4939 - accuracy: 0.7832 - val_loss: 0.4937 - val_accuracy: 0.7863\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7863\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4908 - accuracy: 0.7855 - val_loss: 0.4910 - val_accuracy: 0.7837\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4895 - accuracy: 0.7844 - val_loss: 0.4894 - val_accuracy: 0.7863\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7836 - val_loss: 0.4882 - val_accuracy: 0.7855\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7851 - val_loss: 0.4869 - val_accuracy: 0.7855\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7840 - val_loss: 0.4861 - val_accuracy: 0.7855\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7844 - val_loss: 0.4850 - val_accuracy: 0.7855\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4839 - accuracy: 0.7844 - val_loss: 0.4843 - val_accuracy: 0.7855\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.7809 - val_loss: 0.4836 - val_accuracy: 0.7837\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4824 - accuracy: 0.7832 - val_loss: 0.4828 - val_accuracy: 0.7855\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7836 - val_loss: 0.4821 - val_accuracy: 0.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7821 - val_loss: 0.4815 - val_accuracy: 0.7855\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7836 - val_loss: 0.4810 - val_accuracy: 0.7855\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7825 - val_loss: 0.4804 - val_accuracy: 0.7855\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4794 - accuracy: 0.7832 - val_loss: 0.4800 - val_accuracy: 0.7855\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.7802 - val_loss: 0.4796 - val_accuracy: 0.7863\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7832 - val_loss: 0.4793 - val_accuracy: 0.7846\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7855\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4778 - accuracy: 0.7828 - val_loss: 0.4786 - val_accuracy: 0.7855\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.7836 - val_loss: 0.4785 - val_accuracy: 0.7819\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4770 - accuracy: 0.7836 - val_loss: 0.4781 - val_accuracy: 0.7863\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4769 - accuracy: 0.7836 - val_loss: 0.4778 - val_accuracy: 0.7855\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4765 - accuracy: 0.7828 - val_loss: 0.4775 - val_accuracy: 0.7855\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4765 - accuracy: 0.7840 - val_loss: 0.4773 - val_accuracy: 0.7855\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4763 - accuracy: 0.7825 - val_loss: 0.4772 - val_accuracy: 0.7863\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4761 - accuracy: 0.7832 - val_loss: 0.4770 - val_accuracy: 0.7855\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4759 - accuracy: 0.7825 - val_loss: 0.4769 - val_accuracy: 0.7855\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4758 - accuracy: 0.7836 - val_loss: 0.4767 - val_accuracy: 0.7855\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4756 - accuracy: 0.7855 - val_loss: 0.4766 - val_accuracy: 0.7846\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4755 - accuracy: 0.7855 - val_loss: 0.4764 - val_accuracy: 0.7855\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.7847 - val_loss: 0.4763 - val_accuracy: 0.7855\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.7859 - val_loss: 0.4762 - val_accuracy: 0.7846\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4751 - accuracy: 0.7825 - val_loss: 0.4762 - val_accuracy: 0.7855\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4750 - accuracy: 0.7855 - val_loss: 0.4761 - val_accuracy: 0.7846\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4748 - accuracy: 0.7836 - val_loss: 0.4764 - val_accuracy: 0.7801\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4750 - accuracy: 0.7802 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4749 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4748 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4747 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4747 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4746 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4746 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4745 - accuracy: 0.7832 - val_loss: 0.4758 - val_accuracy: 0.7819\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4743 - accuracy: 0.7855 - val_loss: 0.4759 - val_accuracy: 0.7801\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4742 - accuracy: 0.7806 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4745 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4744 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.4744 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.4742 - accuracy: 0.7859 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4743 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.4743 - accuracy: 0.7844 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4742 - accuracy: 0.7844 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4741 - accuracy: 0.7851 - val_loss: 0.4757 - val_accuracy: 0.7793\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4743 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4741 - accuracy: 0.7828 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4742 - accuracy: 0.7825 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4742 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4741 - accuracy: 0.7825 - val_loss: 0.4754 - val_accuracy: 0.7837\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7801\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4742 - accuracy: 0.7844 - val_loss: 0.4755 - val_accuracy: 0.7828\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.7844 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4740 - accuracy: 0.7836 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4741 - accuracy: 0.7828 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4740 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7810\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4741 - accuracy: 0.7825 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.7844 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4740 - accuracy: 0.7859 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.7821 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4755 - val_accuracy: 0.7828\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.7832 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7817 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.7832 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4754 - val_accuracy: 0.7837\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7851 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7793\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7859 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7810\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4739 - accuracy: 0.7828 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4739 - accuracy: 0.7851 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4739 - accuracy: 0.7832 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4740 - accuracy: 0.7821 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4738 - accuracy: 0.7828 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7828 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4755 - val_accuracy: 0.7863\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4739 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4739 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7832 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7809 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7817 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7855 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7828\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7817 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7801\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7819\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7806 - val_loss: 0.4758 - val_accuracy: 0.7793\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7784\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7859 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7851 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4755 - val_accuracy: 0.7846\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4759 - val_accuracy: 0.7801\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7810\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7851 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7813 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7828\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7817 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7810\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7837\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4755 - val_accuracy: 0.7855\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7863\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7810\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4758 - val_accuracy: 0.7810\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4760 - val_accuracy: 0.7801\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7851 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7793\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7817 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7859 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7809 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7851 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7810\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7851 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7855 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7863\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7859 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7809 - val_loss: 0.4756 - val_accuracy: 0.7863\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7846\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4758 - val_accuracy: 0.7828\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7863\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7832 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7828\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7810\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4734 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7863\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4739 - accuracy: 0.7840 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7819\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7832 - val_loss: 0.4765 - val_accuracy: 0.7784\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4739 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4736 - accuracy: 0.7851 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7851 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4738 - accuracy: 0.7851 - val_loss: 0.4757 - val_accuracy: 0.7863\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7863 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7863\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7817 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7837\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7851 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4733 - accuracy: 0.7806 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7855 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7817 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7855 - val_loss: 0.4759 - val_accuracy: 0.7801\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7817 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7863\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7817 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7828 - val_loss: 0.4760 - val_accuracy: 0.7793\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4759 - val_accuracy: 0.7801\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7855 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7828\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7793\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4765 - val_accuracy: 0.7793\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7840 - val_loss: 0.4761 - val_accuracy: 0.7801\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7863\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4733 - accuracy: 0.7832 - val_loss: 0.4761 - val_accuracy: 0.7801\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7836 - val_loss: 0.4762 - val_accuracy: 0.7793\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4732 - accuracy: 0.7828 - val_loss: 0.4759 - val_accuracy: 0.7863\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.7828 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7851 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7828 - val_loss: 0.4759 - val_accuracy: 0.7863\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4757 - val_accuracy: 0.7837\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7859 - val_loss: 0.4761 - val_accuracy: 0.7793\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7863\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7809 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7801\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.7855 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7851 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4757 - val_accuracy: 0.7855\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7817 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7828 - val_loss: 0.4761 - val_accuracy: 0.7793\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7832 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7863\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7828\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7828 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7810\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7817 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7846\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4760 - val_accuracy: 0.7819\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7825 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.4761 - val_accuracy: 0.7801\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7859 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7855\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7817 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7851 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7806 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7851 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7836 - val_loss: 0.4763 - val_accuracy: 0.7801\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4761 - val_accuracy: 0.7819\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7855 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7866 - val_loss: 0.4761 - val_accuracy: 0.7819\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4761 - val_accuracy: 0.7819\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7809 - val_loss: 0.4762 - val_accuracy: 0.7801\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7825 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7828 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4734 - accuracy: 0.7825 - val_loss: 0.4762 - val_accuracy: 0.7793\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7813 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4735 - accuracy: 0.7840 - val_loss: 0.4759 - val_accuracy: 0.7855\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4733 - accuracy: 0.7844 - val_loss: 0.4762 - val_accuracy: 0.7784\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4737 - accuracy: 0.7844 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.4763 - val_accuracy: 0.7793\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4730 - accuracy: 0.7813 - val_loss: 0.4762 - val_accuracy: 0.7863\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7855 - val_loss: 0.4762 - val_accuracy: 0.7801\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4762 - val_accuracy: 0.7784\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4736 - accuracy: 0.7806 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7844 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7837\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7855 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4759 - val_accuracy: 0.7846\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7832 - val_loss: 0.4762 - val_accuracy: 0.7810\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4736 - accuracy: 0.7851 - val_loss: 0.4762 - val_accuracy: 0.7801\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4761 - val_accuracy: 0.7810\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7851 - val_loss: 0.4762 - val_accuracy: 0.7801\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4734 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7825 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7832 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.7832 - val_loss: 0.4763 - val_accuracy: 0.7784\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7844 - val_loss: 0.4761 - val_accuracy: 0.7855\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7828 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7832 - val_loss: 0.4761 - val_accuracy: 0.7828\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7844 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7817 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7837\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7851 - val_loss: 0.4761 - val_accuracy: 0.7846\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4735 - accuracy: 0.7851 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7836 - val_loss: 0.4764 - val_accuracy: 0.7793\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7840 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7825 - val_loss: 0.4761 - val_accuracy: 0.7846\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.7840 - val_loss: 0.4762 - val_accuracy: 0.7810\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4732 - accuracy: 0.7832 - val_loss: 0.4765 - val_accuracy: 0.7793\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7832 - val_loss: 0.4761 - val_accuracy: 0.7846\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7813 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.7855 - val_loss: 0.4761 - val_accuracy: 0.7846\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7855\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.4761 - val_accuracy: 0.7837\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7837\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 1s 3ms/step\n",
      "[[ 0.3]\n",
      " [ 0.6]\n",
      " [ 0.4]\n",
      " [ 0.3]\n",
      " [ 0.8]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7773755656108597\n",
      "0.7292020373514432\n",
      "0.7525186158563295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.6]\n",
      " [ 0.8]\n",
      " [ 0.1]\n",
      " [ 0.4]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794432548179872\n",
      "0.7207920792079208\n",
      "0.7489711934156379\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
