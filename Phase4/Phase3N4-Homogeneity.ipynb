{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  6.6  489.7 ...  3.5  1.0  0.0]\n",
      " [ 1.0  13.6  1201.8 ...  6.3  0.9  0.0]\n",
      " [ 0.0  6.4  533.1 ...  6.0  0.9  0.0]\n",
      " ...\n",
      " [ 1.0  2.7  355.2 ...  5.3  1.0  0.0]\n",
      " [ 0.0  1.9  109.5 ...  5.2  0.9  0.0]\n",
      " [ 0.0  0.1  3.3 ...  5.5  0.8  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 10]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 10]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 14ms/step - loss: 0.7161 - accuracy: 0.3732 - val_loss: 0.7047 - val_accuracy: 0.0647\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6999 - accuracy: 0.4009 - val_loss: 0.6969 - val_accuracy: 0.5399\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6901 - accuracy: 0.5581 - val_loss: 0.6874 - val_accuracy: 0.5399\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6827 - accuracy: 0.5581 - val_loss: 0.6841 - val_accuracy: 0.5399\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5581 - val_loss: 0.6810 - val_accuracy: 0.5399\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6754 - accuracy: 0.5581 - val_loss: 0.6780 - val_accuracy: 0.5399\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6719 - accuracy: 0.5581 - val_loss: 0.6746 - val_accuracy: 0.5399\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6680 - accuracy: 0.5581 - val_loss: 0.6708 - val_accuracy: 0.5399\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.5581 - val_loss: 0.6669 - val_accuracy: 0.5399\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.5581 - val_loss: 0.6622 - val_accuracy: 0.5399\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6543 - accuracy: 0.5581 - val_loss: 0.6568 - val_accuracy: 0.5399\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.5581 - val_loss: 0.6514 - val_accuracy: 0.5399\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.5581 - val_loss: 0.6450 - val_accuracy: 0.5399\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.5588 - val_loss: 0.6390 - val_accuracy: 0.5399\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.5604 - val_loss: 0.6323 - val_accuracy: 0.5408\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.5638 - val_loss: 0.6248 - val_accuracy: 0.5505\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.5756 - val_loss: 0.6171 - val_accuracy: 0.5612\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.5938 - val_loss: 0.6092 - val_accuracy: 0.5789\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.6166 - val_loss: 0.6011 - val_accuracy: 0.6037\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6435 - val_loss: 0.5924 - val_accuracy: 0.6321\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.6777 - val_loss: 0.5842 - val_accuracy: 0.6605\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7024 - val_loss: 0.5751 - val_accuracy: 0.6941\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7202 - val_loss: 0.5667 - val_accuracy: 0.7119\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7422 - val_loss: 0.5582 - val_accuracy: 0.7358\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.7703 - val_loss: 0.5486 - val_accuracy: 0.7686\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7988 - val_loss: 0.5394 - val_accuracy: 0.7846\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.8125 - val_loss: 0.5294 - val_accuracy: 0.8156\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.8257 - val_loss: 0.5205 - val_accuracy: 0.8200\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.8307 - val_loss: 0.5116 - val_accuracy: 0.8351\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.8424 - val_loss: 0.5019 - val_accuracy: 0.8440\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.8485 - val_loss: 0.4922 - val_accuracy: 0.8590\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.8618 - val_loss: 0.4828 - val_accuracy: 0.8715\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.8660 - val_loss: 0.4740 - val_accuracy: 0.8750\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.8690 - val_loss: 0.4640 - val_accuracy: 0.8901\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.8808 - val_loss: 0.4548 - val_accuracy: 0.8918\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8846 - val_loss: 0.4459 - val_accuracy: 0.8936\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.8865 - val_loss: 0.4367 - val_accuracy: 0.8980\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8922 - val_loss: 0.4278 - val_accuracy: 0.8998\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8971 - val_loss: 0.4189 - val_accuracy: 0.9007\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8971 - val_loss: 0.4102 - val_accuracy: 0.9060\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.9032 - val_loss: 0.4015 - val_accuracy: 0.9069\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3998 - accuracy: 0.9036 - val_loss: 0.3925 - val_accuracy: 0.9113\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3919 - accuracy: 0.9074 - val_loss: 0.3845 - val_accuracy: 0.9176\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.9142 - val_loss: 0.3768 - val_accuracy: 0.9176\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3768 - accuracy: 0.9131 - val_loss: 0.3686 - val_accuracy: 0.9220\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.9153 - val_loss: 0.3606 - val_accuracy: 0.9238\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.9176 - val_loss: 0.3527 - val_accuracy: 0.9264\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.9226 - val_loss: 0.3457 - val_accuracy: 0.9255\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.9237 - val_loss: 0.3390 - val_accuracy: 0.9264\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.9248 - val_loss: 0.3323 - val_accuracy: 0.9300\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3354 - accuracy: 0.9286 - val_loss: 0.3259 - val_accuracy: 0.9300\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.9282 - val_loss: 0.3188 - val_accuracy: 0.9335\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.9290 - val_loss: 0.3121 - val_accuracy: 0.9335\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3167 - accuracy: 0.9317 - val_loss: 0.3056 - val_accuracy: 0.9362\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.9332 - val_loss: 0.2997 - val_accuracy: 0.9371\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.9324 - val_loss: 0.2935 - val_accuracy: 0.9415\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2999 - accuracy: 0.9366 - val_loss: 0.2883 - val_accuracy: 0.9397\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.9366 - val_loss: 0.2828 - val_accuracy: 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2897 - accuracy: 0.9355 - val_loss: 0.2772 - val_accuracy: 0.9424\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2848 - accuracy: 0.9366 - val_loss: 0.2721 - val_accuracy: 0.9424\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2801 - accuracy: 0.9370 - val_loss: 0.2669 - val_accuracy: 0.9441\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2755 - accuracy: 0.9377 - val_loss: 0.2622 - val_accuracy: 0.9441\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2711 - accuracy: 0.9374 - val_loss: 0.2575 - val_accuracy: 0.9468\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2668 - accuracy: 0.9389 - val_loss: 0.2529 - val_accuracy: 0.9477\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2630 - accuracy: 0.9385 - val_loss: 0.2490 - val_accuracy: 0.9477\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2589 - accuracy: 0.9400 - val_loss: 0.2445 - val_accuracy: 0.9477\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2549 - accuracy: 0.9396 - val_loss: 0.2403 - val_accuracy: 0.9468\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2513 - accuracy: 0.9404 - val_loss: 0.2366 - val_accuracy: 0.9468\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2478 - accuracy: 0.9408 - val_loss: 0.2329 - val_accuracy: 0.9468\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.9400 - val_loss: 0.2289 - val_accuracy: 0.9504\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2409 - accuracy: 0.9412 - val_loss: 0.2255 - val_accuracy: 0.9486\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2379 - accuracy: 0.9419 - val_loss: 0.2222 - val_accuracy: 0.9504\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2348 - accuracy: 0.9419 - val_loss: 0.2190 - val_accuracy: 0.9504\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9419 - val_loss: 0.2159 - val_accuracy: 0.9521\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.9423 - val_loss: 0.2130 - val_accuracy: 0.9521\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9431 - val_loss: 0.2102 - val_accuracy: 0.9521\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2240 - accuracy: 0.9434 - val_loss: 0.2072 - val_accuracy: 0.9530\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2215 - accuracy: 0.9427 - val_loss: 0.2044 - val_accuracy: 0.9539\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9438 - val_loss: 0.2017 - val_accuracy: 0.9530\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2166 - accuracy: 0.9450 - val_loss: 0.1992 - val_accuracy: 0.9530\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2145 - accuracy: 0.9450 - val_loss: 0.1971 - val_accuracy: 0.9539\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.9442 - val_loss: 0.1947 - val_accuracy: 0.9539\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2103 - accuracy: 0.9442 - val_loss: 0.1927 - val_accuracy: 0.9530\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2083 - accuracy: 0.9461 - val_loss: 0.1907 - val_accuracy: 0.9539\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2063 - accuracy: 0.9450 - val_loss: 0.1880 - val_accuracy: 0.9530\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9457 - val_loss: 0.1861 - val_accuracy: 0.9548\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9465 - val_loss: 0.1843 - val_accuracy: 0.9539\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2009 - accuracy: 0.9465 - val_loss: 0.1823 - val_accuracy: 0.9539\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9465 - val_loss: 0.1806 - val_accuracy: 0.9539\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9468 - val_loss: 0.1788 - val_accuracy: 0.9548\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9468 - val_loss: 0.1775 - val_accuracy: 0.9539\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1948 - accuracy: 0.9465 - val_loss: 0.1757 - val_accuracy: 0.9566\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1935 - accuracy: 0.9472 - val_loss: 0.1741 - val_accuracy: 0.9548\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9491 - val_loss: 0.1727 - val_accuracy: 0.9548\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1908 - accuracy: 0.9468 - val_loss: 0.1712 - val_accuracy: 0.9566\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1894 - accuracy: 0.9484 - val_loss: 0.1701 - val_accuracy: 0.9539\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1882 - accuracy: 0.9476 - val_loss: 0.1684 - val_accuracy: 0.9566\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9499 - val_loss: 0.1670 - val_accuracy: 0.9566\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1857 - accuracy: 0.9495 - val_loss: 0.1662 - val_accuracy: 0.9548\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1848 - accuracy: 0.9484 - val_loss: 0.1647 - val_accuracy: 0.9566\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1837 - accuracy: 0.9484 - val_loss: 0.1635 - val_accuracy: 0.9548\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9487 - val_loss: 0.1620 - val_accuracy: 0.9566\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1815 - accuracy: 0.9499 - val_loss: 0.1610 - val_accuracy: 0.9574\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9487 - val_loss: 0.1598 - val_accuracy: 0.9566\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1797 - accuracy: 0.9487 - val_loss: 0.1589 - val_accuracy: 0.9566\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1786 - accuracy: 0.9484 - val_loss: 0.1576 - val_accuracy: 0.9574\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1777 - accuracy: 0.9495 - val_loss: 0.1567 - val_accuracy: 0.9592\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1768 - accuracy: 0.9510 - val_loss: 0.1558 - val_accuracy: 0.9574\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1759 - accuracy: 0.9491 - val_loss: 0.1547 - val_accuracy: 0.9566\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1751 - accuracy: 0.9499 - val_loss: 0.1538 - val_accuracy: 0.9583\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1744 - accuracy: 0.9495 - val_loss: 0.1529 - val_accuracy: 0.9583\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9503 - val_loss: 0.1521 - val_accuracy: 0.9583\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1729 - accuracy: 0.9503 - val_loss: 0.1512 - val_accuracy: 0.9601\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9510 - val_loss: 0.1505 - val_accuracy: 0.9583\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9499 - val_loss: 0.1498 - val_accuracy: 0.9583\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1708 - accuracy: 0.9510 - val_loss: 0.1490 - val_accuracy: 0.9583\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1702 - accuracy: 0.9510 - val_loss: 0.1482 - val_accuracy: 0.9583\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1695 - accuracy: 0.9506 - val_loss: 0.1476 - val_accuracy: 0.9583\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1688 - accuracy: 0.9503 - val_loss: 0.1473 - val_accuracy: 0.9566\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1684 - accuracy: 0.9510 - val_loss: 0.1463 - val_accuracy: 0.9574\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1677 - accuracy: 0.9506 - val_loss: 0.1453 - val_accuracy: 0.9601\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1669 - accuracy: 0.9514 - val_loss: 0.1448 - val_accuracy: 0.9583\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1664 - accuracy: 0.9518 - val_loss: 0.1439 - val_accuracy: 0.9601\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1659 - accuracy: 0.9522 - val_loss: 0.1434 - val_accuracy: 0.9601\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1653 - accuracy: 0.9518 - val_loss: 0.1427 - val_accuracy: 0.9601\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1647 - accuracy: 0.9510 - val_loss: 0.1420 - val_accuracy: 0.9610\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1642 - accuracy: 0.9503 - val_loss: 0.1418 - val_accuracy: 0.9583\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1639 - accuracy: 0.9518 - val_loss: 0.1410 - val_accuracy: 0.9601\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.9514 - val_loss: 0.1403 - val_accuracy: 0.9601\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1628 - accuracy: 0.9514 - val_loss: 0.1399 - val_accuracy: 0.9601\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1623 - accuracy: 0.9518 - val_loss: 0.1393 - val_accuracy: 0.9601\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.9518 - val_loss: 0.1387 - val_accuracy: 0.9601\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1615 - accuracy: 0.9510 - val_loss: 0.1382 - val_accuracy: 0.9601\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1611 - accuracy: 0.9514 - val_loss: 0.1379 - val_accuracy: 0.9601\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9514 - val_loss: 0.1378 - val_accuracy: 0.9583\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1604 - accuracy: 0.9518 - val_loss: 0.1369 - val_accuracy: 0.9601\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1599 - accuracy: 0.9518 - val_loss: 0.1365 - val_accuracy: 0.9601\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1595 - accuracy: 0.9514 - val_loss: 0.1362 - val_accuracy: 0.9601\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1592 - accuracy: 0.9522 - val_loss: 0.1358 - val_accuracy: 0.9601\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1588 - accuracy: 0.9510 - val_loss: 0.1350 - val_accuracy: 0.9610\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.9529 - val_loss: 0.1346 - val_accuracy: 0.9610\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1581 - accuracy: 0.9518 - val_loss: 0.1343 - val_accuracy: 0.9601\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.9514 - val_loss: 0.1340 - val_accuracy: 0.9601\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1574 - accuracy: 0.9518 - val_loss: 0.1334 - val_accuracy: 0.9619\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 0.9522 - val_loss: 0.1330 - val_accuracy: 0.9619\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1568 - accuracy: 0.9518 - val_loss: 0.1326 - val_accuracy: 0.9628\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1564 - accuracy: 0.9525 - val_loss: 0.1324 - val_accuracy: 0.9601\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1562 - accuracy: 0.9518 - val_loss: 0.1320 - val_accuracy: 0.9619\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1559 - accuracy: 0.9510 - val_loss: 0.1317 - val_accuracy: 0.9610\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.9518 - val_loss: 0.1313 - val_accuracy: 0.9628\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1554 - accuracy: 0.9518 - val_loss: 0.1310 - val_accuracy: 0.9628\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.9514 - val_loss: 0.1306 - val_accuracy: 0.9628\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1549 - accuracy: 0.9506 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 0.1302 - val_accuracy: 0.9610\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1544 - accuracy: 0.9503 - val_loss: 0.1298 - val_accuracy: 0.9610\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1541 - accuracy: 0.9522 - val_loss: 0.1296 - val_accuracy: 0.9610\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1540 - accuracy: 0.9518 - val_loss: 0.1292 - val_accuracy: 0.9619\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.9518 - val_loss: 0.1289 - val_accuracy: 0.9619\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1534 - accuracy: 0.9518 - val_loss: 0.1286 - val_accuracy: 0.9628\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1533 - accuracy: 0.9518 - val_loss: 0.1283 - val_accuracy: 0.9628\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1530 - accuracy: 0.9514 - val_loss: 0.1280 - val_accuracy: 0.9619\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1528 - accuracy: 0.9522 - val_loss: 0.1279 - val_accuracy: 0.9619\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1525 - accuracy: 0.9518 - val_loss: 0.1275 - val_accuracy: 0.9628\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1523 - accuracy: 0.9518 - val_loss: 0.1274 - val_accuracy: 0.9619\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1521 - accuracy: 0.9518 - val_loss: 0.1270 - val_accuracy: 0.9628\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1519 - accuracy: 0.9514 - val_loss: 0.1268 - val_accuracy: 0.9628\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1518 - accuracy: 0.9510 - val_loss: 0.1265 - val_accuracy: 0.9628\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1516 - accuracy: 0.9522 - val_loss: 0.1263 - val_accuracy: 0.9628\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1514 - accuracy: 0.9518 - val_loss: 0.1261 - val_accuracy: 0.9628\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1511 - accuracy: 0.9518 - val_loss: 0.1259 - val_accuracy: 0.9628\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9533 - val_loss: 0.1256 - val_accuracy: 0.9645\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1508 - accuracy: 0.9518 - val_loss: 0.1254 - val_accuracy: 0.9645\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.9510 - val_loss: 0.1251 - val_accuracy: 0.9645\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1505 - accuracy: 0.9518 - val_loss: 0.1249 - val_accuracy: 0.9645\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1503 - accuracy: 0.9514 - val_loss: 0.1246 - val_accuracy: 0.9645\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1501 - accuracy: 0.9518 - val_loss: 0.1244 - val_accuracy: 0.9619\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1499 - accuracy: 0.9514 - val_loss: 0.1242 - val_accuracy: 0.9628\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 0.1240 - val_accuracy: 0.9628\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1496 - accuracy: 0.9518 - val_loss: 0.1238 - val_accuracy: 0.9645\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1495 - accuracy: 0.9510 - val_loss: 0.1236 - val_accuracy: 0.9628\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1493 - accuracy: 0.9514 - val_loss: 0.1234 - val_accuracy: 0.9645\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9518 - val_loss: 0.1232 - val_accuracy: 0.9645\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9514 - val_loss: 0.1230 - val_accuracy: 0.9645\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1489 - accuracy: 0.9510 - val_loss: 0.1229 - val_accuracy: 0.9645\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9518 - val_loss: 0.1227 - val_accuracy: 0.9619\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9510 - val_loss: 0.1226 - val_accuracy: 0.9628\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.9518 - val_loss: 0.1225 - val_accuracy: 0.9628\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1482 - accuracy: 0.9514 - val_loss: 0.1224 - val_accuracy: 0.9628\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1483 - accuracy: 0.9510 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1480 - accuracy: 0.9518 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1480 - accuracy: 0.9499 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9518 - val_loss: 0.1215 - val_accuracy: 0.9645\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9522 - val_loss: 0.1214 - val_accuracy: 0.9645\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9514 - val_loss: 0.1212 - val_accuracy: 0.9645\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9510 - val_loss: 0.1213 - val_accuracy: 0.9628\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1474 - accuracy: 0.9514 - val_loss: 0.1210 - val_accuracy: 0.9619\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9518 - val_loss: 0.1209 - val_accuracy: 0.9619\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1472 - accuracy: 0.9510 - val_loss: 0.1207 - val_accuracy: 0.9619\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9514 - val_loss: 0.1205 - val_accuracy: 0.9645\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1469 - accuracy: 0.9518 - val_loss: 0.1206 - val_accuracy: 0.9628\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1468 - accuracy: 0.9518 - val_loss: 0.1203 - val_accuracy: 0.9619\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1468 - accuracy: 0.9525 - val_loss: 0.1201 - val_accuracy: 0.9645\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1466 - accuracy: 0.9514 - val_loss: 0.1200 - val_accuracy: 0.9628\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1466 - accuracy: 0.9518 - val_loss: 0.1199 - val_accuracy: 0.9628\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1465 - accuracy: 0.9510 - val_loss: 0.1197 - val_accuracy: 0.9645\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.9514 - val_loss: 0.1195 - val_accuracy: 0.9645\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1462 - accuracy: 0.9518 - val_loss: 0.1195 - val_accuracy: 0.9628\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1462 - accuracy: 0.9518 - val_loss: 0.1193 - val_accuracy: 0.9645\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1461 - accuracy: 0.9522 - val_loss: 0.1193 - val_accuracy: 0.9628\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.1190 - val_accuracy: 0.9645\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1459 - accuracy: 0.9510 - val_loss: 0.1189 - val_accuracy: 0.9645\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1458 - accuracy: 0.9518 - val_loss: 0.1188 - val_accuracy: 0.9645\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1456 - accuracy: 0.9506 - val_loss: 0.1187 - val_accuracy: 0.9645\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1457 - accuracy: 0.9514 - val_loss: 0.1185 - val_accuracy: 0.9645\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1456 - accuracy: 0.9514 - val_loss: 0.1184 - val_accuracy: 0.9645\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1455 - accuracy: 0.9518 - val_loss: 0.1183 - val_accuracy: 0.9645\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1454 - accuracy: 0.9518 - val_loss: 0.1182 - val_accuracy: 0.9645\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1454 - accuracy: 0.9503 - val_loss: 0.1181 - val_accuracy: 0.9645\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1452 - accuracy: 0.9506 - val_loss: 0.1180 - val_accuracy: 0.9637\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1453 - accuracy: 0.9522 - val_loss: 0.1179 - val_accuracy: 0.9645\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1452 - accuracy: 0.9510 - val_loss: 0.1178 - val_accuracy: 0.9645\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1451 - accuracy: 0.9518 - val_loss: 0.1177 - val_accuracy: 0.9645\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.1176 - val_accuracy: 0.9645\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1449 - accuracy: 0.9510 - val_loss: 0.1176 - val_accuracy: 0.9628\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1449 - accuracy: 0.9514 - val_loss: 0.1174 - val_accuracy: 0.9645\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1446 - accuracy: 0.9510 - val_loss: 0.1174 - val_accuracy: 0.9628\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1448 - accuracy: 0.9522 - val_loss: 0.1172 - val_accuracy: 0.9645\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.1448 - accuracy: 0.9518 - val_loss: 0.1172 - val_accuracy: 0.9645\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1446 - accuracy: 0.9510 - val_loss: 0.1173 - val_accuracy: 0.9628\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 13ms/step - loss: 0.1447 - accuracy: 0.9518 - val_loss: 0.1170 - val_accuracy: 0.9645\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1445 - accuracy: 0.9514 - val_loss: 0.1169 - val_accuracy: 0.9645\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.1445 - accuracy: 0.9506 - val_loss: 0.1168 - val_accuracy: 0.9645\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1444 - accuracy: 0.9514 - val_loss: 0.1167 - val_accuracy: 0.9645\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1443 - accuracy: 0.9506 - val_loss: 0.1166 - val_accuracy: 0.9645\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1442 - accuracy: 0.9495 - val_loss: 0.1166 - val_accuracy: 0.9628\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1443 - accuracy: 0.9525 - val_loss: 0.1165 - val_accuracy: 0.9645\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1442 - accuracy: 0.9506 - val_loss: 0.1164 - val_accuracy: 0.9645\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9510 - val_loss: 0.1163 - val_accuracy: 0.9645\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1440 - accuracy: 0.9499 - val_loss: 0.1163 - val_accuracy: 0.9645\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1440 - accuracy: 0.9514 - val_loss: 0.1163 - val_accuracy: 0.9645\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1440 - accuracy: 0.9506 - val_loss: 0.1161 - val_accuracy: 0.9645\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9503 - val_loss: 0.1161 - val_accuracy: 0.9645\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1439 - accuracy: 0.9510 - val_loss: 0.1159 - val_accuracy: 0.9645\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9518 - val_loss: 0.1158 - val_accuracy: 0.9645\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9518 - val_loss: 0.1158 - val_accuracy: 0.9628\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.9510 - val_loss: 0.1157 - val_accuracy: 0.9645\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.9514 - val_loss: 0.1156 - val_accuracy: 0.9637\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1436 - accuracy: 0.9499 - val_loss: 0.1156 - val_accuracy: 0.9645\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1435 - accuracy: 0.9525 - val_loss: 0.1155 - val_accuracy: 0.9628\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1436 - accuracy: 0.9506 - val_loss: 0.1154 - val_accuracy: 0.9628\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.1154 - val_accuracy: 0.9645\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1434 - accuracy: 0.9506 - val_loss: 0.1154 - val_accuracy: 0.9645\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1434 - accuracy: 0.9506 - val_loss: 0.1154 - val_accuracy: 0.9645\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1432 - accuracy: 0.9529 - val_loss: 0.1152 - val_accuracy: 0.9628\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1433 - accuracy: 0.9506 - val_loss: 0.1151 - val_accuracy: 0.9637\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1432 - accuracy: 0.9506 - val_loss: 0.1150 - val_accuracy: 0.9645\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1433 - accuracy: 0.9506 - val_loss: 0.1150 - val_accuracy: 0.9645\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1432 - accuracy: 0.9510 - val_loss: 0.1150 - val_accuracy: 0.9645\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1432 - accuracy: 0.9525 - val_loss: 0.1149 - val_accuracy: 0.9645\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9506 - val_loss: 0.1148 - val_accuracy: 0.9645\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9499 - val_loss: 0.1147 - val_accuracy: 0.9637\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1429 - accuracy: 0.9518 - val_loss: 0.1147 - val_accuracy: 0.9645\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1430 - accuracy: 0.9503 - val_loss: 0.1146 - val_accuracy: 0.9637\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1430 - accuracy: 0.9503 - val_loss: 0.1146 - val_accuracy: 0.9645\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1429 - accuracy: 0.9514 - val_loss: 0.1145 - val_accuracy: 0.9645\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1144 - val_accuracy: 0.9637\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.1428 - accuracy: 0.9510 - val_loss: 0.1144 - val_accuracy: 0.9628\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1428 - accuracy: 0.9506 - val_loss: 0.1143 - val_accuracy: 0.9645\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9510 - val_loss: 0.1143 - val_accuracy: 0.9645\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1427 - accuracy: 0.9510 - val_loss: 0.1142 - val_accuracy: 0.9628\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1426 - accuracy: 0.9514 - val_loss: 0.1143 - val_accuracy: 0.9645\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1427 - accuracy: 0.9522 - val_loss: 0.1141 - val_accuracy: 0.9637\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1427 - accuracy: 0.9503 - val_loss: 0.1141 - val_accuracy: 0.9628\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1426 - accuracy: 0.9503 - val_loss: 0.1141 - val_accuracy: 0.9645\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1426 - accuracy: 0.9529 - val_loss: 0.1140 - val_accuracy: 0.9637\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1426 - accuracy: 0.9506 - val_loss: 0.1139 - val_accuracy: 0.9628\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9518 - val_loss: 0.1139 - val_accuracy: 0.9619\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9510 - val_loss: 0.1138 - val_accuracy: 0.9637\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9522 - val_loss: 0.1137 - val_accuracy: 0.9628\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1425 - accuracy: 0.9506 - val_loss: 0.1137 - val_accuracy: 0.9628\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9499 - val_loss: 0.1137 - val_accuracy: 0.9645\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9506 - val_loss: 0.1136 - val_accuracy: 0.9637\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9522 - val_loss: 0.1136 - val_accuracy: 0.9637\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1424 - accuracy: 0.9510 - val_loss: 0.1135 - val_accuracy: 0.9628\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9510 - val_loss: 0.1135 - val_accuracy: 0.9637\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9503 - val_loss: 0.1135 - val_accuracy: 0.9645\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9506 - val_loss: 0.1134 - val_accuracy: 0.9628\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1422 - accuracy: 0.9506 - val_loss: 0.1133 - val_accuracy: 0.9637\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1421 - accuracy: 0.9506 - val_loss: 0.1133 - val_accuracy: 0.9628\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1420 - accuracy: 0.9518 - val_loss: 0.1135 - val_accuracy: 0.9645\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1422 - accuracy: 0.9518 - val_loss: 0.1132 - val_accuracy: 0.9628\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.9506 - val_loss: 0.1132 - val_accuracy: 0.9637\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1421 - accuracy: 0.9510 - val_loss: 0.1131 - val_accuracy: 0.9628\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.9514 - val_loss: 0.1131 - val_accuracy: 0.9619\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1421 - accuracy: 0.9514 - val_loss: 0.1130 - val_accuracy: 0.9637\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.9503 - val_loss: 0.1130 - val_accuracy: 0.9628\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1420 - accuracy: 0.9518 - val_loss: 0.1129 - val_accuracy: 0.9628\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1420 - accuracy: 0.9499 - val_loss: 0.1129 - val_accuracy: 0.9628\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1419 - accuracy: 0.9495 - val_loss: 0.1129 - val_accuracy: 0.9645\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1420 - accuracy: 0.9503 - val_loss: 0.1129 - val_accuracy: 0.9637\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1419 - accuracy: 0.9514 - val_loss: 0.1129 - val_accuracy: 0.9645\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1419 - accuracy: 0.9518 - val_loss: 0.1128 - val_accuracy: 0.9637\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1419 - accuracy: 0.9518 - val_loss: 0.1127 - val_accuracy: 0.9628\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1419 - accuracy: 0.9506 - val_loss: 0.1127 - val_accuracy: 0.9628\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9510 - val_loss: 0.1127 - val_accuracy: 0.9637\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9514 - val_loss: 0.1126 - val_accuracy: 0.9628\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9514 - val_loss: 0.1126 - val_accuracy: 0.9628\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9518 - val_loss: 0.1125 - val_accuracy: 0.9628\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9506 - val_loss: 0.1125 - val_accuracy: 0.9628\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9506 - val_loss: 0.1125 - val_accuracy: 0.9628\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9518 - val_loss: 0.1124 - val_accuracy: 0.9628\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9503 - val_loss: 0.1124 - val_accuracy: 0.9628\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1416 - accuracy: 0.9525 - val_loss: 0.1123 - val_accuracy: 0.9628\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9506 - val_loss: 0.1123 - val_accuracy: 0.9628\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1416 - accuracy: 0.9518 - val_loss: 0.1123 - val_accuracy: 0.9645\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1416 - accuracy: 0.9499 - val_loss: 0.1123 - val_accuracy: 0.9645\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1416 - accuracy: 0.9514 - val_loss: 0.1122 - val_accuracy: 0.9637\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9499 - val_loss: 0.1121 - val_accuracy: 0.9628\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9506 - val_loss: 0.1121 - val_accuracy: 0.9619\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1416 - accuracy: 0.9503 - val_loss: 0.1121 - val_accuracy: 0.9628\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9514 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1415 - accuracy: 0.9503 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1415 - accuracy: 0.9518 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9510 - val_loss: 0.1121 - val_accuracy: 0.9645\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1415 - accuracy: 0.9499 - val_loss: 0.1119 - val_accuracy: 0.9628\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1415 - accuracy: 0.9503 - val_loss: 0.1119 - val_accuracy: 0.9628\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.1121 - val_accuracy: 0.9645\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1415 - accuracy: 0.9510 - val_loss: 0.1119 - val_accuracy: 0.9637\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9506 - val_loss: 0.1118 - val_accuracy: 0.9628\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9506 - val_loss: 0.1118 - val_accuracy: 0.9637\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9514 - val_loss: 0.1117 - val_accuracy: 0.9628\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9506 - val_loss: 0.1117 - val_accuracy: 0.9628\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9514 - val_loss: 0.1117 - val_accuracy: 0.9610\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9510 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9499 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9514 - val_loss: 0.1118 - val_accuracy: 0.9645\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1413 - accuracy: 0.9525 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9506 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9506 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9514 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9510 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1412 - accuracy: 0.9518 - val_loss: 0.1115 - val_accuracy: 0.9637\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9495 - val_loss: 0.1114 - val_accuracy: 0.9628\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.1113 - val_accuracy: 0.9619\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9503 - val_loss: 0.1113 - val_accuracy: 0.9619\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9514 - val_loss: 0.1113 - val_accuracy: 0.9628\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9506 - val_loss: 0.1113 - val_accuracy: 0.9619\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9499 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.1112 - val_accuracy: 0.9619\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9514 - val_loss: 0.1114 - val_accuracy: 0.9645\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9522 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9518 - val_loss: 0.1111 - val_accuracy: 0.9628\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9506 - val_loss: 0.1111 - val_accuracy: 0.9628\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9522 - val_loss: 0.1111 - val_accuracy: 0.9619\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9506 - val_loss: 0.1111 - val_accuracy: 0.9628\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9506 - val_loss: 0.1110 - val_accuracy: 0.9628\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9495 - val_loss: 0.1111 - val_accuracy: 0.9637\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9506 - val_loss: 0.1110 - val_accuracy: 0.9628\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1110 - val_accuracy: 0.9610\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1410 - accuracy: 0.9510 - val_loss: 0.1110 - val_accuracy: 0.9610\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9510 - val_loss: 0.1109 - val_accuracy: 0.9619\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1410 - accuracy: 0.9503 - val_loss: 0.1109 - val_accuracy: 0.9628\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9506 - val_loss: 0.1109 - val_accuracy: 0.9610\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9510 - val_loss: 0.1109 - val_accuracy: 0.9628\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9514 - val_loss: 0.1109 - val_accuracy: 0.9628\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1108 - val_accuracy: 0.9619\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9518 - val_loss: 0.1108 - val_accuracy: 0.9628\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9514 - val_loss: 0.1109 - val_accuracy: 0.9637\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9506 - val_loss: 0.1107 - val_accuracy: 0.9619\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1107 - val_accuracy: 0.9628\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9499 - val_loss: 0.1107 - val_accuracy: 0.9619\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9518 - val_loss: 0.1108 - val_accuracy: 0.9628\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9495 - val_loss: 0.1107 - val_accuracy: 0.9628\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1107 - val_accuracy: 0.9628\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9518 - val_loss: 0.1106 - val_accuracy: 0.9619\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9506 - val_loss: 0.1106 - val_accuracy: 0.9619\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9522 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1105 - val_accuracy: 0.9619\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1407 - accuracy: 0.9522 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1105 - val_accuracy: 0.9628\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1105 - val_accuracy: 0.9619\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1105 - val_accuracy: 0.9628\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1407 - accuracy: 0.9525 - val_loss: 0.1105 - val_accuracy: 0.9628\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1106 - val_accuracy: 0.9637\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1408 - accuracy: 0.9503 - val_loss: 0.1104 - val_accuracy: 0.9628\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1406 - accuracy: 0.9518 - val_loss: 0.1106 - val_accuracy: 0.9645\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1103 - val_accuracy: 0.9628\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1406 - accuracy: 0.9506 - val_loss: 0.1103 - val_accuracy: 0.9628\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1103 - val_accuracy: 0.9619\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1103 - val_accuracy: 0.9628\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.1103 - val_accuracy: 0.9628\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9510 - val_loss: 0.1103 - val_accuracy: 0.9619\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9518 - val_loss: 0.1103 - val_accuracy: 0.9628\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1406 - accuracy: 0.9503 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9506 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9510 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1405 - accuracy: 0.9503 - val_loss: 0.1102 - val_accuracy: 0.9601\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9518 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1407 - accuracy: 0.9506 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9506 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.1101 - val_accuracy: 0.9619\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9514 - val_loss: 0.1101 - val_accuracy: 0.9619\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9525 - val_loss: 0.1101 - val_accuracy: 0.9619\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1406 - accuracy: 0.9503 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9514 - val_loss: 0.1101 - val_accuracy: 0.9619\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9518 - val_loss: 0.1100 - val_accuracy: 0.9619\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.1102 - val_accuracy: 0.9637\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.1100 - val_accuracy: 0.9619\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1100 - val_accuracy: 0.9610\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.1099 - val_accuracy: 0.9610\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9503 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1404 - accuracy: 0.9506 - val_loss: 0.1099 - val_accuracy: 0.9601\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.1099 - val_accuracy: 0.9610\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.1098 - val_accuracy: 0.9619\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9503 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1098 - val_accuracy: 0.9628\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1404 - accuracy: 0.9514 - val_loss: 0.1098 - val_accuracy: 0.9619\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1098 - val_accuracy: 0.9619\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9503 - val_loss: 0.1098 - val_accuracy: 0.9610\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1098 - val_accuracy: 0.9628\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9514 - val_loss: 0.1097 - val_accuracy: 0.9619\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1097 - val_accuracy: 0.9610\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.1097 - val_accuracy: 0.9610\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9514 - val_loss: 0.1097 - val_accuracy: 0.9619\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9506 - val_loss: 0.1097 - val_accuracy: 0.9610\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9522 - val_loss: 0.1098 - val_accuracy: 0.9628\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.1097 - val_accuracy: 0.9619\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1097 - val_accuracy: 0.9628\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1096 - val_accuracy: 0.9619\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1096 - val_accuracy: 0.9601\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1096 - val_accuracy: 0.9619\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1096 - val_accuracy: 0.9610\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1096 - val_accuracy: 0.9619\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1096 - val_accuracy: 0.9601\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9514 - val_loss: 0.1096 - val_accuracy: 0.9619\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1097 - val_accuracy: 0.9628\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1096 - val_accuracy: 0.9628\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9506 - val_loss: 0.1096 - val_accuracy: 0.9628\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1095 - val_accuracy: 0.9610\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1095 - val_accuracy: 0.9619\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9518 - val_loss: 0.1095 - val_accuracy: 0.9619\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1095 - val_accuracy: 0.9619\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1095 - val_accuracy: 0.9619\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1095 - val_accuracy: 0.9628\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1095 - val_accuracy: 0.9628\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.1095 - val_accuracy: 0.9610\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9522 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9518 - val_loss: 0.1096 - val_accuracy: 0.9628\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9510 - val_loss: 0.1096 - val_accuracy: 0.9628\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9503 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9499 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1095 - val_accuracy: 0.9628\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9510 - val_loss: 0.1093 - val_accuracy: 0.9619\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9525 - val_loss: 0.1095 - val_accuracy: 0.9628\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.9506 - val_loss: 0.1093 - val_accuracy: 0.9610\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9522 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9518 - val_loss: 0.1093 - val_accuracy: 0.9619\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.1093 - val_accuracy: 0.9619\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1093 - val_accuracy: 0.9619\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9510 - val_loss: 0.1094 - val_accuracy: 0.9628\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1093 - val_accuracy: 0.9619\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9610\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9510 - val_loss: 0.1092 - val_accuracy: 0.9610\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1093 - val_accuracy: 0.9628\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1092 - val_accuracy: 0.9610\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9610\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9518 - val_loss: 0.1093 - val_accuracy: 0.9628\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1091 - val_accuracy: 0.9610\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.1091 - val_accuracy: 0.9610\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.9510 - val_loss: 0.1091 - val_accuracy: 0.9619\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1091 - val_accuracy: 0.9619\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.1091 - val_accuracy: 0.9601\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9518 - val_loss: 0.1091 - val_accuracy: 0.9619\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.1092 - val_accuracy: 0.9628\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuh0lEQVR4nO3deXRc1Znv/e9Tg6o0S5bkSbKxDSZgwNjGAToMgQCJHaaQOMEhE3TTNA4ESN+bC919E0Jusjo305vQTUKgL4R+wxsuAZyELCAhNIQZbIMxthlsPEl4kKx5KtW03z9OSchySSoLlQupfp+1tFRnrGdXnTrP2Wefs4855xARkfzly3UAIiKSW0oEIiJ5TolARCTPKRGIiOQ5JQIRkTynRCAikueylgjM7C4zazSzjcNMNzO71cy2mtkGM1uSrVhERGR4gSyu+1fAvwP/Ocz05cD81N8pwC9S/0dUXV3t5syZMz4RiojkiXXr1u13ztWkm5a1ROCce9rM5owwy8XAfzrvjrYXzazCzGY45/aMtN45c+awdu3a8QxVRGTSM7Odw03LZRtBLVA/aLghNe4gZnaVma01s7VNTU2HJTgRkXyRy0Rgacal7e/COXeHc26pc25pTU3amo2IiIxRLhNBAzBr0HAdsDtHsYiI5K1cJoI/AF9OXT10KtA+WvuAiIiMv6w1FpvZb4CzgGozawBuBoIAzrnbgUeATwJbgR7gimzFIiIiw8vmVUOfH2W6A67J1vuLiEhmdGexiEiey+YNZZJv4n0QCIFz0LkHfEEoGXSVV6QdEjEorIRYD0S7vWGApreg/iXvdbAQjv807F4PTW+CS3rrnHUyTD3We42DXS/B/reh6kg44bPeOna/CmUzvPeKdkNbPfj8kEx46xkqXAaRDjAD83vrdQ7MB8m4N4+ljpeGLm8+8AcgWASlM7yyNG+Fkqnee3akmrwCBeAv8NabjEPlHG8+80NxNfgC4A/C3DOhbZe3nqY3vflivdDdCGW10LoDSqfD1AWpzzoMXXth70ZwCZj9Ee9/QQmESgcF6qD+ZWh+B+acBjMWQW8rRNpgx3NQ8yEvnppjvLJUHenF2V4P9WvgqHO8+HHQutObL1zmzdPbCuFyeP23MPU4qJjtfX+t271yTTseElHvs+pq9ObdtwmmzIWCYuhp8d4zXO5tM8FCwLzPL9brxbX/bSifBbNPhb5Ob97eVq9opdO99foLvG0t2uO9b28LdLzrLZeIQulMr7yBkLdddjd5n1Gk3fvuS2d660v0pWJIbc/JuPc9BcPvfZx9Xd77F1VBQZE3rrfN2z6KpnjDsQj0NB/4HuFyr0yhMu/7dg7iEQiVpL4m500vKPK2Aee8badf937vPUqmHrwdv09KBPmkdYe3c6yYDR274Z0nYdoCbycD3o9q7d3Qk9rgOvd5P6ri6vfWYT4GdpbRbmh5B8rrYMez3k7CJbwNPtLuzV+71PvB79/i7bRcEgKFEO8dJkjz1v/ELYdWtj/+I8S6M5hx8FXLmTydz4bM936XnwzM2/Em+kafdepx3nY32ncz4jaRoXAFRLu8bTYeOXBa+Sxob/Cmhcu8nfRgBSXewUIyBjOXQOdeLxHiwB/ydvDBQm+b72nx5jM/FFZ423RvmzdvYSVgqYOcET6fYLE3f7wPKmZ58/tD0NHgJZjeNu93M3WBlwzBS26nXQ/nfvv9fU5p2ER7VOXSpUtd3t1ZnEx4G2ZRlfejKpriHcW27fSORFu3wxt/9MZ37oV9G6E4dSTukt4yJVO9I7FENLP39AUGHRH7vWF4b+P2Bb2dwZR50LINao72fmwNa70jynkf9ZLBrtRRfnkdVM/3fkyde72NvKj6vSPXYCEcc773v/5l2PEMVM5970jZH4I1d3rT/SFvmeJqmP8JeOsR2P60d/Q05UjvB1NW600vq0sdnQa9I1sbtCNPxLyEWDHb+yFuexIwmLkY9qyHI8/xjgRbtnlH93NOO/Az6tjjfaZV86DxDe9zmv9x2PG09/lPXeC9X0+Ld6Rn5h3F178M00/w3qO8DrqavOS57SlvxxIqgxkneokTvM+5p9lbNt7nHTlHu7z38AWhdok3reFlL/7+I9nBiqbAnDPgnSe8GkTlEV5SL67x4pt+vFdjSMbhnf/y4pl2vLfNdQ+6iTNcBo1vet9tIORtf117vXijPd6RcrTL++7a6+HtP3lH/72t3kFBvNdbprvJ+/wrZnvfV1eTtw31daZ2yAnvyLis1nufaLdXMyiqgq593ueWiMGLv4ATVnjbUVt96mg67u2QA6ntxCVgy+NeHI1veOU+9iIvzvI67/NqehPa34XiKti/1VtfQZFXK2ur976zilneb2n+ed42sv0Zb55AoRdXT7P3V1TlvXfFbG+4/z269nn/W7ZB2czU78rvvXfxVO8zKqzwvg9/0PuNtO7wlt/5gldLXvxFr1Y8Bma2zjm3NO00JYIPmEQctj7u7Ti2PuFtJK3bU0cwmR9dJoKl+GOdAHTUnUWRL06s/Ah2tsUpsQhdMz/CnkQFfZ3NJBNxSpPtzOzYwLbSJWyK1fJ8/GhOqHLUdG/hdf/x+Pw+ks4xy9eM69jLBuYTiSdo7Y4ytSxMWThAW0+Mrr44R00tIRpPUhwKsG1/N52RGNUlIUpCAQI+I+A3Aj4fAZ+Bwa7mHlp7ovTFkyyZXUki6YglkgQDPgqDfnqjCcJBP9GEd2om6Decg5buKL3RBEdUFdEXT1IQ8NEVibOrpYeScIDpZWFCAR+NnV7yqq0sJBpP4hx098WpLA4CsL8rSmNnH9PLQhSHAuzriDCtLAwOphQXMKWkgOe3NjOtLMz08hCRWJKa0hAbGtrw+3z4DN7a28nfHFnFlKICfv/abk6oLae2opCXtjdz1NQS+mJJPjS9lPrWHkpCQUIBH/UtPexpj3Dk1GKefns/MyvClIaDTCsLMXtKES9ta+HIqSXMqiykN5Zg8+4OHFBXWUhrT4xILMHcqmLm1ZTw3Dv7aezoY/60Ejp6Y7R0RzmypoRt+7vY2tjF9PJCqksKqKssorwwyJ62Xlp6oswsL2ReTTH1Lb0knaMj4p2qCwX8zKkq4rFNewkH/Bw9rYSmrih98QQloQCl4QCxhKO4IEAknqCxo4/61h7KwkGKQ34WzarAOWju7sNnRlk4SENrD72xBJFYkqOnlRBPOrY2dlFU4Kcg4KO7L8Ge9l6Cfh/Ty8K09kTpjSWYlvoeg34frT0x+mIJqkoKqK0opK0nRnc0Tk1JiB3NPexu62VaeRifGfHU9lJbUYjfZ/h8xrTSEM3dUfZ39REK+KkuKeDtfV1UFgWZUhyivrUHAJ9520X/8i09UaYUFdDaEyUU8DO1LERjRx+xRJJE0hEK+qirLGJXczftvTH8Ph/VJQVUFhdgQHtvjKSDzbu9mvL08jDVJSGCfh9dfXHiiSTxpCPpHPGEI5F0TC0LAUYo4KOlO0o8meT8E2Zy/sIZY9q1KBF8UDkHO5+HZ37sHSGVTveqtNuf9qb7gt550bKZuJpjaW1rIVF5JH2t79IWcexzFXREoc9fTHegksd3ObY09TLX38QriXkUEcFHkg68c5BmqdPro6itKGRaWYgt+7rojSWYNaUI5xyxhCMSS1BdEqKsMEA0nqS1J0ZRgR+AsnCQgN/Y0tg1kBiau70f06JZFQM/mnjSpf4n6YzEmVtdjM+MaDzJnvYIpeEAQb/RF/emlxcG6YnGSSS9MvjN2NfpVf0X1lXwbmsP4aA/tXP3dnaNHRFaUu89vTxMe2+M5q4o0XiSiqIg5YVBdjb3EE8mKSsMMrO8kH0dERLOMa00TFOXtwNr7u4b9jOrqywkkXTs64iQTDOPGQR8Rizx3sTCoJ940vvRTy8LE/Ab9S3eKZGSUICA3+hI7TSKC7zk1798ZZGXuNp7YxQVBOjqe++ovyQUoKqkgJ3NPUwpLqAw6OfdtsxPtfRvGwGf4fAOOeJJNzDeZ1BeGKS1J3bQsn6fUV1SwPTyQt7Y00E0njxgGkAi6SgNBfD7jcKgnz3t7526CQV8xJOOmpIQxSE/nZE40UQSn9nAd1BcECDpHNPKwhT4fWzf3z1wYNAff2VRAS3dUcoLgwT9PopDfpLO0ZQ6EIgnvG3PZ16Cj8SSdPXFmVYWoisSpzuaoKY0RIHfR28sQSLpmFEeZndbLxWpdZeFvZpxY2df6j28pNgZibG/KzqQJAuDfpq6+uiMeN9RWTiAmQ1USIN+H919cfxmlIYDBPzegZE/9QewtbGLssIg0XiSqpICfGZ8buksVp11ZMbf64Hf8fCJQG0Eh9u767wq9M7nYONDsP8tKJ1BcvpCks3bSPZ10TPjdNaUf4K1wQ+zNxbmrV2ddL4dH/TDfq8BNhR478KvmtIQhZXlFNUcxddmVVAc8tPdl6C6NER7T5RYwnHm0TW0dkcpKvBTV1lEOOijIOAb2JGWpX5EAPFEkkg8SUlobJtJ/0FGV1+c0nBwbJ/XMGKJJI2dfdRWFB5yTJb6NXZGYgR8PgpTiSydeCLJ3o4IffEkc6qK2d3Wy/TyMB29MapKvFMPHZEY8YSjMOjteMJBP4mkI+g3zIzGjgihgJ/OvhjTysIEfEY86Qj6fTjn2NMeYWppiEDqc2/vjdHaHeWIqiISSUdTVx8loQBFBYGBOqHPoDeWYGdzDz3RBAvrygn6fcQTyYH19EYTBPzmxVbgZ2dzN0G/DzMvaft9RndfnNaeGHWVhQPfO3g77l0tPdRVFhJNJAkHvKP2rr44O/Z3U1dZSEkoQEtPlHDQT9mg7zeeSLKzpQefGXNStbXeaIKKouABn31jZx/ReJKZ5YWUhAMDO8DBkklHXzxJOOgj6d5LLJ2RGP5Uku3fPv0+I5l0JJw7oCz9Yokkrd1RphQXEEh99q09MSqLgjgHbb0xphQXDGwnwEC86eIC8A2KOZZIEvDZwDLxRJKeWIL2nhi1FYX4fIZzzrsWIbXYcOvvj2Gk6eNJNYLDaecLuLuXY6nTOx0l89hcvZy7es/khX02cPQA3oZSXhikuCDAvJpiAM5bMI2g30c0nuSoqSXMn1rC1LJw2rcSERlMNYJc69wHj34Dt/kPxAjwf+LLeCl5DE/tXwz7YWZ5kDPnV3J8bTlzq4twDk6aU8nUUu3kRST7lAiyKdoDbzxM8ndfxefirE6czrdjX2bBvNmsOuso/kdJiHk1xYSDw5+aEBHJNiWCbEjE4a/fh6d/CMCO5HT+Jf53TFt4Hi9++gQKg/7Ddu5PRGQ0SgTjra8LHr4ONj7IG4FjWR1ZTPPRl3H35z+iI38R+UBSIhhn7jeXYjue5cnSC7miaSU/+uwiVpxUl+uwRESGpU7nxtOul7Adz/Jg4gyubPoc151zNJ9ZkvbpmyIiHxiqEYyX+pdx93+ZNt8UvhW5nIevO4sFM8tyHZWIyKhUIxgPLdtwD/wtnd3dXN17Ddd/crGSgIhMGKoRvF9bn8D9ZiXJRJzrov+Nk8++kCtPn5frqEREMqYawfvxzpPwu1W0FszktMjPCB6zjH887+gDbjsXEfmgUyIYq6a34P+9hESwmL/v+SonLFjAnV9eqvsDRGTC0amhsap/CXBc3vffeS1WyR8/fnSuIxIRGRPVCMZq70aivkJebCvnnr89mWOmq3FYRCYmJYKxSCah/iXesdmcemQNpx1VPfoyIiIfUEoEY7HxAdiznnsjH+HDc6bkOhoRkfdFiWAM3PZn6PKVcm/yXM7+0NRchyMi8r6osXgMOrevYX1sDv+8fAEn1JXnOhwRkfdFNYJDFYtQ3PY2b/mO5G9Pn5vraERE3jclgkO1bxN+EnRVnZD2GasiIhONEsEh6t3lPS85NDvtoz9FRCYcJYJDtGvDMzS7Us5cuijXoYiIjAslgkORTDB939NsCi3m+LqKXEcjIjIulAgOQd+uNZS7dlpmnZfrUERExo0SwSHY/tqzAFQd+9EcRyIiMn6UCA7Bzs0v004pp5x4fK5DEREZN0oEGeqKxKjrfZP28g9REPTnOhwRkXGjRJChhpd/x3G+nfTN+0SuQxERGVdZTQRmtszM3jKzrWZ2U5rp5Wb2sJm9ZmabzOyKbMbzfvS+8xxR52fK2dfkOhQRkXGVtURgZn7gNmA5sAD4vJktGDLbNcBm59yJwFnAj82sIFsxvR+R1j20WQVVZcW5DkVEZFxls0ZwMrDVObfNORcF7gMuHjKPA0rNe75jCdACxLMY09h1NREJqctpEZl8spkIaoH6QcMNqXGD/TtwLLAbeB243jmXHLoiM7vKzNaa2dqmpqZsxTusjkiM4ngLrlhdTovI5JPNRJCuRzY3ZPgTwHpgJrAI+HczO+iZj865O5xzS51zS2tqasY7zlHtaYtQbe1YiRKBiEw+2UwEDcCsQcN1eEf+g10BPOQ8W4HtwDFZjGlMGjt6qaKDQJkSgYhMPtlMBGuA+WY2N9UAvBL4w5B5dgHnAJjZNOBDwLYsxjQmrc2NhCxOuHx6rkMRERl3WXtCmXMubmbXAn8C/MBdzrlNZnZ1avrtwP8CfmVmr+OdSrrRObc/WzGNVbzxbQCKZx6d40hERMZfVh9V6Zx7BHhkyLjbB73eDXw8mzGMh2DzGwCEZp6Q40hERMaf7izOQGn7FnoIQ/ms0WcWEZlglAgyUN5bz57gLPDp4xKRyUd7tgwUxVvoLajKdRgiIlmhRDAK5xxliXYSYSUCEZmclAhG0RWJMYV2XHF1rkMREckKJYJRNLU0E7I4gVLdTCYik5MSwSjaG72boUPl03IciYhIdigRjKK92UsExVN0V7GITE5KBKPoat4DQNXUoR2niohMDkoEo4i3ej1ph6pm5zgSEZHsUCIYhb9zN30UQJEuHxWRyUmJYBRFkT20B6eCpXu8gojIxKdEMIJILEFlbB+RIjUUi8jkpUQwgp3NPcy0Ziiry3UoIiJZo0Qwgp279zLdWglN03MIRGTyUiIYQWu99xyCitkLchyJiEj2KBGMwDV5TyYLTT82x5GIiGSPEsEIwh3bSOCDKXNzHYqISNYoEYygoLeJbn8ZBEK5DkVEJGuUCEYQirYSCVbmOgwRkaxSIhhGZyRGmWsnpgfSiMgkp0QwjH0dfUyhE/RAGhGZ5JQIhtHSHaXKOjAlAhGZ5JQIhtHa2UWFdRMorcl1KCIiWaVEMIyutiZATyYTkclPiWAY0ba9ABRVqsM5EZnclAiGkejwEkGwfGaOIxERyS4lgmH4uvZ5L0p1akhEJjclgmEEehu9FyU6NSQik5sSwTAKehrp9pVAMJzrUEREskqJYBhF0f30FOgeAhGZ/JQI0uiMxKhyLUTDuodARCY/JYI09rRHmGatJEtn5DoUEZGsUyJIY09bD1NpJVBRm+tQRESyTokgjZbG3RRYgvAUJQIRmfyymgjMbJmZvWVmW83spmHmOcvM1pvZJjP7azbjyVTX/gYASmtm5zgSEZHsC2RrxWbmB24DzgMagDVm9gfn3OZB81QAPweWOed2mdnUbMVzKOKtXiLQqSERyQej1gjM7AIzG0vN4WRgq3Num3MuCtwHXDxknsuAh5xzuwCcc41jeJ9x5zr3eC/UWCwieSCTHfxKYIuZ/cDMjj2EddcC9YOGG1LjBjsaqDSzp8xsnZl9Od2KzOwqM1trZmubmpoOIYSxCXTvJYlByQeigiIiklWjJgLn3BeBxcA7wN1m9kJqx1w6yqKWbnVDhgPAScD5wCeAb5rZ0WliuMM5t9Q5t7SmJrvX9jvnKOprpDswBfzBrL6XiMgHQUanfJxzHcCDeKd3ZgCXAK+Y2ddGWKwBmDVouA7YnWaex5xz3c65/cDTwIkZxp4VTZ19VCdb6CtSZ3Mikh8yaSO40MxWA/8FBIGTnXPL8XbY/32ERdcA881srpkV4J1i+sOQeX4PnGFmATMrAk4B3hhDOcbNO03dTLNWrFSdzYlIfsjkqqHPAv+Pc+7pwSOdcz1m9rfDLeSci5vZtcCfAD9wl3Nuk5ldnZp+u3PuDTN7DNgAJIH/cM5tHGthxsO2/V0stxYKptTlMgwRkcMmk0RwM7Cnf8DMCoFpzrkdzrknRlrQOfcI8MiQcbcPGf4h8MOMI86y+t17mGJdJKfOy3UoIiKHRSZtBL/FO1rvl0iNm5Sad24CwFfzoRxHIiJyeGSSCAKp+wAASL0uyF5IudMTjcP+t72B6oMuXhIRmZQyOTXUZGYXOef+AGBmFwP7sxtW9uzY301LT/Sg8fGE454XdnAC75L0BfFVHpGD6EREDr9MEsHVwL1m9u949wbUA2lv/Pqga+2O8rEfP0Vy6N0MKX6f8T+rduArO1H3EIhI3hg1ETjn3gFONbMSwJxzndkPKzs6I3GSDv7+jLmcdtSBTx8zM46tSDD1F5tgyTdyFKGIyOGXUadzZnY+cBwQNvNuGHbOfSeLcWVFLOm1eR9fW85ZH0rTfcTm34NLwpEfO8yRiYjkzqiJwMxuB4qAs4H/AFYAL2c5rqxwkQ4W2xaq2gzqh97kDKy9GwpKofakwx+ciEiOZFIj+IhzbqGZbXDO3WJmPwYeynZg2VDzX/+N1aFH4Cm8v3QWfVHtAyKSVzJJBJHU/x4zmwk0A3OzF1L2+Po62JKspeujt7B4duXBMxQUQ93Swx+YiEgOZZIIHk49QOaHwCt4PYjemc2gssW5JG0U0133UZivLqZFRGCURJB6IM0Tzrk24EEz+yMQds61H47gxp1zJPER8OlRzSIi/UbcIzrnksCPBw33TdgkALjUVUMBf7pHJYiI5KdMDo3/bGafsf7rRicwR5Kk8xHwTfiiiIiMm0zaCP4RKAbiZhbBu7vYOefKshpZNiSTOCDg16khEZF+mdxZPNojKScM5xxJTDUCEZFBMrmh7Mx044c+qGZCcEkcpjYCEZFBMjk1NLjjnTBwMrAOmHD9MDjnvESgq4ZERAZkcmrowsHDZjYL+EHWIsqm/hqBTg2JiAwYy6FxA3D8eAdyOAy0EejUkIjIgEzaCP4N725i8BLHIuC1LMaUPS6JI6BTQyIig2TSRrB20Os48Bvn3HNZiifLVCMQERkqk0TwABBxziUAzMxvZkXOuZ7shpYFSbURiIgMlck5kieAwkHDhcBfshNOdjkcYLqhTERkkEz2iGHnXFf/QOp1UfZCyh5zSd1QJiIyRCaJoNvMlvQPmNlJQG/2Qsqe9+4jUCIQEemXSRvBDcBvzaz/2Y4zgEuzFlE2pWoEfiUCEZEBmdxQtsbMjgE+hNfh3JvOuVjWI8sKh5kxCTpSFREZN6OeGjKza4Bi59xG59zrQImZfTX7oY0/S50aEhGR92TSRvD3qSeUAeCcawX+PmsRZZFzDu+hayIi0i+TvaJv8ENpzMwPFGQvpOwxkjidFhIROUAmjcV/Au43s9vxupq4Gng0q1Fli3NqHxARGSKTRHAjcBWwCq+x+FW8K4cmHpcEnRoSETnAqHvF1APsXwS2AUuBc4A3shxXljjG1uGqiMjkNWyNwMyOBlYCnweagf8L4Jw7+/CENv7MOdA9BCIiBxjp1NCbwDPAhc65rQBm9vXDElXWOEyXj4qIHGCk8ySfAfYCT5rZnWZ2DhzaXtTMlpnZW2a21cxuGmG+D5tZwsxWHMr6D5W5JJg/m28hIjLhDJsInHOrnXOXAscATwFfB6aZ2S/M7OOjrTh1meltwHJgAfB5M1swzHz/G+/qpCxzmE4NiYgcIJPG4m7n3L3OuQuAOmA9MOzR/SAnA1udc9ucc1HgPuDiNPN9DXgQaMw46jEy53VDLSIi7zmkS2iccy3OuV865z6Wwey1QP2g4YbUuAFmVgtcAtw+0orM7CozW2tma5uamg4l5AM4HAG/Tg2JiAyWzWsp0x16uyHDPwVu7H/62XCcc3c455Y655bW1NSMPaJkgnBBJrdOiIjkj2zuFRuAWYOG64DdQ+ZZCtyXutu3GvikmcWdc78b72CcczjnKFQiEBE5QDb3imuA+WY2F3gX756EywbP4Jyb2//azH4F/DEbSQCgrScGOMIFwWysXkRkwspaInDOxc3sWryrgfzAXc65TWZ2dWr6iO0C462xs49pqEYgIjJUVveKzrlHgEeGjEubAJxzl2czln0dEabjKAqpRiAiMljedLwTiSXwG6oRiIgMkTeJ4OPHTaekwE9ZYSjXoYiIfKDkTSIAUt1Q64YyEZHB8isR4JQIRESGyK9E4JKoiwkRkQPlWSJwekKZiMgQ+bVXVBuBiMhB8isRoBqBiMhQ+bVXVBuBiMhB8iwRqEYgIjJUnu0VdfmoiMhQ+ZMIXOpRCKoRiIgcIH/2ii6ZeqEagYjIYHmUCFQjEBFJJ3/2iv01AlUIREQOkD+JANUIRETSyZ+9otoIRETSyqNEoBqBiEg6+bNXHGgjUI1ARGSw/EkEaiMQEUkrf/aKaiMQEUkrjxKBagQiIunkz15RbQQiImnlTyLopxqBiMgB8mevqDYCEZG08igR9LcRKBGIiAyWR4lAbQQiIunkTyLQfQQiImnlz15RbQQiImnlUSJQjUBEJJ382SuqjUBEJK38SQRqIxARSSt/9opqIxARSSuPEoFqBCIi6eTPXlFtBCIiaWU1EZjZMjN7y8y2mtlNaaZ/wcw2pP6eN7MTsxmP96b5k/tERDKRtb2imfmB24DlwALg82a2YMhs24GPOucWAv8LuCNb8aiNQEQkvWweHp8MbHXObXPORYH7gIsHz+Cce94515oafBGoy1o06mtIRCStbCaCWqB+0HBDatxw/g54NN0EM7vKzNaa2dqmpqaxRaM2AhGRtLKZCNLtcV3aGc3OxksEN6ab7py7wzm31Dm3tKamZozh6KohEZF0AllcdwMwa9BwHbB76ExmthD4D2C5c645a9GojUDkkMRiMRoaGohEIrkORQ5BOBymrq6OYDCY8TLZTARrgPlmNhd4F1gJXDZ4BjObDTwEfMk593YWY9F9BCKHqKGhgdLSUubMmYPplOqE4JyjubmZhoYG5s6dm/FyWdsrOufiwLXAn4A3gPudc5vM7Gozuzo127eAKuDnZrbezNZmKx61EYgcmkgkQlVVlZLABGJmVFVVHXItLps1ApxzjwCPDBl3+6DXVwJXZjOGQe/s/VONQCRjSgITz1i+s/zZK6qNQEQkrTxKBKoRiEwkbW1t/PznPx/Tsp/85Cdpa2sbcZ5vfetb/OUvfxnT+kfyq1/9imuvvXbEeZ566imef/75cX/vscqfvaJuKBOZUEZKBIlEYsRlH3nkESoqKkac5zvf+Q7nnnvuWMN7Xz5oiSCrbQQfLKoRiIzVLQ9vYvPujnFd54KZZdx84XHDTr/pppt45513WLRoEeeddx7nn38+t9xyCzNmzGD9+vVs3ryZT33qU9TX1xOJRLj++uu56qqrAJgzZw5r166lq6uL5cuXc/rpp/P8889TW1vL73//ewoLC7n88su54IILWLFiBXPmzOErX/kKDz/8MLFYjN/+9rccc8wxNDU1cdlll9Hc3MyHP/xhHnvsMdatW0d1dfUBsd59993867/+KzNmzODoo48mFAoB8PDDD/Pd736XaDRKVVUV9957L729vdx+++34/X5+/etf82//9m+0tbUdNN+0adPG9fMeSf7sFdVGIDKhfP/73+fII49k/fr1/PCHPwTg5Zdf5nvf+x6bN28G4K677mLdunWsXbuWW2+9lebmg29F2rJlC9dccw2bNm2ioqKCBx98MO37VVdX88orr7Bq1Sp+9KMfAXDLLbfwsY99jFdeeYVLLrmEXbt2HbTcnj17uPnmm3nuued4/PHHB2IDOP3003nxxRd59dVXWblyJT/4wQ+YM2cOV199NV//+tdZv349Z5xxRtr5Dqf8qRHo1JDImI105H44nXzyyQdcH3/rrbeyevVqAOrr69myZQtVVVUHLDN37lwWLVoEwEknncSOHTvSrvvTn/70wDwPPfQQAM8+++zA+pctW0ZlZeVBy7300kucddZZ9Pd6cOmll/L2295tUQ0NDVx66aXs2bOHaDQ67LX9mc6XLflXI1AiEJmwiouLB14/9dRT/OUvf+GFF17gtddeY/HixWmvn+8/TQPg9/uJx+Np190/3+B5nEvbK85Bhrtk82tf+xrXXnstr7/+Or/85S+Hvb4/0/myJX8SgdoIRCaU0tJSOjs7h53e3t5OZWUlRUVFvPnmm7z44ovjHsPpp5/O/fffD8Cf//xnWltbD5rnlFNO4amnnqK5uXmgfWFwjLW1Xl+b99xzz8D4oWUbbr7DJX/2imojEJlQqqqqOO200zj++OP5xje+cdD0ZcuWEY/HWbhwId/85jc59dRTxz2Gm2++mT//+c8sWbKERx99lBkzZlBaWnrAPDNmzODb3/42f/M3f8O5557LkiVLBqZ9+9vf5rOf/SxnnHHGAQ3MF154IatXr2bRokU888wzw853uFimVZ8PiqVLl7q1a8fQE8X2Z+CeC+Arf4S5Z4x/YCKTzBtvvMGxxx6b6zByqq+vD7/fTyAQ4IUXXmDVqlWsX78+12GNKt13Z2brnHNL082fR43FaiMQkUOza9cuPve5z5FMJikoKODOO+/MdUhZkT+JQG0EInKI5s+fz6uvvprrMLIuf/aKaiMQEUkrjxKBagQiIunkz15RN5SJiKSVP4lAbQQiImnlz15RbQQik15JSQkAu3fvZsWKFWnnOeussxjtEvSf/vSn9PT0DAxn0q31WPTHO5z30xX3ocijRKBTQyL5YubMmTzwwANjXn5oIsikW+tsOFyJIH8uH9V9BCJj9+hNsPf18V3n9BNg+feHnXzjjTdyxBFH8NWvfhXw7tItLS3lH/7hH7j44otpbW0lFovx3e9+l4svvviAZXfs2MEFF1zAxo0b6e3t5YorrmDz5s0ce+yx9Pb2Dsy3atUq1qxZQ29vLytWrOCWW27h1ltvZffu3Zx99tlUV1fz5JNPDnRrXV1dzU9+8hPuuusuAK688kpuuOEGduzYMWx314Nt376dyy67jHg8zrJlywbGd3V1pS3T0K64b7755lHLPhb5kwjURiAyoaxcuZIbbrhhIBHcf//9PPbYY4TDYVavXk1ZWRn79+/n1FNP5aKLLhq247df/OIXFBUVsWHDBjZs2HBAFxDf+973mDJlColEgnPOOYcNGzZw3XXX8ZOf/IQnn3zyoO4e1q1bx913381LL72Ec45TTjmFj370o1RWVrJlyxZ+85vfcOedd/K5z32OBx98kC9+8YsHLH/99dezatUqvvzlL3PbbbcNjB+uTN///vfZuHHjwN3M8Xj8kMqeqfxJBGojEBm7EY7cs2Xx4sU0Njaye/dumpqaqKysZPbs2cRiMf75n/+Zp59+Gp/Px7vvvsu+ffuYPn162vU8/fTTXHfddQAsXLiQhQsXDky7//77ueOOO4jH4+zZs4fNmzcfMH2oZ599lksuuWSgF9RPf/rTPPPMM1x00UUZdXf93HPPDTwP4Utf+hI33ngj4PVymq5MQw0333Blz1QeJQLVCEQmmhUrVvDAAw+wd+9eVq5cCcC9995LU1MT69atIxgMMmfOnFG7bU53xLx9+3Z+9KMfsWbNGiorK7n88stHXc9IfbMN7e568Cmo0WLJtExjKXsm8mevqDYCkQln5cqV3HfffTzwwAMDVwG1t7czdepUgsEgTz75JDt37hxxHWeeeSb33nsvABs3bmTDhg0AdHR0UFxcTHl5Ofv27ePRRx8dWGa4LrDPPPNMfve739HT00N3dzerV6/mjDMy78TytNNO47777gMYiGmkMqXrrvpQyp6p/KkR9LcR6NSQyIRx3HHH0dnZSW1tLTNmzADgC1/4AhdeeCFLly5l0aJFHHPMMSOuY9WqVVxxxRUsXLiQRYsWcfLJJwNw4oknsnjxYo477jjmzZvHaaedNrDMVVddxfLly5kxYwZPPvnkwPglS5Zw+eWXD6zjyiuvZPHixcM+9Wyon/3sZ1x22WX87Gc/4zOf+czA+OHKNLgr7uXLl3PjjTceUtkzlT/dUNe/DC/cBp/4HpTXjX9gIpOMuqGeuNQN9XBmnez9iYjIAfKnjUBERNJSIhCRYU20U8cytu9MiUBE0gqHwzQ3NysZTCDOOZqbmwmHw4e0XP60EYjIIamrq6OhoYGmpqZchyKHIBwOU1d3aBfEKBGISFrBYJC5c+fmOgw5DHRqSEQkzykRiIjkOSUCEZE8N+HuLDazJmCsHWxUA/vHMZyJQGXODypzfng/ZT7COVeTbsKESwTvh5mtHe4W68lKZc4PKnN+yFaZdWpIRCTPKRGIiOS5fEsEd+Q6gBxQmfODypwfslLmvGojEBGRg+VbjUBERIZQIhARyXN5kwjMbJmZvWVmW83splzHM17M7C4zazSzjYPGTTGzx81sS+p/5aBp/5T6DN4ys0/kJur3x8xmmdmTZvaGmW0ys+tT4ydtuc0sbGYvm9lrqTLfkho/acsMYGZ+M3vVzP6YGp7U5QUwsx1m9rqZrTeztalx2S23c27S/wF+4B1gHlAAvAYsyHVc41S2M4ElwMZB434A3JR6fRPwv1OvF6TKHgLmpj4Tf67LMIYyzwCWpF6XAm+nyjZpy433sO2S1Osg8BJw6mQuc6oc/wj8f8AfU8OTurypsuwAqoeMy2q586VGcDKw1Tm3zTkXBe4DLs5xTOPCOfc00DJk9MXAPanX9wCfGjT+Pudcn3NuO7AV77OZUJxze5xzr6RedwJvALVM4nI7T1dqMJj6c0ziMptZHXA+8B+DRk/a8o4iq+XOl0RQC9QPGm5IjZuspjnn9oC30wSmpsZPus/BzOYAi/GOkCd1uVOnSdYDjcDjzrnJXuafAv8DSA4aN5nL288BfzazdWZ2VWpcVsudL88jsDTj8vG62Un1OZhZCfAgcINzrsMsXfG8WdOMm3Dlds4lgEVmVgGsNrPjR5h9QpfZzC4AGp1z68zsrEwWSTNuwpR3iNOcc7vNbCrwuJm9OcK841LufKkRNACzBg3XAbtzFMvhsM/MZgCk/jemxk+az8HMgnhJ4F7n3EOp0ZO+3ADOuTbgKWAZk7fMpwEXmdkOvFO5HzOzXzN5yzvAObc79b8RWI13qier5c6XRLAGmG9mc82sAFgJ/CHHMWXTH4CvpF5/Bfj9oPErzSxkZnOB+cDLOYjvfTHv0P//AG84534yaNKkLbeZ1aRqAphZIXAu8CaTtMzOuX9yztU55+bg/V7/yzn3RSZpefuZWbGZlfa/Bj4ObCTb5c51C/lhbIn/JN7VJe8A/5LreMaxXL8B9gAxvKODvwOqgCeALan/UwbN/y+pz+AtYHmu4x9jmU/Hq/5uANan/j45mcsNLAReTZV5I/Ct1PhJW+ZB5TiL964amtTlxbuy8bXU36b+fVW2y60uJkRE8ly+nBoSEZFhKBGIiOQ5JQIRkTynRCAikueUCERE8pwSgchhZGZn9fekKfJBoUQgIpLnlAhE0jCzL6b6/19vZr9MdfjWZWY/NrNXzOwJM6tJzbvIzF40sw1mtrq/r3gzO8rM/pJ6hsArZnZkavUlZvaAmb1pZvfaCJ0kiRwOSgQiQ5jZscCleJ1/LQISwBeAYuAV59wS4K/AzalF/hO40Tm3EHh90Ph7gduccycCH8G7Axy83lJvwOtLfh5evzoiOZMvvY+KHIpzgJOANamD9UK8Tr6SwP9NzfNr4CEzKwcqnHN/TY2/B/htqr+YWufcagDnXAQgtb6XnXMNqeH1wBzg2ayXSmQYSgQiBzPgHufcPx0w0uybQ+YbqX+WkU739A16nUC/Q8kxnRoSOdgTwIpUf/D9z4s9Au/3siI1z2XAs865dqDVzM5Ijf8S8FfnXAfQYGafSq0jZGZFh7MQIpnSkYjIEM65zWb2P/GeEuXD69n1GqAbOM7M1gHteO0I4HULfHtqR78NuCI1/kvAL83sO6l1fPYwFkMkY+p9VCRDZtblnCvJdRwi402nhkRE8pxqBCIieU41AhGRPKdEICKS55QIRETynBKBiEieUyIQEclz/z/B6HtwuBVzogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 5ms/step - loss: 0.1400 - accuracy: 0.9510\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9628\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 1s 5ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963294538943599\n",
      "0.9243986254295533\n",
      "0.943445857080228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.7]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9779559118236473\n",
      "0.9402697495183044\n",
      "0.9587426326129665\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
