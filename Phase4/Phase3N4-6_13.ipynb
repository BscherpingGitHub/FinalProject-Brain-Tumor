{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  19.5  1642.6 ...  5.3  1.0  0.0]\n",
      " [ 1.0  1.5  135.9 ...  5.3  0.9  0.0]\n",
      " [ 0.0  15.3  813.5 ...  4.4  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  8.8  523.7 ...  3.1  1.0  0.0]\n",
      " [ 0.0  5.9  512.2 ...  3.8  1.0  0.0]\n",
      " [ 1.0  7.2  900.3 ...  6.0  0.9  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  0.0  3.0 ...  0.0  0.4  5.3]\n",
      " [ 1.0  0.0  8.5 ...  0.0  0.3  5.3]\n",
      " [ 0.0  0.1  2.4 ...  0.1  0.5  4.4]\n",
      " ...\n",
      " [ 0.0  0.3  3.0 ...  0.2  0.7  3.1]\n",
      " [ 0.0  0.1  4.2 ...  0.1  0.6  3.8]\n",
      " [ 1.0  0.0  4.5 ...  0.0  0.4  6.0]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 6, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 2, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 4s 19ms/step - loss: 0.6591 - accuracy: 0.5896 - val_loss: 0.6429 - val_accuracy: 0.6241\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6235 - accuracy: 0.7274 - val_loss: 0.6079 - val_accuracy: 0.7739\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5877 - accuracy: 0.8223 - val_loss: 0.5734 - val_accuracy: 0.8466\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5529 - accuracy: 0.8516 - val_loss: 0.5401 - val_accuracy: 0.8546\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5179 - accuracy: 0.8709 - val_loss: 0.5058 - val_accuracy: 0.8688\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4832 - accuracy: 0.8789 - val_loss: 0.4731 - val_accuracy: 0.8768\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4517 - accuracy: 0.8827 - val_loss: 0.4435 - val_accuracy: 0.8794\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8831 - val_loss: 0.4157 - val_accuracy: 0.8839\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3938 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8865\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3677 - accuracy: 0.8899 - val_loss: 0.3638 - val_accuracy: 0.8892\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3461 - accuracy: 0.8918 - val_loss: 0.3425 - val_accuracy: 0.8936\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3251 - accuracy: 0.8971 - val_loss: 0.3231 - val_accuracy: 0.8954\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.8971 - val_loss: 0.3059 - val_accuracy: 0.8980\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2920 - accuracy: 0.9024 - val_loss: 0.2903 - val_accuracy: 0.9060\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.9005 - val_loss: 0.2758 - val_accuracy: 0.9105\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2662 - accuracy: 0.9039 - val_loss: 0.2640 - val_accuracy: 0.9131\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2548 - accuracy: 0.9096 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2451 - accuracy: 0.9123 - val_loss: 0.2424 - val_accuracy: 0.9184\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2366 - accuracy: 0.9157 - val_loss: 0.2337 - val_accuracy: 0.9193\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2279 - accuracy: 0.9165 - val_loss: 0.2243 - val_accuracy: 0.9282\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9210 - val_loss: 0.2163 - val_accuracy: 0.9238\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2136 - accuracy: 0.9229 - val_loss: 0.2088 - val_accuracy: 0.9255\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2077 - accuracy: 0.9244 - val_loss: 0.2027 - val_accuracy: 0.9335\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9260 - val_loss: 0.1965 - val_accuracy: 0.9344\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1968 - accuracy: 0.9279 - val_loss: 0.1903 - val_accuracy: 0.9335\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1917 - accuracy: 0.9279 - val_loss: 0.1855 - val_accuracy: 0.9353\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1873 - accuracy: 0.9290 - val_loss: 0.1799 - val_accuracy: 0.9371\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1828 - accuracy: 0.9309 - val_loss: 0.1748 - val_accuracy: 0.9379\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9332 - val_loss: 0.1699 - val_accuracy: 0.9397\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1741 - accuracy: 0.9355 - val_loss: 0.1653 - val_accuracy: 0.9406\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1698 - accuracy: 0.9374 - val_loss: 0.1612 - val_accuracy: 0.9459\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9385 - val_loss: 0.1578 - val_accuracy: 0.9477\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9381 - val_loss: 0.1529 - val_accuracy: 0.9477\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9408 - val_loss: 0.1489 - val_accuracy: 0.9486\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1556 - accuracy: 0.9404 - val_loss: 0.1456 - val_accuracy: 0.9521\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1525 - accuracy: 0.9438 - val_loss: 0.1424 - val_accuracy: 0.9539\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9453 - val_loss: 0.1419 - val_accuracy: 0.9557\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9427 - val_loss: 0.1364 - val_accuracy: 0.9583\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9453 - val_loss: 0.1331 - val_accuracy: 0.9539\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9457 - val_loss: 0.1305 - val_accuracy: 0.9574\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9461 - val_loss: 0.1281 - val_accuracy: 0.9592\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1378 - accuracy: 0.9480 - val_loss: 0.1256 - val_accuracy: 0.9583\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1355 - accuracy: 0.9499 - val_loss: 0.1234 - val_accuracy: 0.9583\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1335 - accuracy: 0.9499 - val_loss: 0.1212 - val_accuracy: 0.9610\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 0.9510 - val_loss: 0.1191 - val_accuracy: 0.9619\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9506 - val_loss: 0.1171 - val_accuracy: 0.9637\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9518 - val_loss: 0.1168 - val_accuracy: 0.9637\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9560 - val_loss: 0.1131 - val_accuracy: 0.9654\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1242 - accuracy: 0.9560 - val_loss: 0.1112 - val_accuracy: 0.9681\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9563 - val_loss: 0.1096 - val_accuracy: 0.9681\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1207 - accuracy: 0.9571 - val_loss: 0.1094 - val_accuracy: 0.9672\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.9594 - val_loss: 0.1060 - val_accuracy: 0.9690\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1178 - accuracy: 0.9609 - val_loss: 0.1049 - val_accuracy: 0.9699\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1165 - accuracy: 0.9609 - val_loss: 0.1038 - val_accuracy: 0.9699\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1152 - accuracy: 0.9617 - val_loss: 0.1019 - val_accuracy: 0.9716\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1138 - accuracy: 0.9628 - val_loss: 0.1002 - val_accuracy: 0.9716\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9636 - val_loss: 0.0987 - val_accuracy: 0.9725\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1113 - accuracy: 0.9620 - val_loss: 0.0976 - val_accuracy: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1103 - accuracy: 0.9647 - val_loss: 0.0965 - val_accuracy: 0.9725\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1089 - accuracy: 0.9677 - val_loss: 0.0954 - val_accuracy: 0.9725\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9674 - val_loss: 0.0937 - val_accuracy: 0.9725\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1066 - accuracy: 0.9681 - val_loss: 0.0932 - val_accuracy: 0.9761\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1060 - accuracy: 0.9674 - val_loss: 0.0920 - val_accuracy: 0.9752\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1049 - accuracy: 0.9681 - val_loss: 0.0908 - val_accuracy: 0.9752\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1040 - accuracy: 0.9681 - val_loss: 0.0893 - val_accuracy: 0.9734\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1032 - accuracy: 0.9692 - val_loss: 0.0884 - val_accuracy: 0.9743\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0877 - val_accuracy: 0.9752\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9689 - val_loss: 0.0867 - val_accuracy: 0.9752\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1004 - accuracy: 0.9681 - val_loss: 0.0855 - val_accuracy: 0.9752\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1001 - accuracy: 0.9700 - val_loss: 0.0849 - val_accuracy: 0.9752\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0995 - accuracy: 0.9692 - val_loss: 0.0845 - val_accuracy: 0.9770\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0984 - accuracy: 0.9700 - val_loss: 0.0834 - val_accuracy: 0.9761\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0978 - accuracy: 0.9696 - val_loss: 0.0826 - val_accuracy: 0.9761\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0974 - accuracy: 0.9708 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.9711 - val_loss: 0.0813 - val_accuracy: 0.9770\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9708 - val_loss: 0.0809 - val_accuracy: 0.9770\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0956 - accuracy: 0.9715 - val_loss: 0.0819 - val_accuracy: 0.9805\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0949 - accuracy: 0.9723 - val_loss: 0.0809 - val_accuracy: 0.9796\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0946 - accuracy: 0.9700 - val_loss: 0.0803 - val_accuracy: 0.9796\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.0780 - val_accuracy: 0.9770\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0937 - accuracy: 0.9719 - val_loss: 0.0775 - val_accuracy: 0.9805\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9708 - val_loss: 0.0770 - val_accuracy: 0.9770\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9708 - val_loss: 0.0764 - val_accuracy: 0.9814\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.0760 - val_accuracy: 0.9814\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0922 - accuracy: 0.9704 - val_loss: 0.0756 - val_accuracy: 0.9814\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0914 - accuracy: 0.9711 - val_loss: 0.0753 - val_accuracy: 0.9823\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0913 - accuracy: 0.9711 - val_loss: 0.0745 - val_accuracy: 0.9814\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0908 - accuracy: 0.9708 - val_loss: 0.0749 - val_accuracy: 0.9814\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9715 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.0732 - val_accuracy: 0.9805\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0898 - accuracy: 0.9715 - val_loss: 0.0726 - val_accuracy: 0.9814\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0894 - accuracy: 0.9723 - val_loss: 0.0723 - val_accuracy: 0.9823\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0892 - accuracy: 0.9711 - val_loss: 0.0720 - val_accuracy: 0.9796\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0887 - accuracy: 0.9719 - val_loss: 0.0720 - val_accuracy: 0.9823\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 0.0711 - val_accuracy: 0.9796\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0881 - accuracy: 0.9734 - val_loss: 0.0719 - val_accuracy: 0.9805\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9727 - val_loss: 0.0719 - val_accuracy: 0.9796\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.0701 - val_accuracy: 0.9796\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0876 - accuracy: 0.9719 - val_loss: 0.0698 - val_accuracy: 0.9796\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0872 - accuracy: 0.9723 - val_loss: 0.0694 - val_accuracy: 0.9823\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0871 - accuracy: 0.9715 - val_loss: 0.0703 - val_accuracy: 0.9805\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0867 - accuracy: 0.9730 - val_loss: 0.0689 - val_accuracy: 0.9796\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0869 - accuracy: 0.9715 - val_loss: 0.0692 - val_accuracy: 0.9823\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0866 - accuracy: 0.9727 - val_loss: 0.0690 - val_accuracy: 0.9814\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0863 - accuracy: 0.9738 - val_loss: 0.0679 - val_accuracy: 0.9823\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9730 - val_loss: 0.0676 - val_accuracy: 0.9823\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0859 - accuracy: 0.9727 - val_loss: 0.0680 - val_accuracy: 0.9823\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0857 - accuracy: 0.9727 - val_loss: 0.0670 - val_accuracy: 0.9823\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0856 - accuracy: 0.9730 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0855 - accuracy: 0.9730 - val_loss: 0.0670 - val_accuracy: 0.9823\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0856 - accuracy: 0.9730 - val_loss: 0.0666 - val_accuracy: 0.9823\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0850 - accuracy: 0.9738 - val_loss: 0.0664 - val_accuracy: 0.9823\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0851 - accuracy: 0.9734 - val_loss: 0.0663 - val_accuracy: 0.9823\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.0684 - val_accuracy: 0.9814\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0852 - accuracy: 0.9730 - val_loss: 0.0657 - val_accuracy: 0.9823\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0846 - accuracy: 0.9730 - val_loss: 0.0654 - val_accuracy: 0.9823\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0846 - accuracy: 0.9734 - val_loss: 0.0656 - val_accuracy: 0.9823\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0842 - accuracy: 0.9734 - val_loss: 0.0662 - val_accuracy: 0.9814\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0845 - accuracy: 0.9746 - val_loss: 0.0655 - val_accuracy: 0.9832\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0842 - accuracy: 0.9738 - val_loss: 0.0657 - val_accuracy: 0.9814\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.0648 - val_accuracy: 0.9823\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0840 - accuracy: 0.9738 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0837 - accuracy: 0.9734 - val_loss: 0.0661 - val_accuracy: 0.9814\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9738 - val_loss: 0.0644 - val_accuracy: 0.9805\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0838 - accuracy: 0.9742 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0834 - accuracy: 0.9738 - val_loss: 0.0640 - val_accuracy: 0.9832\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0835 - accuracy: 0.9738 - val_loss: 0.0634 - val_accuracy: 0.9823\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.9746 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.0632 - val_accuracy: 0.9832\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9734 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0830 - accuracy: 0.9734 - val_loss: 0.0630 - val_accuracy: 0.9832\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9734 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0826 - accuracy: 0.9742 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0827 - accuracy: 0.9738 - val_loss: 0.0625 - val_accuracy: 0.9832\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0827 - accuracy: 0.9734 - val_loss: 0.0625 - val_accuracy: 0.9823\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0826 - accuracy: 0.9730 - val_loss: 0.0624 - val_accuracy: 0.9832\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9749 - val_loss: 0.0625 - val_accuracy: 0.9814\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9742 - val_loss: 0.0619 - val_accuracy: 0.9832\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0823 - accuracy: 0.9734 - val_loss: 0.0624 - val_accuracy: 0.9823\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9727 - val_loss: 0.0623 - val_accuracy: 0.9823\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 0.0619 - val_accuracy: 0.9805\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9746 - val_loss: 0.0615 - val_accuracy: 0.9832\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.0619 - val_accuracy: 0.9823\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 0.9734 - val_loss: 0.0629 - val_accuracy: 0.9832\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.0611 - val_accuracy: 0.9823\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0820 - accuracy: 0.9742 - val_loss: 0.0610 - val_accuracy: 0.9832\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0811 - accuracy: 0.9761 - val_loss: 0.0628 - val_accuracy: 0.9832\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.9753 - val_loss: 0.0627 - val_accuracy: 0.9832\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9749 - val_loss: 0.0608 - val_accuracy: 0.9832\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.0614 - val_accuracy: 0.9823\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9753 - val_loss: 0.0623 - val_accuracy: 0.9832\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9734 - val_loss: 0.0605 - val_accuracy: 0.9832\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0813 - accuracy: 0.9746 - val_loss: 0.0604 - val_accuracy: 0.9832\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0811 - accuracy: 0.9753 - val_loss: 0.0613 - val_accuracy: 0.9823\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9746 - val_loss: 0.0600 - val_accuracy: 0.9832\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0812 - accuracy: 0.9753 - val_loss: 0.0603 - val_accuracy: 0.9823\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0811 - accuracy: 0.9749 - val_loss: 0.0610 - val_accuracy: 0.9823\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 0.0599 - val_accuracy: 0.9832\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0811 - accuracy: 0.9749 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.0597 - val_accuracy: 0.9832\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0809 - accuracy: 0.9742 - val_loss: 0.0595 - val_accuracy: 0.9832\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9742 - val_loss: 0.0597 - val_accuracy: 0.9823\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0805 - accuracy: 0.9757 - val_loss: 0.0608 - val_accuracy: 0.9832\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9734 - val_loss: 0.0599 - val_accuracy: 0.9805\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0811 - accuracy: 0.9746 - val_loss: 0.0594 - val_accuracy: 0.9823\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0808 - accuracy: 0.9746 - val_loss: 0.0593 - val_accuracy: 0.9840\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9749 - val_loss: 0.0594 - val_accuracy: 0.9823\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9753 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0801 - accuracy: 0.9749 - val_loss: 0.0607 - val_accuracy: 0.9832\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.0590 - val_accuracy: 0.9840\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0806 - accuracy: 0.9742 - val_loss: 0.0595 - val_accuracy: 0.9823\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0804 - accuracy: 0.9742 - val_loss: 0.0594 - val_accuracy: 0.9823\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0805 - accuracy: 0.9742 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0803 - accuracy: 0.9742 - val_loss: 0.0591 - val_accuracy: 0.9823\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.0591 - val_accuracy: 0.9823\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0802 - accuracy: 0.9753 - val_loss: 0.0588 - val_accuracy: 0.9832\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 0.0599 - val_accuracy: 0.9832\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9746 - val_loss: 0.0588 - val_accuracy: 0.9832\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0802 - accuracy: 0.9753 - val_loss: 0.0584 - val_accuracy: 0.9849\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.0584 - val_accuracy: 0.9849\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9757 - val_loss: 0.0584 - val_accuracy: 0.9832\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0799 - accuracy: 0.9742 - val_loss: 0.0584 - val_accuracy: 0.9832\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.0592 - val_accuracy: 0.9832\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0801 - accuracy: 0.9749 - val_loss: 0.0587 - val_accuracy: 0.9832\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0801 - accuracy: 0.9746 - val_loss: 0.0582 - val_accuracy: 0.9832\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0799 - accuracy: 0.9746 - val_loss: 0.0582 - val_accuracy: 0.9849\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.0584 - val_accuracy: 0.9832\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0802 - accuracy: 0.9757 - val_loss: 0.0591 - val_accuracy: 0.9840\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0800 - accuracy: 0.9746 - val_loss: 0.0596 - val_accuracy: 0.9823\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0799 - accuracy: 0.9753 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.0580 - val_accuracy: 0.9849\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0798 - accuracy: 0.9742 - val_loss: 0.0580 - val_accuracy: 0.9840\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9753 - val_loss: 0.0588 - val_accuracy: 0.9832\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0580 - val_accuracy: 0.9840\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.0579 - val_accuracy: 0.9832\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9757 - val_loss: 0.0580 - val_accuracy: 0.9832\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.0580 - val_accuracy: 0.9832\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0796 - accuracy: 0.9761 - val_loss: 0.0578 - val_accuracy: 0.9849\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9761 - val_loss: 0.0585 - val_accuracy: 0.9832\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9753 - val_loss: 0.0578 - val_accuracy: 0.9832\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0798 - accuracy: 0.9757 - val_loss: 0.0582 - val_accuracy: 0.9832\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9753 - val_loss: 0.0578 - val_accuracy: 0.9840\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9749 - val_loss: 0.0591 - val_accuracy: 0.9832\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0576 - val_accuracy: 0.9840\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9761 - val_loss: 0.0578 - val_accuracy: 0.9840\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0797 - accuracy: 0.9753 - val_loss: 0.0577 - val_accuracy: 0.9832\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9761 - val_loss: 0.0586 - val_accuracy: 0.9832\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9768 - val_loss: 0.0588 - val_accuracy: 0.9832\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9761 - val_loss: 0.0579 - val_accuracy: 0.9832\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0577 - val_accuracy: 0.9832\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0573 - val_accuracy: 0.9840\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0583 - val_accuracy: 0.9832\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0574 - val_accuracy: 0.9832\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9757 - val_loss: 0.0576 - val_accuracy: 0.9832\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9768 - val_loss: 0.0582 - val_accuracy: 0.9832\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0572 - val_accuracy: 0.9832\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0573 - val_accuracy: 0.9832\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0573 - val_accuracy: 0.9840\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0586 - val_accuracy: 0.9832\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0593 - val_accuracy: 0.9840\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0790 - accuracy: 0.9772 - val_loss: 0.0576 - val_accuracy: 0.9840\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0795 - accuracy: 0.9761 - val_loss: 0.0574 - val_accuracy: 0.9832\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0574 - val_accuracy: 0.9832\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0580 - val_accuracy: 0.9832\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9761 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9753 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.0593 - val_accuracy: 0.9849\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0581 - val_accuracy: 0.9840\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0583 - val_accuracy: 0.9840\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9765 - val_loss: 0.0581 - val_accuracy: 0.9840\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0582 - val_accuracy: 0.9840\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0573 - val_accuracy: 0.9832\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0582 - val_accuracy: 0.9849\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0580 - val_accuracy: 0.9840\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9761 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0791 - accuracy: 0.9753 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0577 - val_accuracy: 0.9840\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0564 - val_accuracy: 0.9849\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0567 - val_accuracy: 0.9832\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9753 - val_loss: 0.0569 - val_accuracy: 0.9823\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9757 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9761 - val_loss: 0.0567 - val_accuracy: 0.9832\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.0577 - val_accuracy: 0.9840\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9772 - val_loss: 0.0572 - val_accuracy: 0.9832\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9772 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9776 - val_loss: 0.0568 - val_accuracy: 0.9823\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9765 - val_loss: 0.0567 - val_accuracy: 0.9823\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.0571 - val_accuracy: 0.9832\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0791 - accuracy: 0.9753 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0789 - accuracy: 0.9772 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0587 - val_accuracy: 0.9849\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9757 - val_loss: 0.0573 - val_accuracy: 0.9840\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9772 - val_loss: 0.0576 - val_accuracy: 0.9840\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0576 - val_accuracy: 0.9832\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0567 - val_accuracy: 0.9823\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9753 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0570 - val_accuracy: 0.9832\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0565 - val_accuracy: 0.9823\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9772 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0576 - val_accuracy: 0.9832\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9757 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9768 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0589 - val_accuracy: 0.9849\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9753 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0560 - val_accuracy: 0.9840\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0567 - val_accuracy: 0.9832\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0570 - val_accuracy: 0.9840\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0564 - val_accuracy: 0.9823\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.0582 - val_accuracy: 0.9849\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0564 - val_accuracy: 0.9823\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9757 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0573 - val_accuracy: 0.9832\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9768 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9772 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9832\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9776 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0570 - val_accuracy: 0.9832\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9753 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9840\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9772 - val_loss: 0.0567 - val_accuracy: 0.9840\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0574 - val_accuracy: 0.9849\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0570 - val_accuracy: 0.9840\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9757 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0564 - val_accuracy: 0.9840\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9753 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9772 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0565 - val_accuracy: 0.9840\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9776 - val_loss: 0.0570 - val_accuracy: 0.9840\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9840\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9840\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9772 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9772 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0574 - val_accuracy: 0.9849\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9753 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9772 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9772 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9776 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0780 - accuracy: 0.9772 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9768 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9757 - val_loss: 0.0562 - val_accuracy: 0.9840\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9749 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9772 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0581 - val_accuracy: 0.9840\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9772 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9753 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9772 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0574 - val_accuracy: 0.9840\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9761 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9832\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9772 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827288428324698\n",
      "0.964406779661017\n",
      "0.9734816082121471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.1]\n",
      " [ 0.0]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9898580121703854\n",
      "0.9701789264413518\n",
      "0.9799196787148594\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
