{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0  1.0  126.3 ...  3.5  0.8  0.0]\n",
      " [ 0.0  8.5  224.8 ...  2.2  1.0  0.0]\n",
      " [ 1.0  12.3  1460.6 ...  6.0  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  18.6  1291.3 ...  4.2  1.0  0.0]\n",
      " [ 1.0  10.1  939.2 ...  5.6  1.0  0.0]\n",
      " [ 1.0  9.5  635.4 ...  4.3  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 4]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 4]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 13ms/step - loss: 0.6767 - accuracy: 0.5535 - val_loss: 0.6728 - val_accuracy: 0.5505\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6707 - accuracy: 0.5535 - val_loss: 0.6682 - val_accuracy: 0.5505\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6662 - accuracy: 0.5535 - val_loss: 0.6638 - val_accuracy: 0.5505\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6620 - accuracy: 0.5535 - val_loss: 0.6593 - val_accuracy: 0.5505\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6576 - accuracy: 0.5535 - val_loss: 0.6549 - val_accuracy: 0.5505\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6531 - accuracy: 0.5535 - val_loss: 0.6502 - val_accuracy: 0.5505\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6482 - accuracy: 0.5535 - val_loss: 0.6450 - val_accuracy: 0.5505\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.5535 - val_loss: 0.6397 - val_accuracy: 0.5505\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6378 - accuracy: 0.5535 - val_loss: 0.6340 - val_accuracy: 0.5505\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6321 - accuracy: 0.5535 - val_loss: 0.6279 - val_accuracy: 0.5505\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.5535 - val_loss: 0.6216 - val_accuracy: 0.5505\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6197 - accuracy: 0.5535 - val_loss: 0.6149 - val_accuracy: 0.5505\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.5535 - val_loss: 0.6081 - val_accuracy: 0.5505\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6064 - accuracy: 0.5535 - val_loss: 0.6009 - val_accuracy: 0.5505\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.6230 - val_loss: 0.5938 - val_accuracy: 0.7314\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5925 - accuracy: 0.7077 - val_loss: 0.5867 - val_accuracy: 0.8360\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.7950 - val_loss: 0.5792 - val_accuracy: 0.8715\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5779 - accuracy: 0.8459 - val_loss: 0.5715 - val_accuracy: 0.8617\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.8702 - val_loss: 0.5638 - val_accuracy: 0.8989\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.8872 - val_loss: 0.5559 - val_accuracy: 0.9176\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.9024 - val_loss: 0.5478 - val_accuracy: 0.9273\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.9180 - val_loss: 0.5397 - val_accuracy: 0.9291\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.9241 - val_loss: 0.5315 - val_accuracy: 0.9344\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5311 - accuracy: 0.9286 - val_loss: 0.5231 - val_accuracy: 0.9397\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.9336 - val_loss: 0.5145 - val_accuracy: 0.9495\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5148 - accuracy: 0.9408 - val_loss: 0.5061 - val_accuracy: 0.9512\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.9457 - val_loss: 0.4975 - val_accuracy: 0.9539\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4982 - accuracy: 0.9476 - val_loss: 0.4893 - val_accuracy: 0.9592\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4897 - accuracy: 0.9506 - val_loss: 0.4803 - val_accuracy: 0.9583\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4815 - accuracy: 0.9525 - val_loss: 0.4717 - val_accuracy: 0.9610\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4731 - accuracy: 0.9556 - val_loss: 0.4631 - val_accuracy: 0.9654\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.9582 - val_loss: 0.4546 - val_accuracy: 0.9654\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4566 - accuracy: 0.9605 - val_loss: 0.4462 - val_accuracy: 0.9672\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4482 - accuracy: 0.9605 - val_loss: 0.4375 - val_accuracy: 0.9699\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.9620 - val_loss: 0.4292 - val_accuracy: 0.9699\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4318 - accuracy: 0.9620 - val_loss: 0.4207 - val_accuracy: 0.9716\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.9636 - val_loss: 0.4124 - val_accuracy: 0.9725\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4155 - accuracy: 0.9647 - val_loss: 0.4040 - val_accuracy: 0.9734\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4074 - accuracy: 0.9662 - val_loss: 0.3957 - val_accuracy: 0.9725\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3995 - accuracy: 0.9670 - val_loss: 0.3875 - val_accuracy: 0.9743\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3916 - accuracy: 0.9681 - val_loss: 0.3797 - val_accuracy: 0.9761\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.9681 - val_loss: 0.3719 - val_accuracy: 0.9743\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3765 - accuracy: 0.9689 - val_loss: 0.3640 - val_accuracy: 0.9752\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3689 - accuracy: 0.9692 - val_loss: 0.3563 - val_accuracy: 0.9761\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3615 - accuracy: 0.9696 - val_loss: 0.3487 - val_accuracy: 0.9770\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.9704 - val_loss: 0.3412 - val_accuracy: 0.9761\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3469 - accuracy: 0.9704 - val_loss: 0.3338 - val_accuracy: 0.9761\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3400 - accuracy: 0.9696 - val_loss: 0.3268 - val_accuracy: 0.9770\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3330 - accuracy: 0.9715 - val_loss: 0.3197 - val_accuracy: 0.9761\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3263 - accuracy: 0.9711 - val_loss: 0.3128 - val_accuracy: 0.9761\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3197 - accuracy: 0.9711 - val_loss: 0.3060 - val_accuracy: 0.9778\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3133 - accuracy: 0.9711 - val_loss: 0.2996 - val_accuracy: 0.9778\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3069 - accuracy: 0.9715 - val_loss: 0.2926 - val_accuracy: 0.9778\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.9723 - val_loss: 0.2864 - val_accuracy: 0.9778\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2945 - accuracy: 0.9719 - val_loss: 0.2803 - val_accuracy: 0.9778\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2886 - accuracy: 0.9723 - val_loss: 0.2746 - val_accuracy: 0.9770\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2828 - accuracy: 0.9719 - val_loss: 0.2683 - val_accuracy: 0.9778\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2770 - accuracy: 0.9727 - val_loss: 0.2623 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2714 - accuracy: 0.9727 - val_loss: 0.2566 - val_accuracy: 0.9778\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2661 - accuracy: 0.9719 - val_loss: 0.2510 - val_accuracy: 0.9778\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2609 - accuracy: 0.9727 - val_loss: 0.2457 - val_accuracy: 0.9778\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2559 - accuracy: 0.9727 - val_loss: 0.2406 - val_accuracy: 0.9778\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2510 - accuracy: 0.9723 - val_loss: 0.2359 - val_accuracy: 0.9770\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2462 - accuracy: 0.9727 - val_loss: 0.2307 - val_accuracy: 0.9778\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2417 - accuracy: 0.9723 - val_loss: 0.2260 - val_accuracy: 0.9778\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2373 - accuracy: 0.9723 - val_loss: 0.2215 - val_accuracy: 0.9778\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2332 - accuracy: 0.9727 - val_loss: 0.2173 - val_accuracy: 0.9778\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2290 - accuracy: 0.9723 - val_loss: 0.2130 - val_accuracy: 0.9770\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2250 - accuracy: 0.9723 - val_loss: 0.2088 - val_accuracy: 0.9778\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2211 - accuracy: 0.9727 - val_loss: 0.2047 - val_accuracy: 0.9778\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2172 - accuracy: 0.9723 - val_loss: 0.2008 - val_accuracy: 0.9778\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2136 - accuracy: 0.9727 - val_loss: 0.1971 - val_accuracy: 0.9778\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2101 - accuracy: 0.9730 - val_loss: 0.1933 - val_accuracy: 0.9778\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2067 - accuracy: 0.9727 - val_loss: 0.1898 - val_accuracy: 0.9770\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2033 - accuracy: 0.9727 - val_loss: 0.1863 - val_accuracy: 0.9778\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9727 - val_loss: 0.1832 - val_accuracy: 0.9778\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9723 - val_loss: 0.1803 - val_accuracy: 0.9770\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9727 - val_loss: 0.1774 - val_accuracy: 0.9770\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1918 - accuracy: 0.9730 - val_loss: 0.1744 - val_accuracy: 0.9778\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1893 - accuracy: 0.9727 - val_loss: 0.1717 - val_accuracy: 0.9778\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 0.9723 - val_loss: 0.1691 - val_accuracy: 0.9778\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.9727 - val_loss: 0.1668 - val_accuracy: 0.9770\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.9727 - val_loss: 0.1641 - val_accuracy: 0.9770\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9734 - val_loss: 0.1620 - val_accuracy: 0.9770\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1778 - accuracy: 0.9723 - val_loss: 0.1596 - val_accuracy: 0.9778\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1757 - accuracy: 0.9723 - val_loss: 0.1575 - val_accuracy: 0.9770\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1737 - accuracy: 0.9730 - val_loss: 0.1553 - val_accuracy: 0.9778\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9727 - val_loss: 0.1533 - val_accuracy: 0.9770\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1699 - accuracy: 0.9727 - val_loss: 0.1513 - val_accuracy: 0.9778\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9727 - val_loss: 0.1495 - val_accuracy: 0.9778\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1666 - accuracy: 0.9723 - val_loss: 0.1479 - val_accuracy: 0.9770\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1649 - accuracy: 0.9727 - val_loss: 0.1461 - val_accuracy: 0.9770\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1634 - accuracy: 0.9730 - val_loss: 0.1444 - val_accuracy: 0.9770\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1621 - accuracy: 0.9727 - val_loss: 0.1431 - val_accuracy: 0.9770\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1608 - accuracy: 0.9723 - val_loss: 0.1416 - val_accuracy: 0.9770\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1595 - accuracy: 0.9730 - val_loss: 0.1402 - val_accuracy: 0.9778\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1583 - accuracy: 0.9719 - val_loss: 0.1389 - val_accuracy: 0.9770\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1569 - accuracy: 0.9727 - val_loss: 0.1374 - val_accuracy: 0.9778\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1559 - accuracy: 0.9727 - val_loss: 0.1361 - val_accuracy: 0.9770\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1547 - accuracy: 0.9730 - val_loss: 0.1350 - val_accuracy: 0.9770\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9727 - val_loss: 0.1338 - val_accuracy: 0.9770\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9727 - val_loss: 0.1327 - val_accuracy: 0.9770\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.9723 - val_loss: 0.1316 - val_accuracy: 0.9770\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1507 - accuracy: 0.9723 - val_loss: 0.1307 - val_accuracy: 0.9770\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1498 - accuracy: 0.9730 - val_loss: 0.1296 - val_accuracy: 0.9778\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1490 - accuracy: 0.9727 - val_loss: 0.1287 - val_accuracy: 0.9770\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9730 - val_loss: 0.1277 - val_accuracy: 0.9778\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9730 - val_loss: 0.1269 - val_accuracy: 0.9770\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1466 - accuracy: 0.9730 - val_loss: 0.1262 - val_accuracy: 0.9770\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1460 - accuracy: 0.9727 - val_loss: 0.1253 - val_accuracy: 0.9770\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1452 - accuracy: 0.9730 - val_loss: 0.1244 - val_accuracy: 0.9770\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9730 - val_loss: 0.1236 - val_accuracy: 0.9770\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1440 - accuracy: 0.9723 - val_loss: 0.1230 - val_accuracy: 0.9770\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1434 - accuracy: 0.9727 - val_loss: 0.1223 - val_accuracy: 0.9770\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1428 - accuracy: 0.9727 - val_loss: 0.1215 - val_accuracy: 0.9770\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1421 - accuracy: 0.9727 - val_loss: 0.1208 - val_accuracy: 0.9770\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1415 - accuracy: 0.9727 - val_loss: 0.1201 - val_accuracy: 0.9770\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9723 - val_loss: 0.1195 - val_accuracy: 0.9770\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9734 - val_loss: 0.1189 - val_accuracy: 0.9770\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1399 - accuracy: 0.9730 - val_loss: 0.1183 - val_accuracy: 0.9770\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.9727 - val_loss: 0.1180 - val_accuracy: 0.9770\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1390 - accuracy: 0.9727 - val_loss: 0.1174 - val_accuracy: 0.9770\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1386 - accuracy: 0.9727 - val_loss: 0.1168 - val_accuracy: 0.9770\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1382 - accuracy: 0.9727 - val_loss: 0.1164 - val_accuracy: 0.9770\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1377 - accuracy: 0.9734 - val_loss: 0.1162 - val_accuracy: 0.9778\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1374 - accuracy: 0.9734 - val_loss: 0.1153 - val_accuracy: 0.9770\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1370 - accuracy: 0.9727 - val_loss: 0.1149 - val_accuracy: 0.9770\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1366 - accuracy: 0.9730 - val_loss: 0.1145 - val_accuracy: 0.9770\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1363 - accuracy: 0.9730 - val_loss: 0.1141 - val_accuracy: 0.9770\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1360 - accuracy: 0.9727 - val_loss: 0.1136 - val_accuracy: 0.9770\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1356 - accuracy: 0.9734 - val_loss: 0.1132 - val_accuracy: 0.9770\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1353 - accuracy: 0.9730 - val_loss: 0.1128 - val_accuracy: 0.9770\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1350 - accuracy: 0.9730 - val_loss: 0.1125 - val_accuracy: 0.9770\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1348 - accuracy: 0.9727 - val_loss: 0.1121 - val_accuracy: 0.9770\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1345 - accuracy: 0.9730 - val_loss: 0.1118 - val_accuracy: 0.9770\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1342 - accuracy: 0.9730 - val_loss: 0.1115 - val_accuracy: 0.9770\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1339 - accuracy: 0.9727 - val_loss: 0.1111 - val_accuracy: 0.9770\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9730 - val_loss: 0.1107 - val_accuracy: 0.9770\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1335 - accuracy: 0.9734 - val_loss: 0.1105 - val_accuracy: 0.9770\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1332 - accuracy: 0.9734 - val_loss: 0.1103 - val_accuracy: 0.9770\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1330 - accuracy: 0.9730 - val_loss: 0.1101 - val_accuracy: 0.9770\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1328 - accuracy: 0.9730 - val_loss: 0.1097 - val_accuracy: 0.9770\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1326 - accuracy: 0.9730 - val_loss: 0.1094 - val_accuracy: 0.9770\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1323 - accuracy: 0.9734 - val_loss: 0.1090 - val_accuracy: 0.9770\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1322 - accuracy: 0.9730 - val_loss: 0.1088 - val_accuracy: 0.9770\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1320 - accuracy: 0.9730 - val_loss: 0.1086 - val_accuracy: 0.9770\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1318 - accuracy: 0.9730 - val_loss: 0.1083 - val_accuracy: 0.9770\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1316 - accuracy: 0.9730 - val_loss: 0.1081 - val_accuracy: 0.9770\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1314 - accuracy: 0.9730 - val_loss: 0.1078 - val_accuracy: 0.9770\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1312 - accuracy: 0.9730 - val_loss: 0.1077 - val_accuracy: 0.9770\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1311 - accuracy: 0.9734 - val_loss: 0.1073 - val_accuracy: 0.9770\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1309 - accuracy: 0.9730 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1307 - accuracy: 0.9730 - val_loss: 0.1069 - val_accuracy: 0.9770\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1306 - accuracy: 0.9730 - val_loss: 0.1068 - val_accuracy: 0.9770\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1304 - accuracy: 0.9727 - val_loss: 0.1068 - val_accuracy: 0.9778\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1303 - accuracy: 0.9730 - val_loss: 0.1064 - val_accuracy: 0.9770\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.1302 - accuracy: 0.9730 - val_loss: 0.1062 - val_accuracy: 0.9770\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1299 - accuracy: 0.9734 - val_loss: 0.1059 - val_accuracy: 0.9770\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1299 - accuracy: 0.9730 - val_loss: 0.1058 - val_accuracy: 0.9770\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1297 - accuracy: 0.9730 - val_loss: 0.1057 - val_accuracy: 0.9778\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1296 - accuracy: 0.9730 - val_loss: 0.1054 - val_accuracy: 0.9770\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1295 - accuracy: 0.9730 - val_loss: 0.1052 - val_accuracy: 0.9770\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1294 - accuracy: 0.9734 - val_loss: 0.1051 - val_accuracy: 0.9770\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1293 - accuracy: 0.9727 - val_loss: 0.1050 - val_accuracy: 0.9770\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1291 - accuracy: 0.9734 - val_loss: 0.1047 - val_accuracy: 0.9770\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1291 - accuracy: 0.9734 - val_loss: 0.1046 - val_accuracy: 0.9770\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1290 - accuracy: 0.9723 - val_loss: 0.1047 - val_accuracy: 0.9778\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1287 - accuracy: 0.9730 - val_loss: 0.1043 - val_accuracy: 0.9770\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1288 - accuracy: 0.9734 - val_loss: 0.1042 - val_accuracy: 0.9770\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1286 - accuracy: 0.9730 - val_loss: 0.1040 - val_accuracy: 0.9770\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1286 - accuracy: 0.9730 - val_loss: 0.1039 - val_accuracy: 0.9770\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1285 - accuracy: 0.9730 - val_loss: 0.1039 - val_accuracy: 0.9770\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1285 - accuracy: 0.9730 - val_loss: 0.1039 - val_accuracy: 0.9778\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9738 - val_loss: 0.1035 - val_accuracy: 0.9770\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9730 - val_loss: 0.1035 - val_accuracy: 0.9770\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1282 - accuracy: 0.9730 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9730 - val_loss: 0.1033 - val_accuracy: 0.9770\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1280 - accuracy: 0.9734 - val_loss: 0.1033 - val_accuracy: 0.9787\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9730 - val_loss: 0.1030 - val_accuracy: 0.9770\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1279 - accuracy: 0.9734 - val_loss: 0.1029 - val_accuracy: 0.9770\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1278 - accuracy: 0.9730 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.9727 - val_loss: 0.1029 - val_accuracy: 0.9796\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9730 - val_loss: 0.1028 - val_accuracy: 0.9796\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.9727 - val_loss: 0.1025 - val_accuracy: 0.9770\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.9730 - val_loss: 0.1024 - val_accuracy: 0.9770\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1275 - accuracy: 0.9730 - val_loss: 0.1024 - val_accuracy: 0.9778\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1275 - accuracy: 0.9730 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1273 - accuracy: 0.9734 - val_loss: 0.1021 - val_accuracy: 0.9770\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1274 - accuracy: 0.9730 - val_loss: 0.1019 - val_accuracy: 0.9770\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1273 - accuracy: 0.9730 - val_loss: 0.1019 - val_accuracy: 0.9770\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9730 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1272 - accuracy: 0.9738 - val_loss: 0.1017 - val_accuracy: 0.9770\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9730 - val_loss: 0.1017 - val_accuracy: 0.9770\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1271 - accuracy: 0.9730 - val_loss: 0.1016 - val_accuracy: 0.9778\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1270 - accuracy: 0.9730 - val_loss: 0.1015 - val_accuracy: 0.9778\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1270 - accuracy: 0.9734 - val_loss: 0.1015 - val_accuracy: 0.9778\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1269 - accuracy: 0.9730 - val_loss: 0.1015 - val_accuracy: 0.9796\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1269 - accuracy: 0.9730 - val_loss: 0.1014 - val_accuracy: 0.9778\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1268 - accuracy: 0.9734 - val_loss: 0.1012 - val_accuracy: 0.9770\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.9730 - val_loss: 0.1012 - val_accuracy: 0.9778\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.9727 - val_loss: 0.1011 - val_accuracy: 0.9770\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1267 - accuracy: 0.9734 - val_loss: 0.1010 - val_accuracy: 0.9770\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1267 - accuracy: 0.9730 - val_loss: 0.1010 - val_accuracy: 0.9778\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1266 - accuracy: 0.9734 - val_loss: 0.1009 - val_accuracy: 0.9778\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9738 - val_loss: 0.1008 - val_accuracy: 0.9770\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9738 - val_loss: 0.1007 - val_accuracy: 0.9770\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9730 - val_loss: 0.1007 - val_accuracy: 0.9778\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9730 - val_loss: 0.1007 - val_accuracy: 0.9778\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.9727 - val_loss: 0.1007 - val_accuracy: 0.9796\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.9734 - val_loss: 0.1006 - val_accuracy: 0.9778\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9734 - val_loss: 0.1005 - val_accuracy: 0.9778\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.9734 - val_loss: 0.1005 - val_accuracy: 0.9796\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1264 - accuracy: 0.9734 - val_loss: 0.1004 - val_accuracy: 0.9778\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1264 - accuracy: 0.9730 - val_loss: 0.1003 - val_accuracy: 0.9770\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1263 - accuracy: 0.9730 - val_loss: 0.1002 - val_accuracy: 0.9770\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1263 - accuracy: 0.9730 - val_loss: 0.1003 - val_accuracy: 0.9778\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1262 - accuracy: 0.9738 - val_loss: 0.1001 - val_accuracy: 0.9770\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9738 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9738 - val_loss: 0.1002 - val_accuracy: 0.9796\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9738 - val_loss: 0.1001 - val_accuracy: 0.9796\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9730 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9734 - val_loss: 0.0999 - val_accuracy: 0.9778\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9730 - val_loss: 0.0999 - val_accuracy: 0.9796\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9734 - val_loss: 0.0999 - val_accuracy: 0.9796\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9730 - val_loss: 0.0999 - val_accuracy: 0.9796\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1260 - accuracy: 0.9730 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1260 - accuracy: 0.9734 - val_loss: 0.0998 - val_accuracy: 0.9787\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9730 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9730 - val_loss: 0.0997 - val_accuracy: 0.9796\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1260 - accuracy: 0.9738 - val_loss: 0.0996 - val_accuracy: 0.9778\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9730 - val_loss: 0.0997 - val_accuracy: 0.9805\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9734 - val_loss: 0.0995 - val_accuracy: 0.9778\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9734 - val_loss: 0.0996 - val_accuracy: 0.9805\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1258 - accuracy: 0.9738 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9730 - val_loss: 0.0994 - val_accuracy: 0.9787\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9734 - val_loss: 0.0993 - val_accuracy: 0.9778\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1258 - accuracy: 0.9738 - val_loss: 0.0993 - val_accuracy: 0.9778\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1258 - accuracy: 0.9734 - val_loss: 0.0994 - val_accuracy: 0.9796\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1258 - accuracy: 0.9734 - val_loss: 0.0992 - val_accuracy: 0.9778\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1258 - accuracy: 0.9730 - val_loss: 0.0993 - val_accuracy: 0.9796\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1257 - accuracy: 0.9734 - val_loss: 0.0994 - val_accuracy: 0.9814\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1258 - accuracy: 0.9730 - val_loss: 0.0993 - val_accuracy: 0.9805\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1257 - accuracy: 0.9730 - val_loss: 0.0992 - val_accuracy: 0.9805\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1257 - accuracy: 0.9734 - val_loss: 0.0991 - val_accuracy: 0.9796\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1257 - accuracy: 0.9738 - val_loss: 0.0990 - val_accuracy: 0.9778\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1257 - accuracy: 0.9730 - val_loss: 0.0990 - val_accuracy: 0.9796\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9738 - val_loss: 0.0989 - val_accuracy: 0.9770\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1257 - accuracy: 0.9730 - val_loss: 0.0988 - val_accuracy: 0.9770\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9730 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9730 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9734 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.9730 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.9738 - val_loss: 0.0987 - val_accuracy: 0.9778\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1256 - accuracy: 0.9730 - val_loss: 0.0988 - val_accuracy: 0.9796\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9770\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.9734 - val_loss: 0.0987 - val_accuracy: 0.9796\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1256 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9778\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1255 - accuracy: 0.9730 - val_loss: 0.0987 - val_accuracy: 0.9805\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9796\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9734 - val_loss: 0.0987 - val_accuracy: 0.9805\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1255 - accuracy: 0.9730 - val_loss: 0.0986 - val_accuracy: 0.9778\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1255 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9805\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9734 - val_loss: 0.0987 - val_accuracy: 0.9805\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9730 - val_loss: 0.0985 - val_accuracy: 0.9796\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9738 - val_loss: 0.0985 - val_accuracy: 0.9805\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9734 - val_loss: 0.0984 - val_accuracy: 0.9787\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9734 - val_loss: 0.0985 - val_accuracy: 0.9805\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.0985 - val_accuracy: 0.9805\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.0983 - val_accuracy: 0.9778\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.0984 - val_accuracy: 0.9796\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1255 - accuracy: 0.9730 - val_loss: 0.0983 - val_accuracy: 0.9796\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9734 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9734 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9730 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9730 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9734 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0980 - val_accuracy: 0.9770\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1254 - accuracy: 0.9730 - val_loss: 0.0980 - val_accuracy: 0.9778\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0981 - val_accuracy: 0.9805\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0980 - val_accuracy: 0.9770\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9730 - val_loss: 0.0980 - val_accuracy: 0.9778\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0979 - val_accuracy: 0.9770\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0981 - val_accuracy: 0.9805\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9738 - val_loss: 0.0980 - val_accuracy: 0.9796\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0981 - val_accuracy: 0.9805\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0979 - val_accuracy: 0.9778\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9730 - val_loss: 0.0979 - val_accuracy: 0.9796\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9738 - val_loss: 0.0980 - val_accuracy: 0.9805\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9738 - val_loss: 0.0979 - val_accuracy: 0.9778\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0979 - val_accuracy: 0.9787\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0979 - val_accuracy: 0.9796\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0978 - val_accuracy: 0.9796\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.0978 - val_accuracy: 0.9796\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0980 - val_accuracy: 0.9823\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1253 - accuracy: 0.9738 - val_loss: 0.0979 - val_accuracy: 0.9814\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9742 - val_loss: 0.0978 - val_accuracy: 0.9805\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9727 - val_loss: 0.0977 - val_accuracy: 0.9787\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0979 - val_accuracy: 0.9814\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0977 - val_accuracy: 0.9787\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0977 - val_accuracy: 0.9796\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0977 - val_accuracy: 0.9796\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0977 - val_accuracy: 0.9805\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0975 - val_accuracy: 0.9770\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0975 - val_accuracy: 0.9778\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0976 - val_accuracy: 0.9796\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0976 - val_accuracy: 0.9796\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9742 - val_loss: 0.0976 - val_accuracy: 0.9805\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0975 - val_accuracy: 0.9778\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0975 - val_accuracy: 0.9796\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0976 - val_accuracy: 0.9805\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0975 - val_accuracy: 0.9796\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0975 - val_accuracy: 0.9796\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9727 - val_loss: 0.0976 - val_accuracy: 0.9814\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0976 - val_accuracy: 0.9814\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0975 - val_accuracy: 0.9805\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0974 - val_accuracy: 0.9796\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0975 - val_accuracy: 0.9814\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0975 - val_accuracy: 0.9814\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0973 - val_accuracy: 0.9796\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1253 - accuracy: 0.9730 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0975 - val_accuracy: 0.9823\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0976 - val_accuracy: 0.9823\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0973 - val_accuracy: 0.9805\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0973 - val_accuracy: 0.9805\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0973 - val_accuracy: 0.9805\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0972 - val_accuracy: 0.9796\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0973 - val_accuracy: 0.9805\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0973 - val_accuracy: 0.9805\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0973 - val_accuracy: 0.9814\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0973 - val_accuracy: 0.9814\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0973 - val_accuracy: 0.9814\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9742 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0973 - val_accuracy: 0.9823\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0972 - val_accuracy: 0.9814\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0972 - val_accuracy: 0.9814\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0971 - val_accuracy: 0.9814\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0972 - val_accuracy: 0.9814\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9796\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0971 - val_accuracy: 0.9814\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9796\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9796\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0970 - val_accuracy: 0.9805\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9770\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9770\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9796\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9805\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0969 - val_accuracy: 0.9805\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0971 - val_accuracy: 0.9823\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0971 - val_accuracy: 0.9823\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9805\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9805\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9796\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0970 - val_accuracy: 0.9823\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9727 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9805\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9770\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9770\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9805\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9805\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9805\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0968 - val_accuracy: 0.9814\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0968 - val_accuracy: 0.9805\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9814\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9796\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9796\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9805\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9814\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0968 - val_accuracy: 0.9814\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9742 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9787\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0968 - val_accuracy: 0.9814\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9796\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9778\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0967 - val_accuracy: 0.9805\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9727 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9787\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9787\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9832\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0968 - val_accuracy: 0.9823\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9823\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9746 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9778\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9742 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9730 - val_loss: 0.0964 - val_accuracy: 0.9770\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0964 - val_accuracy: 0.9787\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1250 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9796\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9805\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9730 - val_loss: 0.0964 - val_accuracy: 0.9805\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9796\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1250 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9805\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 1s 4ms/step\n",
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9842381786339754\n",
      "0.95578231292517\n",
      "0.9698015530629853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 0.1]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938900203665988\n",
      "0.9625246548323472\n",
      "0.9779559118236473\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
