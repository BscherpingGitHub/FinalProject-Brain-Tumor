{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  3.7  296.0 ...  5.8  1.0  0.0]\n",
      " [ 0.0  13.1  887.5 ...  3.7  1.0  0.0]\n",
      " [ 1.0  2.8  459.8 ...  6.5  1.0  0.0]\n",
      " ...\n",
      " [ 1.0  6.0  1038.6 ...  6.7  1.0  0.0]\n",
      " [ 1.0  1.5  193.3 ...  5.4  1.0  0.0]\n",
      " [ 1.0  9.2  796.0 ...  6.4  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT \n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4855087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  0.1  5.5 ...  0.1  0.5  5.8]\n",
      " [ 0.0  0.2  2.7 ...  0.2  0.6  3.7]\n",
      " [ 1.0  0.0  8.2 ...  0.0  0.3  6.5]\n",
      " ...\n",
      " [ 1.0  0.0  5.8 ...  0.0  0.4  6.7]\n",
      " [ 1.0  0.0  9.6 ...  0.0  0.3  5.4]\n",
      " [ 1.0  0.0  4.1 ...  0.0  0.3  6.4]]\n"
     ]
    }
   ],
   "source": [
    "#Dropping everything below 60% accuracy\n",
    "brainT = np.delete(brainT, 13, axis = 1)\n",
    "brainT = np.delete(brainT, 12, axis = 1)\n",
    "brainT = np.delete(brainT, 7, axis = 1)\n",
    "brainT = np.delete(brainT, 3, axis = 1)\n",
    "brainT = np.delete(brainT, 2, axis = 1)\n",
    "brainT = np.delete(brainT, 1, axis = 1)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = len(XTRAIN[0, :]), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 13ms/step - loss: 3.3182 - accuracy: 0.5372 - val_loss: 2.1885 - val_accuracy: 0.5656\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9315 - accuracy: 0.4408 - val_loss: 1.3881 - val_accuracy: 0.4069\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.2376 - accuracy: 0.4476 - val_loss: 0.9484 - val_accuracy: 0.5053\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.8749 - accuracy: 0.5592 - val_loss: 0.7550 - val_accuracy: 0.6232\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.7338 - accuracy: 0.6245 - val_loss: 0.6750 - val_accuracy: 0.6613\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.6632 - val_loss: 0.6522 - val_accuracy: 0.6844\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.6948 - val_loss: 0.6334 - val_accuracy: 0.7225\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.7297 - val_loss: 0.6081 - val_accuracy: 0.7482\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.7491 - val_loss: 0.5607 - val_accuracy: 0.7793\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7979\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7946 - val_loss: 0.4460 - val_accuracy: 0.8431\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.8280 - val_loss: 0.4185 - val_accuracy: 0.8449\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8512 - val_loss: 0.4027 - val_accuracy: 0.8865\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8652 - val_loss: 0.3844 - val_accuracy: 0.8901\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8759 - val_loss: 0.3685 - val_accuracy: 0.8945\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8827 - val_loss: 0.3482 - val_accuracy: 0.8945\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8918 - val_loss: 0.3320 - val_accuracy: 0.9060\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3457 - accuracy: 0.8998 - val_loss: 0.3175 - val_accuracy: 0.9122\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.3297 - accuracy: 0.9066 - val_loss: 0.3013 - val_accuracy: 0.9149\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3128 - accuracy: 0.9150 - val_loss: 0.2857 - val_accuracy: 0.9255\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2976 - accuracy: 0.9229 - val_loss: 0.2762 - val_accuracy: 0.9273\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.9301 - val_loss: 0.2612 - val_accuracy: 0.9309\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2721 - accuracy: 0.9313 - val_loss: 0.2483 - val_accuracy: 0.9309\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.9362 - val_loss: 0.2387 - val_accuracy: 0.9371\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.9385 - val_loss: 0.2283 - val_accuracy: 0.9371\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.9396 - val_loss: 0.2182 - val_accuracy: 0.9406\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2323 - accuracy: 0.9404 - val_loss: 0.2116 - val_accuracy: 0.9441\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2219 - accuracy: 0.9423 - val_loss: 0.2054 - val_accuracy: 0.9468\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9446 - val_loss: 0.1957 - val_accuracy: 0.9486\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9461 - val_loss: 0.1895 - val_accuracy: 0.9512\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9461 - val_loss: 0.1830 - val_accuracy: 0.9539\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9472 - val_loss: 0.1753 - val_accuracy: 0.9521\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1863 - accuracy: 0.9495 - val_loss: 0.1673 - val_accuracy: 0.9557\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.9499 - val_loss: 0.1643 - val_accuracy: 0.9574\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9522 - val_loss: 0.1594 - val_accuracy: 0.9601\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1707 - accuracy: 0.9503 - val_loss: 0.1517 - val_accuracy: 0.9637\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9556 - val_loss: 0.1512 - val_accuracy: 0.9654\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9548 - val_loss: 0.1467 - val_accuracy: 0.9637\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9560 - val_loss: 0.1387 - val_accuracy: 0.9672\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9571 - val_loss: 0.1388 - val_accuracy: 0.9672\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9571 - val_loss: 0.1337 - val_accuracy: 0.9672\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9579 - val_loss: 0.1308 - val_accuracy: 0.9663\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9590 - val_loss: 0.1263 - val_accuracy: 0.9699\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1357 - accuracy: 0.9624 - val_loss: 0.1250 - val_accuracy: 0.9716\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1373 - accuracy: 0.9647 - val_loss: 0.1222 - val_accuracy: 0.9716\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9662 - val_loss: 0.1178 - val_accuracy: 0.9725\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9647 - val_loss: 0.1132 - val_accuracy: 0.9743\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9658 - val_loss: 0.1174 - val_accuracy: 0.9725\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1242 - accuracy: 0.9662 - val_loss: 0.1130 - val_accuracy: 0.9716\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9674 - val_loss: 0.1081 - val_accuracy: 0.9734\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9681 - val_loss: 0.1097 - val_accuracy: 0.9725\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9696 - val_loss: 0.1083 - val_accuracy: 0.9761\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9708 - val_loss: 0.1000 - val_accuracy: 0.9752\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9715 - val_loss: 0.1035 - val_accuracy: 0.9734\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9723 - val_loss: 0.0977 - val_accuracy: 0.9743\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1089 - accuracy: 0.9730 - val_loss: 0.0986 - val_accuracy: 0.9761\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9711 - val_loss: 0.0976 - val_accuracy: 0.9770\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9730 - val_loss: 0.1028 - val_accuracy: 0.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1079 - accuracy: 0.9715 - val_loss: 0.0978 - val_accuracy: 0.9725\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9734 - val_loss: 0.0927 - val_accuracy: 0.9761\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.0975 - val_accuracy: 0.9752\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9727 - val_loss: 0.0899 - val_accuracy: 0.9752\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0999 - accuracy: 0.9723 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0977 - accuracy: 0.9738 - val_loss: 0.0951 - val_accuracy: 0.9725\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9727 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.9738 - val_loss: 0.0936 - val_accuracy: 0.9734\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9727 - val_loss: 0.0839 - val_accuracy: 0.9770\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0951 - accuracy: 0.9738 - val_loss: 0.0859 - val_accuracy: 0.9752\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0938 - accuracy: 0.9738 - val_loss: 0.0829 - val_accuracy: 0.9752\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0941 - accuracy: 0.9738 - val_loss: 0.0867 - val_accuracy: 0.9752\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0919 - accuracy: 0.9738 - val_loss: 0.0839 - val_accuracy: 0.9761\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0934 - accuracy: 0.9742 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9734 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0910 - accuracy: 0.9719 - val_loss: 0.0816 - val_accuracy: 0.9761\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0914 - accuracy: 0.9738 - val_loss: 0.0814 - val_accuracy: 0.9761\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9730 - val_loss: 0.0788 - val_accuracy: 0.9761\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9742 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9730 - val_loss: 0.0813 - val_accuracy: 0.9770\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9753 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9738 - val_loss: 0.0801 - val_accuracy: 0.9770\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9749 - val_loss: 0.0839 - val_accuracy: 0.9796\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9738 - val_loss: 0.0765 - val_accuracy: 0.9761\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9765 - val_loss: 0.0747 - val_accuracy: 0.9778\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9742 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9730 - val_loss: 0.0749 - val_accuracy: 0.9770\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9742 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9742 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9742 - val_loss: 0.0759 - val_accuracy: 0.9805\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9749 - val_loss: 0.0754 - val_accuracy: 0.9770\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9742 - val_loss: 0.0742 - val_accuracy: 0.9787\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9746 - val_loss: 0.0779 - val_accuracy: 0.9805\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9749 - val_loss: 0.0758 - val_accuracy: 0.9770\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.0724 - val_accuracy: 0.9787\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9742 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9753 - val_loss: 0.0724 - val_accuracy: 0.9778\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9753 - val_loss: 0.0723 - val_accuracy: 0.9770\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9757 - val_loss: 0.0804 - val_accuracy: 0.9770\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9742 - val_loss: 0.0716 - val_accuracy: 0.9778\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9761 - val_loss: 0.0819 - val_accuracy: 0.9805\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9742 - val_loss: 0.0715 - val_accuracy: 0.9787\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9749 - val_loss: 0.0768 - val_accuracy: 0.9761\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.0731 - val_accuracy: 0.9778\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9757 - val_loss: 0.0737 - val_accuracy: 0.9761\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.0731 - val_accuracy: 0.9787\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9749 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9761 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9753 - val_loss: 0.0742 - val_accuracy: 0.9787\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9757 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9757 - val_loss: 0.0712 - val_accuracy: 0.9787\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9742 - val_loss: 0.0697 - val_accuracy: 0.9787\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9761 - val_loss: 0.0722 - val_accuracy: 0.9770\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9753 - val_loss: 0.0704 - val_accuracy: 0.9787\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9772 - val_loss: 0.0692 - val_accuracy: 0.9796\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0832 - accuracy: 0.9749 - val_loss: 0.0687 - val_accuracy: 0.9778\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0800 - accuracy: 0.9749 - val_loss: 0.0720 - val_accuracy: 0.9787\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0814 - accuracy: 0.9761 - val_loss: 0.0712 - val_accuracy: 0.9761\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0738 - val_accuracy: 0.9805\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0720 - val_accuracy: 0.9770\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0712 - val_accuracy: 0.9796\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.0705 - val_accuracy: 0.9778\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0803 - accuracy: 0.9742 - val_loss: 0.0679 - val_accuracy: 0.9778\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0792 - accuracy: 0.9765 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0838 - accuracy: 0.9757 - val_loss: 0.0697 - val_accuracy: 0.9778\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9753 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9761 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9768 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0716 - val_accuracy: 0.9761\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9761 - val_loss: 0.0668 - val_accuracy: 0.9805\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9761 - val_loss: 0.0675 - val_accuracy: 0.9823\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9761 - val_loss: 0.0694 - val_accuracy: 0.9770\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9772 - val_loss: 0.0715 - val_accuracy: 0.9778\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0677 - val_accuracy: 0.9770\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9761 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0675 - val_accuracy: 0.9778\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.0792 - val_accuracy: 0.9796\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9761 - val_loss: 0.0701 - val_accuracy: 0.9787\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9765 - val_loss: 0.0698 - val_accuracy: 0.9787\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9776 - val_loss: 0.0710 - val_accuracy: 0.9770\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0726 - val_accuracy: 0.9787\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9757 - val_loss: 0.0678 - val_accuracy: 0.9778\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0723 - val_accuracy: 0.9805\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 0.0679 - val_accuracy: 0.9796\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9768 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0714 - val_accuracy: 0.9770\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.0729 - val_accuracy: 0.9796\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 0.0679 - val_accuracy: 0.9796\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9776 - val_loss: 0.0661 - val_accuracy: 0.9796\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0808 - accuracy: 0.9749 - val_loss: 0.0671 - val_accuracy: 0.9778\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0800 - accuracy: 0.9772 - val_loss: 0.0714 - val_accuracy: 0.9778\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9765 - val_loss: 0.0668 - val_accuracy: 0.9778\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.9772 - val_loss: 0.0690 - val_accuracy: 0.9778\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 0.0657 - val_accuracy: 0.9796\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0800 - accuracy: 0.9753 - val_loss: 0.0666 - val_accuracy: 0.9796\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0775 - accuracy: 0.9761 - val_loss: 0.0723 - val_accuracy: 0.9770\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.0668 - val_accuracy: 0.9778\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0801 - accuracy: 0.9765 - val_loss: 0.0665 - val_accuracy: 0.9796\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.0666 - val_accuracy: 0.9778\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0727 - val_accuracy: 0.9805\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.9768 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0801 - accuracy: 0.9765 - val_loss: 0.0653 - val_accuracy: 0.9796\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9772 - val_loss: 0.0657 - val_accuracy: 0.9796\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.0655 - val_accuracy: 0.9805\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0820 - accuracy: 0.9765 - val_loss: 0.0688 - val_accuracy: 0.9770\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0779 - accuracy: 0.9768 - val_loss: 0.0697 - val_accuracy: 0.9770\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0778 - accuracy: 0.9757 - val_loss: 0.0654 - val_accuracy: 0.9805\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0670 - val_accuracy: 0.9778\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0816 - accuracy: 0.9757 - val_loss: 0.0650 - val_accuracy: 0.9814\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 0.0657 - val_accuracy: 0.9787\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0771 - accuracy: 0.9761 - val_loss: 0.0671 - val_accuracy: 0.9770\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0774 - accuracy: 0.9768 - val_loss: 0.0694 - val_accuracy: 0.9770\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9746 - val_loss: 0.0682 - val_accuracy: 0.9770\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0810 - accuracy: 0.9761 - val_loss: 0.0660 - val_accuracy: 0.9778\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0765 - accuracy: 0.9768 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.9749 - val_loss: 0.0699 - val_accuracy: 0.9778\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0771 - accuracy: 0.9765 - val_loss: 0.0669 - val_accuracy: 0.9770\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0804 - accuracy: 0.9772 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9768 - val_loss: 0.0724 - val_accuracy: 0.9770\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9757 - val_loss: 0.0712 - val_accuracy: 0.9770\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0795 - accuracy: 0.9761 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0764 - accuracy: 0.9780 - val_loss: 0.0712 - val_accuracy: 0.9770\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0772 - accuracy: 0.9772 - val_loss: 0.0673 - val_accuracy: 0.9778\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0774 - accuracy: 0.9772 - val_loss: 0.0755 - val_accuracy: 0.9805\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0785 - accuracy: 0.9757 - val_loss: 0.0653 - val_accuracy: 0.9796\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0781 - accuracy: 0.9757 - val_loss: 0.0674 - val_accuracy: 0.9761\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0768 - accuracy: 0.9776 - val_loss: 0.0689 - val_accuracy: 0.9805\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9761 - val_loss: 0.0700 - val_accuracy: 0.9805\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0701 - val_accuracy: 0.9761\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.0705 - val_accuracy: 0.9814\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0780 - accuracy: 0.9772 - val_loss: 0.0642 - val_accuracy: 0.9814\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0784 - accuracy: 0.9772 - val_loss: 0.0674 - val_accuracy: 0.9761\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 0.0702 - val_accuracy: 0.9770\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0792 - accuracy: 0.9757 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0654 - val_accuracy: 0.9805\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0766 - accuracy: 0.9768 - val_loss: 0.0664 - val_accuracy: 0.9770\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.0671 - val_accuracy: 0.9770\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.9778\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9768 - val_loss: 0.0658 - val_accuracy: 0.9814\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0768 - accuracy: 0.9784 - val_loss: 0.0657 - val_accuracy: 0.9778\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0809 - accuracy: 0.9765 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9772 - val_loss: 0.0707 - val_accuracy: 0.9805\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9757 - val_loss: 0.0685 - val_accuracy: 0.9796\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0808 - accuracy: 0.9784 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 0.0639 - val_accuracy: 0.9805\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9765 - val_loss: 0.0682 - val_accuracy: 0.9778\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 0.0650 - val_accuracy: 0.9805\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9776 - val_loss: 0.0657 - val_accuracy: 0.9814\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9757 - val_loss: 0.0658 - val_accuracy: 0.9778\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 0.0667 - val_accuracy: 0.9814\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0777 - accuracy: 0.9776 - val_loss: 0.0690 - val_accuracy: 0.9770\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 0.0650 - val_accuracy: 0.9805\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9768 - val_loss: 0.0685 - val_accuracy: 0.9778\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0796 - accuracy: 0.9772 - val_loss: 0.0673 - val_accuracy: 0.9761\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9768 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9776 - val_loss: 0.0659 - val_accuracy: 0.9787\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0667 - val_accuracy: 0.9770\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9761 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9776 - val_loss: 0.0742 - val_accuracy: 0.9814\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9765 - val_loss: 0.0691 - val_accuracy: 0.9770\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0736 - val_accuracy: 0.9805\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0713 - val_accuracy: 0.9805\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9768 - val_loss: 0.0678 - val_accuracy: 0.9805\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9761 - val_loss: 0.0679 - val_accuracy: 0.9778\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.0712 - val_accuracy: 0.9778\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 0.0656 - val_accuracy: 0.9770\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9772 - val_loss: 0.0639 - val_accuracy: 0.9805\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9772 - val_loss: 0.0676 - val_accuracy: 0.9805\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9757 - val_loss: 0.0654 - val_accuracy: 0.9778\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9768 - val_loss: 0.0657 - val_accuracy: 0.9770\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 0.9761 - val_loss: 0.0696 - val_accuracy: 0.9778\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.0670 - val_accuracy: 0.9778\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0660 - val_accuracy: 0.9787\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9768 - val_loss: 0.0666 - val_accuracy: 0.9778\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0735 - val_accuracy: 0.9787\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9772 - val_loss: 0.0737 - val_accuracy: 0.9814\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9761 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0641 - val_accuracy: 0.9787\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9757 - val_loss: 0.0636 - val_accuracy: 0.9814\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.0651 - val_accuracy: 0.9787\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0796 - accuracy: 0.9780 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9784 - val_loss: 0.0638 - val_accuracy: 0.9796\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.0654 - val_accuracy: 0.9770\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9761 - val_loss: 0.0643 - val_accuracy: 0.9805\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.0634 - val_accuracy: 0.9805\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0788 - accuracy: 0.9772 - val_loss: 0.0679 - val_accuracy: 0.9770\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9761 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0769 - accuracy: 0.9772 - val_loss: 0.0648 - val_accuracy: 0.9770\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 0.0666 - val_accuracy: 0.9778\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0654 - val_accuracy: 0.9778\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0695 - val_accuracy: 0.9770\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9780 - val_loss: 0.0649 - val_accuracy: 0.9796\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9776 - val_loss: 0.0648 - val_accuracy: 0.9770\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9768 - val_loss: 0.0638 - val_accuracy: 0.9796\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0779 - accuracy: 0.9761 - val_loss: 0.0645 - val_accuracy: 0.9770\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.0649 - val_accuracy: 0.9770\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0769 - accuracy: 0.9765 - val_loss: 0.0660 - val_accuracy: 0.9778\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.0689 - val_accuracy: 0.9770\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0653 - val_accuracy: 0.9770\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9768 - val_loss: 0.0655 - val_accuracy: 0.9778\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9776 - val_loss: 0.0673 - val_accuracy: 0.9814\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9772 - val_loss: 0.0654 - val_accuracy: 0.9787\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.0692 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.0769 - val_accuracy: 0.9823\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0756 - accuracy: 0.9787 - val_loss: 0.0631 - val_accuracy: 0.9796\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9780 - val_loss: 0.0717 - val_accuracy: 0.9814\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9761 - val_loss: 0.0633 - val_accuracy: 0.9787\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0764 - accuracy: 0.9768 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0643 - val_accuracy: 0.9787\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0766 - accuracy: 0.9776 - val_loss: 0.0652 - val_accuracy: 0.9787\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9784 - val_loss: 0.0665 - val_accuracy: 0.9778\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0775 - accuracy: 0.9776 - val_loss: 0.0635 - val_accuracy: 0.9814\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9780 - val_loss: 0.0633 - val_accuracy: 0.9805\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9784 - val_loss: 0.0633 - val_accuracy: 0.9787\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0657 - val_accuracy: 0.9770\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0779 - accuracy: 0.9761 - val_loss: 0.0660 - val_accuracy: 0.9761\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9765 - val_loss: 0.0707 - val_accuracy: 0.9778\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9776 - val_loss: 0.0669 - val_accuracy: 0.9761\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0759 - accuracy: 0.9776 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.0627 - val_accuracy: 0.9814\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9772 - val_loss: 0.0643 - val_accuracy: 0.9787\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 0.0673 - val_accuracy: 0.9770\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0778 - accuracy: 0.9765 - val_loss: 0.0686 - val_accuracy: 0.9814\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0664 - val_accuracy: 0.9770\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9772 - val_loss: 0.0699 - val_accuracy: 0.9814\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0748 - accuracy: 0.9776 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9780 - val_loss: 0.0653 - val_accuracy: 0.9814\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9772 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0768 - accuracy: 0.9768 - val_loss: 0.0669 - val_accuracy: 0.9814\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 0.0632 - val_accuracy: 0.9778\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.0713 - val_accuracy: 0.9814\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9757 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0783 - accuracy: 0.9776 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9787 - val_loss: 0.0723 - val_accuracy: 0.9814\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9776 - val_loss: 0.0642 - val_accuracy: 0.9787\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 0.0669 - val_accuracy: 0.9761\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.0665 - val_accuracy: 0.9814\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0797 - accuracy: 0.9772 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0772 - accuracy: 0.9768 - val_loss: 0.0667 - val_accuracy: 0.9770\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 0.0662 - val_accuracy: 0.9761\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0740 - accuracy: 0.9784 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0754 - accuracy: 0.9776 - val_loss: 0.0758 - val_accuracy: 0.9770\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0769 - accuracy: 0.9768 - val_loss: 0.0702 - val_accuracy: 0.9814\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0781 - accuracy: 0.9780 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9787 - val_loss: 0.0660 - val_accuracy: 0.9778\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9784 - val_loss: 0.0625 - val_accuracy: 0.9823\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0656 - val_accuracy: 0.9778\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0754 - accuracy: 0.9772 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9784 - val_loss: 0.0913 - val_accuracy: 0.9787\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9780 - val_loss: 0.0750 - val_accuracy: 0.9787\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0750 - accuracy: 0.9784 - val_loss: 0.0709 - val_accuracy: 0.9778\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9780 - val_loss: 0.0639 - val_accuracy: 0.9787\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0748 - accuracy: 0.9776 - val_loss: 0.0803 - val_accuracy: 0.9770\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0769 - accuracy: 0.9772 - val_loss: 0.0656 - val_accuracy: 0.9814\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9757 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.9768 - val_loss: 0.0636 - val_accuracy: 0.9787\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 0.0704 - val_accuracy: 0.9787\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0839 - accuracy: 0.9776 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9784 - val_loss: 0.0661 - val_accuracy: 0.9796\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0674 - val_accuracy: 0.9770\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0681 - val_accuracy: 0.9778\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9784 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9791 - val_loss: 0.0688 - val_accuracy: 0.9770\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.0664 - val_accuracy: 0.9770\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 0.9784 - val_loss: 0.0659 - val_accuracy: 0.9778\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0695 - val_accuracy: 0.9814\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9772 - val_loss: 0.0630 - val_accuracy: 0.9796\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9784 - val_loss: 0.0690 - val_accuracy: 0.9770\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0760 - accuracy: 0.9780 - val_loss: 0.0649 - val_accuracy: 0.9787\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0794 - accuracy: 0.9768 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0675 - val_accuracy: 0.9778\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0750 - accuracy: 0.9780 - val_loss: 0.0655 - val_accuracy: 0.9778\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.0647 - val_accuracy: 0.9787\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 0.0645 - val_accuracy: 0.9778\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9768 - val_loss: 0.0710 - val_accuracy: 0.9770\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0769 - accuracy: 0.9768 - val_loss: 0.0647 - val_accuracy: 0.9778\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0767 - accuracy: 0.9776 - val_loss: 0.0691 - val_accuracy: 0.9778\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0675 - val_accuracy: 0.9770\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 0.9780 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.0737 - val_accuracy: 0.9778\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0769 - accuracy: 0.9784 - val_loss: 0.0650 - val_accuracy: 0.9778\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9780 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0767 - accuracy: 0.9765 - val_loss: 0.0640 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0782 - accuracy: 0.9776 - val_loss: 0.0652 - val_accuracy: 0.9778\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0767 - accuracy: 0.9765 - val_loss: 0.0687 - val_accuracy: 0.9796\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0772 - accuracy: 0.9772 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0792 - accuracy: 0.9780 - val_loss: 0.0652 - val_accuracy: 0.9787\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9776 - val_loss: 0.0640 - val_accuracy: 0.9778\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 0.0650 - val_accuracy: 0.9778\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0750 - accuracy: 0.9780 - val_loss: 0.0650 - val_accuracy: 0.9778\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0818 - accuracy: 0.9780 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0770 - accuracy: 0.9768 - val_loss: 0.0656 - val_accuracy: 0.9796\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0759 - accuracy: 0.9784 - val_loss: 0.0631 - val_accuracy: 0.9778\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9791 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0669 - val_accuracy: 0.9814\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0753 - accuracy: 0.9791 - val_loss: 0.0655 - val_accuracy: 0.9814\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0771 - accuracy: 0.9784 - val_loss: 0.0623 - val_accuracy: 0.9823\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0701 - val_accuracy: 0.9778\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 0.0695 - val_accuracy: 0.9778\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0784 - accuracy: 0.9776 - val_loss: 0.0652 - val_accuracy: 0.9787\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9765 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9776 - val_loss: 0.0636 - val_accuracy: 0.9787\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9772 - val_loss: 0.0636 - val_accuracy: 0.9814\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 0.0648 - val_accuracy: 0.9796\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9784 - val_loss: 0.0637 - val_accuracy: 0.9778\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.0653 - val_accuracy: 0.9805\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0766 - accuracy: 0.9772 - val_loss: 0.0628 - val_accuracy: 0.9787\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0790 - accuracy: 0.9787 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0797 - accuracy: 0.9780 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 0.0635 - val_accuracy: 0.9778\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0750 - accuracy: 0.9765 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9761 - val_loss: 0.0631 - val_accuracy: 0.9814\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9780 - val_loss: 0.0641 - val_accuracy: 0.9787\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9784 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0625 - val_accuracy: 0.9823\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9772 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.0629 - val_accuracy: 0.9787\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9780 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0643 - val_accuracy: 0.9787\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9772 - val_loss: 0.0626 - val_accuracy: 0.9805\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0750 - accuracy: 0.9780 - val_loss: 0.0631 - val_accuracy: 0.9796\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.0662 - val_accuracy: 0.9814\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0746 - accuracy: 0.9776 - val_loss: 0.0673 - val_accuracy: 0.9814\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0767 - accuracy: 0.9761 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0809 - accuracy: 0.9768 - val_loss: 0.0637 - val_accuracy: 0.9778\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0777 - accuracy: 0.9772 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9776 - val_loss: 0.0640 - val_accuracy: 0.9770\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9784 - val_loss: 0.0635 - val_accuracy: 0.9778\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0755 - accuracy: 0.9761 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9772 - val_loss: 0.0664 - val_accuracy: 0.9796\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9772 - val_loss: 0.0626 - val_accuracy: 0.9787\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0654 - val_accuracy: 0.9778\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.0623 - val_accuracy: 0.9823\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.0720 - val_accuracy: 0.9796\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 0.0625 - val_accuracy: 0.9787\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9776 - val_loss: 0.0699 - val_accuracy: 0.9814\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0761 - accuracy: 0.9791 - val_loss: 0.0636 - val_accuracy: 0.9778\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9768 - val_loss: 0.0723 - val_accuracy: 0.9796\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0779 - accuracy: 0.9765 - val_loss: 0.0665 - val_accuracy: 0.9778\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.0636 - val_accuracy: 0.9787\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9784 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0636 - val_accuracy: 0.9778\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9765 - val_loss: 0.0626 - val_accuracy: 0.9805\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9784 - val_loss: 0.0671 - val_accuracy: 0.9770\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9784 - val_loss: 0.0684 - val_accuracy: 0.9814\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9768 - val_loss: 0.0663 - val_accuracy: 0.9778\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9761 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9776 - val_loss: 0.0659 - val_accuracy: 0.9814\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9768 - val_loss: 0.0635 - val_accuracy: 0.9787\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9780 - val_loss: 0.0623 - val_accuracy: 0.9787\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9787 - val_loss: 0.0708 - val_accuracy: 0.9778\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9780 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9776 - val_loss: 0.0659 - val_accuracy: 0.9814\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9780 - val_loss: 0.0623 - val_accuracy: 0.9787\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 0.0689 - val_accuracy: 0.9814\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.0635 - val_accuracy: 0.9787\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9787 - val_loss: 0.0664 - val_accuracy: 0.9778\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9768 - val_loss: 0.0652 - val_accuracy: 0.9814\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9765 - val_loss: 0.0688 - val_accuracy: 0.9814\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.0654 - val_accuracy: 0.9796\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9780 - val_loss: 0.0667 - val_accuracy: 0.9796\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9780 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.0632 - val_accuracy: 0.9778\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 0.0670 - val_accuracy: 0.9761\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9768 - val_loss: 0.0641 - val_accuracy: 0.9770\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 0.0690 - val_accuracy: 0.9787\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 0.0621 - val_accuracy: 0.9823\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9780 - val_loss: 0.0696 - val_accuracy: 0.9823\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0627 - val_accuracy: 0.9787\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0756 - accuracy: 0.9768 - val_loss: 0.0686 - val_accuracy: 0.9778\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0768 - accuracy: 0.9772 - val_loss: 0.0646 - val_accuracy: 0.9778\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0783 - accuracy: 0.9776 - val_loss: 0.0623 - val_accuracy: 0.9787\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0628 - val_accuracy: 0.9778\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9780 - val_loss: 0.0645 - val_accuracy: 0.9787\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9787 - val_loss: 0.0643 - val_accuracy: 0.9778\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 0.0621 - val_accuracy: 0.9823\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0820 - accuracy: 0.9772 - val_loss: 0.0644 - val_accuracy: 0.9778\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9787 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9784 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0766 - accuracy: 0.9757 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0630 - val_accuracy: 0.9787\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9765 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9780 - val_loss: 0.0643 - val_accuracy: 0.9787\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0741 - accuracy: 0.9776 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.0632 - val_accuracy: 0.9787\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0750 - accuracy: 0.9776 - val_loss: 0.0704 - val_accuracy: 0.9778\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.0642 - val_accuracy: 0.9778\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9768 - val_loss: 0.0634 - val_accuracy: 0.9787\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.0632 - val_accuracy: 0.9778\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0783 - accuracy: 0.9780 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9780 - val_loss: 0.0626 - val_accuracy: 0.9787\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.0626 - val_accuracy: 0.9787\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9765 - val_loss: 0.0655 - val_accuracy: 0.9778\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0659 - val_accuracy: 0.9778\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0627 - val_accuracy: 0.9778\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.0648 - val_accuracy: 0.9814\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9776 - val_loss: 0.0641 - val_accuracy: 0.9787\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9772 - val_loss: 0.0645 - val_accuracy: 0.9796\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.0764 - accuracy: 0.9765 - val_loss: 0.0626 - val_accuracy: 0.9787\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.0636 - val_accuracy: 0.9796\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0619 - val_accuracy: 0.9823\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0623 - val_accuracy: 0.9787\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9772 - val_loss: 0.0624 - val_accuracy: 0.9787\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.0665 - val_accuracy: 0.9778\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9761 - val_loss: 0.0744 - val_accuracy: 0.9823\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9772 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9791 - val_loss: 0.0628 - val_accuracy: 0.9787\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 0.0619 - val_accuracy: 0.9823\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0745 - accuracy: 0.9772 - val_loss: 0.0655 - val_accuracy: 0.9787\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9772 - val_loss: 0.0639 - val_accuracy: 0.9787\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.9]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841269841269841\n",
      "0.9703459637561779\n",
      "0.9771878888428038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.2]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978494623655914\n",
      "0.9701492537313433\n",
      "0.9743040685224841\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
