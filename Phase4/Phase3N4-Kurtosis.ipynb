{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  7.3  427.9 ...  3.2  1.0  0.0]\n",
      " [ 0.0  5.4  255.3 ...  2.5  1.0  0.0]\n",
      " [ 0.0  1.5  85.6 ...  5.8  0.9  0.0]\n",
      " ...\n",
      " [ 1.0  4.7  614.5 ...  9.5  0.9  0.0]\n",
      " [ 0.0  8.6  413.7 ...  3.1  1.0  0.0]\n",
      " [ 1.0  13.1  1649.2 ...  5.1  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 6]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 6]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape = (1,), activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfd75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 3s 11ms/step - loss: 2.8418 - accuracy: 0.4529 - val_loss: 2.5952 - val_accuracy: 0.4344\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8009 - accuracy: 0.4529 - val_loss: 1.5794 - val_accuracy: 0.4344\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0583 - accuracy: 0.4529 - val_loss: 0.8822 - val_accuracy: 0.4344\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.5433 - val_loss: 0.6431 - val_accuracy: 0.6933\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.6986 - val_loss: 0.6297 - val_accuracy: 0.7358\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.7304 - val_loss: 0.6331 - val_accuracy: 0.7092\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7289 - val_loss: 0.6324 - val_accuracy: 0.7137\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.7308 - val_loss: 0.6260 - val_accuracy: 0.7270\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.7373 - val_loss: 0.6177 - val_accuracy: 0.7518\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7396 - val_loss: 0.6141 - val_accuracy: 0.7527\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7403 - val_loss: 0.6141 - val_accuracy: 0.7500\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5872 - accuracy: 0.7388 - val_loss: 0.6100 - val_accuracy: 0.7473\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.7392 - val_loss: 0.6157 - val_accuracy: 0.7518\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5811 - accuracy: 0.7403 - val_loss: 0.6167 - val_accuracy: 0.7518\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7415 - val_loss: 0.6085 - val_accuracy: 0.7465\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.7418 - val_loss: 0.6067 - val_accuracy: 0.7465\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7407 - val_loss: 0.6076 - val_accuracy: 0.7473\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5755 - accuracy: 0.7373 - val_loss: 0.6070 - val_accuracy: 0.7465\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7388 - val_loss: 0.6126 - val_accuracy: 0.7491\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7411 - val_loss: 0.6091 - val_accuracy: 0.7473\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.7415 - val_loss: 0.6125 - val_accuracy: 0.7473\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7422 - val_loss: 0.6074 - val_accuracy: 0.7482\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5713 - accuracy: 0.7377 - val_loss: 0.6093 - val_accuracy: 0.7482\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7407 - val_loss: 0.6096 - val_accuracy: 0.7473\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.7426 - val_loss: 0.6065 - val_accuracy: 0.7429\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7365 - val_loss: 0.6086 - val_accuracy: 0.7473\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7365 - val_loss: 0.6108 - val_accuracy: 0.7473\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7361 - val_loss: 0.6125 - val_accuracy: 0.7482\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7388 - val_loss: 0.6108 - val_accuracy: 0.7482\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.7411 - val_loss: 0.6093 - val_accuracy: 0.7429\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.7377 - val_loss: 0.6118 - val_accuracy: 0.7473\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5695 - accuracy: 0.7411 - val_loss: 0.6122 - val_accuracy: 0.7473\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5671 - accuracy: 0.7350 - val_loss: 0.6208 - val_accuracy: 0.7482\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6090 - val_accuracy: 0.7385\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.7377 - val_loss: 0.6145 - val_accuracy: 0.7473\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7392 - val_loss: 0.6086 - val_accuracy: 0.7394\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7354 - val_loss: 0.6114 - val_accuracy: 0.7429\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6124 - val_accuracy: 0.7420\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7358 - val_loss: 0.6111 - val_accuracy: 0.7411\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7377 - val_loss: 0.6142 - val_accuracy: 0.7473\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5691 - accuracy: 0.7380 - val_loss: 0.6143 - val_accuracy: 0.7465\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5689 - accuracy: 0.7369 - val_loss: 0.6164 - val_accuracy: 0.7482\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7407 - val_loss: 0.6085 - val_accuracy: 0.7402\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.7339 - val_loss: 0.6235 - val_accuracy: 0.7465\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7415 - val_loss: 0.6163 - val_accuracy: 0.7500\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7373 - val_loss: 0.6125 - val_accuracy: 0.7411\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.7407 - val_loss: 0.6128 - val_accuracy: 0.7411\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7358 - val_loss: 0.6147 - val_accuracy: 0.7420\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7411 - val_loss: 0.6158 - val_accuracy: 0.7456\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7373 - val_loss: 0.6239 - val_accuracy: 0.7473\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7418 - val_loss: 0.6165 - val_accuracy: 0.7473\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5683 - accuracy: 0.7377 - val_loss: 0.6146 - val_accuracy: 0.7420\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5694 - accuracy: 0.7380 - val_loss: 0.6164 - val_accuracy: 0.7456\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5699 - accuracy: 0.7396 - val_loss: 0.6116 - val_accuracy: 0.7402\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7380 - val_loss: 0.6134 - val_accuracy: 0.7385\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7373 - val_loss: 0.6141 - val_accuracy: 0.7411\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7396 - val_loss: 0.6153 - val_accuracy: 0.7411\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7361 - val_loss: 0.6189 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6174 - val_accuracy: 0.7456\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7411 - val_loss: 0.6196 - val_accuracy: 0.7482\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7342 - val_loss: 0.6182 - val_accuracy: 0.7465\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7403 - val_loss: 0.6198 - val_accuracy: 0.7482\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.6165 - val_accuracy: 0.7429\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7361 - val_loss: 0.6174 - val_accuracy: 0.7420\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7411 - val_loss: 0.6159 - val_accuracy: 0.7402\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7384 - val_loss: 0.6234 - val_accuracy: 0.7473\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7384 - val_loss: 0.6192 - val_accuracy: 0.7473\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5697 - accuracy: 0.7377 - val_loss: 0.6200 - val_accuracy: 0.7491\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6173 - val_accuracy: 0.7420\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5700 - accuracy: 0.7392 - val_loss: 0.6207 - val_accuracy: 0.7473\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.7377 - val_loss: 0.6201 - val_accuracy: 0.7473\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6187 - val_accuracy: 0.7473\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7377 - val_loss: 0.6198 - val_accuracy: 0.7482\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7384 - val_loss: 0.6204 - val_accuracy: 0.7473\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7403 - val_loss: 0.6148 - val_accuracy: 0.7394\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7399 - val_loss: 0.6147 - val_accuracy: 0.7402\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7388 - val_loss: 0.6191 - val_accuracy: 0.7500\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7346 - val_loss: 0.6182 - val_accuracy: 0.7465\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7388 - val_loss: 0.6211 - val_accuracy: 0.7482\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7399 - val_loss: 0.6164 - val_accuracy: 0.7420\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5701 - accuracy: 0.7396 - val_loss: 0.6221 - val_accuracy: 0.7465\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6193 - val_accuracy: 0.7482\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5699 - accuracy: 0.7396 - val_loss: 0.6171 - val_accuracy: 0.7438\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6151 - val_accuracy: 0.7420\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7377 - val_loss: 0.6144 - val_accuracy: 0.7402\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5686 - accuracy: 0.7403 - val_loss: 0.6159 - val_accuracy: 0.7429\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5695 - accuracy: 0.7380 - val_loss: 0.6163 - val_accuracy: 0.7420\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7396 - val_loss: 0.6172 - val_accuracy: 0.7420\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.7392 - val_loss: 0.6179 - val_accuracy: 0.7465\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7358 - val_loss: 0.6170 - val_accuracy: 0.7420\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6147 - val_accuracy: 0.7394\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7369 - val_loss: 0.6185 - val_accuracy: 0.7473\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7415 - val_loss: 0.6171 - val_accuracy: 0.7420\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5689 - accuracy: 0.7358 - val_loss: 0.6243 - val_accuracy: 0.7473\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5700 - accuracy: 0.7422 - val_loss: 0.6200 - val_accuracy: 0.7482\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7377 - val_loss: 0.6181 - val_accuracy: 0.7456\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7430 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7354 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7350 - val_loss: 0.6187 - val_accuracy: 0.7473\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7380 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5684 - accuracy: 0.7396 - val_loss: 0.6254 - val_accuracy: 0.7456\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7415 - val_loss: 0.6164 - val_accuracy: 0.7429\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7403 - val_loss: 0.6187 - val_accuracy: 0.7473\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7373 - val_loss: 0.6186 - val_accuracy: 0.7473\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5699 - accuracy: 0.7399 - val_loss: 0.6169 - val_accuracy: 0.7420\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6152 - val_accuracy: 0.7411\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7377 - val_loss: 0.6151 - val_accuracy: 0.7411\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7399 - val_loss: 0.6133 - val_accuracy: 0.7402\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.7354 - val_loss: 0.6188 - val_accuracy: 0.7500\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6147 - val_accuracy: 0.7411\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5689 - accuracy: 0.7403 - val_loss: 0.6131 - val_accuracy: 0.7402\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6198 - val_accuracy: 0.7473\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6217 - val_accuracy: 0.7491\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6175 - val_accuracy: 0.7438\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6173 - val_accuracy: 0.7420\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7403 - val_loss: 0.6167 - val_accuracy: 0.7429\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5694 - accuracy: 0.7373 - val_loss: 0.6141 - val_accuracy: 0.7411\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7384 - val_loss: 0.6197 - val_accuracy: 0.7482\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7396 - val_loss: 0.6260 - val_accuracy: 0.7465\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5707 - accuracy: 0.7399 - val_loss: 0.6187 - val_accuracy: 0.7473\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5686 - accuracy: 0.7388 - val_loss: 0.6132 - val_accuracy: 0.7402\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5687 - accuracy: 0.7380 - val_loss: 0.6178 - val_accuracy: 0.7438\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7403 - val_loss: 0.6183 - val_accuracy: 0.7465\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7388 - val_loss: 0.6223 - val_accuracy: 0.7482\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7430 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5688 - accuracy: 0.7373 - val_loss: 0.6265 - val_accuracy: 0.7465\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7396 - val_loss: 0.6203 - val_accuracy: 0.7482\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6132 - val_accuracy: 0.7402\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7369 - val_loss: 0.6189 - val_accuracy: 0.7473\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6185 - val_accuracy: 0.7473\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7384 - val_loss: 0.6162 - val_accuracy: 0.7429\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7388 - val_loss: 0.6210 - val_accuracy: 0.7473\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5699 - accuracy: 0.7399 - val_loss: 0.6161 - val_accuracy: 0.7420\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5702 - accuracy: 0.7415 - val_loss: 0.6176 - val_accuracy: 0.7420\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6160 - val_accuracy: 0.7420\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.7377 - val_loss: 0.6151 - val_accuracy: 0.7402\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5688 - accuracy: 0.7369 - val_loss: 0.6164 - val_accuracy: 0.7429\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7373 - val_loss: 0.6177 - val_accuracy: 0.7456\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7415 - val_loss: 0.6163 - val_accuracy: 0.7420\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6189 - val_accuracy: 0.7482\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5683 - accuracy: 0.7411 - val_loss: 0.6227 - val_accuracy: 0.7465\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5702 - accuracy: 0.7399 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7369 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7384 - val_loss: 0.6163 - val_accuracy: 0.7420\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.7392 - val_loss: 0.6244 - val_accuracy: 0.7465\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7407 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7396 - val_loss: 0.6194 - val_accuracy: 0.7473\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7411 - val_loss: 0.6160 - val_accuracy: 0.7411\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5687 - accuracy: 0.7361 - val_loss: 0.6208 - val_accuracy: 0.7482\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6226 - val_accuracy: 0.7491\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7392 - val_loss: 0.6164 - val_accuracy: 0.7402\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7380 - val_loss: 0.6169 - val_accuracy: 0.7429\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7380 - val_loss: 0.6209 - val_accuracy: 0.7473\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7407 - val_loss: 0.6188 - val_accuracy: 0.7465\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7380 - val_loss: 0.6165 - val_accuracy: 0.7420\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7384 - val_loss: 0.6189 - val_accuracy: 0.7465\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5697 - accuracy: 0.7403 - val_loss: 0.6169 - val_accuracy: 0.7429\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6146 - val_accuracy: 0.7385\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5683 - accuracy: 0.7373 - val_loss: 0.6219 - val_accuracy: 0.7482\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.7403 - val_loss: 0.6150 - val_accuracy: 0.7394\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7358 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7373 - val_loss: 0.6205 - val_accuracy: 0.7473\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7399 - val_loss: 0.6158 - val_accuracy: 0.7411\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6137 - val_accuracy: 0.7402\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6161 - val_accuracy: 0.7402\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7396 - val_loss: 0.6169 - val_accuracy: 0.7420\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6162 - val_accuracy: 0.7429\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6170 - val_accuracy: 0.7420\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5687 - accuracy: 0.7396 - val_loss: 0.6199 - val_accuracy: 0.7473\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6180 - val_accuracy: 0.7473\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7392 - val_loss: 0.6168 - val_accuracy: 0.7420\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6180 - val_accuracy: 0.7473\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6161 - val_accuracy: 0.7429\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7407 - val_loss: 0.6164 - val_accuracy: 0.7429\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5687 - accuracy: 0.7388 - val_loss: 0.6228 - val_accuracy: 0.7465\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7403 - val_loss: 0.6188 - val_accuracy: 0.7473\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7396 - val_loss: 0.6161 - val_accuracy: 0.7429\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7399 - val_loss: 0.6161 - val_accuracy: 0.7429\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5687 - accuracy: 0.7377 - val_loss: 0.6230 - val_accuracy: 0.7473\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7384 - val_loss: 0.6236 - val_accuracy: 0.7473\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7392 - val_loss: 0.6171 - val_accuracy: 0.7420\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5701 - accuracy: 0.7403 - val_loss: 0.6171 - val_accuracy: 0.7429\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.7365 - val_loss: 0.6190 - val_accuracy: 0.7465\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.6190 - val_accuracy: 0.7465\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7388 - val_loss: 0.6181 - val_accuracy: 0.7420\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6210 - val_accuracy: 0.7473\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7396 - val_loss: 0.6191 - val_accuracy: 0.7473\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7392 - val_loss: 0.6192 - val_accuracy: 0.7473\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6166 - val_accuracy: 0.7420\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.7388 - val_loss: 0.6148 - val_accuracy: 0.7394\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5699 - accuracy: 0.7415 - val_loss: 0.6153 - val_accuracy: 0.7411\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6143 - val_accuracy: 0.7402\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5699 - accuracy: 0.7396 - val_loss: 0.6186 - val_accuracy: 0.7465\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7384 - val_loss: 0.6212 - val_accuracy: 0.7473\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7407 - val_loss: 0.6211 - val_accuracy: 0.7473\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7384 - val_loss: 0.6195 - val_accuracy: 0.7473\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7399 - val_loss: 0.6278 - val_accuracy: 0.7473\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5707 - accuracy: 0.7403 - val_loss: 0.6216 - val_accuracy: 0.7482\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7411 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7392 - val_loss: 0.6154 - val_accuracy: 0.7394\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7369 - val_loss: 0.6169 - val_accuracy: 0.7411\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.7377 - val_loss: 0.6181 - val_accuracy: 0.7420\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6182 - val_accuracy: 0.7420\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7377 - val_loss: 0.6166 - val_accuracy: 0.7411\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6159 - val_accuracy: 0.7420\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6152 - val_accuracy: 0.7394\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7365 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7365 - val_loss: 0.6217 - val_accuracy: 0.7482\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7388 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7407 - val_loss: 0.6195 - val_accuracy: 0.7482\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6196 - val_accuracy: 0.7491\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6204 - val_accuracy: 0.7473\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7388 - val_loss: 0.6192 - val_accuracy: 0.7465\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7384 - val_loss: 0.6172 - val_accuracy: 0.7429\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7380 - val_loss: 0.6195 - val_accuracy: 0.7473\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7384 - val_loss: 0.6168 - val_accuracy: 0.7420\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7377 - val_loss: 0.6173 - val_accuracy: 0.7420\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6167 - val_accuracy: 0.7429\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7392 - val_loss: 0.6232 - val_accuracy: 0.7465\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7399 - val_loss: 0.6240 - val_accuracy: 0.7482\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7407 - val_loss: 0.6160 - val_accuracy: 0.7420\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5707 - accuracy: 0.7396 - val_loss: 0.6191 - val_accuracy: 0.7465\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.7350 - val_loss: 0.6186 - val_accuracy: 0.7456\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7358 - val_loss: 0.6192 - val_accuracy: 0.7473\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5704 - accuracy: 0.7388 - val_loss: 0.6194 - val_accuracy: 0.7473\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7373 - val_loss: 0.6161 - val_accuracy: 0.7420\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.7358 - val_loss: 0.6200 - val_accuracy: 0.7500\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7384 - val_loss: 0.6212 - val_accuracy: 0.7473\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7377 - val_loss: 0.6200 - val_accuracy: 0.7500\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6157 - val_accuracy: 0.7411\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5714 - accuracy: 0.7396 - val_loss: 0.6230 - val_accuracy: 0.7482\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7388 - val_loss: 0.6192 - val_accuracy: 0.7456\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7407 - val_loss: 0.6200 - val_accuracy: 0.7473\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7396 - val_loss: 0.6210 - val_accuracy: 0.7482\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7407 - val_loss: 0.6168 - val_accuracy: 0.7411\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5704 - accuracy: 0.7399 - val_loss: 0.6204 - val_accuracy: 0.7482\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7392 - val_loss: 0.6171 - val_accuracy: 0.7402\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7384 - val_loss: 0.6203 - val_accuracy: 0.7465\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5701 - accuracy: 0.7407 - val_loss: 0.6220 - val_accuracy: 0.7473\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7403 - val_loss: 0.6194 - val_accuracy: 0.7465\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7388 - val_loss: 0.6197 - val_accuracy: 0.7465\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5702 - accuracy: 0.7396 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6188 - val_accuracy: 0.7420\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6188 - val_accuracy: 0.7438\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6175 - val_accuracy: 0.7429\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7396 - val_loss: 0.6170 - val_accuracy: 0.7402\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7369 - val_loss: 0.6190 - val_accuracy: 0.7465\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.7392 - val_loss: 0.6168 - val_accuracy: 0.7420\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7388 - val_loss: 0.6238 - val_accuracy: 0.7465\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5697 - accuracy: 0.7399 - val_loss: 0.6175 - val_accuracy: 0.7429\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5693 - accuracy: 0.7377 - val_loss: 0.6154 - val_accuracy: 0.7402\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7380 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7358 - val_loss: 0.6197 - val_accuracy: 0.7482\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7392 - val_loss: 0.6186 - val_accuracy: 0.7456\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6186 - val_accuracy: 0.7456\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5705 - accuracy: 0.7380 - val_loss: 0.6202 - val_accuracy: 0.7482\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7377 - val_loss: 0.6224 - val_accuracy: 0.7491\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5701 - accuracy: 0.7399 - val_loss: 0.6186 - val_accuracy: 0.7420\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5690 - accuracy: 0.7373 - val_loss: 0.6198 - val_accuracy: 0.7473\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6208 - val_accuracy: 0.7482\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7403 - val_loss: 0.6169 - val_accuracy: 0.7411\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7392 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5702 - accuracy: 0.7411 - val_loss: 0.6199 - val_accuracy: 0.7473\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6166 - val_accuracy: 0.7402\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7373 - val_loss: 0.6165 - val_accuracy: 0.7402\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6193 - val_accuracy: 0.7473\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6179 - val_accuracy: 0.7420\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5686 - accuracy: 0.7407 - val_loss: 0.6136 - val_accuracy: 0.7402\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5690 - accuracy: 0.7358 - val_loss: 0.6168 - val_accuracy: 0.7429\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5695 - accuracy: 0.7407 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7380 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5695 - accuracy: 0.7411 - val_loss: 0.6174 - val_accuracy: 0.7420\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6169 - val_accuracy: 0.7429\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5705 - accuracy: 0.7403 - val_loss: 0.6151 - val_accuracy: 0.7411\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5689 - accuracy: 0.7377 - val_loss: 0.6148 - val_accuracy: 0.7402\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5697 - accuracy: 0.7407 - val_loss: 0.6180 - val_accuracy: 0.7420\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.5697 - accuracy: 0.7396 - val_loss: 0.6182 - val_accuracy: 0.7420\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6170 - val_accuracy: 0.7420\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5693 - accuracy: 0.7369 - val_loss: 0.6158 - val_accuracy: 0.7411\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.7377 - val_loss: 0.6162 - val_accuracy: 0.7411\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7377 - val_loss: 0.6180 - val_accuracy: 0.7420\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7392 - val_loss: 0.6179 - val_accuracy: 0.7420\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6192 - val_accuracy: 0.7465\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5702 - accuracy: 0.7403 - val_loss: 0.6188 - val_accuracy: 0.7456\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.5691 - accuracy: 0.7396 - val_loss: 0.6163 - val_accuracy: 0.7420\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.5696 - accuracy: 0.7399 - val_loss: 0.6172 - val_accuracy: 0.7429\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7392 - val_loss: 0.6184 - val_accuracy: 0.7438\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6166 - val_accuracy: 0.7402\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7399 - val_loss: 0.6196 - val_accuracy: 0.7473\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7365 - val_loss: 0.6203 - val_accuracy: 0.7500\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6165 - val_accuracy: 0.7420\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6172 - val_accuracy: 0.7420\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6207 - val_accuracy: 0.7473\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.7418 - val_loss: 0.6186 - val_accuracy: 0.7465\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5698 - accuracy: 0.7392 - val_loss: 0.6186 - val_accuracy: 0.7465\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5702 - accuracy: 0.7399 - val_loss: 0.6171 - val_accuracy: 0.7429\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7369 - val_loss: 0.6175 - val_accuracy: 0.7420\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6183 - val_accuracy: 0.7456\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7407 - val_loss: 0.6183 - val_accuracy: 0.7420\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7377 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7399 - val_loss: 0.6242 - val_accuracy: 0.7473\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7380 - val_loss: 0.6199 - val_accuracy: 0.7482\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.7403 - val_loss: 0.6205 - val_accuracy: 0.7491\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.7418 - val_loss: 0.6192 - val_accuracy: 0.7465\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6215 - val_accuracy: 0.7473\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7392 - val_loss: 0.6167 - val_accuracy: 0.7420\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7377 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7380 - val_loss: 0.6180 - val_accuracy: 0.7456\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7415 - val_loss: 0.6156 - val_accuracy: 0.7411\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6174 - val_accuracy: 0.7420\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7403 - val_loss: 0.6179 - val_accuracy: 0.7447\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7396 - val_loss: 0.6152 - val_accuracy: 0.7411\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6169 - val_accuracy: 0.7420\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5697 - accuracy: 0.7411 - val_loss: 0.6158 - val_accuracy: 0.7420\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7373 - val_loss: 0.6167 - val_accuracy: 0.7429\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5685 - accuracy: 0.7377 - val_loss: 0.6217 - val_accuracy: 0.7482\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7388 - val_loss: 0.6183 - val_accuracy: 0.7456\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6176 - val_accuracy: 0.7420\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5691 - accuracy: 0.7384 - val_loss: 0.6203 - val_accuracy: 0.7482\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5705 - accuracy: 0.7430 - val_loss: 0.6223 - val_accuracy: 0.7482\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5698 - accuracy: 0.7403 - val_loss: 0.6154 - val_accuracy: 0.7394\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7384 - val_loss: 0.6182 - val_accuracy: 0.7438\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5693 - accuracy: 0.7377 - val_loss: 0.6208 - val_accuracy: 0.7482\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7411 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7388 - val_loss: 0.6207 - val_accuracy: 0.7473\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7373 - val_loss: 0.6150 - val_accuracy: 0.7394\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7377 - val_loss: 0.6152 - val_accuracy: 0.7411\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5686 - accuracy: 0.7365 - val_loss: 0.6185 - val_accuracy: 0.7465\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5692 - accuracy: 0.7399 - val_loss: 0.6234 - val_accuracy: 0.7482\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5704 - accuracy: 0.7411 - val_loss: 0.6206 - val_accuracy: 0.7473\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6202 - val_accuracy: 0.7482\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5689 - accuracy: 0.7392 - val_loss: 0.6237 - val_accuracy: 0.7482\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5705 - accuracy: 0.7411 - val_loss: 0.6216 - val_accuracy: 0.7473\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7392 - val_loss: 0.6180 - val_accuracy: 0.7429\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7388 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6220 - val_accuracy: 0.7482\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5710 - accuracy: 0.7388 - val_loss: 0.6217 - val_accuracy: 0.7473\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7399 - val_loss: 0.6189 - val_accuracy: 0.7456\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7396 - val_loss: 0.6182 - val_accuracy: 0.7420\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6179 - val_accuracy: 0.7420\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6187 - val_accuracy: 0.7456\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7396 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7380 - val_loss: 0.6152 - val_accuracy: 0.7411\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7407 - val_loss: 0.6173 - val_accuracy: 0.7420\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5689 - accuracy: 0.7369 - val_loss: 0.6212 - val_accuracy: 0.7473\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7403 - val_loss: 0.6193 - val_accuracy: 0.7482\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6175 - val_accuracy: 0.7420\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7384 - val_loss: 0.6200 - val_accuracy: 0.7491\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7411 - val_loss: 0.6179 - val_accuracy: 0.7420\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6190 - val_accuracy: 0.7465\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7403 - val_loss: 0.6140 - val_accuracy: 0.7402\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6161 - val_accuracy: 0.7402\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6191 - val_accuracy: 0.7473\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7403 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5698 - accuracy: 0.7418 - val_loss: 0.6203 - val_accuracy: 0.7491\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7392 - val_loss: 0.6159 - val_accuracy: 0.7411\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7384 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7380 - val_loss: 0.6176 - val_accuracy: 0.7420\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7380 - val_loss: 0.6191 - val_accuracy: 0.7473\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7373 - val_loss: 0.6180 - val_accuracy: 0.7420\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7388 - val_loss: 0.6183 - val_accuracy: 0.7438\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6168 - val_accuracy: 0.7429\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7373 - val_loss: 0.6183 - val_accuracy: 0.7456\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6185 - val_accuracy: 0.7465\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6153 - val_accuracy: 0.7411\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7396 - val_loss: 0.6141 - val_accuracy: 0.7411\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7388 - val_loss: 0.6169 - val_accuracy: 0.7420\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7399 - val_loss: 0.6145 - val_accuracy: 0.7394\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5689 - accuracy: 0.7388 - val_loss: 0.6207 - val_accuracy: 0.7473\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7373 - val_loss: 0.6185 - val_accuracy: 0.7465\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5686 - accuracy: 0.7403 - val_loss: 0.6168 - val_accuracy: 0.7420\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7377 - val_loss: 0.6198 - val_accuracy: 0.7473\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7399 - val_loss: 0.6209 - val_accuracy: 0.7473\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7373 - val_loss: 0.6196 - val_accuracy: 0.7500\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7415 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7384 - val_loss: 0.6145 - val_accuracy: 0.7385\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7361 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7384 - val_loss: 0.6181 - val_accuracy: 0.7465\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6195 - val_accuracy: 0.7500\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6194 - val_accuracy: 0.7500\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6183 - val_accuracy: 0.7465\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5701 - accuracy: 0.7407 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5700 - accuracy: 0.7392 - val_loss: 0.6179 - val_accuracy: 0.7420\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7396 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5687 - accuracy: 0.7380 - val_loss: 0.6215 - val_accuracy: 0.7473\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7411 - val_loss: 0.6164 - val_accuracy: 0.7411\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7396 - val_loss: 0.6183 - val_accuracy: 0.7456\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7441 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7415 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7418 - val_loss: 0.6177 - val_accuracy: 0.7420\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7377 - val_loss: 0.6189 - val_accuracy: 0.7465\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7365 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7411 - val_loss: 0.6203 - val_accuracy: 0.7491\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7411 - val_loss: 0.6184 - val_accuracy: 0.7456\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.7377 - val_loss: 0.6169 - val_accuracy: 0.7429\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6156 - val_accuracy: 0.7411\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7377 - val_loss: 0.6155 - val_accuracy: 0.7411\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7392 - val_loss: 0.6182 - val_accuracy: 0.7429\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7365 - val_loss: 0.6225 - val_accuracy: 0.7491\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7369 - val_loss: 0.6206 - val_accuracy: 0.7482\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7407 - val_loss: 0.6167 - val_accuracy: 0.7429\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5688 - accuracy: 0.7369 - val_loss: 0.6214 - val_accuracy: 0.7473\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7399 - val_loss: 0.6208 - val_accuracy: 0.7473\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5699 - accuracy: 0.7396 - val_loss: 0.6184 - val_accuracy: 0.7456\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7380 - val_loss: 0.6188 - val_accuracy: 0.7473\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7399 - val_loss: 0.6181 - val_accuracy: 0.7456\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6192 - val_accuracy: 0.7473\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6168 - val_accuracy: 0.7429\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7369 - val_loss: 0.6164 - val_accuracy: 0.7429\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7392 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.6169 - val_accuracy: 0.7429\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7384 - val_loss: 0.6184 - val_accuracy: 0.7465\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7399 - val_loss: 0.6181 - val_accuracy: 0.7429\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7384 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7380 - val_loss: 0.6164 - val_accuracy: 0.7411\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7377 - val_loss: 0.6207 - val_accuracy: 0.7482\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5699 - accuracy: 0.7407 - val_loss: 0.6184 - val_accuracy: 0.7456\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5699 - accuracy: 0.7388 - val_loss: 0.6196 - val_accuracy: 0.7473\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5701 - accuracy: 0.7399 - val_loss: 0.6196 - val_accuracy: 0.7473\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6186 - val_accuracy: 0.7456\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7396 - val_loss: 0.6172 - val_accuracy: 0.7429\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6203 - val_accuracy: 0.7491\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.6212 - val_accuracy: 0.7473\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7392 - val_loss: 0.6181 - val_accuracy: 0.7429\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6146 - val_accuracy: 0.7411\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.7392 - val_loss: 0.6156 - val_accuracy: 0.7411\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5688 - accuracy: 0.7358 - val_loss: 0.6208 - val_accuracy: 0.7473\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.7369 - val_loss: 0.6163 - val_accuracy: 0.7420\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6171 - val_accuracy: 0.7429\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.7377 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5689 - accuracy: 0.7380 - val_loss: 0.6168 - val_accuracy: 0.7420\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7358 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6190 - val_accuracy: 0.7473\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.7418 - val_loss: 0.6163 - val_accuracy: 0.7411\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7392 - val_loss: 0.6159 - val_accuracy: 0.7411\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5685 - accuracy: 0.7388 - val_loss: 0.6199 - val_accuracy: 0.7473\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5707 - accuracy: 0.7384 - val_loss: 0.6191 - val_accuracy: 0.7473\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5695 - accuracy: 0.7392 - val_loss: 0.6176 - val_accuracy: 0.7420\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5695 - accuracy: 0.7388 - val_loss: 0.6171 - val_accuracy: 0.7420\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6159 - val_accuracy: 0.7402\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5689 - accuracy: 0.7384 - val_loss: 0.6144 - val_accuracy: 0.7385\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7384 - val_loss: 0.6156 - val_accuracy: 0.7402\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7399 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5683 - accuracy: 0.7399 - val_loss: 0.6206 - val_accuracy: 0.7473\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7411 - val_loss: 0.6168 - val_accuracy: 0.7429\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7392 - val_loss: 0.6187 - val_accuracy: 0.7465\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6185 - val_accuracy: 0.7465\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5693 - accuracy: 0.7373 - val_loss: 0.6209 - val_accuracy: 0.7473\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5704 - accuracy: 0.7415 - val_loss: 0.6216 - val_accuracy: 0.7473\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5699 - accuracy: 0.7403 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7403 - val_loss: 0.6181 - val_accuracy: 0.7420\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5701 - accuracy: 0.7399 - val_loss: 0.6183 - val_accuracy: 0.7420\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7399 - val_loss: 0.6197 - val_accuracy: 0.7465\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7384 - val_loss: 0.6243 - val_accuracy: 0.7465\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7426 - val_loss: 0.6192 - val_accuracy: 0.7456\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7426 - val_loss: 0.6162 - val_accuracy: 0.7402\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.7384 - val_loss: 0.6188 - val_accuracy: 0.7420\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5695 - accuracy: 0.7384 - val_loss: 0.6175 - val_accuracy: 0.7429\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7365 - val_loss: 0.6161 - val_accuracy: 0.7411\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7407 - val_loss: 0.6161 - val_accuracy: 0.7411\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7369 - val_loss: 0.6172 - val_accuracy: 0.7420\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6159 - val_accuracy: 0.7411\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7380 - val_loss: 0.6182 - val_accuracy: 0.7438\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5694 - accuracy: 0.7380 - val_loss: 0.6206 - val_accuracy: 0.7473\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.7377 - val_loss: 0.6213 - val_accuracy: 0.7473\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5683 - accuracy: 0.7422 - val_loss: 0.6133 - val_accuracy: 0.7394\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7369 - val_loss: 0.6149 - val_accuracy: 0.7394\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7380 - val_loss: 0.6141 - val_accuracy: 0.7411\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7380 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5691 - accuracy: 0.7369 - val_loss: 0.6154 - val_accuracy: 0.7411\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5681 - accuracy: 0.7377 - val_loss: 0.6218 - val_accuracy: 0.7482\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6173 - val_accuracy: 0.7420\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6193 - val_accuracy: 0.7500\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5692 - accuracy: 0.7377 - val_loss: 0.6223 - val_accuracy: 0.7473\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5697 - accuracy: 0.7369 - val_loss: 0.6216 - val_accuracy: 0.7482\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.5699 - accuracy: 0.7403 - val_loss: 0.6186 - val_accuracy: 0.7465\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5692 - accuracy: 0.7384 - val_loss: 0.6170 - val_accuracy: 0.7420\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7392 - val_loss: 0.6170 - val_accuracy: 0.7429\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7396 - val_loss: 0.6152 - val_accuracy: 0.7411\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.7407 - val_loss: 0.6205 - val_accuracy: 0.7482\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7380 - val_loss: 0.6174 - val_accuracy: 0.7420\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5689 - accuracy: 0.7388 - val_loss: 0.6146 - val_accuracy: 0.7394\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7380 - val_loss: 0.6165 - val_accuracy: 0.7429\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7392 - val_loss: 0.6170 - val_accuracy: 0.7420\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.7380 - val_loss: 0.6174 - val_accuracy: 0.7429\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7388 - val_loss: 0.6160 - val_accuracy: 0.7420\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7388 - val_loss: 0.6166 - val_accuracy: 0.7429\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7388 - val_loss: 0.6151 - val_accuracy: 0.7394\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.7396 - val_loss: 0.6153 - val_accuracy: 0.7411\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5695 - accuracy: 0.7373 - val_loss: 0.6206 - val_accuracy: 0.7473\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7407 - val_loss: 0.6184 - val_accuracy: 0.7465\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5691 - accuracy: 0.7380 - val_loss: 0.6161 - val_accuracy: 0.7411\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N5check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d07c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7388\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ee4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.7411\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d375d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 1.0]]\n",
      "83/83 [==============================] - 1s 5ms/step\n",
      "[[ 1.0]\n",
      " [ 0.6]\n",
      " [ 0.7]\n",
      " [ 0.2]\n",
      " [ 0.9]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160200250312891\n",
      "0.5465213746856664\n",
      "0.6546184738955824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279b96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "[[ 0.3]\n",
      " [ 0.3]\n",
      " [ 0.9]\n",
      " [ 0.5]\n",
      " [ 0.3]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461aace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877906976744186\n",
      "0.5530612244897959\n",
      "0.6498800959232613\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
