{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in text form separated by commas\n",
    "brainT = np.loadtxt('Braintumor.csv', delimiter = ',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f080e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 14)\n"
     ]
    }
   ],
   "source": [
    "#check the shape\n",
    "print(brainT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a17378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the format so calculations and reading are easier\n",
    "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe3d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0  7.8  635.6 ...  3.7  1.0  0.0]\n",
      " [ 1.0  0.9  107.8 ...  4.5  0.9  0.0]\n",
      " [ 1.0  15.9  1114.3 ...  4.6  1.0  0.0]\n",
      " ...\n",
      " [ 0.0  8.5  979.5 ...  5.0  1.0  0.0]\n",
      " [ 0.0  3.7  296.0 ...  5.8  1.0  0.0]\n",
      " [ 1.0  19.5  1229.0 ...  4.9  1.0  0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the datasets\n",
    "import random\n",
    "brainT\n",
    "np.random.shuffle(brainT)\n",
    "print(brainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1851550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation, 30% validation set and 70% training \n",
    "index_30percent = int(0.3 * len(brainT[:, 0]))\n",
    "print(index_30percent)\n",
    "XVALID = brainT[:index_30percent, 1:]\n",
    "YVALID = brainT[:index_30percent, :1]\n",
    "XTRAIN = brainT[index_30percent:, 1:]\n",
    "YTRAIN = brainT[index_30percent:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow for neuron netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bfbc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 159.9781 - accuracy: 0.4506 - val_loss: 153.9496 - val_accuracy: 0.4078\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 130.0829 - accuracy: 0.4487 - val_loss: 121.3253 - val_accuracy: 0.4105\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 101.8693 - accuracy: 0.4495 - val_loss: 90.9505 - val_accuracy: 0.4264\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 74.2123 - accuracy: 0.4522 - val_loss: 62.5049 - val_accuracy: 0.4309\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 50.5152 - accuracy: 0.4552 - val_loss: 37.7778 - val_accuracy: 0.4557\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 31.2901 - accuracy: 0.4867 - val_loss: 20.9718 - val_accuracy: 0.5186\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 22.1074 - accuracy: 0.5471 - val_loss: 16.3667 - val_accuracy: 0.5975\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 18.6311 - accuracy: 0.5756 - val_loss: 13.9659 - val_accuracy: 0.6020\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 15.5134 - accuracy: 0.5877 - val_loss: 11.6052 - val_accuracy: 0.6152\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 12.4156 - accuracy: 0.6006 - val_loss: 9.4199 - val_accuracy: 0.6170\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 9.6779 - accuracy: 0.6230 - val_loss: 7.1839 - val_accuracy: 0.6569\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 7.0785 - accuracy: 0.6538 - val_loss: 5.1842 - val_accuracy: 0.7119\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 4.8048 - accuracy: 0.6826 - val_loss: 3.5491 - val_accuracy: 0.7296\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 3.1432 - accuracy: 0.7297 - val_loss: 2.5303 - val_accuracy: 0.7181\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9197 - accuracy: 0.7627 - val_loss: 1.6630 - val_accuracy: 0.8121\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.2500 - accuracy: 0.8102 - val_loss: 1.2844 - val_accuracy: 0.8236\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9608 - accuracy: 0.8288 - val_loss: 1.0914 - val_accuracy: 0.8395\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.7869 - accuracy: 0.8451 - val_loss: 1.0562 - val_accuracy: 0.8023\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.8481 - val_loss: 0.8720 - val_accuracy: 0.8413\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.8584 - val_loss: 0.7492 - val_accuracy: 0.8644\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.8747 - val_loss: 0.6678 - val_accuracy: 0.8697\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5024 - accuracy: 0.8774 - val_loss: 0.6870 - val_accuracy: 0.8626\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.8853 - val_loss: 0.5685 - val_accuracy: 0.8856\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.8891 - val_loss: 0.6494 - val_accuracy: 0.8582\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8846 - val_loss: 0.5006 - val_accuracy: 0.8927\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8884 - val_loss: 0.5637 - val_accuracy: 0.8715\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3624 - accuracy: 0.8929 - val_loss: 0.4728 - val_accuracy: 0.8945\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.8952 - val_loss: 0.4974 - val_accuracy: 0.8812\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3456 - accuracy: 0.8986 - val_loss: 0.4962 - val_accuracy: 0.8830\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.9021 - val_loss: 0.4796 - val_accuracy: 0.8856\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8964 - val_loss: 0.3920 - val_accuracy: 0.9096\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3241 - accuracy: 0.8990 - val_loss: 0.3725 - val_accuracy: 0.8989\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3089 - accuracy: 0.8964 - val_loss: 0.3537 - val_accuracy: 0.9016\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.9070 - val_loss: 0.4397 - val_accuracy: 0.8883\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2957 - accuracy: 0.9005 - val_loss: 0.3439 - val_accuracy: 0.9016\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.9093 - val_loss: 0.3370 - val_accuracy: 0.9229\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.9036 - val_loss: 0.4066 - val_accuracy: 0.8688\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.9032 - val_loss: 0.3156 - val_accuracy: 0.9229\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.9047 - val_loss: 0.3129 - val_accuracy: 0.9202\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.9093 - val_loss: 0.3060 - val_accuracy: 0.9096\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.9077 - val_loss: 0.7302 - val_accuracy: 0.7766\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.9085 - val_loss: 0.4271 - val_accuracy: 0.8732\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9146 - val_loss: 0.4912 - val_accuracy: 0.8387\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2494 - accuracy: 0.9089 - val_loss: 0.2734 - val_accuracy: 0.9238\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9134 - val_loss: 0.2939 - val_accuracy: 0.9043\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2428 - accuracy: 0.9161 - val_loss: 0.2801 - val_accuracy: 0.9105\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2429 - accuracy: 0.9188 - val_loss: 0.2814 - val_accuracy: 0.9264\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2306 - accuracy: 0.9210 - val_loss: 0.2539 - val_accuracy: 0.9229\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2356 - accuracy: 0.9195 - val_loss: 0.2514 - val_accuracy: 0.9291\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9165 - val_loss: 0.4608 - val_accuracy: 0.8466\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.9165 - val_loss: 0.2925 - val_accuracy: 0.9087\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9210 - val_loss: 0.2733 - val_accuracy: 0.9034\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2167 - accuracy: 0.9207 - val_loss: 0.2369 - val_accuracy: 0.9282\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9169 - val_loss: 0.5698 - val_accuracy: 0.7961\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9203 - val_loss: 0.2633 - val_accuracy: 0.9202\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9218 - val_loss: 0.2324 - val_accuracy: 0.9326\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9218 - val_loss: 0.2311 - val_accuracy: 0.9282\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9229 - val_loss: 0.2910 - val_accuracy: 0.8954\n",
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2082 - accuracy: 0.9260 - val_loss: 0.2271 - val_accuracy: 0.9255\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2095 - accuracy: 0.9244 - val_loss: 0.2376 - val_accuracy: 0.9202\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9226 - val_loss: 0.2568 - val_accuracy: 0.9193\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2117 - accuracy: 0.9290 - val_loss: 0.2324 - val_accuracy: 0.9362\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2097 - accuracy: 0.9244 - val_loss: 0.3973 - val_accuracy: 0.8555\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.9298 - val_loss: 0.2862 - val_accuracy: 0.9060\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9271 - val_loss: 0.3424 - val_accuracy: 0.8839\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2062 - accuracy: 0.9290 - val_loss: 0.2275 - val_accuracy: 0.9353\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9267 - val_loss: 0.2615 - val_accuracy: 0.9078\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9313 - val_loss: 0.2120 - val_accuracy: 0.9415\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9355 - val_loss: 0.2199 - val_accuracy: 0.9309\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2017 - accuracy: 0.9336 - val_loss: 0.2401 - val_accuracy: 0.9184\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9301 - val_loss: 0.2156 - val_accuracy: 0.9433\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9328 - val_loss: 0.2478 - val_accuracy: 0.9158\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9317 - val_loss: 0.2253 - val_accuracy: 0.9379\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9332 - val_loss: 0.2112 - val_accuracy: 0.9326\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9343 - val_loss: 0.2183 - val_accuracy: 0.9388\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1922 - accuracy: 0.9351 - val_loss: 0.2955 - val_accuracy: 0.9025\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9374 - val_loss: 0.2091 - val_accuracy: 0.9388\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9370 - val_loss: 0.2434 - val_accuracy: 0.9184\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9366 - val_loss: 0.2210 - val_accuracy: 0.9353\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9408 - val_loss: 0.2828 - val_accuracy: 0.9051\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9374 - val_loss: 0.2312 - val_accuracy: 0.9255\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.9351 - val_loss: 0.2015 - val_accuracy: 0.9459\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9374 - val_loss: 0.2192 - val_accuracy: 0.9388\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9396 - val_loss: 0.2405 - val_accuracy: 0.9282\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.9404 - val_loss: 0.2016 - val_accuracy: 0.9468\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9431 - val_loss: 0.2471 - val_accuracy: 0.9167\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9389 - val_loss: 0.2203 - val_accuracy: 0.9291\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.9336 - val_loss: 0.2055 - val_accuracy: 0.9353\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1779 - accuracy: 0.9377 - val_loss: 0.1948 - val_accuracy: 0.9441\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9404 - val_loss: 0.2031 - val_accuracy: 0.9344\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9366 - val_loss: 0.2844 - val_accuracy: 0.9034\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.9381 - val_loss: 0.2198 - val_accuracy: 0.9388\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 0.9423 - val_loss: 0.2404 - val_accuracy: 0.9176\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9396 - val_loss: 0.1979 - val_accuracy: 0.9504\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9434 - val_loss: 0.3082 - val_accuracy: 0.8927\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1728 - accuracy: 0.9457 - val_loss: 0.1978 - val_accuracy: 0.9459\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9415 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9434 - val_loss: 0.2319 - val_accuracy: 0.9335\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9404 - val_loss: 0.2712 - val_accuracy: 0.9069\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9423 - val_loss: 0.1891 - val_accuracy: 0.9459\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1643 - accuracy: 0.9461 - val_loss: 0.2230 - val_accuracy: 0.9344\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.9446 - val_loss: 0.2275 - val_accuracy: 0.9309\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9446 - val_loss: 0.1867 - val_accuracy: 0.9459\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1647 - accuracy: 0.9461 - val_loss: 0.2036 - val_accuracy: 0.9406\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.9476 - val_loss: 0.3393 - val_accuracy: 0.8759\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9457 - val_loss: 0.3537 - val_accuracy: 0.8688\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9472 - val_loss: 0.2474 - val_accuracy: 0.9282\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9472 - val_loss: 0.1861 - val_accuracy: 0.9530\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9457 - val_loss: 0.2459 - val_accuracy: 0.9246\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9465 - val_loss: 0.1933 - val_accuracy: 0.9415\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9472 - val_loss: 0.2069 - val_accuracy: 0.9362\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9476 - val_loss: 0.1892 - val_accuracy: 0.9459\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9484 - val_loss: 0.1998 - val_accuracy: 0.9371\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.2912 - val_accuracy: 0.8998\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1528 - accuracy: 0.9491 - val_loss: 0.3738 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.9487 - val_loss: 0.2603 - val_accuracy: 0.9193\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9461 - val_loss: 0.2313 - val_accuracy: 0.9229\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9514 - val_loss: 0.2247 - val_accuracy: 0.9264\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9453 - val_loss: 0.2811 - val_accuracy: 0.9060\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9457 - val_loss: 0.1835 - val_accuracy: 0.9548\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9506 - val_loss: 0.1895 - val_accuracy: 0.9477\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9472 - val_loss: 0.1800 - val_accuracy: 0.9539\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9503 - val_loss: 0.1908 - val_accuracy: 0.9539\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9499 - val_loss: 0.2001 - val_accuracy: 0.9459\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9472 - val_loss: 0.2009 - val_accuracy: 0.9441\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9518 - val_loss: 0.1756 - val_accuracy: 0.9548\n",
      "Epoch 127/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9518 - val_loss: 0.2597 - val_accuracy: 0.9176\n",
      "Epoch 128/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9442 - val_loss: 0.1754 - val_accuracy: 0.9539\n",
      "Epoch 129/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9522 - val_loss: 0.1856 - val_accuracy: 0.9574\n",
      "Epoch 130/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9491 - val_loss: 0.2138 - val_accuracy: 0.9362\n",
      "Epoch 131/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9506 - val_loss: 0.1753 - val_accuracy: 0.9548\n",
      "Epoch 132/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1528 - accuracy: 0.9476 - val_loss: 0.2375 - val_accuracy: 0.9202\n",
      "Epoch 133/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1473 - accuracy: 0.9510 - val_loss: 0.1750 - val_accuracy: 0.9566\n",
      "Epoch 134/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1515 - accuracy: 0.9476 - val_loss: 0.1794 - val_accuracy: 0.9486\n",
      "Epoch 135/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1530 - accuracy: 0.9491 - val_loss: 0.1905 - val_accuracy: 0.9459\n",
      "Epoch 136/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9484 - val_loss: 0.1857 - val_accuracy: 0.9574\n",
      "Epoch 137/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9533 - val_loss: 0.2588 - val_accuracy: 0.9184\n",
      "Epoch 138/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9533 - val_loss: 0.1739 - val_accuracy: 0.9557\n",
      "Epoch 139/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9510 - val_loss: 0.1763 - val_accuracy: 0.9566\n",
      "Epoch 140/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9503 - val_loss: 0.1769 - val_accuracy: 0.9530\n",
      "Epoch 141/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9510 - val_loss: 0.2933 - val_accuracy: 0.8972\n",
      "Epoch 142/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9510 - val_loss: 0.1919 - val_accuracy: 0.9557\n",
      "Epoch 143/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9525 - val_loss: 0.2492 - val_accuracy: 0.9158\n",
      "Epoch 144/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9563 - val_loss: 0.3682 - val_accuracy: 0.8777\n",
      "Epoch 145/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9506 - val_loss: 0.1706 - val_accuracy: 0.9566\n",
      "Epoch 146/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1504 - accuracy: 0.9499 - val_loss: 0.1815 - val_accuracy: 0.9592\n",
      "Epoch 147/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.9506 - val_loss: 0.1767 - val_accuracy: 0.9592\n",
      "Epoch 148/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9541 - val_loss: 0.1677 - val_accuracy: 0.9574\n",
      "Epoch 149/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9560 - val_loss: 0.2206 - val_accuracy: 0.9371\n",
      "Epoch 150/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1676 - val_accuracy: 0.9601\n",
      "Epoch 151/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.1719 - val_accuracy: 0.9566\n",
      "Epoch 152/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9579 - val_loss: 0.1863 - val_accuracy: 0.9459\n",
      "Epoch 153/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9560 - val_loss: 0.1828 - val_accuracy: 0.9459\n",
      "Epoch 154/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9525 - val_loss: 0.1695 - val_accuracy: 0.9592\n",
      "Epoch 155/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9552 - val_loss: 0.2081 - val_accuracy: 0.9406\n",
      "Epoch 156/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9598 - val_loss: 0.1734 - val_accuracy: 0.9601\n",
      "Epoch 157/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9556 - val_loss: 0.1712 - val_accuracy: 0.9592\n",
      "Epoch 158/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9548 - val_loss: 0.2088 - val_accuracy: 0.9406\n",
      "Epoch 159/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9571 - val_loss: 0.1883 - val_accuracy: 0.9521\n",
      "Epoch 160/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9541 - val_loss: 0.2730 - val_accuracy: 0.9158\n",
      "Epoch 161/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.9563 - val_loss: 0.2089 - val_accuracy: 0.9326\n",
      "Epoch 162/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9537 - val_loss: 0.1832 - val_accuracy: 0.9566\n",
      "Epoch 163/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9552 - val_loss: 0.2172 - val_accuracy: 0.9388\n",
      "Epoch 164/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9567 - val_loss: 0.1767 - val_accuracy: 0.9548\n",
      "Epoch 165/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9582 - val_loss: 0.1928 - val_accuracy: 0.9433\n",
      "Epoch 166/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9525 - val_loss: 0.1700 - val_accuracy: 0.9530\n",
      "Epoch 167/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9541 - val_loss: 0.2380 - val_accuracy: 0.9291\n",
      "Epoch 168/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1386 - accuracy: 0.9556 - val_loss: 0.1634 - val_accuracy: 0.9619\n",
      "Epoch 169/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9556 - val_loss: 0.1691 - val_accuracy: 0.9619\n",
      "Epoch 170/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9503 - val_loss: 0.1641 - val_accuracy: 0.9628\n",
      "Epoch 171/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9552 - val_loss: 0.3084 - val_accuracy: 0.8972\n",
      "Epoch 172/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1350 - accuracy: 0.9594 - val_loss: 0.1641 - val_accuracy: 0.9601\n",
      "Epoch 173/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9586 - val_loss: 0.2083 - val_accuracy: 0.9335\n",
      "Epoch 174/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9560 - val_loss: 0.1611 - val_accuracy: 0.9637\n",
      "Epoch 175/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9567 - val_loss: 0.1913 - val_accuracy: 0.9530\n",
      "Epoch 176/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9537 - val_loss: 0.1650 - val_accuracy: 0.9637\n",
      "Epoch 177/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9586 - val_loss: 0.1733 - val_accuracy: 0.9619\n",
      "Epoch 178/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9544 - val_loss: 0.2680 - val_accuracy: 0.9096\n",
      "Epoch 179/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9556 - val_loss: 0.1645 - val_accuracy: 0.9637\n",
      "Epoch 180/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1283 - accuracy: 0.9586 - val_loss: 0.3332 - val_accuracy: 0.8865\n",
      "Epoch 181/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9590 - val_loss: 0.2459 - val_accuracy: 0.9309\n",
      "Epoch 182/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1318 - accuracy: 0.9590 - val_loss: 0.3190 - val_accuracy: 0.8954\n",
      "Epoch 183/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9552 - val_loss: 0.1713 - val_accuracy: 0.9521\n",
      "Epoch 184/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9563 - val_loss: 0.3214 - val_accuracy: 0.8936\n",
      "Epoch 185/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1325 - accuracy: 0.9575 - val_loss: 0.1642 - val_accuracy: 0.9645\n",
      "Epoch 186/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9560 - val_loss: 0.3070 - val_accuracy: 0.8980\n",
      "Epoch 187/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9594 - val_loss: 0.2047 - val_accuracy: 0.9362\n",
      "Epoch 188/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9563 - val_loss: 0.1652 - val_accuracy: 0.9681\n",
      "Epoch 189/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9575 - val_loss: 0.2256 - val_accuracy: 0.9353\n",
      "Epoch 190/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9590 - val_loss: 0.1626 - val_accuracy: 0.9610\n",
      "Epoch 191/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9598 - val_loss: 0.1802 - val_accuracy: 0.9486\n",
      "Epoch 192/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9594 - val_loss: 0.1616 - val_accuracy: 0.9663\n",
      "Epoch 193/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9563 - val_loss: 0.1791 - val_accuracy: 0.9610\n",
      "Epoch 194/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9609 - val_loss: 0.1629 - val_accuracy: 0.9628\n",
      "Epoch 195/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9582 - val_loss: 0.1582 - val_accuracy: 0.9654\n",
      "Epoch 196/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9579 - val_loss: 0.1606 - val_accuracy: 0.9681\n",
      "Epoch 197/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9590 - val_loss: 0.1580 - val_accuracy: 0.9663\n",
      "Epoch 198/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9594 - val_loss: 0.1607 - val_accuracy: 0.9628\n",
      "Epoch 199/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9571 - val_loss: 0.1606 - val_accuracy: 0.9681\n",
      "Epoch 200/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.1636 - val_accuracy: 0.9663\n",
      "Epoch 201/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 0.3034 - val_accuracy: 0.8989\n",
      "Epoch 202/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9586 - val_loss: 0.2317 - val_accuracy: 0.9344\n",
      "Epoch 203/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9586 - val_loss: 0.1644 - val_accuracy: 0.9628\n",
      "Epoch 204/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9632 - val_loss: 0.1729 - val_accuracy: 0.9654\n",
      "Epoch 205/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1264 - accuracy: 0.9563 - val_loss: 0.1580 - val_accuracy: 0.9663\n",
      "Epoch 206/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9582 - val_loss: 0.1895 - val_accuracy: 0.9459\n",
      "Epoch 207/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9552 - val_loss: 0.1571 - val_accuracy: 0.9672\n",
      "Epoch 208/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9605 - val_loss: 0.2087 - val_accuracy: 0.9344\n",
      "Epoch 209/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1248 - accuracy: 0.9613 - val_loss: 0.1606 - val_accuracy: 0.9645\n",
      "Epoch 210/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9639 - val_loss: 0.1575 - val_accuracy: 0.9663\n",
      "Epoch 211/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9598 - val_loss: 0.1800 - val_accuracy: 0.9574\n",
      "Epoch 212/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9613 - val_loss: 0.1704 - val_accuracy: 0.9654\n",
      "Epoch 213/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9590 - val_loss: 0.1621 - val_accuracy: 0.9645\n",
      "Epoch 214/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9624 - val_loss: 0.1923 - val_accuracy: 0.9521\n",
      "Epoch 215/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9628 - val_loss: 0.2123 - val_accuracy: 0.9353\n",
      "Epoch 216/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9582 - val_loss: 0.2052 - val_accuracy: 0.9433\n",
      "Epoch 217/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9601 - val_loss: 0.1587 - val_accuracy: 0.9628\n",
      "Epoch 218/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9643 - val_loss: 0.2456 - val_accuracy: 0.9211\n",
      "Epoch 219/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9620 - val_loss: 0.1588 - val_accuracy: 0.9654\n",
      "Epoch 220/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9579 - val_loss: 0.1625 - val_accuracy: 0.9628\n",
      "Epoch 221/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9651 - val_loss: 0.3727 - val_accuracy: 0.8794\n",
      "Epoch 222/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9639 - val_loss: 0.1824 - val_accuracy: 0.9486\n",
      "Epoch 223/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9620 - val_loss: 0.1991 - val_accuracy: 0.9459\n",
      "Epoch 224/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 0.1594 - val_accuracy: 0.9707\n",
      "Epoch 225/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9636 - val_loss: 0.2961 - val_accuracy: 0.9043\n",
      "Epoch 226/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9651 - val_loss: 0.2509 - val_accuracy: 0.9264\n",
      "Epoch 227/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.2075 - val_accuracy: 0.9433\n",
      "Epoch 228/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9575 - val_loss: 0.2012 - val_accuracy: 0.9397\n",
      "Epoch 229/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9590 - val_loss: 0.2019 - val_accuracy: 0.9424\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9613 - val_loss: 0.1644 - val_accuracy: 0.9707\n",
      "Epoch 231/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9651 - val_loss: 0.1568 - val_accuracy: 0.9654\n",
      "Epoch 232/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9609 - val_loss: 0.1544 - val_accuracy: 0.9654\n",
      "Epoch 233/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9636 - val_loss: 0.2749 - val_accuracy: 0.9105\n",
      "Epoch 234/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9605 - val_loss: 0.1745 - val_accuracy: 0.9592\n",
      "Epoch 235/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9658 - val_loss: 0.1514 - val_accuracy: 0.9725\n",
      "Epoch 236/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9624 - val_loss: 0.1546 - val_accuracy: 0.9725\n",
      "Epoch 237/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9624 - val_loss: 0.2294 - val_accuracy: 0.9255\n",
      "Epoch 238/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9651 - val_loss: 0.2165 - val_accuracy: 0.9326\n",
      "Epoch 239/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9636 - val_loss: 0.1509 - val_accuracy: 0.9716\n",
      "Epoch 240/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9598 - val_loss: 0.1768 - val_accuracy: 0.9530\n",
      "Epoch 241/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9639 - val_loss: 0.1587 - val_accuracy: 0.9628\n",
      "Epoch 242/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9636 - val_loss: 0.1510 - val_accuracy: 0.9707\n",
      "Epoch 243/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9639 - val_loss: 0.1544 - val_accuracy: 0.9672\n",
      "Epoch 244/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9632 - val_loss: 0.1741 - val_accuracy: 0.9566\n",
      "Epoch 245/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9605 - val_loss: 0.1526 - val_accuracy: 0.9743\n",
      "Epoch 246/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9601 - val_loss: 0.2022 - val_accuracy: 0.9397\n",
      "Epoch 247/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9609 - val_loss: 0.1910 - val_accuracy: 0.9433\n",
      "Epoch 248/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9594 - val_loss: 0.1609 - val_accuracy: 0.9619\n",
      "Epoch 249/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9658 - val_loss: 0.3230 - val_accuracy: 0.8963\n",
      "Epoch 250/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9666 - val_loss: 0.1797 - val_accuracy: 0.9583\n",
      "Epoch 251/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9647 - val_loss: 0.2276 - val_accuracy: 0.9300\n",
      "Epoch 252/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9620 - val_loss: 0.1579 - val_accuracy: 0.9743\n",
      "Epoch 253/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9605 - val_loss: 0.2615 - val_accuracy: 0.9131\n",
      "Epoch 254/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9613 - val_loss: 0.1583 - val_accuracy: 0.9645\n",
      "Epoch 255/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9632 - val_loss: 0.1859 - val_accuracy: 0.9477\n",
      "Epoch 256/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9620 - val_loss: 0.1833 - val_accuracy: 0.9504\n",
      "Epoch 257/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9662 - val_loss: 0.1776 - val_accuracy: 0.9530\n",
      "Epoch 258/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9636 - val_loss: 0.1789 - val_accuracy: 0.9601\n",
      "Epoch 259/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9643 - val_loss: 0.2243 - val_accuracy: 0.9371\n",
      "Epoch 260/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9620 - val_loss: 0.1959 - val_accuracy: 0.9477\n",
      "Epoch 261/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9643 - val_loss: 0.1835 - val_accuracy: 0.9557\n",
      "Epoch 262/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9620 - val_loss: 0.1495 - val_accuracy: 0.9725\n",
      "Epoch 263/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9651 - val_loss: 0.1544 - val_accuracy: 0.9725\n",
      "Epoch 264/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9620 - val_loss: 0.2183 - val_accuracy: 0.9353\n",
      "Epoch 265/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9658 - val_loss: 0.1495 - val_accuracy: 0.9707\n",
      "Epoch 266/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9643 - val_loss: 0.1818 - val_accuracy: 0.9557\n",
      "Epoch 267/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9670 - val_loss: 0.1825 - val_accuracy: 0.9583\n",
      "Epoch 268/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9666 - val_loss: 0.1514 - val_accuracy: 0.9681\n",
      "Epoch 269/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9685 - val_loss: 0.1579 - val_accuracy: 0.9752\n",
      "Epoch 270/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9681 - val_loss: 0.1535 - val_accuracy: 0.9681\n",
      "Epoch 271/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.9647 - val_loss: 0.1483 - val_accuracy: 0.9752\n",
      "Epoch 272/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9643 - val_loss: 0.2371 - val_accuracy: 0.9317\n",
      "Epoch 273/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9647 - val_loss: 0.1553 - val_accuracy: 0.9752\n",
      "Epoch 274/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9689 - val_loss: 0.1622 - val_accuracy: 0.9637\n",
      "Epoch 275/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9662 - val_loss: 0.1532 - val_accuracy: 0.9734\n",
      "Epoch 276/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9662 - val_loss: 0.1513 - val_accuracy: 0.9707\n",
      "Epoch 277/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9677 - val_loss: 0.1741 - val_accuracy: 0.9548\n",
      "Epoch 278/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9674 - val_loss: 0.1591 - val_accuracy: 0.9672\n",
      "Epoch 279/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9636 - val_loss: 0.1532 - val_accuracy: 0.9725\n",
      "Epoch 280/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9647 - val_loss: 0.1540 - val_accuracy: 0.9681\n",
      "Epoch 281/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9666 - val_loss: 0.1840 - val_accuracy: 0.9566\n",
      "Epoch 282/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9651 - val_loss: 0.1481 - val_accuracy: 0.9707\n",
      "Epoch 283/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9651 - val_loss: 0.2331 - val_accuracy: 0.9353\n",
      "Epoch 284/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9662 - val_loss: 0.1567 - val_accuracy: 0.9654\n",
      "Epoch 285/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9655 - val_loss: 0.1664 - val_accuracy: 0.9610\n",
      "Epoch 286/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.9632 - val_loss: 0.1495 - val_accuracy: 0.9707\n",
      "Epoch 287/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9655 - val_loss: 0.1497 - val_accuracy: 0.9734\n",
      "Epoch 288/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9677 - val_loss: 0.1548 - val_accuracy: 0.9654\n",
      "Epoch 289/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9685 - val_loss: 0.1547 - val_accuracy: 0.9770\n",
      "Epoch 290/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9655 - val_loss: 0.2523 - val_accuracy: 0.9184\n",
      "Epoch 291/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9689 - val_loss: 0.1585 - val_accuracy: 0.9743\n",
      "Epoch 292/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9658 - val_loss: 0.1516 - val_accuracy: 0.9654\n",
      "Epoch 293/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9643 - val_loss: 0.1544 - val_accuracy: 0.9743\n",
      "Epoch 294/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.9700 - val_loss: 0.1857 - val_accuracy: 0.9539\n",
      "Epoch 295/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9692 - val_loss: 0.3088 - val_accuracy: 0.9060\n",
      "Epoch 296/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1124 - accuracy: 0.9681 - val_loss: 0.1598 - val_accuracy: 0.9716\n",
      "Epoch 297/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9681 - val_loss: 0.1832 - val_accuracy: 0.9512\n",
      "Epoch 298/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9689 - val_loss: 0.1515 - val_accuracy: 0.9770\n",
      "Epoch 299/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9685 - val_loss: 0.1522 - val_accuracy: 0.9707\n",
      "Epoch 300/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9689 - val_loss: 0.1750 - val_accuracy: 0.9574\n",
      "Epoch 301/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.9655 - val_loss: 0.1481 - val_accuracy: 0.9725\n",
      "Epoch 302/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9647 - val_loss: 0.1587 - val_accuracy: 0.9637\n",
      "Epoch 303/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9651 - val_loss: 0.1521 - val_accuracy: 0.9699\n",
      "Epoch 304/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 0.1856 - val_accuracy: 0.9592\n",
      "Epoch 305/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1097 - accuracy: 0.9670 - val_loss: 0.1488 - val_accuracy: 0.9752\n",
      "Epoch 306/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9632 - val_loss: 0.2165 - val_accuracy: 0.9397\n",
      "Epoch 307/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1121 - accuracy: 0.9658 - val_loss: 0.2397 - val_accuracy: 0.9353\n",
      "Epoch 308/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9666 - val_loss: 0.1771 - val_accuracy: 0.9628\n",
      "Epoch 309/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9674 - val_loss: 0.1593 - val_accuracy: 0.9690\n",
      "Epoch 310/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9685 - val_loss: 0.1643 - val_accuracy: 0.9699\n",
      "Epoch 311/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9658 - val_loss: 0.1562 - val_accuracy: 0.9770\n",
      "Epoch 312/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9715 - val_loss: 0.1543 - val_accuracy: 0.9770\n",
      "Epoch 313/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9685 - val_loss: 0.2666 - val_accuracy: 0.9193\n",
      "Epoch 314/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9670 - val_loss: 0.3056 - val_accuracy: 0.9096\n",
      "Epoch 315/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9658 - val_loss: 0.1677 - val_accuracy: 0.9645\n",
      "Epoch 316/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1084 - accuracy: 0.9689 - val_loss: 0.2292 - val_accuracy: 0.9388\n",
      "Epoch 317/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.9700 - val_loss: 0.1573 - val_accuracy: 0.9690\n",
      "Epoch 318/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9662 - val_loss: 0.1596 - val_accuracy: 0.9663\n",
      "Epoch 319/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1104 - accuracy: 0.9681 - val_loss: 0.2685 - val_accuracy: 0.9158\n",
      "Epoch 320/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9670 - val_loss: 0.1515 - val_accuracy: 0.9778\n",
      "Epoch 321/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9677 - val_loss: 0.1779 - val_accuracy: 0.9566\n",
      "Epoch 322/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9727 - val_loss: 0.1603 - val_accuracy: 0.9716\n",
      "Epoch 323/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9692 - val_loss: 0.1473 - val_accuracy: 0.9743\n",
      "Epoch 324/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9674 - val_loss: 0.1513 - val_accuracy: 0.9761\n",
      "Epoch 325/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.9681 - val_loss: 0.1485 - val_accuracy: 0.9734\n",
      "Epoch 326/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9696 - val_loss: 0.1644 - val_accuracy: 0.9628\n",
      "Epoch 327/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9677 - val_loss: 0.1592 - val_accuracy: 0.9654\n",
      "Epoch 328/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9689 - val_loss: 0.1449 - val_accuracy: 0.9752\n",
      "Epoch 329/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.9719 - val_loss: 0.1614 - val_accuracy: 0.9681\n",
      "Epoch 330/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9670 - val_loss: 0.2164 - val_accuracy: 0.9433\n",
      "Epoch 331/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9681 - val_loss: 0.2112 - val_accuracy: 0.9424\n",
      "Epoch 332/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1097 - accuracy: 0.9651 - val_loss: 0.1410 - val_accuracy: 0.9761\n",
      "Epoch 333/500\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1059 - accuracy: 0.9685 - val_loss: 0.1884 - val_accuracy: 0.9521\n",
      "Epoch 334/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9700 - val_loss: 0.1661 - val_accuracy: 0.9628\n",
      "Epoch 335/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9727 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 336/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.9692 - val_loss: 0.1455 - val_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.1491 - val_accuracy: 0.9752\n",
      "Epoch 338/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9730 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
      "Epoch 339/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9689 - val_loss: 0.1509 - val_accuracy: 0.9690\n",
      "Epoch 340/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.1451 - val_accuracy: 0.9743\n",
      "Epoch 341/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9719 - val_loss: 0.1421 - val_accuracy: 0.9778\n",
      "Epoch 342/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.9692 - val_loss: 0.1548 - val_accuracy: 0.9672\n",
      "Epoch 343/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9685 - val_loss: 0.1796 - val_accuracy: 0.9530\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9719 - val_loss: 0.1961 - val_accuracy: 0.9486\n",
      "Epoch 345/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9723 - val_loss: 0.1472 - val_accuracy: 0.9761\n",
      "Epoch 346/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 0.1444 - val_accuracy: 0.9734\n",
      "Epoch 347/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9692 - val_loss: 0.1544 - val_accuracy: 0.9716\n",
      "Epoch 348/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9704 - val_loss: 0.1637 - val_accuracy: 0.9637\n",
      "Epoch 349/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.9692 - val_loss: 0.1432 - val_accuracy: 0.9725\n",
      "Epoch 350/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1024 - accuracy: 0.9746 - val_loss: 0.1431 - val_accuracy: 0.9778\n",
      "Epoch 351/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1067 - accuracy: 0.9704 - val_loss: 0.1404 - val_accuracy: 0.9761\n",
      "Epoch 352/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9711 - val_loss: 0.1985 - val_accuracy: 0.9450\n",
      "Epoch 353/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9734 - val_loss: 0.2186 - val_accuracy: 0.9406\n",
      "Epoch 354/500\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1034 - accuracy: 0.9719 - val_loss: 0.1574 - val_accuracy: 0.9672\n",
      "Epoch 355/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9704 - val_loss: 0.1469 - val_accuracy: 0.9707\n",
      "Epoch 356/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9700 - val_loss: 0.1693 - val_accuracy: 0.9601\n",
      "Epoch 357/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9685 - val_loss: 0.1414 - val_accuracy: 0.9743\n",
      "Epoch 358/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9711 - val_loss: 0.1397 - val_accuracy: 0.9787\n",
      "Epoch 359/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9689 - val_loss: 0.1773 - val_accuracy: 0.9601\n",
      "Epoch 360/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9734 - val_loss: 0.1469 - val_accuracy: 0.9743\n",
      "Epoch 361/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9692 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9685 - val_loss: 0.1417 - val_accuracy: 0.9743\n",
      "Epoch 363/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9742 - val_loss: 0.2173 - val_accuracy: 0.9406\n",
      "Epoch 364/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9696 - val_loss: 0.1458 - val_accuracy: 0.9778\n",
      "Epoch 365/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9746 - val_loss: 0.1511 - val_accuracy: 0.9778\n",
      "Epoch 366/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9734 - val_loss: 0.1563 - val_accuracy: 0.9707\n",
      "Epoch 367/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9689 - val_loss: 0.1466 - val_accuracy: 0.9770\n",
      "Epoch 368/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9734 - val_loss: 0.1799 - val_accuracy: 0.9574\n",
      "Epoch 369/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9727 - val_loss: 0.1386 - val_accuracy: 0.9734\n",
      "Epoch 370/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9692 - val_loss: 0.1696 - val_accuracy: 0.9583\n",
      "Epoch 371/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9700 - val_loss: 0.1380 - val_accuracy: 0.9734\n",
      "Epoch 372/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.2208 - val_accuracy: 0.9388\n",
      "Epoch 373/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9708 - val_loss: 0.2063 - val_accuracy: 0.9415\n",
      "Epoch 374/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9689 - val_loss: 0.1494 - val_accuracy: 0.9681\n",
      "Epoch 375/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9723 - val_loss: 0.1660 - val_accuracy: 0.9583\n",
      "Epoch 376/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9711 - val_loss: 0.1454 - val_accuracy: 0.9734\n",
      "Epoch 377/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9734 - val_loss: 0.1393 - val_accuracy: 0.9770\n",
      "Epoch 378/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9708 - val_loss: 0.1639 - val_accuracy: 0.9592\n",
      "Epoch 379/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.1968 - val_accuracy: 0.9468\n",
      "Epoch 380/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9719 - val_loss: 0.2065 - val_accuracy: 0.9459\n",
      "Epoch 381/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9734 - val_loss: 0.1401 - val_accuracy: 0.9752\n",
      "Epoch 382/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9734 - val_loss: 0.2154 - val_accuracy: 0.9415\n",
      "Epoch 383/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9719 - val_loss: 0.1514 - val_accuracy: 0.9707\n",
      "Epoch 384/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9704 - val_loss: 0.1555 - val_accuracy: 0.9770\n",
      "Epoch 385/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9727 - val_loss: 0.1413 - val_accuracy: 0.9778\n",
      "Epoch 386/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9708 - val_loss: 0.1752 - val_accuracy: 0.9539\n",
      "Epoch 387/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.1629 - val_accuracy: 0.9707\n",
      "Epoch 388/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9719 - val_loss: 0.1515 - val_accuracy: 0.9707\n",
      "Epoch 389/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9715 - val_loss: 0.1420 - val_accuracy: 0.9734\n",
      "Epoch 390/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9711 - val_loss: 0.1457 - val_accuracy: 0.9770\n",
      "Epoch 391/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9715 - val_loss: 0.2270 - val_accuracy: 0.9379\n",
      "Epoch 392/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9746 - val_loss: 0.1376 - val_accuracy: 0.9778\n",
      "Epoch 393/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9734 - val_loss: 0.1420 - val_accuracy: 0.9778\n",
      "Epoch 394/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9723 - val_loss: 0.2852 - val_accuracy: 0.9167\n",
      "Epoch 395/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9696 - val_loss: 0.1717 - val_accuracy: 0.9566\n",
      "Epoch 396/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9708 - val_loss: 0.1759 - val_accuracy: 0.9530\n",
      "Epoch 397/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9746 - val_loss: 0.1885 - val_accuracy: 0.9530\n",
      "Epoch 398/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9742 - val_loss: 0.1494 - val_accuracy: 0.9699\n",
      "Epoch 399/500\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0988 - accuracy: 0.9708 - val_loss: 0.1700 - val_accuracy: 0.9592\n",
      "Epoch 400/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9723 - val_loss: 0.1533 - val_accuracy: 0.9707\n",
      "Epoch 401/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.1494 - val_accuracy: 0.9787\n",
      "Epoch 402/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9734 - val_loss: 0.1862 - val_accuracy: 0.9574\n",
      "Epoch 403/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9727 - val_loss: 0.1560 - val_accuracy: 0.9716\n",
      "Epoch 404/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9715 - val_loss: 0.1417 - val_accuracy: 0.9796\n",
      "Epoch 405/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9715 - val_loss: 0.2507 - val_accuracy: 0.9309\n",
      "Epoch 406/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9723 - val_loss: 0.2117 - val_accuracy: 0.9433\n",
      "Epoch 407/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9711 - val_loss: 0.2155 - val_accuracy: 0.9433\n",
      "Epoch 408/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9746 - val_loss: 0.1614 - val_accuracy: 0.9690\n",
      "Epoch 409/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9711 - val_loss: 0.1491 - val_accuracy: 0.9716\n",
      "Epoch 410/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9723 - val_loss: 0.1424 - val_accuracy: 0.9787\n",
      "Epoch 411/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9719 - val_loss: 0.1523 - val_accuracy: 0.9778\n",
      "Epoch 412/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9730 - val_loss: 0.1410 - val_accuracy: 0.9796\n",
      "Epoch 413/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9727 - val_loss: 0.1502 - val_accuracy: 0.9707\n",
      "Epoch 414/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9727 - val_loss: 0.1484 - val_accuracy: 0.9770\n",
      "Epoch 415/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9742 - val_loss: 0.1606 - val_accuracy: 0.9681\n",
      "Epoch 416/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9719 - val_loss: 0.1466 - val_accuracy: 0.9752\n",
      "Epoch 417/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9734 - val_loss: 0.1435 - val_accuracy: 0.9761\n",
      "Epoch 418/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9719 - val_loss: 0.2046 - val_accuracy: 0.9477\n",
      "Epoch 419/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.1467 - val_accuracy: 0.9778\n",
      "Epoch 420/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9749 - val_loss: 0.1560 - val_accuracy: 0.9707\n",
      "Epoch 421/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9711 - val_loss: 0.1437 - val_accuracy: 0.9752\n",
      "Epoch 422/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9704 - val_loss: 0.2106 - val_accuracy: 0.9468\n",
      "Epoch 423/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9749 - val_loss: 0.1443 - val_accuracy: 0.9770\n",
      "Epoch 424/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9749 - val_loss: 0.1431 - val_accuracy: 0.9770\n",
      "Epoch 425/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9730 - val_loss: 0.1512 - val_accuracy: 0.9734\n",
      "Epoch 426/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9719 - val_loss: 0.1730 - val_accuracy: 0.9672\n",
      "Epoch 427/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9715 - val_loss: 0.1442 - val_accuracy: 0.9805\n",
      "Epoch 428/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9727 - val_loss: 0.1950 - val_accuracy: 0.9504\n",
      "Epoch 429/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9749 - val_loss: 0.2038 - val_accuracy: 0.9468\n",
      "Epoch 430/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9730 - val_loss: 0.1469 - val_accuracy: 0.9752\n",
      "Epoch 431/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9749 - val_loss: 0.1491 - val_accuracy: 0.9770\n",
      "Epoch 432/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9708 - val_loss: 0.1424 - val_accuracy: 0.9734\n",
      "Epoch 433/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9742 - val_loss: 0.1387 - val_accuracy: 0.9796\n",
      "Epoch 434/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9753 - val_loss: 0.1505 - val_accuracy: 0.9716\n",
      "Epoch 435/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9746 - val_loss: 0.1584 - val_accuracy: 0.9690\n",
      "Epoch 436/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9738 - val_loss: 0.1452 - val_accuracy: 0.9743\n",
      "Epoch 437/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9749 - val_loss: 0.1735 - val_accuracy: 0.9583\n",
      "Epoch 438/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9727 - val_loss: 0.1472 - val_accuracy: 0.9770\n",
      "Epoch 439/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9749 - val_loss: 0.2213 - val_accuracy: 0.9397\n",
      "Epoch 440/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9711 - val_loss: 0.1396 - val_accuracy: 0.9752\n",
      "Epoch 441/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 0.1459 - val_accuracy: 0.9743\n",
      "Epoch 442/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9692 - val_loss: 0.2204 - val_accuracy: 0.9397\n",
      "Epoch 443/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9761 - val_loss: 0.1374 - val_accuracy: 0.9805\n",
      "Epoch 444/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9761 - val_loss: 0.2327 - val_accuracy: 0.9335\n",
      "Epoch 445/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9742 - val_loss: 0.1458 - val_accuracy: 0.9734\n",
      "Epoch 446/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9711 - val_loss: 0.2226 - val_accuracy: 0.9415\n",
      "Epoch 447/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9742 - val_loss: 0.1658 - val_accuracy: 0.9592\n",
      "Epoch 448/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9753 - val_loss: 0.1368 - val_accuracy: 0.9778\n",
      "Epoch 449/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9723 - val_loss: 0.1421 - val_accuracy: 0.9752\n",
      "Epoch 450/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9742 - val_loss: 0.1391 - val_accuracy: 0.9725\n",
      "Epoch 451/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.1617 - val_accuracy: 0.9663\n",
      "Epoch 452/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9749 - val_loss: 0.1390 - val_accuracy: 0.9752\n",
      "Epoch 453/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9761 - val_loss: 0.1512 - val_accuracy: 0.9743\n",
      "Epoch 454/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9734 - val_loss: 0.1390 - val_accuracy: 0.9805\n",
      "Epoch 455/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.1383 - val_accuracy: 0.9796\n",
      "Epoch 456/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9768 - val_loss: 0.1840 - val_accuracy: 0.9512\n",
      "Epoch 457/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9749 - val_loss: 0.1383 - val_accuracy: 0.9752\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9708 - val_loss: 0.1547 - val_accuracy: 0.9725\n",
      "Epoch 459/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9734 - val_loss: 0.1882 - val_accuracy: 0.9495\n",
      "Epoch 460/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.1397 - val_accuracy: 0.9734\n",
      "Epoch 461/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9757 - val_loss: 0.1617 - val_accuracy: 0.9645\n",
      "Epoch 462/500\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9772 - val_loss: 0.1464 - val_accuracy: 0.9707\n",
      "Epoch 463/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9749 - val_loss: 0.1382 - val_accuracy: 0.9805\n",
      "Epoch 464/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9753 - val_loss: 0.1494 - val_accuracy: 0.9725\n",
      "Epoch 465/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9734 - val_loss: 0.1638 - val_accuracy: 0.9663\n",
      "Epoch 466/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9749 - val_loss: 0.1361 - val_accuracy: 0.9805\n",
      "Epoch 467/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.1677 - val_accuracy: 0.9645\n",
      "Epoch 468/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9727 - val_loss: 0.1718 - val_accuracy: 0.9583\n",
      "Epoch 469/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9768 - val_loss: 0.1456 - val_accuracy: 0.9725\n",
      "Epoch 470/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9765 - val_loss: 0.1433 - val_accuracy: 0.9743\n",
      "Epoch 471/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9761 - val_loss: 0.1928 - val_accuracy: 0.9504\n",
      "Epoch 472/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9727 - val_loss: 0.1506 - val_accuracy: 0.9725\n",
      "Epoch 473/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9742 - val_loss: 0.1404 - val_accuracy: 0.9778\n",
      "Epoch 474/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9742 - val_loss: 0.1435 - val_accuracy: 0.9796\n",
      "Epoch 475/500\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9723 - val_loss: 0.1407 - val_accuracy: 0.9805\n",
      "Epoch 476/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9738 - val_loss: 0.1493 - val_accuracy: 0.9716\n",
      "Epoch 477/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9753 - val_loss: 0.1651 - val_accuracy: 0.9645\n",
      "Epoch 478/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9711 - val_loss: 0.1376 - val_accuracy: 0.9787\n",
      "Epoch 479/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9772 - val_loss: 0.1337 - val_accuracy: 0.9796\n",
      "Epoch 480/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9768 - val_loss: 0.1373 - val_accuracy: 0.9796\n",
      "Epoch 481/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9776 - val_loss: 0.1472 - val_accuracy: 0.9778\n",
      "Epoch 482/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9787 - val_loss: 0.1582 - val_accuracy: 0.9690\n",
      "Epoch 483/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9742 - val_loss: 0.1557 - val_accuracy: 0.9716\n",
      "Epoch 484/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9749 - val_loss: 0.1459 - val_accuracy: 0.9743\n",
      "Epoch 485/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9715 - val_loss: 0.1379 - val_accuracy: 0.9787\n",
      "Epoch 486/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9749 - val_loss: 0.1342 - val_accuracy: 0.9778\n",
      "Epoch 487/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9761 - val_loss: 0.1405 - val_accuracy: 0.9796\n",
      "Epoch 488/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9749 - val_loss: 0.1898 - val_accuracy: 0.9512\n",
      "Epoch 489/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9746 - val_loss: 0.1393 - val_accuracy: 0.9770\n",
      "Epoch 490/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9749 - val_loss: 0.1808 - val_accuracy: 0.9557\n",
      "Epoch 491/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9738 - val_loss: 0.1375 - val_accuracy: 0.9787\n",
      "Epoch 492/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9746 - val_loss: 0.1343 - val_accuracy: 0.9778\n",
      "Epoch 493/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9734 - val_loss: 0.1611 - val_accuracy: 0.9681\n",
      "Epoch 494/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9738 - val_loss: 0.1362 - val_accuracy: 0.9761\n",
      "Epoch 495/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9719 - val_loss: 0.1476 - val_accuracy: 0.9707\n",
      "Epoch 496/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9738 - val_loss: 0.1395 - val_accuracy: 0.9787\n",
      "Epoch 497/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9742 - val_loss: 0.1400 - val_accuracy: 0.9770\n",
      "Epoch 498/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9742 - val_loss: 0.1390 - val_accuracy: 0.9805\n",
      "Epoch 499/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9746 - val_loss: 0.1477 - val_accuracy: 0.9743\n",
      "Epoch 500/500\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9742 - val_loss: 0.1769 - val_accuracy: 0.9610\n",
      "{'verbose': 1, 'epochs': 500, 'steps': 83}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#build model for Training\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation = 'sigmoid'))\n",
    "\n",
    "#compile and fit the model with 500 epochs\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('N1check.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max', verbose = 1)\n",
    "\n",
    "# Do the training (specify the validation set as well)\n",
    "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 500)\n",
    "\n",
    "# Check what's in the history\n",
    "print(history.params)\n",
    "\n",
    "# Plot the learning curves (loss/accuracy/MAE)\n",
    "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
    "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24169c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9586\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a99a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(XVALID, YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2321c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "83/83 [==============================] - 0s 3ms/step\n",
      "[[ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YTRAIN[:5])\n",
    "predictions = model.predict(XTRAIN)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b802164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972997299729973\n",
      "0.9126853377265239\n",
      "0.9531182795698925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(YTRAIN, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YTRAIN, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YTRAIN,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87d629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 1.0]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "[[ 0.0]\n",
      " [ 1.0]\n",
      " [ 0.9]\n",
      " [ 0.0]\n",
      " [ 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(YVALID[:5])\n",
    "predictions = model.predict(XVALID)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e48e092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9953379953379954\n",
      "0.9104477611940298\n",
      "0.9510022271714922\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(YVALID, predictions.round())\n",
    "print(precision)\n",
    "recall = recall_score(YVALID, predictions.round())\n",
    "print(recall)\n",
    "f1 = f1_score(YVALID,predictions.round())\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af8399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
